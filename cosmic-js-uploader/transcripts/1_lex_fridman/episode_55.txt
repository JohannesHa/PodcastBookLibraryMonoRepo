00:00:00
The following is a conversation with Whitney Cummings. She's a stand up comedian, actor, producer, writer, director, and recently finally the host of her very own podcast called Good for You. Her most recent Netflix special called Can I Touch It? Features in part a robot she affectionately named Bear Claw, but it's designed to be visually a replica of Whitney. It's exciting for me to see one of my favorite comedians explore the social aspects of robotics and AI in our society.
00:00:30
She also has some fascinating ideas about human behavior, psychology and neurology, some of which she explores in her book called Find and Other Lies. There's truly a pleasure to meet Whitney and have this conversation with her and even to continue to text afterwards. Every once in a while, late at night, I'll be programming over a cup of coffee and we'll get a text from Whitney saying something hilarious or weird or yet sending a video of Brian Cowan saying something hilarious.
00:01:00
That's what I know. The universe has a sense of humor, and it gifted me with one hell of an amazing journey. Then I put the phone down, go back to programming with a stupid, joyful smile on my face. Enjoy this conversation. Listen to it in his podcast. Good for you. And follow her on Twitter and Instagram. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube. Good. Five stars, an Apple podcast, support on Patr√≥n or simply connect with me on Twitter.
00:01:30
Allex Friedman spelled F.R. Idi Amin, the shows presented by Kashyap, the number one finance app in the App Store. They regularly support What Is Good For You podcast as well. I personally used cash to send money to friends, but you can also use it to buy, sell, deposit bitcoin in just seconds. Kashyap also has a new investing feature. You can buy fractions of a stock, say, one dollars worth no matter what the stock price is.
00:01:55
Brokerage services are provided by Cash Happy Investing subsidiary of Square. Remember SIPC? I'm excited to be working with cash to support one of my favorite organizations called the first best known for their first robotics and Lego competitions. They educate and inspire hundreds of thousands of students and over one hundred and ten countries and have a perfect rating. And Charity Navigator, which means that donating money is used to maximum effectiveness. When you get cash from the App Store or Google Play and use Code Lux podcast, you get ten dollars and cash up will also donate ten dollars.
00:02:31
The first, which again is an organization that person is seen, inspire girls and boys to dream of engineering a better world. This podcast is supported by ZIP recruiter hiring great people, it's hard and to me is the most important element of a successful mission driven team. I've been fortunate to be a part of and to lead several great engineering teams. The hiring I've done in the past was mostly the tools that we built ourselves. But reinventing the wheel was painful.
00:03:02
The recruiters, a tool that's readily available for you. It seeks to make hiring simple, fast and smart. For example, Kerbel co-founder Gretchen Hebner uses a preschooler to find a new game artist to join her education tech company by using zip recruiters screening questions to filter candidates. Gretchen found it easier to focus on the best candidates and finally, hiring the perfect person for the role in less than two weeks from start to finish. The recruiter, the smartest way to hire seaways, recruiters effective for businesses of all sizes by signing up as I did for free as a recruiter.
00:03:39
Dotcom Lex Pod. That's recruiter dotcom neglects pod. And now here's my conversation with Whitney Cummings. I have trouble making eye contact, as you can tell me to do, you know that I had to work on making eye contact because I used to look here to see what do you want me to do that I'll do this way?
00:04:19
I'll cheat the camera. But I used to do this. And finally, people like I'd be on dates and guys would be like, are you looking at my hair? Like they get it would make people really insecure because I didn't really get a lot of eye contact as a kid. It's one to three years. Did you not get a lot of eye contact as a kid?
00:04:33
I don't know. I haven't done the soul searching. Right. So I but there's definitely some psychological issue.
00:04:41
Makes you uncomfortable. Yeah, for some reason I, I connect. I start to think I assume that you're judging me. Oh well I am.
00:04:50
That's why you say that. Yeah, we all are. All right. For the to be me and you both stare.
00:04:59
Do you think robots are the future ones with human level intelligence will be female, male, genderless or another gender we have not yet created as a society?
00:05:10
You're the expert at this. Well, I'm going to ask you the answer. I'm going to ask you questions that maybe nobody knows the answer to or or and I just want you to hypothesize this as an imaginative author, director, comedian.
00:05:27
And can we just be very clear that you know a ton about this and I know nothing about this, but I have thought a lot about. Yes. What I think robots can fix in our society.
00:05:39
And I mean, I'm a comedian. It's my job to study human nature, to make jokes about human nature and to sometimes play devil's advocate. And I just see such a tremendous negativity around robots, or at least the idea of robots that it was like, oh, I'm just going to take the opposite side for fun, for jokes. And then I was like, oh, no, I really agree. And the devil's advocate argument. So please correct me when I'm wrong about this stuff.
00:06:06
So first of all, there's there's no right and wrong because we're all I think most of the people working on robotics are really not actually even thinking about some of the big picture things that you've been exploring. In fact, your robot, what's your name, by the way? We're going bearclaw.
00:06:23
That was the genesis nearby.
00:06:28
Bear Claw was I got I don't even remember the joke because I blacked out after I shoot specials. But I was writing something about like the pet names that men call women like Cupcake, sweetie, honey, like we're always named after desserts or something. And I was just writing a joke about, if you want to call it a dessert, at least pick like a cool dessert, you know, like bear claw, like something cool.
00:06:52
So I ended up calling her being stuck.
00:06:55
So do you think future robots of greater and greater intelligence will like to make them female, male?
00:07:03
Would we like to assign them gender or would we'd like to move away from gender and say something more ambiguous?
00:07:10
I think it depends on their purpose. You know, I feel like if it's a sex robot, it people prefer certain genders, you know? And I also know when I went down and explored the robot factory, I was asking about the type of people that bought sex robots. And I was very surprised at the answer because, of course, the stereotype was going to be a bunch of perverts. It ended up being a lot of people that were handicapped, a lot of people with erectile dysfunction and a lot of people that were exploring their sexuality.
00:07:40
A lot of people that were thought they were gay but weren't sure, but didn't want to take the risk of trying on someone that could reject them and being embarrassed or they were closeted or in a city where maybe that's taboo and stigmatized, you know. So I think that a gendered sex robot that would serve an important purpose for someone trying to explore their sexuality. Am I into man, let me try on this thing first. The women let me try on this thing first.
00:08:05
So I think gendered robots would be important for that. But I think genderless robots in terms of emotional support, robots, baby sitters, I'm fine for a genderless babysitter with my husband in the house.
00:08:16
You know, there are places that I think that genderless makes a lot of sense, but obviously not in the sex area.
00:08:24
What do you mean with your husband in the house? Was that have to do with the gender of the robot?
00:08:28
Right. I mean, I don't have a husband, but hypothetically speaking, I think every woman's worst nightmare is like the hot babysitter, you know?
00:08:36
So I think that there is a time and place, I think, for genderless, you know, teachers, doctors, all that. It would be very awkward if the first robotic doctor was a guy or the first robotic nurse is a woman. You know, it's sort of that stuff is so loaded, I think that generalists could just take the unnecessary.
00:08:58
Drama out of it and possibility to sexualize them or be triggered by any of that stuff.
00:09:06
So there's two components to this, to bearclaw. So one is the voice and the talking, so on. And then there's the visual appearance. So on the topic of gender in general, is in your experience, what has been the value of the physical appearance? So has it added much to the depth of the interaction?
00:09:25
I mean, mine's kind of an extenuating circumstances because she is supposed to look exactly like me. I mean, I spent six months getting my face molded and having you know, the idea was I was exploring the concept of can robots replace us? Because that's the big fear, but also the big dream in a lot of ways. And I wanted to dig into that area because, you know, for a lot of people, it's like they're going to take our jobs and replace us.
00:09:48
Legitimate fear. But then a lot of women I know are like, I would love for a robot to replace me every now and then so I can go to baby showers for me and it can pick up my kids at school and I can cook dinner and whatever. So I just think that was an interesting place to explore. So her looking like me was a big part of it. Now her looking like me just adds an unnecessary level of insecurity because I got out a year ago and she already looks younger than me.
00:10:11
So that's a weird problem. But I think that her looking human was the idea.
00:10:17
And I think that where we are now, please correct me if I'm wrong, a human robot resembling an actual human, you know, is going to feel more realistic than some generic face.
00:10:30
Well, you're saying that that robots that have some familiarity, like look similar to somebody that you actually know, you be able to form a deeper connection with those questions.
00:10:42
On some level, that's an open question.
00:10:43
I don't I don't you know, it's an interesting or the opposite then, you know me and you're like, well, I know this isn't real because you're right here. Maybe it does the opposite.
00:10:52
We have a very keen eye for human faces and they're able to detect strangeness, especially that that one has to do with people with whose faces we've seen a lot of.
00:11:03
So I tend to be a bigger fan of moving away completely from faces of recognizable faces, not just human faces at all in general, because I think that's where things get dicey.
00:11:15
And one thing I will say is I think my robot is more realistic than other robots, not necessarily because you have seen me and then you see her and you go, oh, they're so similar, but also because human faces are flawed and asymmetrical. And sometimes we forget when we're making things that are supposed to look human, we make them too symmetrical and that's what makes them stop looking human. So because they molded my symmetrical face, you just even if someone didn't know who I was, I think she'd look more realistic than most generic ones that didn't have some kind of flaws because they start looking creepy when they're too symmetrical because human beings aren't.
00:11:50
Yeah, the flaws is what it means to be human. So visually as well. But I'm just a fan of the idea of of letting humans use a little bit more imagination.
00:12:00
So just hearing the voice is enough for us humans to then start imagining the visual appearance that goes along with that voice. And you don't necessarily need to work too hard on creating the actual visual appearance. So there's some value to that. When you step into the stereotype of actually building a robot that looks like because such a long road of facial expressions of sort of making everything smiling, winking, rolling the eyes, all that kind of stuff, it gets really, really tricky.
00:12:33
It gets tricky. And I think I'm again, I'm a comedian. Like, I'm obsessed with what makes us human. And our human nature in the nasty side of human nature tends to be where I've ended up exploring over and over again. And I was just mostly fascinated by people's reaction. So it's my job to get the biggest reaction from a group of strangers, the loudest possible reaction. And I just had this instinct just when I started building her and people going up and screaming and people screaming.
00:13:01
I mean, I bring her out on stage and people would scream. And I just to me, that was the next level of entertainment, getting a laugh. I've done that. I know how to do that. I think comedians were always trying to figure out what the next level is and comedy's evolving so much. And, you know, Jordan Peele had just done these genius comedy horror movies, which feel like the next level of comedy to me and this sort of funny horror of a robot was fascinating to me.
00:13:28
But I think the thing that I got the most obsessed with was people being freaked out and scared of her. And I started digging around with pathogen avoidance and the idea that we've essentially evolved to be repelled by anything that looks human but is off a little bit, anything that could be sick or diseased or dead, essentially as our reptilian brains way to get us to not try to have sex with it, basically, you know, so I got really fascinated by how for.
00:13:58
And scared, I mean, I would see grown men get upset to get that thing away from me. I don't like it when people get angry.
00:14:04
And it was like, you know what this is, you know, but the sort of like, you know, amygdala getting activated by something that to me is just a fun toy, said a lot about our history as a species and what got us into trouble thousands of years ago.
00:14:21
So that is the deep down stuff that's in our genetics. But also, is it just are people freaked out by the fact that there's a robot? So it's not just the appearance, but there's an artificial human anything people, I think and I'm just I'm also fascinated by the blindspots humans have.
00:14:39
So the idea that you're afraid of that, I mean, how many robots have killed people? How many humans have died at the hands of other humans? Yeah, millions more.
00:14:48
Hundreds of millions. Yet we're scared of that.
00:14:51
And we'll go to the grocery store and be around a bunch of humans who statistically the chances are much higher that you're going to get killed by humans.
00:14:57
So I'm just fascinated by without judgment how irrational we are as a species.
00:15:04
The war is exponential. So it's you know, you can say the same thing about nuclear weapons before we dropped on Hiroshima and Nagasaki. So the worry that people have is the exponential growth.
00:15:16
So so it's like, oh, it's fun and games right now.
00:15:20
But, you know, overnight, especially if a robot provides value to society, will put one in every home and then all of a sudden lose track of the actual large scale impact it has on society and then also to gain greater and greater control to where it will all be, you know, affect our political system and then affect our decision.
00:15:42
Robots already ruined our political system, did not just already happen. Which ones? Russia hacking. No offense, but hasn't that already happened?
00:15:51
I mean, that was like an algorithm of negative things being clicked on more.
00:15:56
We'd like to tell stories and like to demonize certain people. I think nobody understands our current political system or discourse on Twitter, the Twitter mobs. Nobody has a sense, not Twitter, not Facebook, the people running it. Nobody understands the impact of these algorithms. They're trying their best despite what people think. They're not like a bunch of lefties trying to make sure that Hillary Clinton gets elected. It's more that it's an incredibly complex system that we don't.
00:16:24
And that's the worry. It's so complex and moves so fast that nobody will be able to stop it once it happens.
00:16:32
And let me ask a question. This is a very savage question. Yeah. Which is, is this just the next stage of evolution as humans and people will die? Yes. I mean, that's always happens. You know, is this is just taking emotion out of it. Is this basically the next stage of survival of the fittest?
00:16:51
Yeah, you have to think of organisms, you know, what is it mean to be a living organism, I guess a smartphone, part of your living organism or.
00:17:03
We're we're in relationships with our phones. Yeah, but have sex through them with them. What's the difference? Being with them and through them.
00:17:11
But it also expands your cognitive abilities, expands your memory, knowledge and so on. So you're much smarter person because you have a smartphone in your hand.
00:17:19
But if when as soon as it's out of my hands, we've got big problems because we've become sort of so morphed with them with a symbiotic relationship.
00:17:26
And that's what. So you must the neural link is working on trying to. Increase the bandwidth communication between computers and your brain and so further and further expand our ability as human beings to sort of leverage machines, and maybe that's the future, the evolution in next evolutionary step. It could be also that, yes, we'll give birth just like we give birth to human children right now to give birth in other places. I think it's a really interesting possibility.
00:17:59
I'm going to play devil's advocate. I just think that the fear of robots is wildly classist because, I mean, Facebook, like it's easy for us to say they're taking their data. OK, a lot of people that get employment off of Facebook, they are able to get income off of Facebook. They don't care if you take their phone numbers and their emails and their data as long as it's free. They don't want to have to pay five dollars a month for Facebook.
00:18:20
Facebook is a wildly Democratic thing. Forget about the election and all that kind of stuff. You know, a lot of, you know, technology making people's lives easier. I find that most elite people are more scared than lower income people. So and women for the most part. So the idea of something that's stronger than us that might eventually kill us like women are used to that. Like that's not a lot of like really rich men being like the robots are going to kill us.
00:18:48
We're like, what's another thing that's going to kill us?
00:18:49
You know, I tend to see like, oh, something and walk me to my car at night, like something can help me cook dinner or something for, you know, people in underprivileged countries who can't afford eye surgery like a robot.
00:19:02
Can we send a robot to underprivileged, you know, places to do surgery or if they can, I work with this organization called Operation Smile where they do cleft palate surgeries. And there's a lot of places that can't do a very simple surgery because they can't afford doctors and medical care and such. So I just see and this can be completely naive and should be completely wrong, but I feel like we're a lot of people are going like the robots are going to destroy us humans.
00:19:27
We're destroying ourselves. We're self destructing. Robots, to me, are the only hope to clean up all the mess that we've created. Even when we go try to clean up pollution in the ocean, we make it worse because of the oil that the tankers like.
00:19:38
It's like to me, robots are the only solution. You know, firefighters are heroes, but they're limited in how many times they can run into a fire, you know. So there's just something interesting to me.
00:19:49
I'm not hearing a lot of like lower income, more vulnerable populations talking about robots.
00:19:56
Maybe you can speak to it a little bit more.
00:19:58
This is an idea I think you've expressed that I've heard actually a few female writers and roboticists I've talked to expressed this idea that you just said, which is it just seems that being afraid of existential threats, of artificial intelligence is is a male issue.
00:20:23
Yeah. And I wonder what that is. If it because because men have in certain positions, like you said, it's also classicists issue. They haven't been humbled by life. And so you always look for the biggest problems to take on around you.
00:20:39
It's a champagne problem to be afraid of robots. Most people don't have health insurance. They're afraid they're not able to feed their kids. They can't afford a tutor for their kids. I mean, I just think of the way I grew up and I had a mother who worked two jobs, had kids we couldn't afford an essay to tutor, you know, like the idea of a robot coming in, being able to tutor your kids, being able to provide child care for your kids, you know, being able to come in with cameras for eyes and make sure, you know, surveillance.
00:21:04
You know, I'm very pro surveillance because I've had security problems and I've been you know, we're generally in a little more danger than you guys are.
00:21:13
So I think that robots are a little less scary to us because we can see that maybe as like free assistance, help and protection. And then there's sort of another element for me personally, which is maybe more of a female problem.
00:21:25
I don't know. I'm just going to make a generalization.
00:21:27
I'm happy to be wrong.
00:21:29
But, you know, the emotional sort of component of robots and what they can provide in terms of, you know, there I think there's a lot of people that aren't don't have microphones that I just recently kind of stumbled upon in doing all my research on the sex robots for my standup special, which is there's a lot of very shy people that aren't good at dating. There's a lot of people who are scared of human beings who, you know, have personality disorders or grew up in alcoholic homes or struggle with addiction or whatever it is where a robot can solve an emotional problem.
00:22:03
And so we're largely having this conversation about like rich guys that are emotionally healthy and how scared of robots are.
00:22:12
We're getting about like a huge part of the population who maybe isn't as charming and effervescent and solvent as, you know, people like you and Elon Musk, who these robots could solve very real problems in their life, emotional or financial, whether it's in general a really interesting idea that most people.
00:22:31
On the world don't have a voice, it's you've talked about it sort of even the people on Twitter who are driving the conversation, you said comments, people who leave comments represent a very tiny percent of the population.
00:22:45
And they're the ones they you know, we tend to think they speak for the population, but it's very possible. Many topics they don't at all.
00:22:54
And look, I and I'm sure there's got to be some kind of legal, you know, sort of structure in place for when the robots happen. You know way more about this than I do. But, you know, for me to just go, the robots are bad. That's a wild generalization that I feel like is really inhumane in some way. You know, just after the research I've done, like you're going to tell me that a man whose wife died suddenly and he feels guilty moving on with a human woman or can't get over the grief.
00:23:21
You can't have a sex robot in his own house. Why not? Who cares? Why do you care?
00:23:26
Well, there's an interesting aspect of human nature. So, you know, we tend to as a as a civilization to create a group that's the other in all kinds of ways.
00:23:36
Right. And so you work with animals to you're especially sensitive to the suffering of animals. Let me kind of ask, what's your do you think we'll abuse robots in the future?
00:23:51
Do you think some of the darker aspects of human nature will come out?
00:23:54
I think some people will. But if we design them properly, the people that do it, we can put it on a record and they can, but we can put them in jail.
00:24:03
We can find sociopaths more easily, you know, like. But why is that?
00:24:07
Why is that a sociopathic thing to harm a robot? I think look, I don't know enough enough about the consciousness and stuff as you do. I guess it would have to be on their conscious. But it is, you know, the part of the brain that is responsible for compassion, the frontal lobe or whatever, like people that abuse animals also abuse humans and commit other kinds of crimes like that. It's all the same part of the brain. No one abuses animals and then is like awesome to women and children and awesome to underprivileged, you know, minorities like it's all so, you know, we've been working really hard to put a database together of all the people that have abused animals.
00:24:41
So when they commit another crime, you go, OK, this is you know, it's all the same stuff. And I think people probably think I'm nuts for the a lot of the animal work I do.
00:24:51
But because when animal abuse is present, another crime is always present, but the animal abuse is the most socially acceptable. You can kick a dog and there's nothing people can do. But then what they're doing behind closed doors, you can't see.
00:25:04
So there's always something else going on, which is why I never feel compunction about it. But I do think we'll start seeing the same thing with robots. Um, the person that kicks the I felt compassion when the kicking the dog robot really pissed me off.
00:25:18
I know that they're just trying to get the stability right and all that.
00:25:22
But I do think there will come a time where that will be a great way to be able to figure out if somebody is has like, you know, antisocial behaviors.
00:25:32
You kind of mentioned surveillance. Mm hmm. It's also a really interesting idea of yours that you just said, you know, a lot of people seem to be really uncomfortable with surveillance. Yeah. And you just said that, you know what? For me, you know, there's positives for surveillance.
00:25:47
I think people behave better when they know they're being watched. And I know this is a very unpopular opinion. I'm talking about it on stage right now.
00:25:54
We behave better when we know we're being watched. You and I had a very different conversation before we were recording.
00:26:01
If we behave different, you sit up on your best behavior trying to sound eloquent. And I'm trying to not hurt anyone's feelings.
00:26:08
And I mean, I have a camera right there. I'm behaving totally different than when we first started talking.
00:26:13
You know, when you know, there's a camera, you behave differently. I mean, there's cameras all over L.A. at stoplights. So the people don't run stoplights, but there's not even film in it.
00:26:22
They don't even use them anymore. But it works. It works. Right. And I'm working on this thing instead about surveillance. It's like that's why we invented Santa Claus. You know, it's the Santa Claus is the first surveillance. Basically, all we had to say to kids is he's making a list and he's watching you and they behave better as brilliant, you know? So I do I do think that there are benefits to surveillance. You know, I think we all do sketchy things in private.
00:26:47
And we all watched weird porn or Googled weird things. And we don't we don't want people to know about it, the our secret lives. So I do think that obviously there's we should be able to have a modicum of privacy. But I tend to think that people that are the most negative about surveillance of the most the most like.
00:27:07
Well, you should is you you're saying you're doing bits on it.
00:27:10
No, well, I'm just talking in general about privacy and surveillance and how paranoid we're kind of becoming and how, you know, I mean, it's just wild to me that people are like our emails are going to leak and they're taking our phone numbers like they're there used to be a book full of phone numbers and addresses that were they just throw it at your door.
00:27:32
And we all had a book of everyone's numbers. This is a very new thing and, you know, I know our amygdalas is designed to compound sort of threats. And, you know, there's stories about and I think we all just glom on in a very, you know, tribal way of taking our data like we don't even know that means.
00:27:50
But we're like, well, they they you know, so I just think that sometimes, like, OK, well, so what? They're going to sell your data. Who cares? Why do you care?
00:28:00
First of all, that bit will kill in China. So and I see it as sort of only a little bit joking because a lot of people in China, including the citizens, despite what people in the West think of as abuse, are actually in support of the idea of surveillance, sort of they're not in support of the abuse of surveillance, but they're they like I mean, the idea of surveillance is kind of like. The idea of government, like you said, would behave differently in a way, it's almost like why we like sports, there's rules and within the constraints of the rules, this is a more stable society.
00:28:41
And they make good arguments about success, being able to build successful companies, being able to build successful socializing on the fabric that's more stable when you have a surveillance that keeps the criminals away, keeps abuse of animals, whatever the values of the society with surveillance, you can enforce those values better.
00:29:01
And here's what I will say. There's a lot of unethical things happening with surveillance like this. I feel the need to really make that very clear. I mean, the fact that Google is like collecting off people's hands, start moving on the mouse to find out if they're getting Parkinson's and then their insurance goes up like that is completely unethical and wrong. And I think stuff like that we have to really be careful around. So the idea of using our data to raise our insurance rates or, you know, I heard that they're looking they can sort of predict if you're going to have depression based on yourself face by detecting micro muscles in your face, you know, all that kind of stuff.
00:29:35
That is a nightmare. Not OK. But I think, you know, we have to delineate what's a real threat and what's getting spam in your email box. That's that's not what to spend your time and energy on, focused on the fact that every time you buy cigarettes, your insurance is going up without you knowing about it on the topic of animals.
00:29:53
So can we just linger on a little bit like what do you think?
00:29:58
What does it say about our society of the society where abuse of animals that we see in general sort of factory farming is just in general just the way we treat animals of different categories? Like what? What do you think of that? What is a better world look like? What's what should people think about it in general?
00:30:20
I think I think the most interesting thing I can probably say around this that the least emotional, because I'm actually very non emotional animal person, because it's I think everyone's an animal person. It's just a matter of if it's yours or if you've been conditioned to go numb.
00:30:35
You know, I think it's really a testament to what as a species we are able to be in denial about mass denial and mass delusion and how we're able to dehumanize and debase groups, you know, where we're too, in a way, in order to conform and find protection and the conforming.
00:30:55
So we are also a species who used to go to coliseums and watch elephants and tigers fight to the death.
00:31:04
We used to watch human beings be pulled apart and there wasn't that long ago.
00:31:09
We're also species who had slaves and it was socially acceptable by a lot of people, didn't see anything wrong with it. So we're a species that is able to go numb and that is able to dehumanize very quickly and make it the norm.
00:31:24
Child labor wasn't that long ago.
00:31:27
The idea that now we look back and go, oh, yeah, kids, we're losing fingers in factories, making shoes like someone had to come in and make that. So I think it just says a lot about the fact that we are animals and we are self serving and one of the most successful, the most successful species because we are able to debase and degrade and essentially exploit anything that benefits us.
00:31:53
I think the pendulum is going to swing as being like I think we're Roehm now, kind of like I think we're on the verge of collapse because we are dopamine receptors. Like we are just I think we're all kind of addicts when it comes to this stuff. Like we don't know when to stop. It's always the buffet. Like we're the thing that used to keep us alive, which is killing animals and eating them now, killing animals and eating them is what's killing us in a way.
00:32:18
So it's like we just can't we don't know when to call it and we don't. Moderation is not really something that humans have evolved to have yet. So I think it's really just a flaw in our wiring.
00:32:30
Do you think we'll look back at this time as a our society is being deeply unethical?
00:32:36
Yeah. Yeah, I think we'll be embarrassed. Which are the worst parts right now going on? Is it is an animal?
00:32:43
Well, I think in terms of anything, what's the unethical thing is it is very hard to take a step out of it. But you just said we used to watch.
00:32:52
You know, there's been a lot of cruelty throughout history. What's the cruel thing going on?
00:32:59
It's going to be pigs. I think it's going to be. I mean, pigs are one of the most emotionally intelligent animals and they have the intelligence of like a three year old. And I think we'll look back and be really they use tools. I mean, they're I think we have this narrative that they're pigs and they're pigs and they're they're disgusting and they're dirty and they're bacon. And so I think that we'll look back one day and be really embarrassed about that.
00:33:23
Is this for just the what's it called factory farming. So basically mess because we don't see it.
00:33:29
If you saw I mean, we do have I mean, this is probably an evolutionary advantage. We do have the ability to completely pretend something's not something that is so horrific that it overwhelms us. And we are able to essentially deny that it's happening.
00:33:44
I think if people were to see what goes on in factory farming and elsewhere, really to take in how bad it is for us, you know, we're hurting ourselves first and foremost with what we eat.
00:33:55
But that's also a very elitist argument. You know, it's a luxury to be able to complain about meat. It's a luxury to be able to not eat meat. You know, there's very few people because of, you know, how the corporations have set up meat being cheap. You know, it's two dollars to buy a Big Mac. It's ten dollars to buy a healthy meal. You know, that's I think a lot of people don't have the luxury to even think that way.
00:34:19
But I do think that animals in captivity, I think we're going to look back and be pretty grossed out about mammals in captivity, whales, dolphins. I mean, that's already starting to dismantle circuses we're going to be pretty embarrassed about. But I think it's really more testament to, you know, there's just such a ability to go like that thing is different than me and we're better. It's the ego. I mean, it's just we have the species with the biggest ego ultimately.
00:34:46
Well, that's what I think. That's my hope for robots, as though you mentioned consciousness before.
00:34:51
Nobody knows what consciousness is, but I'm hoping robots will help us empathize and understand that.
00:35:01
That there's other creatures out besides ourselves that can suffer, that can they can experience the world and that we can torture by our actions and robots can explicitly teach us that, I think, better than animals can.
00:35:18
I have never seen such compassion from a lot of people in my life.
00:35:27
Toward any human animal child, as I have a lot of people in the way they interact with the robot, because there's I think there's something of I I mean, I was on the robot owners chat boards for a good eight months.
00:35:42
And the main emotional benefit is she's never going to cheat on you. She's never going to hurt you. She's never going to lie to you. She doesn't judge you. You know, I think that robots help people.
00:35:55
And this is part of the work I do in animals like I do equine therapy and train dogs and stuff, because there is this safe space to be authentic with this being that doesn't care what you do for a living, doesn't care how much money you have, doesn't care who you're dating, doesn't care what you look like, doesn't care if you have cellulite, whatever, you feel safe to be able to truly be present without being defensive and worrying about eye contact and being triggered by, you know, needing to be perfect and fear of judgment and all that.
00:36:21
And robots really can't judge you yet, but they can't judge you. And I think it really puts people at their at ease and at their most authentic.
00:36:33
Do you think you can have a deep connection with the robot that's not judging or you think you can really have a relationship with a robot or a human being that's a safe space?
00:36:46
Or is a tension mystery danger necessary for deep connection?
00:36:52
I'm going to speak for myself and say that I grew up and now call come identify as a co-dependent, talks about this stuff before.
00:37:00
But for me, it's very hard to be in a relationship with a human being without feeling like I need to perform in some way or deliver in some way. And I don't know if that's just the people I've been in a relationship with or or me or my brokenness.
00:37:13
But I do think this is going to sound really negative and pessimistic.
00:37:21
But I do think a lot of our relationships are projection and a lot of our relationships are performance. And I don't think I really understood that until I worked with horses. And most indications human is nonverbal. Right? I can say like I love you, but you don't think I love you. Right. Which is with animals. It's very direct. It's all physical. It's all energy. I feel like that with robots, too. It feels very.
00:37:49
What how I say something doesn't matter, my inflection doesn't really matter, and you thinking that my tone is disrespectful, like you're not filtering it through all of the bad relationships you've been in, you're not filtering it through the way your mom talked to you. You're not getting triggered. You know, I find that for the most part, people don't always receive things the way that you intend them to or the way you intended. And that makes relationships really murky.
00:38:12
So the relationships with animals, relationship with the robots as they are now. You kind of imply that that's more healthy, can you have a healthy relationship with other humans or not healthy and don't like that word, but shouldn't it be? You've talked about co-dependency.
00:38:31
Maybe you can talk about what is co-dependency, but is that is the the challenges of that the complexity of that necessary for passion, for for love between humans? You love passion.
00:38:47
That's a good thing. I thought this would be a safe place. I got to go. Right. I got trolled by rogard hours on this.
00:38:56
I look, I am not anti passion. I think that I've just maybe been around long enough to know that sometimes it's ephemeral.
00:39:05
And that passion is a mixture of a lot of different things. Adrenaline, which turns into dopamine, cause it's a lot of neurochemicals. It's a lot of projection. It's a lot of what we've seen in movies. It's a lot of it's I identify as an addict. So for me, sometimes passion is like, oh, this could be bad. And I think we've been so conditioned to believe that passion means like your soul mates. And I mean, how many times have you had a passionate connection with someone?
00:39:32
And then it was a total train wreck.
00:39:35
A train wreck. How many times exactly what you're drinking? A lot of math in your head, a little moment counting.
00:39:43
I mean, what's a train wreck? What's why is obsession? So you described this co-dependency and sort of the idea of attachment. Over attachment to people who don't deserve that kind of attachment as somehow a bad thing. I think our society says it's a bad thing. It probably is a bad thing. Like a like a delicious burger is a bad thing. I don't know.
00:40:09
But right now, that's a good point. I think that you're pointing out something really fascinating, which is like passion. If you go into it knowing this is like pizza, where it's going to be delicious for two hours and then I don't have to have it again for if you can have a choice in the passion I define, passion is something that is relatively unmanageable and something you can't control or stop and start with your own volition.
00:40:30
So maybe we're operating under different definitions.
00:40:33
If passion is something that like, you know, ruins your marriages and screws up your professional life and becomes this thing that you're not in control of, it becomes addictive. I think that's the difference.
00:40:46
Is is it a choice or is it not a choice? And if it is a choice, then passion's great. But if it's something that, like consumes you and makes you start making bad decisions and clouds your frontal lobe and is just all about dopamine and not really about the person and more about the neurochemical, we call it sort of the drug, the internal drug cabinet.
00:41:07
If it's all just your on drugs, that's different because sometimes you're just on drugs.
00:41:11
OK, so this is a philosophical question here. So would you rather it's interesting for a comedian, brilliant comedian to speak so eloquently about a balanced life?
00:41:27
I kind of argue against this point. There's such an obsession of creating this healthy lifestyle now.
00:41:33
It's psychologically speaking, you know, I'm a fan of the idea that you sort of fly high and you crash and die.
00:41:40
Twenty seven is also a possible life. And it's not one you should judge because I think there's moments of greatness.
00:41:47
I talk to Olympic athletes who are some of the greatest moments are achieved in their early 20s, and the rest of their life is in the kind of fog of almost a depression because based on their physical prowess, physical prowess, and they'll never show that.
00:42:04
So they're watching the physical prowess fade and they'll never achieve the kind of height, not just physical of just emotion of the max number of neurochemicals.
00:42:18
Yeah.
00:42:18
And you also put your money on the wrong horse. That's where I would I would just go like, oh, yeah. If you're doing a job where you peak at twenty two. Yeah. The rest of your life is going to be that idea is considering the notion that you want to optimize some kind of. But we're all going to die soon.
00:42:36
What about now. You tell me I've got more to waterlines myself so I'm going to be fine.
00:42:43
See you're almost like how many Oscar winning movies can I direct by the time I'm one hundred? How many this like. But, you know, there's you know, it's all life is short, relatively speaking.
00:42:58
I know. But it can also come department you go life is short play hard fall in love as much as you can run into walls. I would also go life is short. Don't deplete yourself on things that aren't sustainable and that you can't keep. Yeah. You know, so I think everyone gets dopamine from different places. Everyone has meaning from different places. I look at the fleeting passionate relationships I've had in the past and I don't like I don't have pride in, though I think that you have to decide what you know helps you sleep at night.
00:43:28
For me, it's pride and feeling like I behave with grace and integrity. That's just me personally. Everyone can go like, yeah, I slept with all the hot chicks in Italy. I could and I did all the whatever whatever you value, we're allowed to value different.
00:43:43
We're talking about Brian calling.
00:43:46
Frank Allen has lived his life to the fullest, to say the least. But I think that it's just for me personally, I mean, this could be like my workaholism or my achievements is I if I don't have something to show for something, I feel like it's a waste of time or a some kind of loss. I'm in a 12 step program, and the third step would say there's no such thing as waste of time. And everything happens exactly as it should and whatever.
00:44:14
That's the way to just sort of keep us sane so we don't grieve too much and beat ourselves up over past mistakes. There's no such thing as mistakes that add up.
00:44:22
But I think passion is I think it's so life affirming and one of the few things that maybe people like us makes us feel awake and seeing, and we just have such a high threshold for adrenaline, you know.
00:44:37
I mean, you are a fighter, right? Yeah. OK, so yeah. So you have a very high tolerance for adrenaline. And I think that Olympic athletes, the amount of adrenaline they get from performing, it's very hard to follow that. It's like when guys come back from the military and they have to. It's like, do you miss bullets flying out, you kind of because of that adrenaline which turned into dopamine and the camaraderie, I mean, there's people that speak much better about this than I do.
00:45:05
But I just I'm obsessed with neurology and I'm just obsessed with sort of the lies we tell ourselves in order to justify getting neurochemicals.
00:45:14
You've done actually quite done a lot of thinking and talking about neurology and just kind of look at human behavior through the lens of looking at how are actually chemically or brain works.
00:45:26
So what first of all, why did you connect with that idea and what have you how is your view of the world changed by considering the brain?
00:45:37
That's just a machine.
00:45:39
You know, I know it probably sounds really nihilistic, but for me, it's very liberating to know a lot about neurochemicals because you don't have to. It's like the same thing with like like critics, like critical reviews. If you believe the good, you have to believe the bad kind of thing. Like, you know, if you believe that your bad choices were because of your moral integrity or whatever, you have to believe your good ones. I just think there's something really liberating and going like, oh, that was just adrenaline.
00:46:04
I just said that thing because I was adrenalized and I was scared and my amygdala was activated. And that's why I said, you're an asshole and get out. And that's, you know, I think I just think it's important to delineate what's nature and what's nurture, what is your choice and what is just your brain trying to keep you safe. I think we forget that even though we have security systems in homes and locks on our doors, that our brain for the most part is just trying to keep us safe all the time.
00:46:26
It's why we hold grudges. That's why we get angry. It's why we get road rage. That's why we do a lot of things. And it's also when I started learning about neurology, I started having so much more compassion for other people. You know, someone yelled at me being like, fuck you on the road.
00:46:39
I'd be like, OK, he's producing adrenaline right now because we're all going sixty five miles an hour and our brains aren't really designed for this type of stress. And he's scared.
00:46:50
He was. So that really helped me to have more love for people and my everyday life instead of being in fight or flight mode. But the I think more interesting answer to your question is that I've had migraines my whole life, like I've suffered with it, really intense migraines, ocular migraines, ones where my arm would go numb. And I just started going to go to so many doctors to learn about it.
00:47:13
And I started learning that we don't really know that much.
00:47:17
We know a lot. But it's wild to go into one of the best monologist in the world who's like, yeah, we don't know. We don't know. We don't know. And that fascinated me was one of the worst pains.
00:47:26
You can probably have all that stuff and you don't know the source. We don't know the source. And there is something really fascinating about when your left arm starts going numb and you start not being able to see out of the left side of both your eyes. And I remember when the migraines really bad.
00:47:42
It's like a mini stroke almost, and you're able to see words on a page, but I can't read them. They just look like symbols to me. So there's something just really fascinating to me about your brain just being able to stop functioning. And I so I just wanted to learn about it. Study about it. I did all these weird alternative treatments. I got this piercing in here that actually works. I've tried everything. And then both my parents had strokes.
00:48:06
So when both of my parents had strokes, I became sort of the person who had to decide what was going to happen with their recovery, which is just a wild thing to have to deal with it, you know. Twenty eight years old when it happened and I started spending basically all day every day and I see used with neurologists learning about what happened to my dad's brain and why he can't move his left arm, but he can move his right leg, but he can't see out of that, you know.
00:48:30
And then my mom had another stroke in a different part of the brain.
00:48:34
So I started having to learn what parts of the brain did what and so that I wouldn't take that behavior so personally and so that I would be able to manage my expectations in terms of their recovery.
00:48:44
So my mom, because it affected a lot of her frontal lobe, changed a lot as a person. She was way more emotional. She was way more micromanaged. She was forgetting certain things. So it broke my heart less when I was able to know. Oh, yeah, well, the stroke hit this part of the brain, and that's the one that's responsible for short term memory and that's responsible for long term memory. Set it up. And then my brother just got something called viral encephalitis, which is an infection inside the brain.
00:49:10
So it was kind of wild that I was able to go, oh, I know exactly what's happening here and I know, you know, so, um.
00:49:16
So that's allows you to have some more compassion for the struggles that people have. But does it take away some of the magic for some of the from the some of the more positive experiences of the times?
00:49:28
Sometimes. And I don't I don't I'm such a control addict that, you know, I think our biggest someone like me, my biggest dream is to know why someone's doing that's what standup is, is just trying to figure out why or that's what writing is. That's what acting is. That's what performing is, is try to figure out why someone would do something. As an actor, you get a piece of material and you go, this person. Why would he say that?
00:49:48
Why would he she pick up that cup? Why would she walk over here? It's really y why. Why, why? So I think neurology is if you're trying to figure out human motives and why people do what they do and be crazy not to understand how neurochemicals motivate us, I also have a lot of addiction in my family and hardcore drug addiction and mental illness. And in order to cope with that, you really have to understand that borderline personality disorder, schizophrenia and drug addiction.
00:50:15
So I have a lot of people I love that suffer from drug addiction, alcoholism. And the first thing they started teaching you is it's not a choice. These people's dopamine receptors don't hold dopamine the same way as yours do. Their frontal lobe is underdeveloped like, you know. And that really helped me to navigate dealing, loving people that were addicted to substances.
00:50:37
I want to be careful with this question, but how much money do you have?
00:50:42
How much can I borrow? OK. No is how much control, how much, despite the chemical imbalances or the biological limitations that each of our individual brains have, how much mind over matter is there?
00:51:03
So through things and I've known people with clinical depression.
00:51:09
And so it's it's always a touchy subject to say how much they can really help, but very. What can you.
00:51:17
Yeah. Well, what because you've talked about co-dependency, you talked about issues that you're struggled through and nevertheless you choose to take a journey of healing and so on. So that's your choice.
00:51:29
That's your actions. So how much can you do to help fight the limitations of the neurochemicals in your brain? That's such an interesting question.
00:51:38
I don't think I'm at all qualified to answer, but I'll say what I do know. And really quick, just the definition of co-dependency. I think a lot of people think of co-dependency as like to people that can't stop hanging out, you know, or like, you know, that's not totally off. But I think for the most part, my favorite definition of co-dependency is the inability to tolerate the discomfort of others. You grow up in an alcoholic home, you grow up around mental illness, you grow up in chaos.
00:52:03
You have a parent that the narcissist you basically are wired to just people. Please worry about others, be perfect, walk on eggshells, shape shift to accommodate other people. So co-dependency is a very active wiring issue that doesn't just affect your romantic relationships.
00:52:22
It affects you being a boss that affects you in the world online. You get one negative comment and it throws you for two weeks.
00:52:31
It also is linked to eating disorders and other kinds of addiction. So it's it's it's a very big thing. And I think a lot of people sometimes only think that it's in romantic relationships. I always feel the need to say that.
00:52:42
And also one of the reasons I love the idea of robots so much, because you don't have to walk on eggshells around them. You don't have to worry. They're going to get mad at you yet. But there's no codependents are hypersensitive to the needs and moods of others. And it's very exhausting. It's depleting just. Well, one conversation about where we're going to go to dinner is like, you want to go get Chinese food. We just had Chinese food.
00:53:05
Well, why are you mad? Well, no, I didn't mean. And it's just like that codependents live in this. Everything means something and humans can be very emotionally exhausting. Why did you look at me that way? What do you think about what was that? Why did you check your phone? It's just it's a hypersensitivity that can be incredibly time consuming, which is why I love the idea of robots just subbing in even. I've had a hard time running TV shows and stuff because even asking someone to do something, I don't want to come off like a bitch.
00:53:33
I'm very concerned about what other people think of me, how I'm perceived, which is why I think robots will be very beneficial for for codependents.
00:53:40
By the way, just the real quick tangent, that skill or flaw, whatever you want to call it, is actually really useful for if you ever do start your own podcast for interviewing because you're now kind of obsessed about the mindset of others and makes you a good sort of listener and talker with.
00:54:00
So I think.
00:54:03
What's your name from NPR? Talk to Terry Gross talked about having that. So I don't feel like she has that at all.
00:54:12
Was what. But she worries about other people's feelings.
00:54:17
Yeah, absolutely. Oh I don't get that at all.
00:54:20
I mean, you have to put yourself in the mind of the person you're supposed to be. I see. Just in terms of yeah, I am starting a podcast and the reason I haven't is because I'm codependent and I'm too worried it's not going to be perfect. Yeah. So a big codependent adage is perfectionism leads to procrastination, which leads to paralysis.
00:54:37
So how do you take a million changes? How do you survive on social media? Because you exceptionally active.
00:54:42
But by the way, I took you on a tangent and didn't answer your last question about how much we can control, how much you we'll return it.
00:54:48
Or maybe the answer is we can go to we're OK. Yes, we can. But but one of the things that I'm fascinated by is the first thing you learn when you go into 12 step programs are addiction recovery. I think this is, you know, genetics loads the gun environment pulls the trigger. And there are certain parts of your genetics you cannot control. I come from a lot of alcoholism. I come from, you know, a lot of mental illness.
00:55:16
There's certain things I cannot control and a lot of things that maybe we don't even know yet what we can and can't because of how little we actually know about the brain. But we also talk about the warrior spirit. And there are some people that have that warrior spirit.
00:55:28
And we don't necessarily know what that engine is, whether it's you get dopamine from succeeding or achieving or martyring yourself or or that tension you get from growing.
00:55:41
So a lot of people are like, oh, this person can edify themselves and overcome.
00:55:45
But if you're getting attention from improving. Yourself, you're going to keep wanting to do that, so that is something that helps a lot of in terms of changing your brain. If you talk about changing your brain to people and talk about what you're doing to overcome that obstacles, you're going to get more attention from them, which is going to fire off your reward system, and then you're gonna keep doing it so you can leverage that momentum.
00:56:07
So this is why in any step program, you go into a room and you talk about your progress, because then everyone claps for you and then you're more motivated to keep going.
00:56:15
So that's why we say you're only as sick as the secrets you keep, because if you keep things secret, you know, there's no one guiding you to go in a certain direction. It's based on. Right. We're sort of designed to get approval from the tribe or from a group of people because our brain, you know, translates it to safety.
00:56:31
So in that case, the tribe is a positive one that helps you go to a positive direction.
00:56:36
So that's why it's so important to go into a room and also say, hey, I wanted to use drugs today and people go, they go, me too. And you feel less alone and you feel less like your, you know, have been castigated from the pack or whatever. And then you say and I have you get a chip when you haven't drank for 30 days or 60 days or whatever, you get little rewards.
00:56:55
So talking about a pack that's not at all healthy are good, but in fact is often toxic social media.
00:57:03
So you're one of my favorite people on Twitter and Instagram to sort of just both the comedy and the inside and just fun. How do you prevent social media from destroying your mental health? I haven't.
00:57:16
I haven't. It's the next big epidemic, isn't it? I don't think I have I don't I don't think it's moderation, the answer what maybe. But you can do a lot of damage in a moderate way. I mean, I guess, again, it depends on your goals, you know, and and I think for me, the way that my addiction to social media, I'm happy to call it an addiction. I mean, and I define it as an addiction because it stops being a choice.
00:57:43
There are times I just reach over and I'm like, that was that was where I was, where I'll be driving. Sometimes I'll be like, oh, my God, my arm just went to my phone. You know, I can put it down. I can take time away from it. But when I do, I get Nancy, I get restless, irritable and discontent. I mean, that's kind of the definition, isn't it? So I think by no means do I have a healthy relationship with social media.
00:58:07
I'm sure there's a way to. But I think I'm especially a weirdo in this space because it's easy to conflate. Is this work? Is this I can always say that it's for work.
00:58:17
Right. You know, but I mean, don't you get the same kind of thing is you get someone a room full of people laugh your jokes because I mean, I see especially the way you do Twitter, it's an extension of your comedy in a way.
00:58:30
So I took a big break from Twitter, though, the really big break. I took like six months off or something for a while because it was just like it seemed like it was all kind of politics and it was just a little bit it wasn't giving me dopamine because there was like this weird a lot of feedback. So I did take a break from it and then go back to it cause I felt like I didn't have a healthy relationship.
00:58:50
I ever tried the I don't know if I believe them, but Joe Rogan seems to not read comments, have you?
00:58:56
And he's one of the only people at the scale, like at your level who at least claims not to read the because you and him swim in this space of tense ideas. Yeah. The get get get the toxic folks riled up. I think rogue.
00:59:16
I don't I don't know. I don't I think he probably looks at YouTube like the likes. And, you know, I think if something's if he doesn't know, I don't know.
00:59:27
I'm sure he would tell the truth. You know, I'm sure he's got people that look at them and it's like disgusted. Great. Or I don't, you know, like, I'm sure he gets it. You know, I can't picture him, like, in the weeds on know for sure.
00:59:40
I mean, he's honestly actually saying that.
00:59:42
I just it's it's it's a to feedback. Yeah. We're taking your feedback. I mean, you know, look like I think that our brain is designed to get intel on how we're perceived so that we know where we stand. Right. That's our whole deal. Right. As humans, we want to know where we stand. We walk in a room and we go, who's the most powerful person in here? I got to talk to him and get in their good graces.
01:00:04
Let's just were designed to rank ourselves right and constantly know our rank and social media because of you can't figure out your rank with five hundred million people. It's not simple. You know, our brain is like, what's my rank? What's my. And especially if we're following people. I think the big the interesting thing I think I may be able to say about this besides my speech impediment, is that I did start meeting people that rank wildly higher than me because it is just stressful on the brain to constantly look at people that are incredibly successful.
01:00:39
So you keep feeling bad about yourself. You know, I think that that is like cutting to a certain extent, just like look at me looking at all these people that have so much more money than me and so much more success than me.
01:00:50
It's making me feel like a failure, even though I don't think I'm a failure. But it's easy to frame it so that I can feel that.
01:00:58
But yeah, that's really interesting, especially if they're close to like if they're other comedians or something like that. That's right. Or whatever. That's it's really disappointing to me. I do the same thing as well. So other successful people are really close to what I do.
01:01:11
It I don't know. I wish I could just admire. Yeah. And for it not to be a distraction, but that's why you are where you are because you don't just admire your competitive and you want to win.
01:01:22
So it's also the same thing that bums you out when you look at this is the same reason you are where you are. So that's why I think it's so important to learn about neurology and addiction, because you're able to go like, oh, this same instinct. So I'm very sensitive and I and I sometimes don't like that about myself, but I'm like, well, that's the reason I'm able to write good standup. And that's the reason and that's the reason I'm able to be sensitive to feedback.
01:01:42
And so that jokes should have been better. I can make that better. So it's the kind of thing where it's like you have to be really sensitive in your work. In the second you leave, you've got to be able to turn it off. It's about developing the muscle, being able to know when to let it be a superpower and when it's going to hold you back and be an obstacle. So I try to not be in that black and white of like, you know, being competitive is bad or being jealous of someone just to go like, oh, there's that thing that makes me really successful in a lot of other ways.
01:02:08
But right now it's making me feel that, well, I'm kind of looking to you because you're basically a celebrity, a famous sort of world class comedian. And so I feel like you're the right person to. Be one of the key people to define what's the healthy path forward with social media, though, because we're all trying to figure it out now and it's a I'm curious to see where it evolves. I think you're at the center of that. So, like, you know, there's, you know, trying to leave Twitter and then come back.
01:02:39
Can I do this in a healthy way? I mean, you have to keep trying explore to know because it's being know.
01:02:44
I have a couple of answers. I think, you know, I hire a company to do some of my social media for me, you know, so it's also being able to go, OK, I make a certain amount of money by doing this, but now let me be a good business person and say I'm going to pay you this amount to run this for me. So I'm not twenty four seven in the weeds hashtag I'm responding in just it's a lot to take on, it's a lot of energy to take on.
01:03:05
But at the same time, part of what I think makes me successful in social media, if I am, is that people know I'm actually doing it and that I am an engaging and I'm responding and developing a personal relationship with complete strangers.
01:03:17
So I think, you know, figuring out that balance and really approaching it as a business, you know, that's what I try to do. It's not dating. It's not I try to just be really objective about, OK, here's what's working. Here's what's not working. And in terms of taking the break from Twitter, this is a really savage take.
01:03:34
But because I don't talk about my politics publicly, being on Twitter right after the last election was not going to be beneficial because there was going to be you had to take a side. You had to be political in order to get any kind of read tweets or likes. And I just wasn't interested in doing that because you were going to lose as many people as you were going to gain and it was going to all come clean in the wash. So I was just like the best thing I can do for me business wise is to just abstain, you know?
01:04:04
And, you know, the robot.
01:04:06
I joke about her replacing me, but she does do half of my social media, you know, because it's I don't want people to get sick of me. I don't want to be redundant. There are times when I don't have the time or the energy to make a funny video.
01:04:20
But I know she's going to be compelling and interesting. And that's something that you can't see every day.
01:04:25
You know, of course, the the humor comes from your I mean, the cleverness, the with the humor comes from you when you film the robot, that's kind of the trick of it.
01:04:34
I mean, the robot is not quite there to make to do anything funny.
01:04:40
The absurdity is revealed through the filmmaker in that case or whoever is interacting not through the the actual robot, you know, being who she is.
01:04:50
Let me sort of love. OK, what is it?
01:04:57
What is it? Well, first, an engineering question. I know I know you're not an engineer, but how difficult do you think is it to build in the system that you can have a deep, fulfilling, monogamous relationship with sort of replace the human to human relationships that we value? I think anyone can fall in love with anything. You know, like how often have you look back and someone like I ran into someone the other day. That I was in love with and I was like, hey, it was like there was nothing there, there was nothing there, like, you know, like where you're able to go like, oh, that was weird.
01:05:37
Oh, right.
01:05:39
You know, I, I were abused from a distant past or something like. Yeah, when you're able to go like, I can't believe we had an incredible connection. And now it's just I do think that people will be in love with robots probably even more deeply with humans, because it's like when people mourn their animals, when they're animals dying, they're always it's sometimes harder than mourning a human because you can't go.
01:06:05
Well, he was kind of an asshole, but like, he didn't pick me up from school. You know, it's like you're able to get out of your grief a little bit. You're able to kind of be, oh, he was kind of judgmental or she was. With a robot, it's there's something so pure about an innocent, impish and childlike about it that I think it probably will be much more conducive to a narcissistic love for sure at that.
01:06:29
But it's not like, well, he cheated. She can't cheat. You can't leave you. She can't.
01:06:34
Well, if a bear claw leaves your life, it may be a new version or somebody else will enter there.
01:06:42
Are will you miss Bear Claw for guys that have these sex robots? They're building a nursing home for the bodies that are now rusting because they don't want to part with the bodies because they have such an intense emotional connection to it.
01:06:57
I mean, it's kind of like a car club a little bit, you know, like, you know. But I'm not saying this is right.
01:07:04
I'm not saying it's cool. It's weird. It's creepy. But we do anthropomorphize things with faces and we do develop emotional connections to things. I mean, there's certain have you ever tried to, like, throw I can't even throw away my teddy bear from when I was a kid. It's a piece of trash and it's upstairs. Like it's just like, why can I throw that away?
01:07:23
It's bizarre, you know? And there's something kind of beautiful about that. There's something it gives me hope in in humans because I see humans do such horrific things all the time. And maybe I'm too I see too much of it, frankly, but there's something kind of beautiful about the way we're able to have emotional connections to objects, which, you know, a lot of.
01:07:46
I mean, it's kind of specifically, I think, Western right, that we don't see objects as having souls. Like that's kind of specifically us. But I don't think it's so much that we're objectifying humans with these sex robots. We're kind of humanizing objects. Right. So there's something kind of fascinating in our ability to do that, because a lot of us don't humanize humans. So it's just a weird little place to play in.
01:08:09
And I think a lot of people I mean, a lot of people will be marrying these things as my guess.
01:08:14
So you've asked the question, let me ask reviews. What is love? You have a bit of a brilliant definition of love as being willing to die for someone who who you yourself want to kill. So that's that's kind of first of all, it's brilliant. That's a really good definition. I think you'll stick with me for a long time. Is this how little of a romantic I am? A plane went by when you said that and my brain is like, you're going to need to remember that I don't want you to get into post and then not be able to use that.
01:08:47
And I'm a romantic as a on the moon. Actually, I can not be conscious of the fact that I heard the plane and it made me feel like how amazing it is that we live in a world of planes.
01:09:00
And I just went, why have we fucking evolved past planes and why can't they make them quieter?
01:09:05
Yeah, well, yes, this is my definition of what? Yeah.
01:09:12
What's your sort of producing dopamine like consistent output of oxytocin with the same person?
01:09:22
Dopamine is a positive thing. What about the negative? What about the fear and insecurity? The longing?
01:09:31
Anger, all that kind of stuff, I think that's part of love, you know, I think you don't I think that love brings out the best in you, but it also if you don't get angry, upset, it's you know, I don't know. I think that that's that's part of it. I think we have this idea that love has to be like, really, you know, placid or something. I only saw stormy relationships growing up.
01:09:51
So I don't I don't have a judgment on how our relationship should look.
01:09:55
But I do think that this idea that love has to be eternal is is really destructive, is really destructive and self-defeating and a big source of stress for people. I mean, I'm still figuring out love. I think we all kind of are. But I do kind of stand by that definition.
01:10:18
And I think that I think for me, love is like just being able to be authentic with somebody. It's very simple. I know, but I think for me it's about not feeling pressure to have to perform or impress somebody, just feeling truly like accepted unconditionally by someone.
01:10:33
Although I do believe love should be conditional, that might be a hot take and think everything should be conditional.
01:10:41
I think if someone's behavior I don't think love should just be like I'm in love with you now. Behave however you want forever. This is unconditional. I think love is a daily action. It's not something you just like get tenure on and then get to behave however you want because we said I love you ten years ago. It's a daily it's a verb. Well, there's some things there.
01:11:02
You see, if you make it if you explicitly make it clear that it's conditional, it takes away some of the magic of it. So there's some stories we tell ourselves that we don't want to make explicit about love. I don't know. Maybe that's the wrong way to think of it. Maybe you want to be explicit in relationships.
01:11:19
So I also think love is a business decision like I do in a good way.
01:11:24
I like to think that love is not just when you're across from somebody, it's when I go to work. Can I focus? Do I am I worried about you, my stressed out about you? Am I right? You're not responding to me. You're not reliable. Like, I think that being in a relationship, the kind of love that I would want is the kind of relationship where when we're not together, it's not draining me, causing me stress, making me worry, you know, and sometimes passion that word.
01:11:50
You know, we get murky about it.
01:11:53
But I think it's also like I can be the best version of myself when the person's not around and I don't have to feel abandoned or scared or any of these kind of other things. So it's like love, you know, for me. I think I think it's a Flaubert quote. I'm going to butcher it, but I think it's like be, you know, boring in your personal life so you can be violent and take risks in your professional life.
01:12:12
Is that it? I got it wrong. Something like that. But I do think that it's being able to align values in a way to where you can also thrive outside of the relationship.
01:12:21
Some of the most successful people I know are still sort of happily married and have kids and so on.
01:12:26
It's okay to be boring. Boring is OK. Boring is serenity. And it's funny how the those elements actually make you much more productive.
01:12:35
I don't understand the I don't think relationships should drain you and take away energy that you could be using to create things that generate pride.
01:12:42
OK, did you say your relationship with Olivia, have you said your religion, your definition of love? My definition of love?
01:12:50
No, I did not say we're out of time now.
01:12:55
Do we have we have a podcast. Maybe you can invite me online. Oh, no, I already did. You're doing it. OK, we've already talked about this.
01:13:03
And because I also have co-dependency, I have to say yes. No, I think.
01:13:07
Yeah, no, no. You you owe me now actually the. I wondered whether when I asked if we could talk today after sort of doing more research and reading some of your book, a certain wonder, did she just feel pressured to say yes?
01:13:23
Yes, of course. Good. But I'm a fan of yours, too.
01:13:27
No, I actually because I am proud of it, but I'm in recovery for codependents, so I actually do. I don't do anything I don't want to.
01:13:34
Do you really you got to you know what. Good, good.
01:13:40
Trying to remember I moved it from one to two. I just. Yeah. Just just a little lower.
01:13:46
Haven't that but I, I don't do anything I don't want to do. Yeah. You're ahead of me on that.
01:13:52
OK, so I don't want to be.
01:13:57
Do you think about your mortality. Yes. It is a big part of how I was able to sort of like kick start my codependents recovery.
01:14:05
My dad passed a couple of years ago and when you have someone close to you in your life die, everything gets real clear in terms of how we're a speck of dust. Who's only here for a certain amount of time?
01:14:17
What do you think is the meaning of it all? Like what? The speck of dust. What what's maybe in your own life? What's the goal, the purpose of your existence? Is there one?
01:14:32
Well, you're exceptionally ambitious.
01:14:34
You've created some incredible things in different disciplines.
01:14:38
It's all just managing our terror because we know we're going to die. So we create and build all these things and rituals and religions and, you know, robots and whatever we need to do to just distract ourselves from imminent rodding.
01:14:51
We're ready. Yeah, we're all die.
01:14:54
You know, I you know, I got very into terror management theory when my dad died and it resonated. It helped me.
01:15:02
And everyone's got their own religion, our sense of purpose or thing that distracts them from the horrors of being human waste management.
01:15:12
Their terror management is basically the idea that since we're the only animal that knows they're going to die, we have to basically distract ourselves with awards and achievements and games and whatever just in order to distract ourselves from the terror we would feel if we really processed the fact that we could not only we are going to die, but also could die at any minute because we're only superficially at the top of the food chain.
01:15:39
And, you know, technically we're the top of the food chain if we have houses and guns and stuff machines. But if me and a lion are in the woods together, I'm most things could kill us. I mean, a bee can kill some people, like something this big can kill a lot of humans. So it's basically just to manage the terror that we all would feel if we were able to really be awake because we're mostly zombies right at the job.
01:16:04
School religion does go to sleep, train through the football. The relationship doesn't mean love. You know, we're kind of just like trudging along like zombies for the most part.
01:16:15
And then I think the fear of death as a motivation. Yes.
01:16:20
Well, I think I speak for a lot of people in saying that I can't wait to see what your terror creates in the in the next few years.
01:16:30
I'm a huge fan, wouldn't we? Thank you so much for talking to us.
01:16:35
Thanks for listening to this conversation with Whitney Cummings and thank you to our presenting sponsor, Cash. Download it and use code likes podcast. You'll get ten dollars and ten dollars will go to first STEM Education nonprofit that inspires hundreds of thousands of young minds to learn and to dream of engineering our future. You enjoy this podcast. Subscribe on YouTube. Give it five stars, an Apple podcast, support and patron or connect with me on Twitter. Thank you for listening and hope to see you next time.
