WEBVTT

00:00.000 --> 00:12.000
 The following is a conversation with Boris Sofman, who is the senior director of engineering and head of trucking at Waymo, the autonomous vehicle company, formerly the Google self driving car project.

00:12.000 --> 00:24.000
 Before that, Boris was the co founder and CEO of Anki, a robotics company that created Cosmo, which, in my opinion, is one of the most incredible social robots ever built.

00:24.000 --> 00:36.000
 It's a toy robot, but one with an emotional intelligence that creates a fun and engaging human robot interaction. It was truly sad for me to see Anki shut down when he did.

00:36.000 --> 00:46.000
 I had high hopes for those little robots. We talk about this story and the future of autonomous trucks, vehicles, and robotics in general.

00:46.000 --> 00:56.000
 I spoke with Steve Viselli recently on episode 237 about the human side of trucking. This episode looks more at the robotics side.

00:56.000 --> 01:07.000
 This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. And now here's my conversation with Boris Sofman.

01:07.000 --> 01:12.000
 Who is your favorite robot in science fiction, books or movies?

01:12.000 --> 01:25.000
 I like WALLY and R2D2 where they were able to convey such an incredible degree of intent, emotion, and kind of character attachment without having any language whatsoever.

01:25.000 --> 01:36.000
 And just purely through the richness of emotional interaction. So those are fantastic. And then the Terminator series just like really, pretty wide range, right?

01:36.000 --> 01:42.000
 But I kind of love this dynamic. We have this incredible Terminator itself that Arnold played.

01:42.000 --> 01:53.000
 And then he was kind of like the inferior previous generation version that was totally outmatched in terms of specs by the new one, but still kind of held his own.

01:53.000 --> 02:03.000
 And so it was kind of interesting where you realize how many levels there are on the spectrum from human to kind of potentials in AI and robotics to futures.

02:03.000 --> 02:11.000
 So yeah, that movie really, as much as it was like kind of a direct world in a way, was actually quite fascinating, gets the imagination going.

02:11.000 --> 02:21.000
 Well, from an engineer perspective, both the movies you mentioned, WALLY and Terminator, the first one is probably achievable, you know, humanoid robot.

02:21.000 --> 02:30.000
 Maybe not with like the realism in terms of skin and so on, but that humanoid form, we have that humanoid form. It seems like a compelling form.

02:30.000 --> 02:40.000
 Maybe the challenge is that it's super expensive to build, but you can imagine, maybe not a machine of war, but you can imagine Terminator type robots walking around.

02:40.000 --> 02:53.000
 And then the same obviously with WALLY, you've basically, so for people who don't know, you created the company Anki that created a small robot with a big personality called Cosmo that just does exactly what WALLY does,

02:53.000 --> 03:02.000
 which is somehow with very few basic visual tools is able to communicate a depth of emotion. And that's fascinating.

03:02.000 --> 03:11.000
 But then again, the humanoid form is super compelling. So like Cosmo is very distant from a humanoid form.

03:11.000 --> 03:16.000
 And then the Terminator has a humanoid form and you can imagine both of those actually being in our society.

03:16.000 --> 03:32.000
 That's true. And it's interesting because it is very intentional to go really far away from human form when you think about a character like Cosmo or like WALLY where you can completely rethink the constraints you put on that character,

03:32.000 --> 03:47.000
 what tools you leverage and then how you actually create a personality and a level of intelligence interactivity that actually matches the constraints that you're under, whether it's mechanical or sensors or AI of the day.

03:47.000 --> 04:00.000
 This is why I was always very surprised by how much energy people put towards trying to replicate human form in a robot because you actually take on some pretty significant constraints and downsides when you do that.

04:00.000 --> 04:20.000
 The first of which is obviously the cost where the articulation of a human body is just so magical in both the precision as well as the dimensionality that to replicate that even in its reasonably close form takes a giant amount of joints and actuators and motion and sensors and encoders and so forth.

04:20.000 --> 04:27.000
 But then you're almost setting an expectation that the closer you try to get to human form, the more you expect the strengths to match.

04:27.000 --> 04:33.000
 And that's not the way AI works is there's places where you're way stronger and there's places where you're weaker.

04:33.000 --> 04:40.000
 And by moving away from human form, you can actually change the rules and embrace your strengths and bypass your weaknesses.

04:40.000 --> 04:57.000
 And at the same time, the human form has way too many degrees of freedom to play with. It's kind of counterintuitive, just as you're saying, but when you have fewer constraints, it's almost harder to master the communication of emotion.

04:57.000 --> 05:13.000
 Like you see this with cartoons, like stick figures, you can communicate quite a lot with just very minimal, like two dots for eyes and a line for a smile. I think you can almost communicate arbitrary levels of emotion with just two dots and a line.

05:13.000 --> 05:31.000
 And that's enough. And if you focus on just that, you can communicate the full range. And then if you do that, then you can focus on the actual magic of human and dot line interaction versus all the engineering mess.

05:31.000 --> 06:00.000
 Like dimensionality, voice, all these sort of things actually become a crutch where you get lost in a search space almost. And so some of the best animators that we've worked with, they almost like study when they come up kind of in building their expertise by forcing these projects where all you have is like a ball that can like kind of jump and manipulate itself or like really, really like aggressive constraints where you're forced to kind of extract the deepest level of emotion.

06:00.000 --> 06:12.000
 And so in a lot of ways, when we thought about Cosmo, I was like, you're right. If we had to describe it in like one small phrase, it was bringing a Pixar character to life in the real world. It's what we were going for.

06:12.000 --> 06:34.000
 And in a lot of ways, what was interesting is that with WALLY, which we studied incredibly deeply, and in fact, some of our team had worked previously at Pixar on that project, they intentionally constrained WALLY as well, even though in an animated film, you could do whatever you wanted to because it forced you to like really saturate the smaller amount of dimensions.

06:34.000 --> 06:49.000
 But you sometimes end up getting a far more beautiful output because you're pushing at the extremes of this emotional space in a way that you just wouldn't because you get lost in the surface area if you have like something that is just infinitely articulable.

06:49.000 --> 07:06.000
 So if we backtrack a little bit and you thought of Cosmo in 2011 and 2013 actually designed and built it. What is Anki? What is Cosmo? I guess, who is Cosmo? And what was the vision behind this incredible little robot?

07:06.000 --> 07:23.000
 We started Anki back while we were still in graduate school. So myself and my two cofounders, we were PhD students in the Robotics Institute at Carnegie Mellon. And so we were studying robotics, AI, machine learning, different areas.

07:23.000 --> 07:48.000
 One of my cofounders was working on walking robots for a period of time. And so we all had a bit of a deeper passion for applications of robotics and AI where there's like a spectrum where there's people that get really fascinated by the theory of AI and machine learning robotics where whether it gets applied in the near future or not is less of a factor on them, but they love the pursuit of the challenge.

07:48.000 --> 08:07.000
 And that's necessary. And there's a lot of incredible breakthroughs that happened there. We're probably closer to the other end of the spectrum where we love the technology and all the evolution of it, but we were really driven by applications, like how can you really reinvent experiences and functionality and build value that wouldn't have been possible without these approaches.

08:07.000 --> 08:26.000
 And that's what drove us. And we had some experiences through previous jobs and internships where we got to see the applied side of robotics. And at that time, there was actually relatively few applications of robotics that were outside of peer research or industrial applications, military applications and so forth.

08:26.000 --> 08:47.000
 There were very few outside of it. So maybe iRobot was like one exception and maybe there are a few others, but for the most part, there weren't that many. And so we got excited about consumer applications of robotics where you could leverage way higher levels of intelligence through software to create value and experiences that were just not possible in those fields today.

08:47.000 --> 09:08.000
 And we saw kind of a pretty wide range of applications that varied in the complexity of what it would take to actually solve those. And what we wanted to do was to commercialize this into a company, but actually do a bottoms up approach where we could have a huge impact in a space that was ripe to have an impact at that time and then build up off of that and move into other areas.

09:08.000 --> 09:21.000
 And then entertainment became the place to start because you had relatively little innovation in the toy space and entertainment space. You had these really rich experiences in video games and movies, but there was like this chasm in between.

09:21.000 --> 09:35.000
 And so we thought that we could really reinvent that experience. And there was a really fascinating transition technically that was happening at the time where the cost of components was plummeting because of the mobile phone industry and then the smartphone industry.

09:35.000 --> 09:58.000
 And so the cost of a microcontroller, of a camera, of a motor, of memory, of microphones, cameras was dropping by orders of magnitude. And then on top of that with iPhone coming out in 2000, I think it was 2007, I believe, it started to become apparent within a couple of years that this could become a really incredible interface device

09:58.000 --> 10:17.000
 and the brain with much more computation behind a physical world experience that wouldn't have been possible previously. And so we really got excited about that and how we push all the complexity from the physical world into software by using really inexpensive components, but putting huge amounts of complexity into the AI side.

10:17.000 --> 10:32.000
 And so Cosmo became our second product and then the one that we're probably most proud of. The idea there was to create a physical character that had enough understanding and awareness of the physical world around it and the context that mattered to feel like he was alive.

10:32.000 --> 10:51.000
 And to be able to have these emotional connections and experiences with people that you would typically only find inside of a movie. And the motivation very much was Pixar. We had an incredible respect and appreciation for what they were able to build in this really beautiful fashion and film.

10:51.000 --> 11:06.000
 But it was always like, one, it was virtual and two, it was like a story on rails that had no interactivity to it. It was very fixed and it obviously had a magic to it, but where you really start to hit a different level of experiences when you're actually able to physically interact with a robot.

11:06.000 --> 11:23.000
 And then that was your idea with Anki, like the first product was the cars. So basically you take a toy, you add intelligence into it in the same way you would add intelligence into AI systems within a video game, but you're not bringing it into the physical space.

11:23.000 --> 11:29.000
 So the idea is really brilliant, which is you're basically bringing video games to life.

11:29.000 --> 11:47.000
 Exactly. That's exactly right. We literally use that exact same phrase because in the case of Drive, this was a parallel of the racing genre. And the goal was to effectively have a physical racing experience, but have a virtual state at all times that matches what's happening in the physical world.

11:47.000 --> 12:00.000
 And then you can have a video game off of that and you can have different characters, different traits for the cars, weapons and interactions and special abilities and all these sort of things that you think of virtually, but then you can have it physically.

12:00.000 --> 12:15.000
 And one of the things that we were really surprised by that really stood out and immediately led us to really accelerate the path towards Cosmo is that things that feel like they're really constrained and simple in the physical world, they have an amplified impact on people.

12:15.000 --> 12:20.000
 The exact same experience virtually would not have anywhere near the impact, but seeing it physically really stood out.

12:20.000 --> 12:26.000
 And so effectively with Drive, we were creating a video game engine for the physical world.

12:26.000 --> 12:41.000
 And then with Cosmo, we expanded that video game engine to create a character and kind of an animation and interaction engine on top of it that allowed us to start to create these much more rich experiences.

12:41.000 --> 12:51.000
 And a lot of those elements were almost like a proving ground for what would human robot interaction feel like in a domain that's much more forgiving, where you can make mistakes in a game.

12:51.000 --> 12:57.000
 It's okay if a car goes off the track or if Cosmo makes a mistake.

12:57.000 --> 13:00.000
 And what's funny is actually we were so worried about that.

13:00.000 --> 13:11.000
 In reality, we realized very quickly that those mistakes can be endearing, and if you make a mistake, as long as you realize you made a mistake and have the right emotional reaction to it, it builds even more empathy with the character.

13:11.000 --> 13:20.000
 Exactly. So when the thing you're optimizing for is fun, you have so much more freedom to fail, to explore, and also in the toy space.

13:20.000 --> 13:33.000
 Like all of this is really brilliant, and I gotta ask you backtrack, it seems for a roboticist to take a jump into the direction of fun is a brilliant move.

13:33.000 --> 13:37.000
 Because one, you have the freedom to explore and to design all those kinds of things.

13:37.000 --> 13:40.000
 And you can also build cheap robots.

13:40.000 --> 13:53.000
 If you're not chasing perfection and toys, it's understood that you can go cheaper, which means a robot is still expensive, but it's actually affordable by a large number of people.

13:53.000 --> 13:55.000
 So it's a really brilliant space to explore.

13:55.000 --> 13:56.000
 Yeah, that's right.

13:56.000 --> 14:00.000
 And in fact, we realized pretty quickly that perfection is actually not fun.

14:00.000 --> 14:16.000
 Because in a traditional roboticist sense, the first kind of path planner, and this is the part that I worked on out of the gate, was a lot of the AI systems where you have these vehicles and cars racing, making optimal maneuvers to try to get ahead.

14:16.000 --> 14:22.000
 And you realize very quickly that that's actually not fun because you want the chaos from mistakes.

14:22.000 --> 14:37.000
 And so you start to kind of intentionally almost add noise to the system in order to kind of create more of a realism in the exact same way the human player might start really ineffective and inefficient and then start to kind of increase their quality bar as they progress.

14:37.000 --> 14:53.000
 And there is a really, really aggressive constraint that's forced on you by being a consumer product where the price point matters a ton, particularly in kind of an entertainment where you can't make a $1,000 product unless you're going to meet the expectations of a $1,000 product.

14:53.000 --> 15:00.000
 And so in order to make this work, your cost of goods had to be well under $100.

15:00.000 --> 15:04.000
 In the case of Cosmo, we got it under $50 end to end, fully packaged and delivered.

15:04.000 --> 15:09.000
 And it was under $200 cost at retail.

15:09.000 --> 15:23.000
 Okay, if we sit down like at the early stages, if we go back to that and you're sitting down and thinking about what Cosmo looks like from a design perspective and from a cost perspective, I imagine that was part of the conversation.

15:23.000 --> 15:30.000
 Well, first of all, what came first? Did you have a cost in mind? Is there a target you're trying to chase?

15:30.000 --> 15:35.000
 Did you have a vision in mind, like size? Did you have, because there's a lot of unique qualities to Cosmo.

15:35.000 --> 15:44.000
 So for people who don't know, they should definitely check it out. There's a display, there's eyes on the little display and those eyes can, it's pretty low resolution eyes, right?

15:44.000 --> 15:47.000
 But they're still able to convey a lot of emotion.

15:47.000 --> 15:53.000
 And there's this arm, like that sort of lift stuff.

15:53.000 --> 15:59.000
 But there's something about arm movement that adds even more kind of depth.

15:59.000 --> 16:06.000
 It's like the face communicates emotion and sadness and disappointment and happiness.

16:06.000 --> 16:11.000
 And then the arms kind of communicates, I'm trying here.

16:11.000 --> 16:14.000
 I'm doing my best in this complicated world.

16:14.000 --> 16:23.000
 Exactly. So it's interesting because like all of Cosmo is only four degrees of freedom and two of them are the two treads, which is for basic movement.

16:23.000 --> 16:29.000
 And so you literally have only a head that goes up and down, a lift that goes up and down, and then your two wheels.

16:29.000 --> 16:34.000
 And you have sound and a screen, a low resolution screen.

16:34.000 --> 16:46.000
 And with that, it's actually pretty incredible what you can come up with, where, like you said, it's a really interesting give and take because there's a lot of ideas far beyond that, obviously, as you can imagine, where, like you said, how big is it?

16:46.000 --> 16:51.000
 How much degrees of freedom? What does he look like? What does he sound like? How does he communicate?

16:51.000 --> 16:54.000
 It's a formula that actually scales way beyond entertainment.

16:54.000 --> 17:07.000
 This is the formula for human kind of robot interface more generally, is you almost have this triangle between the physical aspects of it, the mechanics, the industrial design, what's mass producible, the cost constraints and so forth.

17:07.000 --> 17:14.000
 You have the AI side of how do you understand the world around you, interact intelligently with it, execute what you want to execute.

17:14.000 --> 17:22.000
 So perceive the environment, make intelligent decisions and move forward. And then you have the character side of it.

17:22.000 --> 17:30.000
 Most companies have done anything in human robot interaction, really missed the mark or underinvest in the character side of it.

17:30.000 --> 17:36.000
 They overinvest in the mechanical side of it and then varied results on the AI side of it.

17:36.000 --> 17:41.000
 And so the thinking is that you put more mechanical flexibility into it, you're going to do better.

17:41.000 --> 17:48.000
 You don't necessarily, you actually create a much higher bar for a high ROI because now your price point goes up, your expectations go up.

17:48.000 --> 17:53.000
 And if the AI can't meet it or the overall experience isn't there, you miss the mark.

17:53.000 --> 18:11.000
 So how did you, through those conversations, get the cost down so much and made it so simple? There's a big theme here because you come from the mecca of robotics, which is Carnegie Mellon University, robotics.

18:11.000 --> 18:19.000
 For all the people I've interacted with that come from there or just from the world experts at robotics, they would never build something like Cosmo.

18:19.000 --> 18:23.000
 And so where did that come from? The simplicity.

18:23.000 --> 18:27.000
 It came from this combination of a team that we had. It was quite cool.

18:27.000 --> 18:34.000
 And by the way, you ask anybody that's experienced in the toy entertainment space, you'll never sell a product over $99.

18:34.000 --> 18:40.000
 That was fundamentally false and we believed it to be false. It was because experience had to meet the mark.

18:40.000 --> 18:46.000
 And so we pushed past that amount, but there was a pressure where the higher you go, the more seasonal you become and the tougher it becomes.

18:46.000 --> 19:03.000
 And so on the cost side, we very quickly partnered up with some previous contacts that we worked with where, just as an example, our head of mechanical engineering was one of the earliest heads of engineering at Logitech and has a billion units of consumer products and circulation that he's worked on.

19:03.000 --> 19:07.000
 So like crazy, low cost, high volume consumer product experience.

19:07.000 --> 19:17.000
 We had a really great mechanical engineering team and just a very practical mindset where we were not going to compromise on feasibility in the market in order to chase something that would be an enabler.

19:17.000 --> 19:27.000
 And we pushed a huge amount of expectations onto the software team where, yes, we're going to use cheap, noisy motors and sensors, but we're going to fix it on the software side.

19:27.000 --> 19:40.000
 Then we found on the design and character side, there was a faction that was more from like a game design background that thought that it should be very games driven, Cosmo, where you create a whole bunch of games experiences and it's all about like game mechanics.

19:40.000 --> 19:47.000
 And then there was a faction which my cofather and I are the most involved in this, like really believed in, which was character driven.

19:47.000 --> 20:03.000
 And the argument is that you will never compete with what you can do virtually from a game standpoint, but you actually on a character side, put this into your wheelhouse and put it more towards your advantage because a physical character has a massively higher impact physically than virtually.

20:03.000 --> 20:22.000
 Okay, can I just pause on that because this is so brilliant. For people who don't know, Cosmo plays games with you, but there's also a depth of character. And I actually, when I was playing with it, I wondered exactly what is the compelling aspect of this.

20:22.000 --> 20:32.000
 Because to me, obviously I'm biased, but to me the character, what I enjoyed most, honestly, or what got me to return to it is the character.

20:32.000 --> 20:33.000
 That's right.

20:33.000 --> 20:42.000
 But that's a fascinating discussion of, you're right, ultimately you cannot compete on the quality of the gaming experience.

20:42.000 --> 20:47.000
 It's too restrictive. The physical world is just too restrictive and you don't have a graphics engine, it's like all this.

20:47.000 --> 21:05.000
 But on the character side, and clearly we moved in that direction as the winning path and we partnered up with this, we immediately went towards Pixar and Carlos Bena had been at Pixar for nine years.

21:05.000 --> 21:15.000
 He'd worked on tons of the movies, including WALLY and others, and just immediately spoke the language and it just clicked on how you think about that magic and drive.

21:15.000 --> 21:32.000
 And then we built out a team with him as a really prominent driver of this with different types of backgrounds and animators and character developers where we put these constraints on the team, but then got them to really try to create magic despite that.

21:32.000 --> 21:50.000
 And we converged on this system that was at the overlap of character and the character AI that where, if you imagine the dimensionality of emotions, happy, sad, angry, surprised, confused, scared, you think of these extreme emotions.

21:50.000 --> 22:02.000
 We almost put this challenge to populate this library of responses on how do you show the extreme response that goes to the extreme spectrum on angry or frustrated or whatever.

22:02.000 --> 22:16.000
 And so that gave us a lot of intuition and learnings and then we started parameterizing them where it wasn't just a fixed recording, but they were parameterized and had randomness to them where you could have infinite permutations of happy and surprised and so forth.

22:16.000 --> 22:27.000
 And then we had a behavioral engine that took the context from the real world and would interpret it and then create probability mappings on what sort of responses you would have that actually made sense.

22:27.000 --> 22:40.000
 And so if Cosmo saw you for the first time in a day, he'd be really surprised and happy in the same way that the first time you walk in and your toddler sees you, they're so happy, but they're not going to be that happy for the entirety of your next two hours.

22:40.000 --> 22:48.000
 But you have this spike in response or if you leave him alone for too long, he gets bored and starts causing trouble and nudging things off the table.

22:48.000 --> 22:59.000
 Or if you beat him in a game, the most enjoyable emotions are him getting frustrated and grumpy to a point where our testers and our customers would be like, I had to let him win because I don't want him to be upset.

22:59.000 --> 23:05.000
 And so you start to create this feedback loop where you see how powerful those emotions are.

23:05.000 --> 23:10.000
 And just to give you an example, something as simple as eye contact, you don't think about it in a movie.

23:10.000 --> 23:16.000
 It kind of happens like camera angles and so forth, but that's not really a prominent source of interaction.

23:16.000 --> 23:27.000
 What happens when a physical character like Cosmo, when he makes eye contact with you, it built universal kind of connection, kids all the way through adults.

23:27.000 --> 23:32.000
 And it was truly universal. It was not like people stopped caring after 10, 12 years old.

23:32.000 --> 23:45.000
 And so we started doing experiments and we found something as simple as increasing the amount of eye contact, like the amount of times in a minute that he'll look over for your approval to make eye contact.

23:45.000 --> 23:50.000
 Just by, I think, doubling it, we increased the playtime engagement by 40%.

23:50.000 --> 23:53.000
 You see these sort of interactions where you build that empathy.

23:53.000 --> 23:57.000
 And so we studied pets. We studied virtual characters.

23:57.000 --> 24:05.000
 There's like a lot of times actually dogs are one of the most perfect influencers behind these sort of interactions.

24:05.000 --> 24:08.000
 And what we realized is that the games were not there to entertain you.

24:08.000 --> 24:11.000
 The games were to create context to bring out the character.

24:11.000 --> 24:22.000
 And if you think about the types of games that you played, they're relatively simple, but they were always once to create scenarios of either tension or winning or losing or surprise or whatever the case might be.

24:22.000 --> 24:28.000
 And they were purely there to just like create context to where an emotion could feel intelligent and not random.

24:28.000 --> 24:30.000
 And in the end, it was all about the character.

24:30.000 --> 24:34.000
 So yeah, there's so many elements to play with here.

24:34.000 --> 24:40.000
 So you said dogs. What lessons do we draw from cats who don't seem to give a damn about you?

24:40.000 --> 24:42.000
 Is that just another character?

24:42.000 --> 24:44.000
 It's just another character.

24:44.000 --> 24:54.000
 So you could almost like in the early explorations, we thought it would be really incredible if you had a diversity of characters where you almost help encourage which direction it goes, just like in a role playing game.

24:54.000 --> 25:00.000
 And you had like think of like the seven dwarves sort of.

25:00.000 --> 25:11.000
 And initially we even thought that it would be amazing if like the other like, you know, like their characters actually help them have strengths and weaknesses and some like whatever they end up doing.

25:11.000 --> 25:18.000
 Like some are scared, some are, you know, arrogant, some are, you know, super warm and like kind of friendly.

25:18.000 --> 25:26.000
 And in the end, we focused on one because it made it very clear that, hey, we got to build out enough depth here because you're kind of trying to expand.

25:26.000 --> 25:36.000
 It's almost like how long can you maintain a fiction that this character is alive to where the person's explorations don't hit a boundary, which happens almost immediately with typical toys.

25:36.000 --> 25:43.000
 And, you know, even with video games, how long can we create that immersive experience to where you expand the boundary?

25:43.000 --> 25:50.000
 And one of the things we realized is that you're just way more forgiving when something has a personality and it's physical.

25:50.000 --> 26:05.000
 That is the key that unlocks robotics interacting in the physical world and more generally is that when you don't have a personality and you make a mistake as a robot, the stupid robot made a mistake.

26:05.000 --> 26:11.000
 Why is it not perfect? When you have a character and you make a mistake, you have empathy and it becomes endearing and you're way more forgiving.

26:11.000 --> 26:15.000
 And that was the key that was like I think goes far, far beyond entertainment.

26:15.000 --> 26:18.000
 It actually builds the depth of the personality, the mistakes.

26:18.000 --> 26:22.000
 So let me ask the movie Her question then.

26:22.000 --> 26:35.000
 How, so Cosmos seems, feels like the early days of something that will obviously be prevalent throughout society at a scale that we cannot even imagine.

26:35.000 --> 26:44.000
 My sense is it seems obvious that these kinds of characters will permeate society and that we'll be friends with them.

26:44.000 --> 26:46.000
 We'll be interacting with them in different ways.

26:46.000 --> 26:54.000
 I mean, you don't think of it this way, but when you play video games, they're often cold and impersonal.

26:54.000 --> 27:02.000
 But even then, you think about role playing games, you become friends with certain characters in that game.

27:02.000 --> 27:07.000
 They don't remember much about you. They're just telling a story.

27:07.000 --> 27:11.000
 It's exactly what you're saying. They exist in that virtual world.

27:11.000 --> 27:14.000
 But if they acknowledge that you exist in this physical world,

27:14.000 --> 27:20.000
 if the characters in the game remember that you exist, that you, like for me, like Lex,

27:20.000 --> 27:26.000
 they understand that I'm a human being who has like hopes and dreams and so on.

27:26.000 --> 27:34.000
 It seems like there's going to be like billions, if not trillions of Cosmos in the world.

27:34.000 --> 27:38.000
 So if we look at that future, there's several questions to ask.

27:38.000 --> 27:48.000
 How intelligent does that future Cosmo need to be to create fulfilling relationships like friendships?

27:48.000 --> 27:50.000
 Yeah, it's a great question.

27:50.000 --> 27:54.000
 And part of it is the recognition that it's going to take time to get there because it has to be a lot more intelligent

27:54.000 --> 28:00.000
 because it was good enough to be a magical experience for an eight year old.

28:00.000 --> 28:08.000
 It's a higher bar to do that, be like a pet in the home or to help with functional interface in an office environment

28:08.000 --> 28:10.000
 or in a home and so forth.

28:10.000 --> 28:16.000
 And the idea was that you build on that and you kind of get there and as technology becomes more prevalent

28:16.000 --> 28:19.000
 and less expensive and so forth, you can start to kind of work up to it.

28:19.000 --> 28:21.000
 But you're absolutely right.

28:21.000 --> 28:26.000
 At the end of the day, we almost equated it to how the touch screen created like this really novel interface

28:26.000 --> 28:29.000
 to physical kind of devices like this.

28:29.000 --> 28:34.000
 This is the extension of it where you have much richer physical interaction in the real world.

28:34.000 --> 28:36.000
 This is the enabler for it.

28:36.000 --> 28:39.000
 And it shows itself in a few kind of really obvious places.

28:39.000 --> 28:42.000
 So just take something as simple as a voice assistant.

28:42.000 --> 28:50.000
 You will never, most people will never tolerate an Alexa or a Google Home just starting a conversation proactively

28:50.000 --> 28:53.000
 when you weren't kind of expecting it because it feels weird.

28:53.000 --> 28:57.000
 It's like you were listening and like, and then now you're kind of, it feels intrusive.

28:57.000 --> 29:03.000
 But if you had a character like a cat that touches you and gets your attention or toddler, like you never think twice about it.

29:03.000 --> 29:08.000
 And what we found really kind of immediately is that these types of characters like Cosmo and they would like roam around

29:08.000 --> 29:10.000
 and kind of get your attention.

29:10.000 --> 29:13.000
 And we had a future version that was always on kind of called Vector.

29:13.000 --> 29:15.000
 People were way more forgiving.

29:15.000 --> 29:21.000
 And so you could initiate interaction in a way that is not acceptable for machines.

29:21.000 --> 29:29.000
 And in general, there's a lot of ways to customize it, but it makes people who are skeptical of technology much more comfortable with it.

29:29.000 --> 29:33.000
 There was like, there were a couple of really, really prominent examples of this.

29:33.000 --> 29:39.000
 So when we launched in Europe and so we were in I think like a dozen countries, if I remember correctly,

29:39.000 --> 29:45.000
 but like we went pretty aggressively in launching in Germany and France and UK.

29:45.000 --> 29:51.000
 And we were very worried in Europe because there's obviously like a really socially higher bar for privacy and security

29:51.000 --> 29:58.000
 where you've heard about how many companies have had troubles on things that might've been okay in the US,

29:58.000 --> 30:01.000
 but like are just not okay in Germany and France in particular.

30:01.000 --> 30:09.000
 And so we were worried about this because you have Cosmo who's in our future product Vector, like where you have cameras,

30:09.000 --> 30:14.000
 you have microphones, it's connected and like you're playing with kids and like in these experiences.

30:14.000 --> 30:19.000
 And you're like, this is like ripe to be like a nightmare if you're not careful.

30:19.000 --> 30:25.000
 And the journalists are like notoriously like really, really tough on these sorts of things.

30:25.000 --> 30:30.000
 We were shocked and we prepared so much for what we would have to encounter.

30:30.000 --> 30:40.000
 We were shocked in that not once from any journalists or customer did we have any complaints beyond like a really casual kind of question.

30:40.000 --> 30:48.000
 And it was because of the character where when the conversation came up, it was almost like, well, of course he has to see and hear.

30:48.000 --> 30:51.000
 How else is he going to be alive and interacting with you?

30:51.000 --> 30:57.000
 And it completely disarmed this like fear of technology that enabled this interaction to be much more fluid.

30:57.000 --> 31:00.000
 And again, like entertainment was a proving ground, but that is like, you know,

31:00.000 --> 31:06.000
 there's like ingredients there that carry over to a lot of other elements down the road.

31:06.000 --> 31:13.000
 That's hilarious that we're a lot less concerned about privacy if the thing has value and charisma.

31:13.000 --> 31:16.000
 I mean, that's true for all of human to human interactions.

31:16.000 --> 31:19.000
 It's an understanding of intent where like, well, he's looking at me, he can see me.

31:19.000 --> 31:21.000
 If he's not looking at me, he can't see me.

31:21.000 --> 31:24.000
 Right. So it's almost like you're communicating intent.

31:24.000 --> 31:29.000
 And with that intent, people are like kind of kind of a more understanding and calmer.

31:29.000 --> 31:34.000
 And it's interesting. It was just the earliest kind of version of starting to experiment with this.

31:34.000 --> 31:36.000
 But it wasn't an enabler.

31:36.000 --> 31:41.000
 And then you have like completely different dimensions where kids with autism had like an incredible connection with Cosmo

31:41.000 --> 31:43.000
 that just went beyond anything we'd ever seen.

31:43.000 --> 31:46.000
 And we have like these just letters that we would receive from parents.

31:46.000 --> 31:51.000
 And we had some research projects kind of going on with some universities on studying this.

31:51.000 --> 31:57.000
 But there's an interesting dimension there that got unlocked that just hadn't existed before

31:57.000 --> 32:05.000
 that has these really interesting kind of links into society and a potential building block of future experience.

32:05.000 --> 32:16.000
 So if you look out into the future, do you think we will have beyond a particular game, you know, a companion like her,

32:16.000 --> 32:26.000
 like the movie Her or like a Cosmo that's kind of asks you how your day went to write, you know, like a friend.

32:26.000 --> 32:30.000
 How many years away from that do you think we are? What's your intuition?

32:30.000 --> 32:31.000
 Good question.

32:31.000 --> 32:38.000
 So I think the idea of a different type of character, like more closer to like kind of a pet style companionship will come way faster.

32:38.000 --> 32:41.000
 And there's a few reasons.

32:41.000 --> 32:47.000
 One is like to do something like in her, that's like effectively almost general AI.

32:47.000 --> 32:55.000
 And the bar is so high that if you miss it by a bit, you hit the uncanny valley where it just becomes creepy and like and not appealing.

32:55.000 --> 33:00.000
 Because the closer you try to get to a human in form and interface and voice, the harder it becomes.

33:00.000 --> 33:08.000
 Whereas you have way more flexibility on still landing a really great experience if you embrace the idea of a character.

33:08.000 --> 33:16.000
 And that's why one of the other reasons why we didn't have a voice and also why like a lot of video game characters like Sims,

33:16.000 --> 33:22.000
 for example, does not have a voice when you when you think about it, it was it wasn't just a cost savings like for them.

33:22.000 --> 33:33.000
 It was actually for all of these purposes. It was because when you have a voice, you immediately narrow down the appeal to some particular demographic or age range or kind of style or gender.

33:33.000 --> 33:37.000
 If you don't have a voice, people interpret what they want to interpret.

33:37.000 --> 33:42.000
 And an eight year old might get a very different interpretation than a 40 year old, but you create a dynamic range.

33:42.000 --> 33:48.000
 And so you just you can lean into these advantages much more in something that doesn't resemble human.

33:48.000 --> 33:50.000
 And so that'll come faster.

33:50.000 --> 33:56.000
 I don't know when a human like that's just still like just complete R&D at this point.

33:56.000 --> 34:04.000
 The chat interfaces are getting way more interesting and richer, but it's still a long way to go to kind of pass the test of, you know.

34:04.000 --> 34:09.000
 Well, let me like let's consider like let me play devil's advocate.

34:09.000 --> 34:13.000
 So Google is a very large company that's servicing.

34:13.000 --> 34:17.000
 It's creating a very compelling product that wants to provide a service to a lot of people.

34:17.000 --> 34:21.000
 But let's go outside of that. You said characters.

34:21.000 --> 34:31.000
 Yeah, it feels like and you also said that it requires general intelligence to be a successful participant in a relationship, which could explain why I'm single.

34:31.000 --> 34:44.000
 But the I honestly want to push back on that a little bit because I feel like is it possible that if you're just good at playing a character in a movie, there's a bunch of characters.

34:44.000 --> 34:56.000
 If you just understand what creates compelling characters and then you just are that character and you exist in the world and other people find you and they connect with you just like you do when you talk to somebody at a bar.

34:56.000 --> 34:59.000
 I like this character. This character is kind of shady. I don't like them.

34:59.000 --> 35:01.000
 You pick the ones that you like.

35:01.000 --> 35:06.000
 And, you know, maybe it's somebody that's reminds you of your father or mother.

35:06.000 --> 35:09.000
 I don't know what it is, but the Freudian thing.

35:09.000 --> 35:14.000
 But there's some kind of connection that happens and that's the Cosmo you connect to.

35:14.000 --> 35:16.000
 That's the future Cosmo you connect.

35:16.000 --> 35:24.000
 And it's so I guess the statement I'm trying to make, is it possible to achieve a depth of friendship without solving general intelligence?

35:24.000 --> 35:27.000
 I think so. And it's about intelligent kind of constraints, right?

35:27.000 --> 35:33.000
 And just you set expectations and constraints such that in the space that's left, you can be successful.

35:33.000 --> 35:37.000
 And so you can do that by having a very focused domain that you can operate in.

35:37.000 --> 35:42.000
 For example, you're a customer support agent for a particular product and you create intelligence and a good interface around that.

35:42.000 --> 35:49.000
 Or, you know, kind of in the personal companionship side, you can't be everything across the board.

35:49.000 --> 35:51.000
 You kind of solve those constraints.

35:51.000 --> 35:53.000
 And I think it's possible.

35:53.000 --> 36:04.000
 My worry is right now I don't see anybody that has picked up on where Cosmo left off and is pushing on it in the same way.

36:04.000 --> 36:14.000
 And so I don't know if it's a sort of thing where similar to like how, you know, in Dotcom there were all these concepts that we considered like, you know, that didn't work out or like failed or like were too early or whatnot.

36:14.000 --> 36:18.000
 And then 20 years later, you have these like incredible successes on almost the same concept.

36:18.000 --> 36:24.000
 Like it might be that sort of thing where like there's another pass at it that happens in five years or in 10 years.

36:24.000 --> 36:44.000
 But it does feel like that appreciation of that, like the three legged stool, if you will, between like, you know, the hardware, the AI and the character, that balance, it's hard to, I'm not aware of anywhere right now where like that same kind of aggressive drive with the value on the character is happening.

36:44.000 --> 36:58.000
 And so to me, just a prediction, exactly as you said, something that looks awfully a lot like Cosmo, not in the actual physical form, but in the three legged stool, something like that in some number of years will be a trillion dollar company.

36:58.000 --> 36:59.000
 I don't understand.

36:59.000 --> 37:10.000
 Like, it's obvious to me that like character, not just as robotic companions, but in all our computers, they'll be there.

37:10.000 --> 37:17.000
 It's like Clippy was like two legs of that stool or something like that.

37:17.000 --> 37:19.000
 I mean, those are all different attempts.

37:19.000 --> 37:31.000
 And what's really confusing to me is they're born these attempts and everybody gets excited and for some reason they die and then nobody else tries to pick it up.

37:31.000 --> 37:42.000
 And then maybe a few years later, a crazy guy like you comes around with just enough brilliance and vision to create this thing and is born.

37:42.000 --> 37:43.000
 A lot of people love it.

37:43.000 --> 37:47.000
 A lot of people get excited, but maybe the timing is not right yet.

37:47.000 --> 37:51.000
 And then when the timing is right, it just blows up.

37:51.000 --> 37:54.000
 It just keeps blowing up more and more until it just blows up.

37:54.000 --> 37:59.000
 And I guess everything in the full span of human civilization collapses eventually.

37:59.000 --> 38:01.000
 And that wouldn't surprise me at all.

38:01.000 --> 38:04.000
 And like, what's going to be different in another five years or 10 years or whatnot?

38:04.000 --> 38:16.000
 Physical component costs will continue to come down in price and mobile devices and computation is going to become more and more prevalent as well as cloud as a big tool to offload cost.

38:16.000 --> 38:35.000
 AI is going to be a massive transformation compared to what we dealt with where everything from voice understanding to just kind of a broader contextual understanding and mapping of semantics and understanding scenes and so forth.

38:35.000 --> 38:39.000
 And then the character side will continue to kind of progress as well because that magic does exist.

38:39.000 --> 38:41.000
 It just exists in different forms.

38:41.000 --> 38:52.000
 And you have just the brilliance of the tapping and animation and these other areas where that was a big unlock in film, obviously.

38:52.000 --> 38:59.000
 And so I think, yeah, the pieces can reconnect and the building blocks are actually going to be way more impressive than they were five years ago.

38:59.000 --> 39:11.000
 So in 2019, Anki, the company that created Cosmo, the company that you started, had to shut down. How did you feel at that time?

39:11.000 --> 39:18.000
 Yeah, it was tough. That was a really emotional stretch and it was a really tough year.

39:18.000 --> 39:32.000
 I think about a year ahead of that was actually a pretty brutal stretch because we were kind of life or death on many, many moments just navigating these insane kind of just ups and downs and barriers.

39:32.000 --> 39:49.000
 And the thing that made it, just sort of winding a tiny bit, what ended up being really challenging about it as a business is from a commercial standpoint and customer reception standpoint, there's a lot of things you could point to that were pretty big successes.

39:49.000 --> 40:00.000
 Sold millions of units, got to pretty serious revenue, kind of close to 100 million annual revenue, number one kind of product in various categories.

40:00.000 --> 40:13.000
 But it was pretty expensive. It ended up being very seasonal where something like 85% of our volume was in Q4 because it was a present and it was expensive to market it and explain it and so forth.

40:13.000 --> 40:24.000
 And even though the volume was really sizable and the reviews were really fantastic, forecasting and planning for it and managing the cash operations was just brutal.

40:24.000 --> 40:35.000
 It was absolutely brutal. You don't think about this when you're starting a company or when you have a few million in revenue because it's just your biggest costs are kind of just your headcount and operations and everything's ahead of you.

40:35.000 --> 40:45.000
 But we got to a point where if you look at the entire year, you have to operate your company, pay all the people and so forth.

40:45.000 --> 40:54.000
 You have to pay for the manufacturing, the marketing and everything else to do your sales in mostly November, December and then get paid in December, January by retailers.

40:54.000 --> 41:11.000
 And those swings were really rough and just made it so difficult because the more it successfully became, the more wild those swings became because you'd have to spend tens of millions of dollars on inventory, tens of millions of dollars on marketing and tens of millions of dollars on payroll and everything else.

41:11.000 --> 41:15.000
 The bigger dip and then you're waiting for the Q4.

41:15.000 --> 41:25.000
 Yeah. And it's not a business that is recurring month to month and predictable. And then you're locking in your forecast in July, maybe August if you're lucky.

41:25.000 --> 41:34.000
 And it's also very hit driven and seasonal where you don't have the sort of continued kind of slow growth like you do in some other consumer electronics industries.

41:34.000 --> 41:46.000
 And so before then, hardware kind of went out of favor too. And so you had Fitbit and GoPro drop from 10 billion revenue to 1 billion revenue and hardware companies are getting valued at like 1x revenue oftentimes, which is tough.

41:46.000 --> 41:55.000
 And so we effectively kind of got caught in the middle where we were trying to quickly evolve out of entertainment and move into some other categories.

41:55.000 --> 42:07.000
 But you can't let go of that business because that's what you're valued on. That's what you're raising money on. But there is no path to kind of pure profitability just there because it was such specific type of price points and so forth.

42:07.000 --> 42:16.000
 And so we tried really hard to make that transition. And we had a financing round that fell apart at the last second.

42:16.000 --> 42:26.000
 And effectively, there was just no path to kind of get through that and get to the next kind of holiday season. And so we ended up selling some of the assets and kind of winding down the company.

42:26.000 --> 42:37.000
 It was brutal. I was very transparent with the company and the team while we were going through it where actually, despite how challenging that period was, very few people left.

42:37.000 --> 42:49.000
 I mean, people loved the vision, the team, the culture, the kind of chemistry and what we were doing. There was just a huge amount of pride there. And then we wanted to see it through. And we felt like we had a shot to kind of get through these checkpoints.

42:49.000 --> 43:11.000
 And by brutal, I mean literally days of cash, like three, four different times runway in the year kind of before it where you're playing games of chicken on negotiating credit line timelines and repayment terms and how to get a bridge loan from an investor.

43:11.000 --> 43:21.000
 There was a level of stress that as hard as things might be anywhere else, you'll never come close to that where you feel that responsibility for 200 plus people.

43:21.000 --> 43:30.000
 And so we were very transparent during our fundraise on who we're talking to, the challenges that we have, how it's going and when things are going well, when things were tough.

43:30.000 --> 43:43.000
 And so it wasn't a complete shock when it happened, but it was just very emotional where we announced it finally that we basically were just watching the runway and trying to kind of time it.

43:43.000 --> 43:51.000
 And when we realized that we didn't have any more outs, we wanted to kind of wind it down, make sure that it was clean and we could kind of take care of people the best we could.

43:51.000 --> 44:06.000
 But they broke down crying at the hands and somebody else had to step in for a bit and it was just very, very emotional. But the beautiful part is afterwards, everybody stayed at the office to two, three in the morning just drinking and hanging out and telling stories and celebrating.

44:06.000 --> 44:14.000
 And it was just one of the best, for many people, it was the best kind of work experience that they had. And there was a lot of pride in what we did.

44:14.000 --> 44:23.000
 And it wasn't anything obvious we could point to that like, hey, if only we had done that different, things would have been completely different. It was just like the physics didn't line up.

44:23.000 --> 44:28.000
 And but the experience was pretty incredible, but it was hard.

44:28.000 --> 44:47.000
 It had this feeling that there was this incredible beauty in both the technology and products and the team that there's a lot there that in the right context could have been pretty incredible, but it was emotional.

44:47.000 --> 45:02.000
 Yeah, just thinking, I mean, just looking at this company, like you said, product and technology, but the vision, the implementation, you got the cost down very low and the compelling, the nature of the product was great.

45:02.000 --> 45:14.000
 So many robotics companies failed at this. The robot was too expensive. It didn't have the personality. It didn't really provide any value, like a sufficient value to justify the price.

45:14.000 --> 45:25.000
 So you succeeded where basically every single other robotics company or most of them that are like going the category of social robotics have kind of failed.

45:25.000 --> 45:37.000
 And I mean, it's it's quite tragic. I remember reading that. I'm not sure if I talked to you before that happened or not, but I remember, you know, I'm distant from this.

45:37.000 --> 45:49.000
 I remember being heartbroken reading that because, like, if if Cosmo is not going to succeed, what is going to succeed?

45:49.000 --> 45:55.000
 Because that to me was incredible. Like it was an incredible idea.

45:55.000 --> 46:03.000
 Cost is down. The minimum that the it's just like the most minimal design in physical form that you could do.

46:03.000 --> 46:11.000
 It's really compelling. The balance of games. So it's a fun toy. It's a great gift for all kinds of age groups.

46:11.000 --> 46:21.000
 Right. It's just it's compelling in every single way. And it seemed like it was a huge success and it failing was.

46:21.000 --> 46:27.000
 I don't know. There was heartbreak on many levels for me, just as an external observer.

46:27.000 --> 46:39.000
 Is I was thinking, how hard is it to run a business? That's that's what I was thinking. Like, if this failed, this must have failed because it's obviously not like, yeah, it's business.

46:39.000 --> 46:45.000
 Yeah. Maybe it's some aspect of the manufacturing and so on. But I'm now realizing it's also not just that it's.

46:45.000 --> 46:52.000
 Yeah. And sales, marketing, all those everything. Right. Like, how do you explain something that's like a new category to people that like how all these positions.

46:52.000 --> 47:09.000
 And so, like, you know, it had some of the hardest elements of if you were to pick a business, it had some of the hardest customer dynamics, because like to sell a hundred fifty dollar product, you got to convince both the child, the one it and the parents to agree that it's valuable.

47:09.000 --> 47:15.000
 So you're having like this dual prong marketing challenge. You have manufacturing, you have like really high precision on the components that you need.

47:15.000 --> 47:29.000
 You have the challenges. So there were a lot of tough elements. But is this feeling where like just really great alignment of unique strength across kind of like all these different areas, just an incredible like, you know, kind of character and animation team between this Carlos.

47:29.000 --> 47:33.000
 And there's like a character director day that came on board and really great people there.

47:33.000 --> 47:45.000
 The A.I. side, the the manufacturing, the you know, where like never missing a launch. Right. And actually, you know, he kind of had that quality was. Yeah, it was heartbreaking.

47:45.000 --> 47:56.000
 But here's one neat thing is like we we had so much like fan mail from kind of kids and parents like I actually like there was a bunch that collected in the end that I actually saved.

47:56.000 --> 48:09.000
 And like I never it was too emotional to open it and I still haven't opened it. And so I actually have this giant envelope of like a stack this much of like letters from, you know, kids and families, just like every kind of permutation permutation you can imagine.

48:09.000 --> 48:18.000
 And so planning to kind of I don't know, maybe like a five year, you know, five year, some year reunion, just inviting everybody over and we'll just like kind of dig into it and kind of bring back some memories.

48:18.000 --> 48:34.000
 But, you know, good impact. And well, I think there will be companies, maybe Waymo and Google will be somehow involved that will carry this flag forward and will will make you proud whether you're involved or not.

48:34.000 --> 48:39.000
 I think this is one of the greatest robotics companies in the history of robotics.

48:39.000 --> 48:57.000
 So you should be proud. It's still tragic to know that, you know, because you read all the stories of Apple and let's see, SpaceX and like companies that were just on the verge of failure several times through that story.

48:57.000 --> 49:04.000
 And they just it's almost like a roll of the dice. They succeeded. And here's a roll of the dice that just happened to go.

49:04.000 --> 49:10.000
 And that's the appreciation that like when you really like talk to a lot of the founders, like everybody goes through those moments.

49:10.000 --> 49:16.000
 And sometimes it really is a matter of like, you know, timing, a little bit of luck, like some things are just out of your control.

49:16.000 --> 49:24.000
 And and you get a much deeper appreciation for just the dimensionality of that challenge.

49:24.000 --> 49:38.000
 But the great thing is, is that like a lot of the team actually like stayed together. And so there were actually a couple of companies that we where we kind of kept big chunks of the team together and we actually kind of helped align this, you know, to to help people out as well.

49:38.000 --> 49:47.000
 And one of them was Waymo, where a majority of the AI and robotics team actually had the exact background that you would look for.

49:47.000 --> 50:05.000
 And like kind of AV space was a space that a lot of us like, you know, you know, worked on in grad school, were always passionate about and ended up, you know, maybe the time, you know, serendipitous timings from another perspective where like kind of landed in a really unique circumstances that should have been quite exciting, too.

50:05.000 --> 50:24.000
 So it's interesting to ask you just your thoughts. Cosmo still lives on under Dream Labs, I think. Is that, are you tracking the progress there or is it too much pain? Is it, are you, is that something that you're excited to see where that goes?

50:24.000 --> 50:43.000
 So keeping an eye on it, of course, just out of curiosity and obviously just kind of careful product line, I think it's deceptive how complex it is to manufacture and evolve that product line and the amount of experiences that are required to complete the picture and be able to move that forward.

50:43.000 --> 50:52.000
 And I think that's going to make it pretty hard to do something really substantial with it. It would be cool if like even the product in the way it was was able to be manufactured.

50:52.000 --> 50:54.000
 Which is the current goal, I suppose.

50:54.000 --> 51:13.000
 Yeah, which will be neat. But I think it's deceptive how tricky that is on like everything from the quality control, the details and then like technology changes that forces you to reinvent and update certain things. So I haven't been super close to it, but just kind of keeping an eye on it.

51:13.000 --> 51:30.000
 Yeah, it's really interesting how it's deceptively difficult, just as you're saying. For example, those same folks, and I've spoken with them, they're, they partner up with Rick and Morty creators to do the Butter Robot.

51:30.000 --> 51:31.000
 Yeah.

51:31.000 --> 51:41.000
 I love the idea. I just recently, I kind of half ass watched Rick and Morty previously, but now I just watched like the first season. It's such a brilliant show.

51:41.000 --> 51:54.000
 I like, I did not understand how brilliant that show is. And obviously I think in season one is where the Butter Robot comes along for just a few minutes or whatever, but I just fell in love with the Butter Robot.

51:54.000 --> 52:12.000
 The sort of the, that particular character, just like you said, there's characters you can create, personalities you can create, and that particular robot who's doing a particular task realizes, you know, this like realizes, that's the existential question.

52:12.000 --> 52:30.000
 The myth of Sisyphus question that Camus writes about, is this all there is? He moves butter. But, you know, that realization, that's a beautiful little realization for a robot that my purpose is very limited to this particular task.

52:30.000 --> 52:53.000
 It's humor of course, it's darkness, it's a beautiful mix. But so they want to release that Butter Robot, but something tells me that to do the same depth of personality as Cosmo had, the same richness, it would be on the manufacturing, on the AI, on the storytelling, on the design, it's going to be very, very difficult.

52:53.000 --> 53:14.000
 It could be a cool sort of toy for Rick and Morty fans, but to create the same depth of existential angst that the Butter Robot symbolizes is really, that's the brave effort you succeeded at with Cosmo, but it's not easy. It's really difficult.

53:14.000 --> 53:25.000
 You can fail on almost any one of the kind of dimensions, and unique convergence of a lot of different skill sets to try to pull that off.

53:25.000 --> 53:44.000
 On this topic, let me ask you for some advice, because as I've been watching Rick and Morty, I told myself, I have to build the Butter Robot, just as a hobby project. And so I got a nice platform for it with treads and there's a camera that moves up and down and so on.

53:44.000 --> 54:02.000
 But the question I'd like to ask, there's obvious technical questions I'm fine with, communication, the personality, storytelling, all those kinds of things. I think I understand the process of that, but how do you know when you got it right?

54:02.000 --> 54:17.000
 So with Cosmo, how did you know this is great? Or something is off. Is this brainstorming with the team? Do you know it when you see it? Is it like love at first sight? It's like, this is right.

54:17.000 --> 54:28.000
 Or I guess if we think of it as an optimization space, is there Uncanny Valley where you're like, that's not right, or this is right, or are a lot of characters right?

54:28.000 --> 54:44.000
 Yeah, we stayed away from Uncanny Valley just by having such a different mapping where it didn't try to look like a dog or a human or anything like that. And so you avoided having a weird pseudo similarity, but not quite hitting the mark.

54:44.000 --> 55:00.000
 But you could just fall flat where just a personality or a character emotion just didn't feel right. And so it actually mirrored very closely to the iterations that a character director at Pixar would have, where you're running through it and you can virtually see what it'll look like.

55:00.000 --> 55:15.000
 We created a plugin to where we actually used Maya, the animation tools, and then we created a plugin that perfectly matched it to the physical one. And so you could test it out virtually and then push a button and see it physically play out.

55:15.000 --> 55:21.000
 And there's subtle differences. And so you want to make sure that that feedback loop is super easy to be able to test it live.

55:21.000 --> 55:37.000
 And then sometimes you would just feel it that it's right and intuitively know. And then we did user testing. But it was very, very often that if we found it magical, it would scale and be magical more broadly.

55:37.000 --> 55:52.000
 There were not too many cases where we were pretty decent about not geeking out or getting too attached to something that was super unique to us, but trying to put a customer hat on and does it truly feel magical?

55:52.000 --> 56:07.000
 And so in a lot of ways, we just give a lot of autonomy to the character team to really think about the character board and mood boards and storyboards and what's the background of this character and how would they react.

56:07.000 --> 56:12.000
 And they went through a process that's actually pretty familiar, but now had to operate under these unique constraints.

56:12.000 --> 56:23.000
 The moment where it felt right kind of took a fairly similar journey than like as a character in an animated film. Actually, it's quite cool. Well, the thing that's really important to me and I wonder if it's possible.

56:23.000 --> 56:34.000
 Well, I hope it's possible. Pretty sure it's possible is for me, even though I know how it works to make sure there's sufficient randomness in the process.

56:34.000 --> 56:44.000
 Probably because it would be machine learning based that I'm surprised that I don't. I'm surprised by certain reactions. I'm surprised by certain communication.

56:44.000 --> 56:52.000
 Maybe that's in a form of a question. Were you surprised by certain things Cosmo did, like certain interactions?

56:52.000 --> 57:06.000
 Yeah, we made it intentionally so that there would be some surprise and a decent amount of variability in how he'd respond in certain circumstances. And so in the end, this isn't general AI.

57:06.000 --> 57:21.000
 This is a giant spectrum and library of parameterized emotional responses and an emotional engine that would map your current state of the game, your emotions, the world, the people who are playing with you, so forth, to what's happening.

57:21.000 --> 57:33.000
 But we could make it feel spontaneous by creating enough diversity and randomness, but still within the bounds of what felt like very realistic to make that work.

57:33.000 --> 57:48.000
 And then what was really neat is that we could get statistics on how much of that space we were saturating and then add more animations and more diversity in the places that would get hit more often so that you stay ahead of the curve and maximize the chance that it stays feeling alive.

57:48.000 --> 57:59.000
 But then when you combine it, the permutations and the combinations of emotions stitched together sometimes surprised us because you see them in isolation.

57:59.000 --> 58:07.000
 But when you actually see them and you see them live relative to some event that happened in the game or whatnot, it was kind of cool to see the combination of the two.

58:07.000 --> 58:26.000
 And it's not too different in other robotics applications where you get so used to thinking about the modules of a system and how things progress through a tech stack that the real magic is when all the pieces come together and you start getting the right emergent behavior in a way that's easy to lose when you just kind of go too deep into any one piece of it.

58:26.000 --> 58:38.000
 Yeah, when the system is sufficiently complex, there is something like emergent behavior and that's where the magic is. As a human being, you can still appreciate the beauty of that magic at the system level. First of all, thank you for humoring me on this.

58:38.000 --> 58:46.000
 It's really, really fascinating. I think a lot of people would love this. One last thing on the butter robot, I promise.

58:46.000 --> 59:10.000
 In terms of speech, Cosmo is able to communicate so much with just movement and face. Do you think speech is too much of a degree of freedom? Like speech a feature or a bug of deep interaction, emotional interaction?

59:10.000 --> 59:27.000
 For a product, it's too deep right now. You would immediately break the fiction because the state of the art is just not good enough. And that's on top of just narrowing down the demographic where the way you speak to an adult versus the way you speak to a child is very different.

59:27.000 --> 59:43.000
 Yet a dog is able to appeal to everybody. And so right now there is no speech system that is rich enough and subtly realistic enough to feel appropriate. And so we very, very quickly kind of moved away from it.

59:43.000 --> 59:57.000
 Now, speech understanding is a different matter where understanding intent, that's a really valuable input. But giving it back requires like a way, way higher bar given kind of where today's world is.

59:57.000 --> 1:00:15.000
 And so that realization that you can do surprisingly much with either no speech or kind of tonal like the way Wally R2D2 and kind of other characters are able to, it's quite powerful and it generalizes across cultures and across ages really, really well.

1:00:15.000 --> 1:00:32.000
 I think we're going to be in that world for a little while where it's still very much an unsolved problem on how to like make something. It touches on the uncanny valley thing. So if you have legs and you're a big humanoid looking thing, you have very different expectations and a much narrower degree of what's going to be acceptable by society.

1:00:32.000 --> 1:00:52.000
 And then if you're a robot like Cosmo or Wally or some other form where you can kind of like reinvent the character, speech has that same property where speech is so well understood in terms of expectations by humans that you have far less flexibility on how to deviate from that and lean into your strengths and avoid weaknesses.

1:00:52.000 --> 1:01:13.000
 But I wonder if there is, obviously there's certain kinds of speech that activates the uncanny valley and breaks the illusion faster. So I guess my intuition is we will solve certain, we would be able to create some speech based personalities sooner than others.

1:01:13.000 --> 1:01:22.000
 So for example, I could think of a robot that doesn't know English and is learning English, right? Those kinds of personalities.

1:01:22.000 --> 1:01:43.000
 It's like a fiction where you're intentionally kind of like getting a toddler level of speech. So that's exactly right. So you can have like tied into the experience where it is a more limited character or you embrace the lack of emotions or the lack of dynamic range in the speech kind of capabilities, emotions as like part of the character itself.

1:01:43.000 --> 1:01:47.000
 And you've seen that in like kind of fictional characters as well.

1:01:47.000 --> 1:01:50.000
 That's why this podcast works.

1:01:50.000 --> 1:01:55.000
 Yeah, and you kind of had that with like, I don't know, I guess like data and some of the other ones.

1:01:55.000 --> 1:02:01.000
 But yeah, so you have to, and that becomes a constraint that lets you meet the bar.

1:02:01.000 --> 1:02:25.000
 See, I honestly think like also if you add drunk and angry, that gives you more constraints that allow you to be dumber from an NLP perspective. Like there's certain aspects. So if you modify human behavior, like, so forget the sort of artificial thing where you don't know English toddler thing.

1:02:25.000 --> 1:02:39.000
 We, if you just look at the full range of humans, I think we, there's certain situations where we put up with a like lower level of intelligence in our communication.

1:02:39.000 --> 1:02:48.000
 Like if somebody is drunk, we understand the situation that they're probably under the influence. Like we understand that they're not going to be making any sense. Anger is another one like that.

1:02:48.000 --> 1:03:05.000
 I'm sure there's a lot of other kind of situations like this. Maybe, again, language, loss in translation, that kind of stuff that I think if you play with that, what is it, the Ukrainian boy that passed the touring test, you know, play with those ideas.

1:03:05.000 --> 1:03:14.000
 I think that's really interesting that you can create compelling characters, but you're right, that's a dangerous sort of road to walk because you're adding degrees of freedom that can get you in trouble.

1:03:14.000 --> 1:03:27.000
 Yeah. And that's why like you have these big pushes that like for most of the last decade plus like where you'd have like full like human replicas of robots really being down to like skin and like kind of in some places.

1:03:27.000 --> 1:03:36.000
 My personal feeling is like, man, like that's not the direction that's most fruitful right now.

1:03:36.000 --> 1:03:44.000
 Beautiful art. It's not in terms of a rich, deep, fulfilling experience. Yeah, you're right.

1:03:44.000 --> 1:04:00.000
 Yeah. And creating a minefield of potential places to feel off. And then you're sidestepping where like the biggest kind of functional AI challenges are to actually have, you know, kind of like really rich productivity that actually kind of justifies the higher price points.

1:04:00.000 --> 1:04:06.000
 And that's part of the challenge is like, yeah, like robots are going to get to like thousands of dollars, tens of thousands of dollars and so forth.

1:04:06.000 --> 1:04:15.000
 But you can imagine what sort of expectation of value that comes with it. And so that's where you want to be able to invest the time and depth.

1:04:15.000 --> 1:04:30.000
 And so going down the full human replica route creates a gigantic distraction and really, really high bar that can end up sucking up so much of your resources.

1:04:30.000 --> 1:04:46.000
 So it's weird to say, but you happen to be one of the greatest at this point roboticists ever because you created this little guy. Your part obviously of a great team that created the little guy with a deep personality.

1:04:46.000 --> 1:05:04.000
 And they're now switching to an entirely, well, maybe not entirely, but a different fascinating, impactful robotics problem, which is autonomous driving and more specifically, the biggest version of autonomous driving, which is autonomous trucking.

1:05:04.000 --> 1:05:20.000
 So you are at Waymo now. Can you give us a big picture overview? What is Waymo? What is Waymo Driver? What is Waymo One? What is Waymo Via? Can you give an overview of the company and the vision behind the company?

1:05:20.000 --> 1:05:35.000
 For sure. Waymo, by the way, has been eye opening on just how incredible the people and the talent is and how in one company you almost have to create 30 companies worth of technology and capability to solve the full spectrum of it.

1:05:35.000 --> 1:05:54.000
 So I've been at Waymo since 2019, so about two and a half years. So Waymo is focused on building what we call a driver, which is creating the ability to have autonomous driving across different environments, vehicle platforms, domains, and use cases.

1:05:54.000 --> 1:06:07.000
 As you know, it got started in 2009. It was almost like an immediate successor to the Grand Challenge and Urban Challenges that were like incredible catalysts for this whole space.

1:06:07.000 --> 1:06:22.000
 And so Google started this project and then eventually Waymo spun out. And so what Waymo is doing is creating the systems, both hardware, software, infrastructure, everything that goes into it to enable and to commercialize autonomous driving.

1:06:22.000 --> 1:06:34.000
 This hits on consumer transportation and ride sharing and kind of vehicles and urban environments. And as you mentioned, it hits on autonomous trucking to transport goods.

1:06:34.000 --> 1:06:45.000
 So in a lot of ways, it's transporting people and transporting goods. But at the end of the day, the underlying capabilities required to do that are surprisingly better aligned than one might expect,

1:06:45.000 --> 1:06:57.000
 where it's the fundamentals of being able to understand the world around you, process it, make intelligent decisions, and prove that we are at a level of safety that enables large scale autonomy.

1:06:57.000 --> 1:07:16.000
 So from a branding perspective, Waymo Driver is the system that's irrespective of a particular vehicle it's operating in. You have a set of sensors that perceive the world, can act in that world, and move whatever the vehicle is through the world.

1:07:16.000 --> 1:07:28.000
 And so in the same way that you have a driver's license and your ability to drive is tied to a particular make and model of a car, and of course, there are special licenses for other types of vehicles, but the fundamentals of a human driver very, very largely carry over.

1:07:28.000 --> 1:07:37.000
 And then there's uniquenesses related to a particular environment or domain or a particular vehicle type that kind of add some extra additive challenges.

1:07:37.000 --> 1:07:54.000
 But that's exactly right. It's the underlying systems that enable a physical vehicle without a human driver to very successfully accomplish the task that previously wasn't possible without 100% human driving.

1:07:54.000 --> 1:08:14.000
 And then there's Waymo One, which is the transporting people from a brand perspective. And just in case we refer to it so people know. And then there's Waymo Via, which is the trucking component. Why Via, by the way? What is that? Is it just like a cool sounding name?

1:08:14.000 --> 1:08:24.000
 Is there an interesting story there? It is a pretty cool sounding name. It's a cool sounding name. I mean, when you think about it, it's just like, well, we're going to transport it via this and that.

1:08:24.000 --> 1:08:31.000
 So it's just kind of like an allusion to the mechanics of transporting something. And it is a pretty good grouping.

1:08:31.000 --> 1:08:46.000
 And the interesting thing is that even the groupings kind of blur where Waymo One is like human transportation and there's a fully autonomous service in the Phoenix area that like every day is transporting people. And it's pretty incredible to like just see that operated reasonably large scale and just kind of happen.

1:08:46.000 --> 1:09:06.000
 And then on the Via side, it doesn't even have to be like long haul trucking is a like a major focus of ours. But down the road, you can stitch together the vehicle transportation as well for local delivery. Also, and a lot of this requirements for local delivery overlap very heavily with consumer transportation.

1:09:06.000 --> 1:09:26.000
 Obviously, given that you're operating on a lot of the same roads and navigating the same safety challenges. And Waymo very much is a multi product company that has ambitions in both. They have different challenges and both are tremendous opportunities.

1:09:26.000 --> 1:09:44.000
 But the cool thing is, is that there's a huge amount of leverage and this kind of core technology stack now gets pushed on by both sides. And that adds its own unique challenges. But the success case is that the challenges that you push on, they get leveraged across all platforms and all.

1:09:44.000 --> 1:09:47.000
 From an engineer perspective, the teams are integrated.

1:09:47.000 --> 1:09:57.000
 It's a mix. So there's a huge amount of centralized kind of core teams that support all applications. And so you think of something like the hardware team that develops the lasers to compute integrates into vehicle platforms.

1:09:57.000 --> 1:10:12.000
 This is an experience that carries over across, you know, any application that we'd have in a ebb and flow with both. Then there's like really unique perception challenges, planning challenges, like other types of challenges where there's a huge amount of leverage on a core tech stack.

1:10:12.000 --> 1:10:28.000
 But then there's like dedicated teams that think of how do you deal with a unique challenge, for example, an articulated trailer with varying loads that completely changes the physical dynamics of a vehicle that doesn't exist on a car, but it becomes one of the most important kind of unique new challenges on a truck.

1:10:28.000 --> 1:10:37.000
 So what's the long term dream of Waymo via the autonomous trucking effort that Waymo is doing?

1:10:37.000 --> 1:10:50.000
 Yeah, so we're starting with developing L4 autonomy for class 8 trucks. These are 53 foot trailers that capture like a pretty sizable percentage of the goods transportation in the country.

1:10:50.000 --> 1:11:03.000
 Long term, the opportunity is obviously to expand to much more diverse types of vehicles, types of goods transportation and start to really expand in both the volume and the route feasibility that's possible.

1:11:03.000 --> 1:11:14.000
 And so just like we did on the car side, you start with a single route with a very specific operating kind of domain and constraints that allow you to solve the problem.

1:11:14.000 --> 1:11:27.000
 But then over time, you start to really try to push against those boundaries and open up deeper feasibility across routes, across surface streets, across environmental conditions, across the type of goods that you carry,

1:11:27.000 --> 1:11:42.000
 the versatility of those goods and how little supervision is necessary to just start to scale this network. And long term, there's actually it's a pretty incredible enabler where today you have already a giant shortage of truck drivers.

1:11:42.000 --> 1:11:48.000
 It's over 80,000 truck driver shortage that's expected to grow to hundreds of thousands in the years ahead.

1:11:48.000 --> 1:11:57.000
 You have really, really quickly increasing demand from ecommerce and just distribution of where people are located.

1:11:57.000 --> 1:12:11.000
 You have one of the deepest safety challenges of any profession in the US where there's a huge, huge, huge kind of challenge around fatigue and around kind of the long routes that are driven.

1:12:11.000 --> 1:12:25.000
 And even beyond kind of the cost and necessity of it, there are fundamental constraints built into our logistics network that are tied to the type of human constraints and regulatory constraints that are tied to trucking today.

1:12:25.000 --> 1:12:34.000
 For example, our limits on how long a driver can be driving in a single day before they're not allowed to drive anymore, which is a very important safety constraint.

1:12:34.000 --> 1:12:49.000
 What that does is it enforces limitations on how far jumps with a single driver could be and makes you very subject to availability of drivers, which influences where warehouses are built, which influences how goods are transported, which influences costs.

1:12:49.000 --> 1:13:09.000
 And so you start to have an opportunity on everything from plugging into existing fleets and brokerages and the existing logistics network and just immediately start to have a huge opportunity to add value from a cost and driving fuel insurance and safety standpoint,

1:13:09.000 --> 1:13:16.000
 all the way to completely reinventing the logistics network across the United States and enabling something completely different than what it looks like today.

1:13:16.000 --> 1:13:23.000
 Yeah, I had to be published before this had a great conversation with Steve Vicelli, who we talked about the manual driving.

1:13:23.000 --> 1:13:31.000
 He echoed many of the same things that you were talking about, but we talked about much of the fascinating human stories of truck drivers.

1:13:31.000 --> 1:13:37.000
 He was also was a truck driver for a bit as a grad student to try to understand the depth of the problem.

1:13:37.000 --> 1:13:42.000
 Fascinating lives. We have some drivers that have four million miles of lifetime driving experience.

1:13:42.000 --> 1:13:51.000
 It's pretty incredible. And yeah, it's learning from them, like some of them are on the road for 300 days a year. It's a very unique type of lifestyle.

1:13:51.000 --> 1:14:04.000
 So there's fascinating stuff there. Just like you said, there's a shortage of actually people, truck drivers taking the job, counter to what I think is publicly believed.

1:14:04.000 --> 1:14:12.000
 So there's an excess of jobs and a shortage of people to take up those jobs. And just like you said, it's such a difficult problem.

1:14:12.000 --> 1:14:21.000
 And these are experts at driving and solving this particular problem. And it's fascinating to learn from them to understand, you know, how hard is this problem?

1:14:21.000 --> 1:14:29.000
 And that's the question I want to ask you from a perception, from a robotics perspective. What's your sense of how difficult is autonomous trucking?

1:14:29.000 --> 1:14:40.000
 Maybe you can comment on which scenarios are super difficult, which are more manageable. Is there is there a way to kind of convert into words how difficult the problem is?

1:14:40.000 --> 1:14:52.000
 Yeah, it's a good question. So there's and as you can expect, it's a mix. Some things become a lot easier or at least more flexible.

1:14:52.000 --> 1:15:07.000
 Some things are harder. And so, you know, on the things that are like the tailwinds, the benefits, a big focus of automating trucking, especially initially, is really focusing on the long haul freeway stretch of it, where that's where a majority of the value is captured.

1:15:07.000 --> 1:15:13.000
 On a freeway, you have a lot more structure and a lot more consistency across freeways across the U.S.

1:15:13.000 --> 1:15:23.000
 compared to surface streets where you have a way higher dimensionality of what can happen, lack of structure, lack of consistency and variability across cities.

1:15:23.000 --> 1:15:32.000
 So you can leverage that consistency to tackle, at least in that respect, a more constrained problem, which has some benefits to it.

1:15:32.000 --> 1:15:37.000
 You can itemize much more of the sort of things you might encounter and so forth. And so those are benefits.

1:15:37.000 --> 1:15:46.000
 Is there a canonical freeway and city we should be thinking about? Like, is there is there a standard thing that's brought up in conversation often?

1:15:46.000 --> 1:15:57.000
 Like, here's a stretch of road. What is it like when people talk about traveling across country, they'll talk about New York, San Francisco.

1:15:57.000 --> 1:16:09.000
 Is that the route? Like, is there a stretch of road that's like nice and clean and then there's like cities with difficulties in them that you kind of think of as the canonical problem to solve here?

1:16:09.000 --> 1:16:13.000
 Right. So starting with the car side.

1:16:13.000 --> 1:16:18.000
 Well, Waymo very intentionally picked the Phoenix area and the San Francisco area as a follow.

1:16:18.000 --> 1:16:28.000
 Once we hit driverless, where when you think of consumer transportation and ride sharing kind of economy, a big percentage of that market is captured in the densest cities in the United States.

1:16:28.000 --> 1:16:40.000
 And so really pushing out and solving San Francisco becomes a really huge opportunity and importance and places one dot on kind of like the spectrum of complexity.

1:16:40.000 --> 1:16:48.000
 The Phoenix area, starting with Chandler and then expanding more broadly in the Phoenix metropolitan area, it's I believe the fastest growing city in the US.

1:16:48.000 --> 1:16:56.000
 It's a kind of a higher medium sized city, but growing quickly and still captures a really wide range of kind of complexities.

1:16:56.000 --> 1:17:03.000
 And so getting to driverless there actually exposes you to a lot of the building blocks you need for the more complicated environments.

1:17:03.000 --> 1:17:15.000
 And so in a lot of ways, there's a thesis that if you start to kind of place a few of these kind of dots where San Francisco has these types of unique challenges, dense pedestrians, all this like complexity, especially when you get into the downtown areas and so forth.

1:17:15.000 --> 1:17:23.000
 And Phoenix has like a really interesting kind of spectrum of challenges, maybe other ones like LA kind of add freeway focus and so forth.

1:17:23.000 --> 1:17:35.000
 You start to kind of cover the full set of features that you might expect and it becomes faster and faster if you have the right systems and the right organization to then open up the fifth city and the 10th city and the 20th city.

1:17:35.000 --> 1:17:47.000
 On trucking, there's similar properties where obviously there's uniquenesses and freeways when you get into really dense environments and then the real opportunity to then get even more

1:17:47.000 --> 1:17:58.000
 valuous to think about how you expand with like some of the surface free challenges. But for example, right now we're looking we have a big facility that we're finishing building in Q1 in Dallas area.

1:17:58.000 --> 1:18:05.000
 That'll allow us to do testing from the Dallas area on routes like Dallas to Houston, Dallas to Phoenix, going out east.

1:18:05.000 --> 1:18:07.000
 Dallas to Austin.

1:18:07.000 --> 1:18:09.000
 Austin to that triangle.

1:18:09.000 --> 1:18:11.000
 Waymo should come to Austin.

1:18:11.000 --> 1:18:14.000
 Well, Waymo the car side wasn't Austin for a while.

1:18:14.000 --> 1:18:16.000
 Yes, I know. Come back.

1:18:16.000 --> 1:18:23.000
 But trucking is actually, Texas is one of the best places to start because of both volume, regulatory weather, there's a lot of benefits.

1:18:23.000 --> 1:18:27.000
 On trucking, a huge opportunity is Port of LA going east.

1:18:27.000 --> 1:18:37.000
 So in a lot of ways, a lot of the work is to start to stitch together a network and converge to Port of LA where you have the biggest port in the United States.

1:18:37.000 --> 1:18:48.000
 And the amount of goods going east from there is pretty tremendous. And then obviously, there's, you know, kind of channels everywhere. And then you have extra complexities as you get into like snow and increment weather and so forth.

1:18:48.000 --> 1:18:54.000
 But what's interesting about trucking is every single route segment that you add increases the value of the whole network.

1:18:54.000 --> 1:19:00.000
 And so it has this kind of network effect and cumulative effect that's very unique. And so there's all these dimensions that we think about.

1:19:00.000 --> 1:19:06.000
 And so in a lot of ways, Dallas is a really unique hub that opens up a lot of options has become a really valuable lever.

1:19:06.000 --> 1:19:11.000
 So the million questions I could ask you, first of all, you mentioned level four.

1:19:11.000 --> 1:19:24.000
 For people who totally don't know, there's these levels of automation that level four refers to kind of the first step that you could recognize as fully autonomous driving.

1:19:24.000 --> 1:19:30.000
 Level five is really fully autonomous driving and level four is kind of fully autonomous driving.

1:19:30.000 --> 1:19:38.000
 And then there are specific definitions, depending on who you ask what that actually means. But for you, what does the level four mean?

1:19:38.000 --> 1:19:43.000
 And you mentioned freeway. Let's say like there's three parts of long haul trucking.

1:19:43.000 --> 1:19:49.000
 Maybe I'm wrong in this, but there's freeway driving. There's like truck stop.

1:19:49.000 --> 1:19:54.000
 And then there's more urban type of area.

1:19:54.000 --> 1:20:00.000
 So which of those do you want to tackle? Which of them do you include under level four?

1:20:00.000 --> 1:20:05.000
 Like how do you think about this problem? What do you focus on? What is the biggest impact to be had in the short term?

1:20:05.000 --> 1:20:13.000
 So the goal is that we got to get to market as fast as we can, because the moment you get to market, you just learn so much and it influences everything that you do.

1:20:13.000 --> 1:20:20.000
 And it is one of the experiences I carried over from before is that you add constraints.

1:20:20.000 --> 1:20:25.000
 You figure out the right compromises. You do whatever it takes because getting to market is so critical.

1:20:25.000 --> 1:20:28.000
 But here with autonomous driving, you can get to market in so many different ways.

1:20:28.000 --> 1:20:35.000
 That's right. And so one of the simplifications that we intentionally have put on is using what we call transfer hubs,

1:20:35.000 --> 1:20:47.000
 where you can imagine depots that are at the entry points to metropolitan areas, like let's say Dallas, like the hub that we're building, which does a few things that are very valuable.

1:20:47.000 --> 1:20:52.000
 So from a first product standpoint, you can automate transfer hub to transfer hub.

1:20:52.000 --> 1:21:04.000
 And that path from the transfer hub to the full freeway route can be a very intentional single route that you can select for the features that you feel you want to handle at that point in time.

1:21:04.000 --> 1:21:08.000
 And you build the hub specifically designed for autonomous trucking.

1:21:08.000 --> 1:21:13.000
 And that's what's going to happen, actually. And you need to come out in January and check it out because it's going to be really cool.

1:21:13.000 --> 1:21:29.000
 Not only is it our main operating headquarters for our fleet there, but it will be the first fully ground up designed driverless hub for autonomous trucks in terms of where do they enter, where do they depart, how do you think about the flow of people, goods, everything.

1:21:29.000 --> 1:21:32.000
 It's quite cool and it's really beautiful on how it's thought through.

1:21:32.000 --> 1:21:44.000
 And so early on, it is totally reasonable to do the last five miles manually to get to the final kind of depot to avoid having to solve the general surface street problem, which is obviously very complex.

1:21:44.000 --> 1:21:57.000
 Now, when the time comes and we are increasingly, already we're pushing on some of this, but we will increasingly be pushing on surface street capabilities to build out the value chain to go all the way depot to depot instead of transfer hub to transfer hub.

1:21:57.000 --> 1:22:07.000
 And we have probably the best advantages in the world because of all the Waymo experience on surface streets, but that's not the highest ROI right now where the highest ROI is hub to hub and get the routes going.

1:22:07.000 --> 1:22:17.000
 And so when you ask what's L4, L4 can be applied to any operating domain or scope, but it's effectively for the places where we say we're ready for autonomous operation.

1:22:17.000 --> 1:22:27.000
 We are 100% operating as a self driving truck with no human behind the wheel.

1:22:27.000 --> 1:22:40.000
 That is L4 autonomy. And it doesn't mean that you operate in every condition, it doesn't mean you operate on every road, but for a particularly well defined area, operating conditions, routes, kind of domain, you are fully autonomous.

1:22:40.000 --> 1:22:50.000
 And that's the difference between L4 and L5. And most people would agree that at least anytime in the foreseeable future, L5 is just not even really worth thinking about because there's always going to be these extremes.

1:22:50.000 --> 1:23:05.000
 And so it's a race and almost like a game where you think of what is the sequence of expanded capabilities that create the most value and teach us the most and create this feedback loop where we're building out and unlocking more and more capability over time.

1:23:05.000 --> 1:23:20.000
 I gotta ask you, just curious. So first of all, I have to, when I'm allowed, visit the Dallas facility because it's super cool. It's like robot on the giving and the receiving end. The truck is a robot and the hub is a robot.

1:23:20.000 --> 1:23:22.000
 Yeah, it's got to be very robot friendly.

1:23:22.000 --> 1:23:40.000
 Yeah, that's great. I will feel at home. What's the sensor suite like on the hub if you can just high level mention it? Does the hub have like lidars? Is the truck doing most of the intelligence or is the hub also intelligent?

1:23:40.000 --> 1:23:58.000
 Yeah, so most of it will be the truck and everything is like connected. So we have our servers where we know exactly where every truck is. We know exactly what's happening at a hub. And so you can imagine like a large backend system that over time starts to manage timings, goods, delivery, windows, all these sort of things.

1:23:58.000 --> 1:24:19.000
 And so you don't actually need to, there might be special cases where that is valuable to equip some sensors in the hub, but a majority of the intelligence is going to be on the truck because whatever's relevant to the truck, relevant should be seen by the truck and can be relayed remotely for any sort of kind of cognizance or decision making.

1:24:19.000 --> 1:24:38.000
 But there's a distinct type of workflow where do you check trucks? Where do you want them to enter? What if there's many operating at once? Where's the staging area to depart? How do you set up the flow of humans and human cars and traffic so that you minimize the interaction between humans and kind of self driving trucks?

1:24:38.000 --> 1:25:01.000
 And then how do you even intelligently select the locations of these transfer hubs that are both really great service locations for a metropolitan area? And there could be over time, many of them for a metropolitan area while at the same time leaning into the path of least resistance to lean into your current capabilities and strengths so that you minimize the amount of work that's necessary to unlock the next kind of big bar.

1:25:01.000 --> 1:25:06.000
 I have a million questions. So first, is the goal to have no human in the truck?

1:25:06.000 --> 1:25:20.000
 The goal is to have no human in the truck. Now, of course, right now we're testing with expert operators and so forth. But the goal is to... Now, there might be circumstances where it makes sense to have a human or... And obviously, these trucks can also be manually driven.

1:25:20.000 --> 1:25:37.000
 So sometimes we talk with our fleet partners about how you can buy a Waymo equipped Dymor truck down the road and on the routes that are autonomous, it's autonomous. On the routes that are not, it's human driven. Maybe there's L2 functionality that adds safety systems and so forth.

1:25:37.000 --> 1:25:51.000
 But as soon as they become, as soon as we expand in software, the availability of driverless routes, the hardware is forward compatible to just now start using them in real time. And so you can imagine this mixed use.

1:25:51.000 --> 1:26:01.000
 But at the end of the day, the largest value proposition is where you're able to have no constraints on how you can operate this truck. And it's 100% autonomous with nobody inside.

1:26:01.000 --> 1:26:12.000
 That's amazing. So the... Let me ask on the logistics front, because you mentioned that also opportunity to revamp or for build from scratch some of the ideas around logistics.

1:26:12.000 --> 1:26:23.000
 I don't want to throw too much shade, but from talking to Steve, my understanding is logistics is not perhaps as great as it could be in the current trucking environment.

1:26:23.000 --> 1:26:32.000
 I'm not, maybe you can break down why, but there's probably competing companies. There's just a mess. Maybe some of it is literally just, it's old school.

1:26:32.000 --> 1:26:39.000
 Like they, it's just like, it's not computer, it's not computerized. Like truckers are almost like contractors.

1:26:39.000 --> 1:26:46.000
 There's an independence and there's not a nice interface where they can communicate where they're going, where they're at, you know, all those kinds of things.

1:26:46.000 --> 1:26:57.000
 And so there, it just feels like there's so much opportunity to digitize everything to where you could optimize the use of human time, optimize the use of all kinds of resources.

1:26:57.000 --> 1:27:03.000
 How much are you thinking about that problem? How fascinating is that problem? How difficult is it?

1:27:03.000 --> 1:27:09.000
 How much opportunity is there to revolutionize the space of logistics in autonomous trucking, in trucking period?

1:27:09.000 --> 1:27:20.000
 It's pretty fascinating. It's one of the most motivating aspects of all this where like, yes, there's like a mountain of problems that are like you want to, you have to solve to get to like the first checkpoints and first drivers and so forth.

1:27:20.000 --> 1:27:27.000
 And inevitably, like in a space like this, you plug in initially into the existing kind of system and start to kind of, you know, learn and iterate.

1:27:27.000 --> 1:27:32.000
 But that opportunity is massive. And so, you know, a couple of the factors that play into it.

1:27:32.000 --> 1:27:39.000
 So first of all, there's obviously just the physical constraints of driving time, driver availability.

1:27:39.000 --> 1:27:48.000
 Some fleets have a 95% attrition rate, you know, right now because of just this demands and like, you know, kind of gaps in competition and so forth.

1:27:48.000 --> 1:27:58.000
 And then it's also incredibly fragmented where you would be shocked at like when you look at industries, like when you think of the top 10 players, like the biggest fleets, like the Walmarts and FedExes and so forth.

1:27:58.000 --> 1:28:04.000
 The percentage of the overall trucking market that's captured by the top 10 or 50 fleets is surprisingly small.

1:28:04.000 --> 1:28:11.000
 The average kind of truck operation is like a one to five truck, you know, family business.

1:28:11.000 --> 1:28:24.000
 And so and so there's just like a huge amount of like fragmentation, which makes for really interesting challenges in kind of stitching together through like bulletin boards and brokerages and some people run their own fleets.

1:28:24.000 --> 1:28:34.000
 And this world's kind of like evolving, but it is one of the less digitized and optimized worlds that there is.

1:28:34.000 --> 1:28:38.000
 And the part that is optimized is optimized to the constraints of today.

1:28:38.000 --> 1:28:44.000
 And even within the constraints of today, this is a 900 billion dollar industry in the US and it's continuing to grow.

1:28:44.000 --> 1:28:59.000
 It feels like from a business perspective, if I were to predict that while trying to solve the autonomous trucking problem, Waymo might solve first the logistics problem because that would already be a huge impact.

1:28:59.000 --> 1:29:14.000
 So on the way to solving autonomous trucking, the human driven, like there's so much opportunity to significantly improve the human driven trucking, the timing, the logistics. So you use humans optimally.

1:29:14.000 --> 1:29:29.000
 You use handoffs to like, you know, well, even you get really ambitious, you start to expand this beyond like how does the fulfillment center work and like how does the transfer hub work, how does the warehouse work?

1:29:29.000 --> 1:29:42.000
 I mean, there's a lot of opportunities to start to automate these chains. And a lot of the inefficiency today is because like you have a delay, like Port of LA has a bunch of ships right now waiting outside of it because they can't dock because there's not enough labor inside of the Port of LA.

1:29:42.000 --> 1:30:00.000
 There's a big backlog of trucks, which means there's a big backlog of deliveries, which means the drivers aren't where they need to be. And so you have this like huge chain reaction and your feasibility of readjusting in this network is low because everything's tied to humans and manual kind of processes or distributed processes across a whole bunch of players.

1:30:00.000 --> 1:30:16.000
 And so one of the biggest enablers is, yes, we have to solve autonomous trucking first. And that, by the way, that's not like an overnight thing. That's decades of continued kind of expansion and work. But the first checkpoint in the first route is like is not that far off.

1:30:16.000 --> 1:30:34.000
 But once you start enabling and you start to learn about how the constraints of autonomous trucking, which are very, very different than the constraints of human trucking and again, strengths and weaknesses, how do you then start to leverage that and rethink a flow of goods more broadly?

1:30:34.000 --> 1:30:50.000
 And this is where like the learnings of like really partnering with some of the largest fleets in the US and the sort of learnings that they have about the industry and the sort of needs that they have. And what would change if you just like really broke this one constraint that like holds up the whole network?

1:30:50.000 --> 1:31:07.000
 Or what if you enable this other constraint? That actually drives the roadmap in a lot of ways because this is not like an all or nothing problem. You start to kind of unlock more and more functionality over time, which functionality most enables this optimization ends up being kind of part of the discussion.

1:31:07.000 --> 1:31:23.000
 But you're totally right. Like you fast forward to like five years, 10 years, 15 years, and you think about like very generalized capability of automation and logistics, as well as the ability to like poke into how those handoffs work.

1:31:23.000 --> 1:31:43.000
 The efficiency goes far beyond just direct cost of today's like unit economics of a truck. They go towards reinventing the entire system in the same way that you see these other industries that like when you get to enough scale, you can really rethink how you build around your new set of capabilities, not the old set of capabilities.

1:31:43.000 --> 1:31:57.000
 Yeah, use the analogy metaphor or whatever that autonomous trucking is like email versus mail. And then with email, you're still doing the communication, but it opens up all kinds of communities, varieties of communication that you didn't anticipate.

1:31:57.000 --> 1:32:02.000
 That's right. Constraints are just completely different. And yeah, there's a definitely a property of that here.

1:32:02.000 --> 1:32:16.000
 And we're also still learning about it because there is a lot of really fascinating and sometimes really elegant things that the industry has done where there's companies whose entire existence is around, despite the constraints, optimizing as much as they can out of it.

1:32:16.000 --> 1:32:25.000
 And those lessons do carry over. But it's an interesting kind of merger of worlds to think about like, well, what if this was completely different? How would we approach it?

1:32:25.000 --> 1:32:36.000
 And the interesting thing is that for a really, really, really long time, it's actually going to be the merger between how to use autonomy and how to use humans that leans into each of their strengths.

1:32:36.000 --> 1:32:40.000
 Yeah. And then we're back to Cosmo, human robot interaction.

1:32:40.000 --> 1:32:56.000
 So and the interesting thing about Waymo is because there's the passenger vehicle, the human, the transportation of humans and transportation of goods, you could see over time, they may kind of meld together more because you'll probably have like zero occupancy vehicles moving around.

1:32:56.000 --> 1:33:11.000
 So you have transportation of goods for short distances and then for slightly longer distances and then slightly longer and then there'll be this, then you just see the difference between a passenger vehicle and a truck is just size and you can have different sizes and all that kind of stuff.

1:33:11.000 --> 1:33:17.000
 And at the core, you can have a Waymo driver that doesn't, as long as you have the same sense of suite, you can just think of it as one problem.

1:33:17.000 --> 1:33:28.000
 And that's why over time, these do kind of converge where in a lot of ways, a lot of the challenges we're solving are freeway driving, which are going to carry over very well to the vehicles, to the car side.

1:33:28.000 --> 1:33:41.000
 But there are like then unique challenges like you have a very different dynamics in your vehicle where you have to see much further out in order to have the proper response time because you have an 80,000 pound fully loaded truck.

1:33:41.000 --> 1:33:44.000
 That's a very, very different type of breaking profile than a car.

1:33:44.000 --> 1:33:58.000
 You have a really interesting kind of dynamic limits because of the trailer where you actually, it's very, very hard to like physically like flip a car or do something like physically like most risk in a car is from just collisions.

1:33:58.000 --> 1:34:10.000
 It's very hard to like in any normal operation to do something other than like unless you hit something to actually kind of like roll over something on a truck, you actually have to drive much closer to the physical bounds of the safety limits.

1:34:10.000 --> 1:34:20.000
 But you actually have like real constraints because you could have really interesting interactions between the cabin and the trailer.

1:34:20.000 --> 1:34:25.000
 There's something called jackknifing if you turn too quickly, you have roll risk and so forth.

1:34:25.000 --> 1:34:32.000
 And so we spent a huge amount of time understanding those boundaries and those boundaries change based on the load that you have, which is also an interesting difference.

1:34:32.000 --> 1:34:41.000
 You have to propagate that through the algorithm so that you're leveraging your dynamic range, but always staying within the safety bounds, but understanding what those safety bounds are.

1:34:41.000 --> 1:34:55.000
 And so we have this like really cool test facility where we like take it to the max and actually imagine a truck with these giant training wheels on the back of the trailer and you're pushing it past the safety limits in order to like try to actually see where it rolls.

1:34:55.000 --> 1:35:02.000
 And so you define this high dimensional boundary, which then gets captured in software to stay safe and actually do the right thing.

1:35:02.000 --> 1:35:06.000
 But it's kind of fascinating the sort of kind of challenges you have there.

1:35:06.000 --> 1:35:12.000
 But then all of these things drive really interesting challenges from perception to unique behavior prediction challenges.

1:35:12.000 --> 1:35:19.000
 And obviously in Planner where you have to think about merging and creating gaps with a 53 foot trailer and so forth.

1:35:19.000 --> 1:35:28.000
 And then obviously the platform itself is very different. We have different numbers of sensors, sometimes types of sensors, and you also have unique blind spots that you have because of the trailer, which you have to think about.

1:35:28.000 --> 1:35:46.000
 And so it's a really interesting spectrum. And in the end, you try to capture these special cases in a way that is cleanly augmentations of the existing tech stack because a majority of what we're solving is actually generalizable to freeway driving and different platforms.

1:35:46.000 --> 1:35:54.000
 And over time, they all start to kind of merge ideally where the things that are unique are as minimal as possible.

1:35:54.000 --> 1:36:05.000
 And that's where you get the most leverage. And that's why Waymo can take on two trillion dollar opportunities and have been nowhere near 2x the cost or investment or size.

1:36:05.000 --> 1:36:10.000
 In fact, it's much, much smaller than that because of the high degree of leverage.

1:36:10.000 --> 1:36:21.000
 So what kind of sensor suite they can speak to that a long haul truck needs to have? Lidar, vision, how many? What are we talking about here?

1:36:21.000 --> 1:36:27.000
 Yeah, so it's more than the car. So very loosely you can think of it as like 2x, but it varies depending on the sensor.

1:36:27.000 --> 1:36:33.000
 And so we have like dozens of cameras, radar, and then multiple Lidar as well.

1:36:33.000 --> 1:36:42.000
 You'll see one difference where the cars have a central main sensor pod on the roof in the middle and then some kind of hood sensors for blind spots.

1:36:42.000 --> 1:36:48.000
 The truck moves to two main sensor pods on the outsides where you would typically have the mirrors next to the driver.

1:36:48.000 --> 1:36:59.000
 They effectively go as far out as possible, kind of up to the front, kind of on the cabin, not all the way in the front, but like kind of where the mirrors for the driver would be.

1:36:59.000 --> 1:37:08.000
 And so those are the main sensor pods. And the reason they're there is because if you had one in the middle, the trailer is higher than the cabin and you would be occluded with this like awkward wedge.

1:37:08.000 --> 1:37:09.000
 Too much occlusion.

1:37:09.000 --> 1:37:15.000
 Too much occlusion. And so then you would add a lot of complexity to the software to make up for that and just unnecessary complexity.

1:37:15.000 --> 1:37:17.000
 There's so many probably fascinating design choices here.

1:37:17.000 --> 1:37:18.000
 It's really cool.

1:37:18.000 --> 1:37:21.000
 Because you can probably bring up a Lidar higher and have it in the center or something.

1:37:21.000 --> 1:37:27.000
 You could have all kinds of choices to make the decisions here that ultimately probably will define the industry.

1:37:27.000 --> 1:37:30.000
 Right. But by having two on the side, there's actually multiple benefits.

1:37:30.000 --> 1:37:36.000
 So one is like you're just beyond the trailer so you can see fully flush with the trailer.

1:37:36.000 --> 1:37:43.000
 And so you eliminate most of your blind spot except for right behind the trailer, which is great because now the software carries over really well.

1:37:43.000 --> 1:37:51.000
 And the same perception system you use on the car side, largely that architecture can carry over and you can retrain some models and so forth that you leverage it a lot.

1:37:51.000 --> 1:38:01.000
 It also actually helps with redundancy where there's a really not nice built in redundancy for all the Lidar cameras and radar where you can afford to have any one of them fail and you're still OK.

1:38:01.000 --> 1:38:04.000
 And at scale, every one of them will fail.

1:38:04.000 --> 1:38:13.000
 And you will be able to detect when one of them fails because they don't because the redundancy that they're giving you the data that's inconsistent with the rest of that's right.

1:38:13.000 --> 1:38:23.000
 And it's not just like they no longer give data. It could be like they're fouled or they stop giving data where some electrical thing gets cut or part of your compute goes down.

1:38:23.000 --> 1:38:30.000
 So what's neat is that like you have way more sensors. Part of his field of view and occlusions, part of its redundancy and part of it is new use cases.

1:38:30.000 --> 1:38:47.000
 So there's new types of sensors to optimize for long range and kind of the sensing horizon that we look for on our vehicles that is unique to trucks because it actually is like kind of much like further out than than a car.

1:38:47.000 --> 1:38:57.000
 But a majority are actually used across both cars and trucks. And so we use the same compute, the same fundamental baseline sensors, cameras, radar, IMUs.

1:38:57.000 --> 1:39:01.000
 And so you get a great leverage from all of the infrastructure and the hardware development as a result.

1:39:01.000 --> 1:39:10.000
 So what about cameras? What role does. So LIDAR is this rich set of information that has its strengths, has some weaknesses.

1:39:10.000 --> 1:39:16.000
 Camera is this rich source of information that has some strengths, has its weaknesses.

1:39:16.000 --> 1:39:25.000
 What role does LIDAR play? What role does vision cameras play in this beautiful problem of autonomous trucking?

1:39:25.000 --> 1:39:28.000
 It is beautiful. There's like so much that comes together.

1:39:28.000 --> 1:39:31.000
 And how much and at which point do they come together?

1:39:31.000 --> 1:39:45.000
 Yeah. So I'll start with LIDAR. So LIDAR has been like Waymo's, one of Waymo's big strengths and advantages where we developed our own LIDAR in house where many generations in both in cost and functionality.

1:39:45.000 --> 1:39:49.000
 It is the best in this space.

1:39:49.000 --> 1:39:56.000
 Which generation? Because I know there's this there's this cool. I mean, I love versions that are increasing.

1:39:56.000 --> 1:40:01.000
 Which version of the hardware stack is it currently, officially, publicly?

1:40:01.000 --> 1:40:05.000
 So some parts iterate more than others. I'm trying to remember on the sensor side.

1:40:05.000 --> 1:40:10.000
 So the entire self driving system, which includes sensors and compute, is fifth generation.

1:40:10.000 --> 1:40:19.000
 I can't wait until there's like iPhone style like announcements for like new versions of the Waymo hardware.

1:40:19.000 --> 1:40:24.000
 Well, we try to be careful because, man, when you change the hardware, it takes a lot to like retrain the models and everything.

1:40:24.000 --> 1:40:27.000
 So we just went through that and going from the Pacificus to the Jaguars.

1:40:27.000 --> 1:40:31.000
 And so the Jaguars and then the trucks are, you know, have the same generation now.

1:40:31.000 --> 1:40:36.000
 But yeah, the LIDAR is it's incredible. And so Waymo has leaned into that as a strength.

1:40:36.000 --> 1:40:46.000
 And so a lot of the near range perception system that obviously kind of carries over a lot from the car side uses LIDAR as a very prominent kind of like primary sensor.

1:40:46.000 --> 1:40:49.000
 But then obviously everything has its strengths and weaknesses.

1:40:49.000 --> 1:41:01.000
 And so in the near range, LIDAR is a gigantic advantage and it has its weaknesses on when it comes to occlusions in certain areas, rain and weather, like things like that.

1:41:01.000 --> 1:41:13.000
 But it's an incredible sensor and it gives you incredible density, perfect location precision and consistency, which is a very valuable property to be able to kind of apply ML approaches.

1:41:13.000 --> 1:41:15.000
 Can you elaborate consistency?

1:41:15.000 --> 1:41:26.000
 Yeah. When you have a camera, the position of the sun, the time of the day, various of the properties can have a big impact, whether there's glare, the field of view, things like that.

1:41:26.000 --> 1:41:34.000
 So consistent in the face of a changing external environment, the signal.

1:41:34.000 --> 1:41:45.000
 Yeah. Daytime, nighttime. It's about 3D physical existence, in effect, like you're seeing beams of light that physically bounce off of something and come back.

1:41:45.000 --> 1:42:00.000
 And so whatever the conditional conditions are, like the shape of a human sensor reading from a human or from a car or from an animal, like you have a reliability there, which ends up being valuable for kind of like the long tail of challenges.

1:42:00.000 --> 1:42:16.000
 So LIDAR is the first sensor to drop off in terms of range and ours has a really good range, but at the end of the day, it drops off. And so particularly for trucks, on top of the general redundancy that you want for near range and complements through cameras and radar for occlusions and for complementary information and so forth,

1:42:16.000 --> 1:42:27.000
 when you get the long range, you have to be radar and camera primary because your LIDAR data will fundamentally drop off after a period of time and you have to be able to see kind of objects further out.

1:42:27.000 --> 1:42:40.000
 Now, cameras have the incredible range where you get a high density, high resolution camera, you can get data, you know, well past a kilometer and it's like really potentially a huge value.

1:42:40.000 --> 1:42:54.000
 Now, the signal drops off, the noise is higher, detecting is harder, classifying is harder and one that you may not think about localizing is harder because you can be off by like two meters and where something's located a kilometer away.

1:42:54.000 --> 1:43:01.000
 And that's the difference between being on the shoulder and being in your lane. And so you have like interesting challenges there that you have to solve, which have a bunch of approaches that come into it.

1:43:01.000 --> 1:43:12.000
 Radar is interesting because it also has longer range than LIDAR and it gives you speed information.

1:43:12.000 --> 1:43:24.000
 So it becomes very, very useful for dynamic information of traffic flow, vehicle motions, animals, pedestrians, like just things that might be useful signals.

1:43:24.000 --> 1:43:30.000
 And it helps with weather conditions where radar actually penetrates weather conditions in a better way than other sensors.

1:43:30.000 --> 1:43:46.000
 And so it's kind of interesting where we've kind of started to converge towards not thinking about a problem as a LIDAR problem or a camera problem or radar problem, but it's a fusion problem where these are all like large scale ML problems where you put data into the system.

1:43:46.000 --> 1:44:01.000
 And in many cases, you just look for the signals that might be present in the union of all of these and leave it to the system as much as possible to start to really identify how to how to extract that. And then there's places we have to intervene and actually include more.

1:44:01.000 --> 1:44:08.000
 But no single sensor is in a great position to really solve this problem and then without a huge extra challenge.

1:44:08.000 --> 1:44:24.000
 That's fascinating. There's a question that's probably still an open question is at which point do you fuse them? Do you solve the perception problem for each sensor suite individually, the LIDAR suite and the camera suite?

1:44:24.000 --> 1:44:35.000
 Or do you do some kind of heterogeneous fusion or do you fuse at the very beginning? Is there a good answer or at least an inkling of intuitions you can come up with?

1:44:35.000 --> 1:44:53.000
 Yeah, so people refer to this as early fusion or late fusion. So late fusion might be that you have the camera pipeline, the LIDAR pipeline, and then you fuse them and when it gets to final semantics and classification and tracking, you fuse them together and figure out which one's best.

1:44:53.000 --> 1:45:07.000
 There's more and more evidence that early fusion is important, and that is because late fusion does not allow you to pick up on the complementary strengths and weaknesses of the sensors.

1:45:07.000 --> 1:45:24.000
 Weather is a great example where if you do early fusion, you have an incredibly hard problem for any single sensor in rain to solve that problem because you have reflections from the LIDAR, you have weird kind of noise from the camera, blah, blah, blah.

1:45:24.000 --> 1:45:32.000
 But the combination of all of them can help you filter and help you get to the real signal that then gets you as close as possible to the original stack.

1:45:32.000 --> 1:45:48.000
 And be much more fluid about the strengths and weaknesses where your camera is much more susceptible to fouling on the actual lens from rain or random stuff, whereas you might be a little bit more resilient in other sensors.

1:45:48.000 --> 1:46:06.000
 So there's an element of logic that always happens late in the game, but that fusion early on, especially as you move towards ML and large scale data driven approaches, just maximizes your ability to pull out the best signal you can out of each modality before you start making constraining decisions that end up being hard to unwind late in the stack.

1:46:06.000 --> 1:46:16.000
 So how much of this is a machine learning problem? What role does ML, machine learning, play in this whole problem of autonomous driving, autonomous trucking?

1:46:16.000 --> 1:46:32.000
 It's massive, and it's increasing over time. If you go back to the grand challenge days and the early days of AV development, there was ML, but it was not in the mass scale data style of ML.

1:46:32.000 --> 1:46:46.000
 It was like learning models, but in a more structured kind of way. And it was a lot of heuristic and search based approaches and planning and so forth. You can make a lot of progress with these types of approaches kind of across the board and almost deceptive amount of progress.

1:46:46.000 --> 1:46:59.000
 We can get pretty far, but then you start to really grind the further you get in some parts of the stack if you don't have an ability to absorb a massive amount of experience in a way that scales very sublinearly in terms of human labor and human attention.

1:46:59.000 --> 1:47:16.000
 And so when you look at the stack, the perception side is probably the first to get really revolutionized by ML, and it goes back many years because ML for computer vision and these types of approaches kind of took off with a lot of the early kind of push in deep learning.

1:47:16.000 --> 1:47:30.000
 And so there's always a debate on the spectrum between end to end ML, which is a little bit too far to how you architect it to where you have modules, but enough ability to think about long tail problems and so forth.

1:47:30.000 --> 1:47:49.000
 But at the end of the day, you have big parts of system that are very ML and data driven, and we're increasingly moving in that direction all the way across the board, including behavior where even when it's not like a gigantic ML problem that covers like a giant swath end to end,

1:47:49.000 --> 1:47:55.000
 more and more parts of the system have this property where you want to be able to put more data into it and it gets better.

1:47:55.000 --> 1:48:12.000
 And that has been one of the realizations as you drive tens of millions of miles and try to solve new expansions of domains without regressing your old ones, it becomes intractable for a human to approach that in the way that traditionally robotics has kind of approached some elements of the tech stack.

1:48:12.000 --> 1:48:30.000
 So are you trying to create a data pipeline specifically for the trucking problem? How much leveraging of the autonomous driving is there in terms of data collection? And how unique is the data required for the trucking problem?

1:48:30.000 --> 1:48:46.000
 So we reuse all the same infrastructure, so labeling workflows, ML workflows, everything, so that actually carries over quite well. We heavily reuse the data even, where almost every model that we have on a truck, we started with the latest car model.

1:48:46.000 --> 1:48:49.000
 So it's almost like a good back arm model.

1:48:49.000 --> 1:49:03.000
 Yeah, it's like you can think of like, despite the different domain and different numbers of sensors and position of sensors, there's a lot of signals that carry over across driving. And so it's almost like pre training and getting a big boost out of the gate where you can reduce the amount of data you need by a lot.

1:49:03.000 --> 1:49:09.000
 And it goes both ways, actually. And so we're increasingly thinking about our data strategy on how we leverage both of these.

1:49:09.000 --> 1:49:19.000
 So you think about, you know, how other agents react to a truck. Yeah, it's a little bit different, but the fundamentals are actually like, what will other vehicles in the road do? There's a lot of carry over that's possible.

1:49:19.000 --> 1:49:26.000
 And in fact, just to give you an example, we're constantly kind of like adding more data from the trucking side.

1:49:26.000 --> 1:49:38.000
 But as of right now, when we think of our, like one of our models, behavior prediction for other agents on the road, like vehicles, 85% of that data comes from cars.

1:49:38.000 --> 1:49:50.000
 And a lot of that 85% comes from surface streets, because we just had so much of it, and it was really valuable. And so we're adding in more and more, particularly in the areas where we need more data, but you get a huge boost out of the gate.

1:49:50.000 --> 1:49:56.000
 Just all different visual characteristics of roads, lane markings, pedestrians, all that that's still relevant.

1:49:56.000 --> 1:50:05.000
 It's all still relevant. And then just the fundamentals of how, you know, you detect the car. Does it really change that much, whether you're detecting it from a car or a truck?

1:50:05.000 --> 1:50:10.000
 The fundamentals of how a person will walk around your vehicle is that it'll change a little bit.

1:50:10.000 --> 1:50:16.000
 But the basics, like there's a lot of signal in there that as a starting point to a network can actually be very valuable.

1:50:16.000 --> 1:50:20.000
 Now, we do have some very unique challenges where there's a sparsity of events on a freeway.

1:50:20.000 --> 1:50:35.000
 The frequency of events happening on a freeway, whether it's interesting objects in the road or incidents or even like from a human benchmark, like how often does a human have an accident on a freeway is far more sparse than on a surface street.

1:50:35.000 --> 1:50:43.000
 And so that leads to really interesting data problems where you can't just drive infinitely to encounter all the different permutations of things you might encounter.

1:50:43.000 --> 1:50:50.000
 And so there you get into interesting tools like structure testing and data collection, data augmentation and so forth.

1:50:50.000 --> 1:50:59.000
 And so there's really interesting kind of technical challenges that push some of the research that enables these new new suites of approaches.

1:50:59.000 --> 1:51:06.000
 What role does simulation play? Really good question. So Waymo simulates about a thousand miles for every mile it drives.

1:51:06.000 --> 1:51:18.000
 So you think of in both. So across the board, across the board. Yeah. So you think of, for example, well, if we've driven over 20 million miles, that's over 20 billion miles in simulation.

1:51:18.000 --> 1:51:25.000
 Now, how do you use simulation? It's a multipurpose. So you use it for basic development.

1:51:25.000 --> 1:51:32.000
 So you want to do make sure you have regression, prevention and protection of everything you're doing. Right. That's an easy one.

1:51:32.000 --> 1:51:38.000
 When you encounter something interesting in the world, let's say there was an issue with how the vehicle behaved versus an ideal human.

1:51:38.000 --> 1:51:46.000
 You can play that back in simulation and start augmenting your system and seeing how you would have reacted to that scenario with this improvement or this new area.

1:51:46.000 --> 1:51:51.000
 You can create scenarios that become part of your regression set after that point.

1:51:51.000 --> 1:51:58.000
 Then you start getting into like really, really kind of hill climbing where you say, hey, I need to improve this system.

1:51:58.000 --> 1:52:04.000
 I have these metrics are really correlated with final performance. How do I know how well I'm doing operation?

1:52:04.000 --> 1:52:08.000
 The actual physical driving is the least efficient form of testing and it's expensive.

1:52:08.000 --> 1:52:20.000
 It's time consuming. So grabbing a large scale batch of historical data and simulating it to get a signal of over these last or just random sample of one hundred thousand miles.

1:52:20.000 --> 1:52:28.000
 How has this metric changed versus where we are today? You can do that far more efficiently in simulation than just driving with that new system on board.

1:52:28.000 --> 1:52:39.000
 And then you go all the way to the validation phase where to actually see your human relative safety of like how well are you performing on the car side or the trucking side relative to a human.

1:52:39.000 --> 1:52:53.000
 A lot of that safety case is actually driven by taking all of the physical operational driving, which probably includes a lot of interventions where the driver took over just in case.

1:52:53.000 --> 1:52:59.000
 And then you simulate those forward and see if would anything have happened. And in most cases, the answer is no.

1:52:59.000 --> 1:53:07.000
 But you can simulate it forward and you can even start to do really interesting things where you add virtual agents to create harder environments.

1:53:07.000 --> 1:53:15.000
 You can fuzz the locations of physical agents. You can muck with the scene and stress test the scenario from a whole bunch of different dimensions.

1:53:15.000 --> 1:53:23.000
 And effectively, you're trying to like more efficiently sample this like infinite dimensional space, but try to encounter the problems as fast as possible.

1:53:23.000 --> 1:53:31.000
 Because what most people don't realize is the hardest problem in autonomous driving is actually the evaluation problem in many ways, not the actual autonomy problem.

1:53:31.000 --> 1:53:39.000
 And so if you could, in theory, evaluate perfectly and instantaneously, you can solve that problem in a really fast feedback loop quite well.

1:53:39.000 --> 1:53:51.000
 But the hardest part is being really smart about this suite of approaches on how can you get an accurate signal on how well you're doing as quickly as possible in a way that correlates to physical driving.

1:53:51.000 --> 1:54:00.000
 Can you explain the evaluation problem? Which metric are you evaluating towards? Are we talking about safety? What are the performance metrics that we're talking about?

1:54:00.000 --> 1:54:10.000
 So in the end, you care about end safety. That's what's deceptive where there's a lot of companies that have a great demo.

1:54:10.000 --> 1:54:18.000
 The path from a really great demo to being able to go driverless can be deceptively long, even when that demo looks like it's driverless quality.

1:54:18.000 --> 1:54:23.000
 And the difference is that the thing that keeps you from going driverless is not the stuff you encounter in a demo.

1:54:23.000 --> 1:54:27.000
 It's the stuff that you encounter once at 100,000 miles or 500,000 miles.

1:54:27.000 --> 1:54:36.000
 And so that is at the root of what is most challenging about going driverless because any issue you encounter, you can go and fix it.

1:54:36.000 --> 1:54:40.000
 But how do you know you didn't create five other issues that you haven't encountered yet?

1:54:40.000 --> 1:54:52.000
 So those were painful learnings in Waymo's history that Waymo went through and led to us then finally being able to go driverless in Phoenix and now are at the heart of how we develop.

1:54:52.000 --> 1:55:00.000
 Evaluation is simultaneously evaluating final kind of end safety of how ready are you to go driverless,

1:55:00.000 --> 1:55:12.000
 which may be as direct as what is your collision, human relative kind of collision rate for all these types of scenarios and

1:55:12.000 --> 1:55:17.000
 and severities to make sure that you're better than a human bar by a good amount.

1:55:17.000 --> 1:55:19.000
 But that's not actually the most useful for development.

1:55:19.000 --> 1:55:28.000
 For development, it's much more kind of analog metrics that are part of the art of finding how,

1:55:28.000 --> 1:55:40.000
 what are the properties of driving that give you a way quicker signal that's more sensitive than a collision that can correlate to the quality you care about and push the feedback loop to all of your development?

1:55:40.000 --> 1:55:49.000
 A lot of these are, for example, comparisons to human drivers, like manual drivers. How do you do relative to a human driver in various dimensions of various circumstances?

1:55:49.000 --> 1:55:55.000
 Can I ask you a tricky question? So if I brought you a truck, how would you test it?

1:55:55.000 --> 1:55:58.000
 Okay, Alan Turing came along and you said,

1:55:58.000 --> 1:56:01.000
 This one can't tell if it's a human driver or autonomous driver.

1:56:01.000 --> 1:56:06.000
 Yeah, exactly. But not the human because, you know, humans are flawed.

1:56:06.000 --> 1:56:11.000
 How do you actually know you're ready, basically? How do you know it's good enough?

1:56:11.000 --> 1:56:22.000
 And by the way, this is the reason why Waymo released the safety framework for the car side, because one, it sets the bar so nobody cuts below it and does something bad for the field that causes an accident.

1:56:22.000 --> 1:56:30.000
 And two, it's to start the conversation on framing what does this need to look like? Same thing we'll end up doing for the trucking side.

1:56:30.000 --> 1:56:39.000
 It ends up being different portfolio of approaches. There's easy things like, are you compliant with all these fundamental rules of the road?

1:56:39.000 --> 1:56:42.000
 Like you never drive above the speed limit. That's actually pretty easy.

1:56:42.000 --> 1:56:57.000
 You can fundamentally prove that it's either impossible to violate that rule or that you can itemize the scenarios where that comes up and you can do a test and show that you pass that test and therefore you can handle that scenario.

1:56:57.000 --> 1:57:09.000
 And so those are like traditional structure testing kind of system engineering approaches where you can just, like fault rates is another example where when something fails, how do you deal with it?

1:57:09.000 --> 1:57:24.000
 You're not going to drive and randomly wait for it to fail. You're going to force a failure and make sure that you can handle it and close courses and simulation or on the road and run through all the permutations of failures, which you can oftentimes for some parts of the system itemize like hardware.

1:57:24.000 --> 1:57:39.000
 The hardest part is behavioral where you have just infinite situations that could in theory happen and you want to figure out the combinations of approaches that can work there.

1:57:39.000 --> 1:57:49.000
 You can probably pass the Turing test pretty quickly, even if you're not like completely ready for driverless because the events that are really kind of like hard will not happen that often.

1:57:49.000 --> 1:58:04.000
 Just to give you a perspective, a human has a serious accident on a freeway, like a truck driver on a freeway. There's a serious event happens once every 1.3 million miles and something that actually has like really serious injuries, 28 million miles.

1:58:04.000 --> 1:58:11.000
 And so those are really rare. And so you could have a driver that looks like it's ready to go, but you have no signal on what happens there.

1:58:11.000 --> 1:58:28.000
 And so that's where you start to get creative on combinations of sampling and statistical arguments, focused structured arguments where you can kind of simulate those scenarios and show that you can handle them and metrics that are correlated with what you care about,

1:58:28.000 --> 1:58:33.000
 but you can measure much more quickly and get to a right answer. And that's what makes it pretty hard.

1:58:33.000 --> 1:58:46.000
 And in the end, you end up borrowing a lot of properties from aerospace and like space shuttles and so forth where you don't get the chance to launch it a million times just to say you're ready because it's too expensive to fail.

1:58:46.000 --> 1:58:58.000
 And so you go through a huge amount of kind of structured approaches in order to validate it. And then by thoroughness, you can make a strong argument that you're ready to go.

1:58:58.000 --> 1:59:08.000
 This is actually a harder problem in a lot of ways, though, because you can think of a space shuttle as getting to a fixed point and then you kind of like or an airplane and you like freeze the software and then you like prove it and you're good to go.

1:59:08.000 --> 1:59:15.000
 Here you have to get to a driverless quality bar, but then continue to aggressively change the software even while you're driverless.

1:59:15.000 --> 1:59:28.000
 And also the full range of environment that you there's an external environment where the shuttle is you're basically testing the like the systems, the internal stuff. Yeah. And you have a lot of control in the external stuff.

1:59:28.000 --> 1:59:32.000
 Yeah. And the hard part is how do you know you didn't get worse in something that you just changed?

1:59:32.000 --> 1:59:43.000
 Yes. Sure. And so so in a lot of ways, like the Turing test starts to fail pretty quickly because you start to feel driverless quality pretty early in that curve.

1:59:43.000 --> 1:59:50.000
 And if you think about it, right, like in most most kind of, you know, really good A.V. demos, maybe you'll sit there for 30 minutes.

1:59:50.000 --> 1:59:57.000
 Right. Yeah. So you've driven, you know, 15 miles or something like that to go driverless.

1:59:57.000 --> 2:00:01.000
 Like what's the sort of rate of issues that you need to have? You won't even encounter.

2:00:01.000 --> 2:00:07.000
 So let's try something different then. Let's try a different version of the Turing test, which is like an IQ test.

2:00:07.000 --> 2:00:14.000
 So there's these difficult questions of increasing difficulty. They're very they're they're designed.

2:00:14.000 --> 2:00:18.000
 You don't know them ahead of time. Nobody knows the answer to them. Right.

2:00:18.000 --> 2:00:25.000
 And so is it possible to in the future orchestrate basically really difficult course almost of like. Yeah.

2:00:25.000 --> 2:00:34.000
 That maybe change every year. And that represent if you can pass these, they don't necessarily represent the full spectrum.

2:00:34.000 --> 2:00:38.000
 That's it. Yeah. They won't be conclusive, but you can at least get a really quick read and filter.

2:00:38.000 --> 2:00:42.000
 Yeah. Like you're able to. Yeah. Because you didn't know them ahead of time. Like, I don't know.

2:00:42.000 --> 2:00:49.000
 Probably like construction zones, failures or or driving anywhere in Russia. Yeah. Yeah.

2:00:49.000 --> 2:00:59.000
 Snow, weather, cut ins, dense traffic, kind of merging, lane closures, animal foreign objects on a road that pop out on short notice,

2:00:59.000 --> 2:01:08.000
 mechanical failures, sensor breaking, tire popped, weird behaviors by other vehicles like a heartbreak, something reckless that they've done,

2:01:08.000 --> 2:01:12.000
 fouling of sensors like bugs or birds, you know, poop or something.

2:01:12.000 --> 2:01:21.000
 So but yeah, like you have these like kind of like extreme conditions where like you have a nasty construction zone where everything shuts down and you have to like, you know,

2:01:21.000 --> 2:01:25.000
 get pulled to the other side of the freeway with a temporary lane like that. Right.

2:01:25.000 --> 2:01:33.000
 Those are sort of conditions where we do that to ourselves. Right. We itemize everything that could possibly happen to give you a starting point to how to think about what you need to develop.

2:01:33.000 --> 2:01:36.000
 And at the end of the day, there's no substitute for real miles.

2:01:36.000 --> 2:01:44.000
 Like if you think of traditional ML, like, you know how there's like a validation set where you hold out some data and like real world driving is the ultimate validation set.

2:01:44.000 --> 2:01:49.000
 That's the in the end, like the cleanest signal. But you can do a really good job on creating an obstacle course.

2:01:49.000 --> 2:02:00.000
 And you're absolutely right. Like at the end, if there was such a thing as automating and kind of a readiness, it would be these extreme conditions like a red light runner.

2:02:00.000 --> 2:02:07.000
 Right. A really reckless pedestrian that's jaywalking, a cyclist that, you know, makes like a really awkward maneuver.

2:02:07.000 --> 2:02:11.000
 That's actually what keeps you from going driverless. Like in the end, that is the long tail.

2:02:11.000 --> 2:02:23.000
 Yeah. And it's interesting to think about that. That to me is the Turing test. Turing test means a lot of things. But to me, in driving, the Turing test is exactly this validation set that is handcrafted.

2:02:23.000 --> 2:02:33.000
 I don't know if you know him. There's a guy named Francois Chollet. He thinks about like how to design a test for general intelligence.

2:02:33.000 --> 2:02:45.000
 He designs these IQ tests for machines. And the validation set for him is handcrafted. And that it requires like human genius or ingenuity to create a really good test.

2:02:45.000 --> 2:02:54.000
 And you hold, you truly hold it out. It's an interesting perspective on the validation set, which is like, make that as hard as possible.

2:02:54.000 --> 2:02:59.000
 Not a generic representation of the data, but this is the hardest.

2:02:59.000 --> 2:03:05.000
 The hardest. Yeah. You know, it's like go. Like you'll never fully itemize like all the world states that you'll expand.

2:03:05.000 --> 2:03:13.000
 And so you have to come up with different approaches. And this is where you start hitting the struggles of ML, where ML is fantastic at optimizing the average case.

2:03:13.000 --> 2:03:24.000
 It's a really unique craft to think about how you deal with the worst case, which is what we care about in the AV space when using an ML system on something that occurs like super infrequently.

2:03:24.000 --> 2:03:29.000
 So like you don't care about the worst case really on ads because if you miss a few, it's not a big deal.

2:03:29.000 --> 2:03:36.000
 But you do care about it on the driving side. And so typically like you'll never fully enumerate the world.

2:03:36.000 --> 2:03:49.000
 And so you have to take a step back and abstract away what are the signals that you care about and the properties of a driver that correlate to defensive driving and avoiding nasty situations.

2:03:49.000 --> 2:03:58.000
 That even though you'll always be surprised by things you'll encounter, you feel good about your ability to generalize from what you've learned.

2:03:58.000 --> 2:04:15.000
 All right. Let me ask you a tricky question. So to me, the two companies that are building at scale some of the most incredible robots ever built is Waymo and Tesla.

2:04:15.000 --> 2:04:23.000
 So there's very distinct approaches technically, philosophically in these two systems.

2:04:23.000 --> 2:04:31.000
 Let me ask you to play sort of devil's advocate and then the devil's advocate to the devil's advocate.

2:04:31.000 --> 2:04:43.000
 It's a bit of a race. Of course, everyone can win. But if Waymo wins this race to level four, why would they win?

2:04:43.000 --> 2:04:55.000
 What aspect of the approach do you think would be the winning aspect? And if Tesla wins, why would they win and which aspect of their approach would be the reason?

2:04:55.000 --> 2:05:01.000
 Just building some intuition, almost not from a business perspective, from any of that, just technically.

2:05:01.000 --> 2:05:15.000
 Yeah. And we could summarize, I think maybe you can correct me, one of the more distinct aspects is Waymo has a richer suite of sensors as LIDAR and vision.

2:05:15.000 --> 2:05:24.000
 Tesla now removed radar. They do vision only. Tesla has a larger fleet of vehicles operated by humans.

2:05:24.000 --> 2:05:32.000
 So it's already deployed on the field and it's a larger, what do you call it, operational domain.

2:05:32.000 --> 2:05:38.000
 And then Waymo is more focused on a specific domain and growing it with fewer vehicles.

2:05:38.000 --> 2:05:44.000
 So both are fascinating approaches. I think there's a lot of brilliant ideas. Nobody knows the answer.

2:05:44.000 --> 2:05:48.000
 So I'd love to get your comments on this lay of the land.

2:05:48.000 --> 2:05:51.000
 Yeah, for sure. So maybe I'll start with Waymo.

2:05:51.000 --> 2:06:00.000
 And you're right, both incredible companies and just a gigantic respect to everything Tesla has accomplished and how they pushed the field forward as well.

2:06:00.000 --> 2:06:08.000
 So on the Waymo side, there is a fundamental advantage in the fact that it is focused and geared towards L4 from the very beginning.

2:06:08.000 --> 2:06:17.000
 We've customized the sensor suite for it, the hardware, the compute, the infrastructure, the tech stack and all of the investment inside the company.

2:06:17.000 --> 2:06:28.000
 That's deceptively important because there's like a giant spectrum of problems you have to solve in order to really do this from infrastructure to hardware to autonomy stack to the safety framework.

2:06:28.000 --> 2:06:36.000
 And that's an advantage because there's a reason why it's the fifth generation hardware and why all of those learnings went into the Dimore program.

2:06:36.000 --> 2:06:43.000
 It becomes such an advantage because you learn a lot as you drive and you optimize for the best information you have.

2:06:43.000 --> 2:06:58.000
 But fundamentally, like there's a big, big jump, like every order of magnitude that you drive in numbers of miles and what you learn and the gap from really kind of like decent progress for L2 and so forth to what it takes to actually go L4.

2:06:58.000 --> 2:07:04.000
 And at the end of the day, there's a feeling that Waymo has there's a long way to go.

2:07:04.000 --> 2:07:19.000
 Nobody's won, but there's a lot of advantages in all of these buckets where it's the only company that has shipped a fully driverless service where you can go and you can use it and it's at a decently sizable scale.

2:07:19.000 --> 2:07:23.000
 And those learnings can feed forward to how to solve the more general problems.

2:07:23.000 --> 2:07:26.000
 And you see this process you've deployed in Chandler.

2:07:26.000 --> 2:07:30.000
 You don't know the timeline exactly, but you could see the steps.

2:07:30.000 --> 2:07:36.000
 They seem almost incremental. It's become more engineering than totally blind R&D.

2:07:36.000 --> 2:07:40.000
 It works in one place and then you move to another place and you grow it this way.

2:07:40.000 --> 2:07:55.000
 And just to give you an example, like we fundamentally changed our hardware and our software stack almost entirely from what went driverless in Phoenix to what is the current generation of the system on both sides because the things that got us to driverless,

2:07:55.000 --> 2:08:08.000
 even though it got to driverless way beyond human relative safety, it is fundamentally not well set up to scale in an exponential fashion without getting into huge kind of scaling pains.

2:08:08.000 --> 2:08:10.000
 And so those learnings you just can't shortcut.

2:08:10.000 --> 2:08:11.000
 And so that's an advantage.

2:08:11.000 --> 2:08:20.000
 And so there's a lot of open challenges to kind of get through, technical, organizational, like how do you solve problems that are increasingly broad and complex like this, work on multiple products.

2:08:20.000 --> 2:08:25.000
 But there's the feeling that, okay, like balls in our court, there's a head start there.

2:08:25.000 --> 2:08:26.000
 Now we've got to go and solve it.

2:08:26.000 --> 2:08:29.000
 And I think that focus on L4, it's a fundamentally different problem.

2:08:29.000 --> 2:08:35.000
 If you think about it, like let's say we were designing an L2 truck that was meant to be safer and help a human.

2:08:35.000 --> 2:08:45.000
 You could do that with far less sensors, far less complexity and provide value very quickly, arguably what we already have today just packaged up in a good product.

2:08:45.000 --> 2:08:55.000
 But you would take a huge risk in having a gap from even the like compute and sensors, not to mention the software, to then jump from that system to an L4 system.

2:08:55.000 --> 2:08:57.000
 So it's a huge risk basically.

2:08:57.000 --> 2:09:03.000
 So again, allow me to be the person that plays the devil's advocate and argue for the Tesla approach.

2:09:03.000 --> 2:09:08.000
 So what you just laid out makes perfect sense and is exactly right.

2:09:08.000 --> 2:09:30.000
 I have some open questions here, which is it's possible that investing more in faster data collection, which is essentially what Tesla is doing, will get us there faster if the sensor suite doesn't matter as much and machine learning can do a lot of the work.

2:09:30.000 --> 2:09:38.000
 My question is, how much is the thing you mentioned before, how much of driving can be end to end learned?

2:09:38.000 --> 2:09:39.000
 That's the open question.

2:09:39.000 --> 2:09:48.000
 Obviously, the Waymo and the vision only machine learning approach will solve driving eventually, both.

2:09:48.000 --> 2:09:50.000
 The question is of timeline, what's faster?

2:09:50.000 --> 2:09:51.000
 That's right.

2:09:51.000 --> 2:09:57.000
 And what you mentioned, like if I were to make the opposite argument, like what puts Tesla in the strongest position, it's data.

2:09:57.000 --> 2:10:05.000
 That is their superpower where they have an access to real world data effectively with a safety driver.

2:10:05.000 --> 2:10:11.000
 They found a way to get paid by safety drivers versus safer safety drivers.

2:10:11.000 --> 2:10:14.000
 It's brilliant.

2:10:14.000 --> 2:10:25.000
 But all joking aside, one, it is incredible that they've built a business that's incredibly successful that can now be a foundation and bootstrap really aggressive investment in the autonomy space.

2:10:25.000 --> 2:10:28.000
 If you can do it, that's always like an incredible kind of advantage.

2:10:28.000 --> 2:10:34.000
 And in the data aspect of it, it is a giant amount of data if you can use it the right way to then solve the problem.

2:10:34.000 --> 2:10:43.000
 But the ability to collect and filter through to the things that matter at real world scale, like a large distribution, that is huge.

2:10:43.000 --> 2:10:45.000
 Like it's a big advantage.

2:10:45.000 --> 2:10:48.000
 And so then the question becomes, can you use it in the right way?

2:10:48.000 --> 2:10:53.000
 And do you have the right software systems and hardware systems in order to solve the problem?

2:10:53.000 --> 2:11:03.000
 And you're right that in the long term, there's no reason to believe that pure camera systems can't solve the problem that humans obviously are solving with vision systems.

2:11:03.000 --> 2:11:06.000
 But it's a risk.

2:11:06.000 --> 2:11:09.000
 So there's no argument that it's not a risk.

2:11:09.000 --> 2:11:12.000
 And it's already such a hard problem.

2:11:12.000 --> 2:11:22.000
 And so much of that problem, by the way, is even beyond the perception side, some of the hardest elements of the problem on the behavioral side and decision making and the long tail safety case.

2:11:22.000 --> 2:11:34.000
 If you are adding risk and complexity on the input side from perception, you're now making a really, really hard problem, which on its own is still almost insurmountably hard, even harder.

2:11:34.000 --> 2:11:36.000
 And so the question is just how much.

2:11:36.000 --> 2:11:46.000
 And this is where you can easily get into a little bit of a kind of a trap where similar to how you how do you evaluate how good an AV company's product is.

2:11:46.000 --> 2:11:53.000
 Like you go and you do a trial kind of a test run with them, a demo run, which they've kind of optimized like crazy and so forth and like and it feels good.

2:11:53.000 --> 2:11:55.000
 Do you do you put any weight in that? Right.

2:11:55.000 --> 2:11:59.000
 You know that that gap is kind of like, you know, pretty large still.

2:11:59.000 --> 2:12:04.000
 Same thing on the like perception case, like the long tail of computer vision is really, really hard.

2:12:04.000 --> 2:12:08.000
 And there's a lot of ways that that can come up.

2:12:08.000 --> 2:12:20.000
 And even if it doesn't happen that often at all, when you think about the safety bar and what it takes to actually go full driverless, not like incredible assistance driverless, but full driverless, that bar gets crazy high.

2:12:20.000 --> 2:12:28.000
 And not only do you have to solve it on the behavioral side, but now you have to push computer vision beyond arguably where it's ever been pushed.

2:12:28.000 --> 2:12:32.000
 And so, you know, on top of the broader AV challenge, you have a really hard perception challenge as well.

2:12:32.000 --> 2:12:48.000
 So there's perception, there's planning, there's human robot interaction. To me, what's fascinating about what Tesla is doing is in this march towards level four, because it's in the hands of so many humans, you get to see video, you get to see humans.

2:12:48.000 --> 2:12:55.000
 I mean, forget companies, forget businesses. It's fascinating for humans to be interacting with robots.

2:12:55.000 --> 2:12:58.000
 That's incredible. And they're actually helping kind of push it forward.

2:12:58.000 --> 2:13:04.000
 And that is valuable, by the way, where even for us, a decent percentage of our data is human driving.

2:13:04.000 --> 2:13:14.000
 We intentionally have humans drive higher percentage than you might expect because that creates some of the best signals to train the autonomy. And so that is on its own a value.

2:13:14.000 --> 2:13:35.000
 So together, we're kind of learning about this problem in an applied sense, just like you had with Cosmo. When you're chasing an actual product that people are going to use, robot based product that people are going to use, you have to contend with the reality of what it takes to build a robot that successfully perceives the world and operates in the world.

2:13:35.000 --> 2:13:49.000
 And what it takes to have a robot that interacts with other humans in the world. And that's like, to me, one of the most interesting problems humans have ever undertaken because you're in trying to create an intelligent agent that operates in a human world.

2:13:49.000 --> 2:13:59.000
 You're also understanding the nature of intelligence itself. Like how hard is driving is still not answered to me.

2:13:59.000 --> 2:14:08.000
 Yeah, I still don't understand the subtle cues, like even little things like your interaction with a pedestrian where you look at each other and just go, OK, go.

2:14:08.000 --> 2:14:14.000
 Like that's hard to do without a human driver. Right. And you're missing that dimension. How do you communicate that?

2:14:14.000 --> 2:14:18.000
 So there's like really, really interesting kind of like elements here. Now, here's what's beautiful.

2:14:18.000 --> 2:14:36.000
 Can you imagine that like when autonomous driving is solved, how much of the technology foundation of that space can go and have like tremendous, just transformative impacts on other problem areas and other spaces that have subsets of these same problems?

2:14:36.000 --> 2:14:38.000
 Like, it's just incredible to think about that.

2:14:38.000 --> 2:14:53.000
 It's both a pro and a con is with autonomous driving is so safety critical. So once you solve it, it's beautiful because there's so many applications that are a lot less safety critical.

2:14:53.000 --> 2:15:07.000
 But it's also the con of that is it's so hard to solve. And the same journalists that you mentioned to get excited for a demo are the ones who write long articles about the failure of your company.

2:15:07.000 --> 2:15:17.000
 If there's one accident that's based on a robot, it's just society is so tense and waiting for failure of robots.

2:15:17.000 --> 2:15:24.000
 You're in such a high stake environment. Failure has such a high cost. And it slows down development. It slows down development.

2:15:24.000 --> 2:15:32.000
 Yeah, like the team like definitely noticed that like once you go driverless, like we're driverless in Phoenix and you continue to iterate, your iteration pace slows down

2:15:32.000 --> 2:15:45.000
 because your fear of regression forces so much more rigor that obviously you have to find a compromise on like, okay, well, how often do we release driverless builds?

2:15:45.000 --> 2:15:50.000
 Because every time you release a driverless build, you have to go through this like validation process, which is very expensive and so forth.

2:15:50.000 --> 2:16:03.000
 So it is interesting. It is one of the hardest things. There's no other industry where like you wouldn't release products way, way quicker when you start to kind of provide even portions of the value that you provide.

2:16:03.000 --> 2:16:05.000
 Healthcare maybe is the other one.

2:16:05.000 --> 2:16:06.000
 That's right.

2:16:06.000 --> 2:16:09.000
 But at the same time, right, like we've gotten there where you think of like surgery, right?

2:16:09.000 --> 2:16:14.000
 Like you have surgery, there's always a risk, but like it's really, really bounded.

2:16:14.000 --> 2:16:20.000
 You know that there's an accident rate when you go out and drive your car today, right? And you know what the fatality rate in the US is per year.

2:16:20.000 --> 2:16:29.000
 We're not banning driving because there was a car accident, but the bar for us is way higher and we hold ourselves very serious to it where you have to not only be better than a human,

2:16:29.000 --> 2:16:43.000
 but you probably have to like at scale be far better than a human by a big margin and you have to be able to like really, really thoughtfully explain all of the ways that we validate that becomes very comfortable for humans to understand

2:16:43.000 --> 2:16:46.000
 because a bunch of jargon that we use internally just doesn't compute.

2:16:46.000 --> 2:16:57.000
 At the end of the day, we have to be able to explain to society how do we quantify the risk and acknowledge that there is some nonzero risk, but it's far above a human relative safety.

2:16:57.000 --> 2:17:14.000
 See, here's the thing, to push back a little bit and bring Cosmo back in the conversation, you said something quite brilliant at the beginning of this conversation that I think probably applies for autonomous driving, which is, you know, there's this desire to make autonomous cars more safer than human driven cars.

2:17:14.000 --> 2:17:33.000
 But if you create a product that's really compelling and is able to explain both the leadership and the engineers and the product itself can communicate intent, then I think people may be able to be willing to put up with the thing that might be even riskier than humans

2:17:33.000 --> 2:17:37.000
 because they understand the value of taking risks.

2:17:37.000 --> 2:17:38.000
 You mentioned the speed limit.

2:17:38.000 --> 2:17:41.000
 Humans understand the value of going over the speed limit.

2:17:41.000 --> 2:17:48.000
 Humans understand the value of going fast through a yellow light.

2:17:48.000 --> 2:17:55.000
 When you're in Manhattan streets, pushing through crossing pedestrians, they understand that.

2:17:55.000 --> 2:17:59.000
 I mean, this is a much more tense topic of discussion, so this is just me talking.

2:17:59.000 --> 2:18:13.000
 So with Cosmo's case, there was something about the way this particular robot communicated, the energy it brought, the intent it was able to communicate to the humans that you understood that of course it needs to have a camera.

2:18:13.000 --> 2:18:15.000
 Of course it needs to have this information.

2:18:15.000 --> 2:18:20.000
 And in that same way, to me, of course a car needs to take risks.

2:18:20.000 --> 2:18:23.000
 Of course there's going to be accidents.

2:18:23.000 --> 2:18:31.000
 If you want a car that never has an accident, have a car that just doesn't go anywhere.

2:18:31.000 --> 2:18:37.000
 But that's tricky because that's not a robotics problem.

2:18:37.000 --> 2:18:41.000
 Many accidents are not even due to you, obviously.

2:18:41.000 --> 2:18:43.000
 So there's a big difference though.

2:18:43.000 --> 2:18:47.000
 That's not a personal decision.

2:18:47.000 --> 2:18:52.000
 You're also impacting obviously kind of the rest of the road and we're facilitating it.

2:18:52.000 --> 2:19:17.000
 And so there's a higher kind of ethical moral bar, which obviously then translates into as a society and from a regulatory standpoint, kind of like what comes out of it where it's hard for us to ever see this even being a debate in the sense that you have to be beyond reproach from a safety standpoint because if you're wrong about this, you could set the entire field back a decade.

2:19:17.000 --> 2:19:19.000
 See, this is me speaking.

2:19:19.000 --> 2:19:30.000
 I think if we look into the future, there will be, I personally believe, this is me speaking, that there will be less and less focus on safety.

2:19:30.000 --> 2:19:32.000
 It's still very, very high.

2:19:32.000 --> 2:19:36.000
 Meaning like after autonomy is very common and accepted.

2:19:36.000 --> 2:19:38.000
 Not so common as everywhere.

2:19:38.000 --> 2:19:46.000
 But there has to be a transition because I think for innovation, just like you were saying to explore ideas, you have to take risks.

2:19:46.000 --> 2:20:00.000
 And I think if autonomy in the near term is to become prevalent in society, I think people need to be more willing to understand the nature of risk, the value of risk.

2:20:00.000 --> 2:20:06.000
 It's very difficult, you're right, of course, with driving, but that's the fascinating nature of it.

2:20:06.000 --> 2:20:16.000
 It's a life and death situation that brings value to millions of people, so you have to figure out what do we value about this world?

2:20:16.000 --> 2:20:23.000
 How much do we value, how deeply do we want to avoid hurting other humans?

2:20:23.000 --> 2:20:24.000
 That's right.

2:20:24.000 --> 2:20:40.000
 And there is a point where you can imagine a scenario where Waymo has a system that is, even when it's beyond human relative safety and provably statistically will save lives,

2:20:40.000 --> 2:20:57.000
 there is a thoughtful navigation of that fact versus just kind of society readiness and perception and education of society and regulators and everything else,

2:20:57.000 --> 2:21:04.000
 where it's multidimensional and it's not a purely logical argument.

2:21:04.000 --> 2:21:15.000
 But ironically, the logic can actually help with the emotions. And just like any technology, there's early adopters and then there's kind of like a curve that happens after it.

2:21:15.000 --> 2:21:19.000
 And eventually celebrities, you get the rock in a Waymo vehicle and then everybody just comes along.

2:21:19.000 --> 2:21:23.000
 And then everybody calms down because the rock likes it.

2:21:23.000 --> 2:21:25.000
 If you post the...

2:21:25.000 --> 2:21:37.000
 And it's an open question on how this plays out. Maybe we're pleasantly surprised and people just realize that this is such an enabler of life and efficiency and cost and everything that there's a pull.

2:21:37.000 --> 2:21:51.000
 At some point, I should fully believe that this will go from a thoughtful kind of movement and tiptoeing and kind of like a push to society realizes how wonderful of an enabler this could become and it becomes more of a pull.

2:21:51.000 --> 2:22:00.000
 And hard to know exactly how that will play out. But at the end of the day, like both the goods transportation and the people transportation side of it has that property where it's not easy.

2:22:00.000 --> 2:22:07.000
 There's a lot of open questions and challenges to navigate. And there's obviously the technical problems to solve as a kind of prerequisite.

2:22:07.000 --> 2:22:28.000
 But they have such an opportunity that is on a scale that very few industries in the last 20, 30 years have even had a chance to tackle that I maybe we're pleasantly surprised by how much that tipping point like in a really short amount of time actually turns into a societal pull to kind of embrace the benefits of this.

2:22:28.000 --> 2:22:29.000
 Yeah, I hope so.

2:22:29.000 --> 2:22:40.000
 It seems like in the recent few decades, there's been tipping points for technologies where like overnight things change. It's like from taxis to ride sharing services, all that shift.

2:22:40.000 --> 2:22:45.000
 I mean, there's just shift after shift after shift that requires digitization to end technology.

2:22:45.000 --> 2:22:47.000
 I hope we're pleasantly surprising this.

2:22:47.000 --> 2:22:51.000
 So there's millions of long haul trucks now in the United States.

2:22:51.000 --> 2:23:07.000
 Do you see a future where there's millions of Waymo trucks and maybe just broadly speaking Waymo vehicles, just like ants running around the United States, freeways and local roads?

2:23:07.000 --> 2:23:09.000
 Yeah, in other countries too.

2:23:09.000 --> 2:23:22.000
 You look back decades from now and it might be one of those things that just feels so natural and then it becomes almost like this kind of interesting kind of oddity that we had none of it like, you know, kind of decades earlier.

2:23:22.000 --> 2:23:25.000
 And it'll take a long time to grow and scale.

2:23:25.000 --> 2:23:28.000
 Very different challenges appear at every stage.

2:23:28.000 --> 2:23:35.000
 But over time, like this is one of the most enabling technologies that we have in the world today.

2:23:35.000 --> 2:23:39.000
 It'll feel like, you know, how is the world before the Internet?

2:23:39.000 --> 2:23:40.000
 How is the world before mobile phones?

2:23:40.000 --> 2:23:42.000
 Like it's going to have that sort of a feeling to it on both sides.

2:23:42.000 --> 2:23:50.000
 It's hard to predict the future, but do you sometimes think about weird ways it might change the world, like surprising ways?

2:23:50.000 --> 2:23:55.000
 So obviously there's more direct ways where like there's increases efficiency.

2:23:55.000 --> 2:24:00.000
 It will enable a lot of kind of logistics, optimizations kind of things.

2:24:00.000 --> 2:24:07.000
 It will change probably our roadways and all that kind of stuff.

2:24:07.000 --> 2:24:11.000
 But it could also change society in some kind of interesting ways.

2:24:11.000 --> 2:24:15.000
 Do you ever think about how might change cities, how might change our lives, all that kind of stuff?

2:24:15.000 --> 2:24:16.000
 Yeah.

2:24:16.000 --> 2:24:23.000
 You can imagine city where people live versus work becoming more distributed because the pain of commuting becomes different, just easier.

2:24:23.000 --> 2:24:26.000
 And there's a lot of options that open up.

2:24:26.000 --> 2:24:39.000
 The layout of cities themselves and how you think about car storage and parking obviously just enables a completely different type of experience in urban environments.

2:24:39.000 --> 2:24:51.000
 I think there was like a statistic that something like 30 percent of the traffic in cities during rush hour is caused by pursuit of parking or like some really high stats.

2:24:51.000 --> 2:24:54.000
 So those obviously kind of open up a lot of options.

2:24:54.000 --> 2:25:03.000
 Flexibility on goods will enable new industries and businesses that never existed before because now the efficiency becomes more palatable.

2:25:03.000 --> 2:25:07.000
 Good delivery, timing, consistency and flexibility is going to change.

2:25:07.000 --> 2:25:10.000
 The way we distribute the logistics network will change.

2:25:10.000 --> 2:25:22.000
 The way we then can integrate with warehousing, with shipping ports, you can start to think about greater automation through the whole kind of stack and how that supply chain,

2:25:22.000 --> 2:25:34.000
 the ripples become much more agile versus like very grindy the way they are today where just the adaptation is like very tough and there's a lot of constraints that we have.

2:25:34.000 --> 2:25:36.000
 I think it'll be great for the environment.

2:25:36.000 --> 2:25:49.000
 It'll be great for safety where like probably about 95 percent of accidents today statistically are due to just attention or things that are preventable with the strengths of automation.

2:25:49.000 --> 2:25:56.000
 Yeah, and it'll be one of those things where industries will shift, but the net creation is going to be massively positive.

2:25:56.000 --> 2:26:03.000
 And then we just have to be thoughtful about the negative implications that will happen in local places and adjust for those.

2:26:03.000 --> 2:26:07.000
 But I'm an optimist in general for the technology where you could argue a negative on any new technology,

2:26:07.000 --> 2:26:14.000
 but you start to kind of see that if there is a big demand for something like this, in almost all cases,

2:26:14.000 --> 2:26:20.000
 that like it's an enabling factor that's going to kind of propagate through society.

2:26:20.000 --> 2:26:32.000
 And particularly as life expectancies get longer and so forth, like there's just a lot more need for a greater percentage of the population to kind of just be serviced with a high level of efficiency

2:26:32.000 --> 2:26:37.000
 because otherwise we're going to have a really hard time kind of scaling to what's ahead in the next 50 years.

2:26:37.000 --> 2:26:38.000
 Yeah, and you're absolutely right.

2:26:38.000 --> 2:26:46.000
 Every technology has negative consequences and positive consequences, and we tend to just focus on the negative a little bit too much.

2:26:46.000 --> 2:26:57.000
 In fact, autonomous trucks are often brought up as an example of artificial intelligence and robots in general taking our jobs.

2:26:57.000 --> 2:27:01.000
 And as we've talked about briefly here, we talk a lot with Steve.

2:27:01.000 --> 2:27:09.000
 It is a concern that automation will take away certain jobs, it will create other jobs.

2:27:09.000 --> 2:27:18.000
 There's temporary pain, hopefully temporary, but pain is pain and people suffer and that human suffering is really important to think about.

2:27:18.000 --> 2:27:28.000
 But trucking is, I mean, there's a lot written on this is I would say far from the thing that will cause the most pain.

2:27:28.000 --> 2:27:34.000
 Yeah, there's even more positive properties about trucking where not only is there just a huge shortage which is going to increase,

2:27:34.000 --> 2:27:39.000
 the average age of truck drivers is getting closer to 50 because the younger people aren't wanting to come into it.

2:27:39.000 --> 2:27:44.000
 They're trying to like incentivize, lower the age limit, like all these sort of things.

2:27:44.000 --> 2:27:46.000
 And the demand is just going to increase.

2:27:46.000 --> 2:27:53.000
 And the least favorable, I mean, it depends on the person, but in most cases, the least favorable types of routes are the massive long haul routes

2:27:53.000 --> 2:27:56.000
 where you're on the road away from your family 300 plus days a year.

2:27:56.000 --> 2:28:00.000
 Steve talked about the pain of those kinds of routes from a family perspective.

2:28:00.000 --> 2:28:03.000
 You're basically away from family.

2:28:03.000 --> 2:28:09.000
 It's not just hours, you work insane hours, but it's also just time away from family.

2:28:09.000 --> 2:28:12.000
 Obesity rate is through the roof because you're just sitting all day.

2:28:12.000 --> 2:28:14.000
 It's really, really tough.

2:28:14.000 --> 2:28:18.000
 And that's also where like the biggest kind of safety risk is because of fatigue.

2:28:18.000 --> 2:28:24.000
 And so when you think of the gradual evolution of how trucking comes in, first of all, it's not overnight.

2:28:24.000 --> 2:28:29.000
 It's going to take decades to kind of phase in all the like, there's just a long, long, long road ahead.

2:28:29.000 --> 2:28:38.000
 But the routes and the portions of trucking that are going to require humans the longest and benefit the most from humans are the short haul

2:28:38.000 --> 2:28:46.000
 and most complicated kind of more urban routes, which are also the more pleasant ones, which are less continual driving time,

2:28:46.000 --> 2:28:54.000
 more flexibility on like geography and location, and you get to kind of sleep at your own home.

2:28:54.000 --> 2:29:05.000
 And very importantly, if you optimize the logistics, you're going to use humans much better and thereby pay them much better.

2:29:05.000 --> 2:29:11.000
 Because like one of the biggest problems is truck drivers currently are paid by like how much they drive.

2:29:11.000 --> 2:29:17.000
 So they really feel the pain of inefficient logistics because like if they're just sitting around for hours,

2:29:17.000 --> 2:29:22.000
 which they often do not driving, waiting, they're not getting paid for that time.

2:29:22.000 --> 2:29:27.000
 So like logistics has a significant impact on the quality of life of a truck driver.

2:29:27.000 --> 2:29:31.000
 And a high percentage of trucks are like empty because of inefficiencies in the system.

2:29:31.000 --> 2:29:36.000
 Yeah, it's one of those things where like, and the other thing is when you increase the efficiency of a system like this,

2:29:36.000 --> 2:29:40.000
 the overall net like volume of the system tends to increase, right?

2:29:40.000 --> 2:29:46.000
 Like the entire market cap of trucking is going to go up when the efficiency improves

2:29:46.000 --> 2:29:51.000
 and facilitates both growth in industries and better utilization of trucking.

2:29:51.000 --> 2:29:57.000
 And so that on its own just creates more and more demand, which of all the places where AI comes in

2:29:57.000 --> 2:30:04.000
 and starts to really kind of reshape an industry, this is one of those where like there's just a lot of positives

2:30:04.000 --> 2:30:12.000
 that for at least any time in the foreseeable future seem really lined up in a good way to kind of come in

2:30:12.000 --> 2:30:19.000
 and help with the shortage and start to kind of optimize for the routes that are most dangerous and most painful.

2:30:19.000 --> 2:30:27.000
 Yeah, so this is true for trucking, but if we zoom out broader, automation and AI does technology broadly, I would say.

2:30:27.000 --> 2:30:36.000
 But you know, automation is a thing that has a potential in the next couple of decades to shift the kind of jobs available to humans.

2:30:36.000 --> 2:30:44.000
 And so that results in, like I said, human suffering because people lose their jobs, there's economic pain there,

2:30:44.000 --> 2:30:46.000
 and there's also a pain of meaning.

2:30:46.000 --> 2:31:00.000
 So for a lot of people, work is a source of meaning, it's a source of identity, of pride, of pride in getting good at the job,

2:31:00.000 --> 2:31:05.000
 pride in craftsmanship and excellence, which is what truck drivers talk about.

2:31:05.000 --> 2:31:08.000
 But this is true for a lot of jobs.

2:31:08.000 --> 2:31:13.000
 And is that something you think about as a sort of a roboticist zooming out from the trucking thing?

2:31:13.000 --> 2:31:24.000
 Like where do you think it would be harder to find activity and work that's a source of identity, a source of meaning in the future?

2:31:24.000 --> 2:31:30.000
 I do think about it because you want to make sure that you worry about the entire system,

2:31:30.000 --> 2:31:35.000
 like not just like the part of the economy plays in it, but what are the ripple effects of it down the road.

2:31:35.000 --> 2:31:40.000
 And on enough of a time window, there's a lot of opportunity to put in the right policies,

2:31:40.000 --> 2:31:44.000
 the right opportunities to kind of reshape and retrain and find those openings.

2:31:44.000 --> 2:31:50.000
 And so just to give you a few examples, both trucking and cars, we have remote assistance facilities

2:31:50.000 --> 2:31:59.000
 that are there to interface with customers and monitor vehicles and provide like very focused kind of assistance

2:31:59.000 --> 2:32:04.000
 on kind of areas where the vehicle may want to request help in understanding an environment.

2:32:04.000 --> 2:32:07.000
 So those are jobs that kind of get created and supported.

2:32:07.000 --> 2:32:13.000
 I remember like taking a tour of one of the Amazon facilities where you've probably seen the Kiva systems robots

2:32:13.000 --> 2:32:19.000
 where you have these orange robots that have automated the warehouse, like kind of picking and collecting of items.

2:32:19.000 --> 2:32:22.000
 And it's like really elegant and beautiful way.

2:32:22.000 --> 2:32:26.000
 It's actually one of my favorite applications of robotics of all time.

2:32:26.000 --> 2:32:30.000
 You know, like I think it kind of came across a company like 2006 was just amazing.

2:32:30.000 --> 2:32:33.000
 And what was the warehouse robots that transport little things?

2:32:33.000 --> 2:32:38.000
 So basically, instead of a person going and walking around and picking the seven items in your order,

2:32:38.000 --> 2:32:45.000
 these robots go and pick up a shelf and move it over in a row where like the seven shelves that contain the seven items

2:32:45.000 --> 2:32:48.000
 are lined up in a laser or whatever points to what you need to get.

2:32:48.000 --> 2:32:50.000
 And you go and pick it and you place it to fill the order.

2:32:50.000 --> 2:32:53.000
 And so the people are fulfilling the final orders.

2:32:53.000 --> 2:32:57.000
 What was interesting about that is that when I was asking them about like kind of the impact on labor

2:32:57.000 --> 2:33:01.000
 when they transitioned that warehouse, the throughput increased so much

2:33:01.000 --> 2:33:09.000
 that the jobs shifted towards the final fulfillment, even though the robots took over entirely the search of the items themselves.

2:33:09.000 --> 2:33:16.000
 And the labor, the job stayed like nobody like that was actually the same amount of jobs, roughly they were necessary.

2:33:16.000 --> 2:33:19.000
 But the throughput increased by I think over 2x or some amount.

2:33:19.000 --> 2:33:24.000
 Right. So you have these situations that are not zero sum games in this really interesting way.

2:33:24.000 --> 2:33:28.000
 And the optimist in me thinks that there's these types of solutions in almost any industry

2:33:28.000 --> 2:33:32.000
 where the growth that's enabled creates opportunities that you can then leverage.

2:33:32.000 --> 2:33:37.000
 But you got to be intentional about finding those and really helping make those links because

2:33:37.000 --> 2:33:41.000
 even if you make the argument that like there's a net positive,

2:33:41.000 --> 2:33:44.000
 locally there's always tough hits that you got to be very careful about.

2:33:44.000 --> 2:33:50.000
 That's right. You have to have an understanding of that link because there's a short period of time

2:33:50.000 --> 2:33:55.000
 whether training is acquired or just mental transition or physical or whatever is acquired,

2:33:55.000 --> 2:34:00.000
 that's still going to be short term pain. The uncertainty of it, there's families involved.

2:34:00.000 --> 2:34:09.000
 It's exceptionally is difficult on a human level and you have to really think about that.

2:34:09.000 --> 2:34:13.000
 You can't just look at economic metrics always, it's human beings.

2:34:13.000 --> 2:34:17.000
 That's right. And you can't even just take it as like, okay, well, we need to like subsidize or whatever

2:34:17.000 --> 2:34:22.000
 because like there is an element of just personal pride where majority of people,

2:34:22.000 --> 2:34:27.000
 like people don't want to just be okay, but like they want to actually like have a craft like you said

2:34:27.000 --> 2:34:31.000
 and have a mission and feel like they're having a really positive impact.

2:34:31.000 --> 2:34:38.000
 And so my personal belief is that there's a lot of transferability and skill set that is possible,

2:34:38.000 --> 2:34:43.000
 especially if you create a bridge and an investment to enable it.

2:34:43.000 --> 2:34:48.000
 And to some degree, that's our responsibility as well in this process.

2:34:48.000 --> 2:34:56.000
 You mentioned Kiva robots, Amazon. Let me ask you about the Astro robot, which is, I don't know if you've seen it,

2:34:56.000 --> 2:35:06.000
 it's Amazon has announced that it's a home robot that they have a screen looks awfully a lot like Cosmo

2:35:06.000 --> 2:35:13.000
 has I think different vision probably. What are your thoughts about like home robotics in this kind of space?

2:35:13.000 --> 2:35:21.000
 There's been quite a bunch of home robots, social robots that very unfortunately have closed their doors

2:35:21.000 --> 2:35:27.000
 that for various reasons, perhaps it were too expensive, there's manufacturing challenges, all that kind of stuff.

2:35:27.000 --> 2:35:30.000
 What are your thoughts about Amazon getting into this space?

2:35:30.000 --> 2:35:34.000
 Yeah, we had some signs that they're getting into it like long, long, long ago.

2:35:34.000 --> 2:35:39.000
 Maybe they were a little bit too interested in Cosmo during our conversations,

2:35:39.000 --> 2:35:44.000
 but they're also very good partners actually for us as we kind of just integrated a lot of shared technology.

2:35:44.000 --> 2:35:53.000
 If I could also get your thoughts on, you could think of Alexa as a robot as well, Echo.

2:35:53.000 --> 2:35:58.000
 Do you see those as fundamentally different just because you can move and look around?

2:35:58.000 --> 2:36:01.000
 Is that fundamentally different than the thing that just sits in place?

2:36:01.000 --> 2:36:09.000
 It opens up options, but my first reaction is I have my doubts that this one's going to hit the mark

2:36:09.000 --> 2:36:15.000
 because I think for the price point that it's at and the kind of functionality and value propositions that they're trying to put out,

2:36:15.000 --> 2:36:23.000
 it's still searching for the killer application that justifies I think it was like a $1,500 price point or kind of somewhere on there.

2:36:23.000 --> 2:36:29.000
 That's a really high bar, so there's enthusiasts and early adopters will obviously kind of pursue it,

2:36:29.000 --> 2:36:34.000
 but you have to really, really hit a high mark at that price point, which we always tried to –

2:36:34.000 --> 2:36:39.000
 we were always very cautious about jumping too quickly to the more advanced systems that we really wanted to make,

2:36:39.000 --> 2:36:46.000
 but would have raised the bar so much you have to be able to hit it in today's cost structures and technologies.

2:36:46.000 --> 2:36:53.000
 The mobility is an angle that hasn't been utilized, but it has to be utilized in the right way,

2:36:53.000 --> 2:36:59.000
 so that's going to be the biggest challenge is can you meet the bar of what the mass market consumer –

2:36:59.000 --> 2:37:10.000
 think our neighbors, our friends, parents, would they find a deep, deep value in this at a mass scale that justifies the price point?

2:37:10.000 --> 2:37:17.000
 I think that's in the end one of the biggest challenges for robotics, especially consumer robotics where you have to kind of meet that bar.

2:37:17.000 --> 2:37:20.000
 It becomes very, very hard.

2:37:20.000 --> 2:37:30.000
 And there's also the higher bar, just like you were saying with Cosmo, of a thing that can look one way and then turn around and look at you.

2:37:30.000 --> 2:37:37.000
 That's either a super desirable quality or a super undesirable quality depending on how much you trust the thing.

2:37:37.000 --> 2:37:38.000
 That's right.

2:37:38.000 --> 2:37:41.000
 And so there's a problem of trust to solve there.

2:37:41.000 --> 2:37:43.000
 There's a problem of personality.

2:37:43.000 --> 2:37:49.000
 It's the quote unquote problem that Cosmo solved so well is that you trust the thing,

2:37:49.000 --> 2:37:56.000
 and that has to do with the company, with the leadership, with the intent that's communicated by the device and the company and everything together.

2:37:56.000 --> 2:37:57.000
 Yeah, exactly right.

2:37:57.000 --> 2:38:04.000
 And I think they also have to retrace some of the learnings on the character side where, as usual,

2:38:04.000 --> 2:38:10.000
 I think that's the place where a lot of companies are great at the hardware side of it and think about those elements.

2:38:10.000 --> 2:38:16.000
 Thinking about the AI challenges, particularly with the advantage of Alexa, is a pretty huge boost for them.

2:38:16.000 --> 2:38:23.000
 The character side of it for technology companies is pretty novel territory, and so that will take some iterations.

2:38:23.000 --> 2:38:30.000
 But yeah, I mean, I hope this continued progress in the space and that thread doesn't kind of go dormant for too long,

2:38:30.000 --> 2:38:36.000
 and it's going to take a while to kind of evolve into the ideal applications.

2:38:36.000 --> 2:38:43.000
 But this is one of Amazon's – I guess you could call it – it's definitely part of their DNA,

2:38:43.000 --> 2:38:50.000
 but in many cases is also strength where they're very willing to iterate kind of aggressively and move quickly.

2:38:50.000 --> 2:38:51.000
 And take risks.

2:38:51.000 --> 2:38:52.000
 And take risks.

2:38:52.000 --> 2:38:54.000
 You have deep pockets so you can kind of –

2:38:54.000 --> 2:39:00.000
 Yeah, and they'll maybe have more misfires than an apple would, but it's different styles and different approaches.

2:39:00.000 --> 2:39:08.000
 And at the end of the day, it's like there's a few familiar kind of elements there for sure, which was kind of –

2:39:08.000 --> 2:39:10.000
 Homage.

2:39:10.000 --> 2:39:12.000
 Is one way to put it.

2:39:12.000 --> 2:39:20.000
 Yeah, so why is it so hard at a high level to build a robotics company?

2:39:20.000 --> 2:39:23.000
 A robotics company that lives for a long time.

2:39:23.000 --> 2:39:29.000
 So if you look at – I thought Cosmo for sure would live for a very long time.

2:39:29.000 --> 2:39:34.000
 That to me was exceptionally successful vision and idea and implementation.

2:39:34.000 --> 2:39:44.000
 iRobot is an example of a company that has pivoted in all the right ways to survive and arguably thrive

2:39:44.000 --> 2:39:53.000
 by focusing on having like a – have a driver that constantly provides profit, which is the vacuum cleaner.

2:39:53.000 --> 2:39:59.000
 And of course there's like Amazon, what they're doing is they're almost like taking risks so they can afford it

2:39:59.000 --> 2:40:02.000
 because they have other sources of revenue.

2:40:02.000 --> 2:40:08.000
 But outside of those examples, most robotics companies fail.

2:40:08.000 --> 2:40:10.000
 Why do they fail?

2:40:10.000 --> 2:40:12.000
 Why is it so hard to run a robotics company?

2:40:12.000 --> 2:40:19.000
 iRobot's impressive because they found a really, really great fit of where the technology could satisfy

2:40:19.000 --> 2:40:28.000
 a really clear use case and need, and they did it well, and they didn't try to overshoot from a cost to benefit standpoint.

2:40:28.000 --> 2:40:32.000
 Robotics is hard because it like tends to be more expensive.

2:40:32.000 --> 2:40:36.000
 It combines way more technologies than a lot of other types of companies do.

2:40:36.000 --> 2:40:41.000
 If I were to like say one thing that is maybe the biggest risk in like a robotics company failing

2:40:41.000 --> 2:40:51.000
 is that it can be either a technology in search of an application or they try to fight off a kind of an offering

2:40:51.000 --> 2:40:56.000
 that has a mismatch in kind of price to function.

2:40:56.000 --> 2:40:59.000
 And just the mass market appeal isn't there.

2:40:59.000 --> 2:41:02.000
 And consumer products are just hard.

2:41:02.000 --> 2:41:07.000
 It's just, I mean, after all the years and I'd like definitely kind of feel a lot of the battle scars

2:41:07.000 --> 2:41:12.000
 because you have, not only do you have to like hit the function, but you have to educate and explain,

2:41:12.000 --> 2:41:15.000
 get awareness up, deal with different types of consumers.

2:41:15.000 --> 2:41:21.000
 There's a reason why a lot of technologies sometimes start in the enterprise space and then kind of continue

2:41:21.000 --> 2:41:27.000
 forward in the consumer space, even like you see AR like starting to kind of make that shift with HoloLens

2:41:27.000 --> 2:41:29.000
 and so forth in some ways.

2:41:29.000 --> 2:41:34.000
 Consumers and price points that they're willing to kind of be attracted in a mass market way.

2:41:34.000 --> 2:41:41.000
 And I don't mean like 10,000 enthusiasts bought it, but I mean like 2 million, 10 million, 50 million

2:41:41.000 --> 2:41:46.000
 like mass market kind of interest have bought it.

2:41:46.000 --> 2:41:52.000
 That bar is very, very high and typically robotics is novel enough and nonstandardized enough to where it pushes

2:41:52.000 --> 2:41:58.000
 on price points so much that you can easily get out of range where the capabilities and today's technology

2:41:58.000 --> 2:42:00.000
 or just the function that was picked just doesn't line up.

2:42:00.000 --> 2:42:03.000
 And so that product market fit is very important.

2:42:03.000 --> 2:42:11.000
 So the space of killer apps or rather super compelling apps is much smaller because it's easy to get outside

2:42:11.000 --> 2:42:13.000
 of the price range for most consumers.

2:42:13.000 --> 2:42:19.000
 And it's not constant, right? And that's why we picked off entertainment because the quality was just so low

2:42:19.000 --> 2:42:25.000
 in physical entertainment that we felt we could leapfrog that and still create a really compelling offering

2:42:25.000 --> 2:42:30.000
 at a price point that was defensible and that proved out to be true.

2:42:30.000 --> 2:42:38.000
 And over time, that same opportunity opens up in healthcare, in home applications and commercial applications

2:42:38.000 --> 2:42:44.000
 and kind of broader, more generalized interface, but there's missing pieces in order for that to happen.

2:42:44.000 --> 2:42:47.000
 And all of those have to be present for it to line up.

2:42:47.000 --> 2:42:54.000
 And we see these sort of trends in technology where kind of technologies that start in one place evolve

2:42:54.000 --> 2:42:55.000
 and kind of grow to another.

2:42:55.000 --> 2:42:56.000
 Some things start in gaming.

2:42:56.000 --> 2:43:03.000
 Some things start in space or aerospace and then kind of move into the consumer market.

2:43:03.000 --> 2:43:09.000
 And sometimes it's just a timing thing, right, where how many stabs at what became the iPhone were there

2:43:09.000 --> 2:43:16.000
 over the 20 years before that just weren't quite ready in the function relative to the kind of price point complexity.

2:43:16.000 --> 2:43:23.000
 And sometimes it's a small detail of the implementation that makes all the difference, which is design is so important.

2:43:23.000 --> 2:43:27.000
 Something, yeah, like the new generation UX, right?

2:43:27.000 --> 2:43:34.000
 And it's tough and oftentimes all of them have to be there and it has to be like a perfect storm.

2:43:34.000 --> 2:43:40.000
 But yeah, history repeats itself in a lot of ways in a lot of these trends, which is pretty fascinating.

2:43:40.000 --> 2:43:42.000
 Well, let me ask you about the humanoid form.

2:43:42.000 --> 2:43:45.000
 What do you think about the Tesla bot and humanoid robotics in general?

2:43:45.000 --> 2:43:51.000
 So obviously, to me, autonomous driving Waymo and the other companies working in the space,

2:43:51.000 --> 2:44:00.000
 that seems to be a great place to invest in potential revolutionary application robotics application folks application.

2:44:00.000 --> 2:44:02.000
 What's the role of humanoid robotics?

2:44:02.000 --> 2:44:05.000
 Do you think Tesla bot is ridiculous?

2:44:05.000 --> 2:44:07.000
 Do you think it's super promising?

2:44:07.000 --> 2:44:10.000
 Do you think it's interesting, full of mystery, nobody knows?

2:44:10.000 --> 2:44:12.000
 What do you think about this thing?

2:44:12.000 --> 2:44:16.000
 Yeah, I think today humanoid form robotics is research.

2:44:16.000 --> 2:44:20.000
 There's very few situations where you actually need a humanoid form to solve a problem.

2:44:20.000 --> 2:44:23.000
 If you think about it, right, like wheels are more efficient than legs.

2:44:23.000 --> 2:44:29.000
 There's joints and degrees of freedom beyond a certain point, just add a lot of complexity and cost.

2:44:29.000 --> 2:44:33.000
 Right. So if you're doing a humanoid robot, oftentimes it's in the pursuit of a humanoid robot,

2:44:33.000 --> 2:44:36.000
 not in the pursuit of an application for the time being.

2:44:36.000 --> 2:44:42.000
 Especially when you have like kind of the gaps in interface and, you know, kind of AI that we kind of talk about today.

2:44:42.000 --> 2:44:45.000
 So anything you want does I'm interested in following.

2:44:45.000 --> 2:44:48.000
 So there's there's an element of that world, no matter how crazy, how crazy it is.

2:44:48.000 --> 2:44:51.000
 I just like, you know, I'll pay attention. I'm curious to see what comes out of it.

2:44:51.000 --> 2:44:54.000
 So it's like you can't you can't ever, you know, ignore it.

2:44:54.000 --> 2:44:59.000
 But, you know, it's definitely far afield from their kind of core business, obviously.

2:44:59.000 --> 2:45:08.000
 What was interesting to me is I've disagreed with Elon a lot about this is to me,

2:45:08.000 --> 2:45:14.000
 the compelling aspect of the humanoid form and a lot of kind of robots, Cosmo,

2:45:14.000 --> 2:45:20.000
 for example, is a human robot interaction part.

2:45:20.000 --> 2:45:25.000
 From Elon Musk's perspective, Tesla bot has nothing to do with the human.

2:45:25.000 --> 2:45:31.000
 It's a form that's effective for the factory because the factory is designed for humans.

2:45:31.000 --> 2:45:37.000
 But to me, the reason you might want to argue for the humanoid form is because, you know,

2:45:37.000 --> 2:45:41.000
 at a party, it's a nice way to fit into the party.

2:45:41.000 --> 2:45:46.000
 The humanoid form has a compelling notion to it in the same way that Cosmo is compelling.

2:45:46.000 --> 2:45:55.000
 I would argue, if we were arguing about this, that it's cheaper to build a Cosmo like that form.

2:45:55.000 --> 2:45:59.000
 But if you wanted to make an argument, which I have with Jim Keller about, you know,

2:45:59.000 --> 2:46:03.000
 you could actually make a human robot for pretty cheap. It's possible.

2:46:03.000 --> 2:46:10.000
 And then the question is, all right, if you're using an application where it can be flawed,

2:46:10.000 --> 2:46:14.000
 it can have a personality and be flawed in the same way that Cosmo is,

2:46:14.000 --> 2:46:18.000
 then maybe it's interesting for integration to human society.

2:46:18.000 --> 2:46:22.000
 That, to me, is an interesting application of a humanoid form because humans are drawn,

2:46:22.000 --> 2:46:27.000
 like I mentioned to you, like robots, we're drawn to legs and limbs and body language

2:46:27.000 --> 2:46:31.000
 and all that kind of stuff. And even a face, even if you don't have the facial features,

2:46:31.000 --> 2:46:38.000
 which you might not want to have to reduce the creepiness factor, all that kind of stuff.

2:46:38.000 --> 2:46:40.000
 But yeah, that, to me, the humanoid form is compelling.

2:46:40.000 --> 2:46:46.000
 But in terms of that being the right form for the factory environment, I'm not so sure.

2:46:46.000 --> 2:46:51.000
 Yeah, for the factory environment, like right off the bat, what are you optimizing for?

2:46:51.000 --> 2:46:53.000
 Is it strength? Is it mobility? Is it versatility, right?

2:46:53.000 --> 2:46:57.000
 Like that changes completely the look and feel of the robot that you create, you know,

2:46:57.000 --> 2:47:03.000
 and almost certainly the human form is over designed for some dimensions and constrained for some dimensions.

2:47:03.000 --> 2:47:07.000
 And so, like, what are you grasping? Is it big? Is it little, right?

2:47:07.000 --> 2:47:14.000
 So you would customize it and make it customizable for the different needs if that was the optimization, right?

2:47:14.000 --> 2:47:18.000
 And then, you know, for the other one, I could totally be wrong.

2:47:18.000 --> 2:47:26.000
 You know, I still feel that the closer you try to get to a human, the more you're subject to the biases of what a human should be

2:47:26.000 --> 2:47:32.000
 and you lose flexibility to shift away from your weaknesses and towards your strengths.

2:47:32.000 --> 2:47:46.000
 And that changes over time, but there's ways to make really approachable and natural interfaces for robotic kind of characters

2:47:46.000 --> 2:47:56.000
 and, you know, kind of deployments in these applications that do not at all look like a human directly,

2:47:56.000 --> 2:48:03.000
 but that actually creates way more flexibility and capability and role and forgiveness and interface and everything else.

2:48:03.000 --> 2:48:09.000
 Yeah, it's interesting, but I'm still confused by the magic I see in legged robots.

2:48:09.000 --> 2:48:16.000
 Yeah, so there is a magic. So I'm absolutely amazed at it from a technical curiosity standpoint

2:48:16.000 --> 2:48:24.000
 and like the magic that like the Boston Dynamics team can do from, you know, like from walking and jumping and so forth.

2:48:24.000 --> 2:48:29.000
 Now, like there's been a long journey to try to find an application for that sort of technology.

2:48:29.000 --> 2:48:32.000
 But wow, that's incredible technology, right?

2:48:32.000 --> 2:48:37.000
 So then you kind of go towards, OK, are you working back from a goal of what you're trying to solve?

2:48:37.000 --> 2:48:39.000
 Are you working forward from a technology and I'm looking for a solution?

2:48:39.000 --> 2:48:45.000
 And I think that's where it's a kind of a bi directional search oftentimes, but you got the two have to meet.

2:48:45.000 --> 2:48:49.000
 And that's where humanoid robots is kind of close to that.

2:48:49.000 --> 2:48:55.000
 And that like it is a decision about a form factor and a technology that it forces

2:48:55.000 --> 2:49:00.000
 that doesn't have a clear justification on why that's the killer app for, you know, from the other end.

2:49:00.000 --> 2:49:05.000
 But I think the core fascinating idea with the Tesla bot is the one that's carried by Waymo as well,

2:49:05.000 --> 2:49:14.000
 is when you're solving the general robotics problem of perception control where there's the very clear applications of driving.

2:49:14.000 --> 2:49:19.000
 It's as you get better and better at it when you have like Waymo driver.

2:49:19.000 --> 2:49:24.000
 Yeah, the whole world starts to kind of start to look like a robotics problem.

2:49:24.000 --> 2:49:26.000
 So it's very interesting for now.

2:49:26.000 --> 2:49:31.000
 Detection, classification, segmentation, tracking, planning, like it's.

2:49:31.000 --> 2:49:40.000
 So there's no reason. I mean, I'm not I'm not speaking for Waymo here, but, you know, moving goods.

2:49:40.000 --> 2:49:48.000
 There's no reason transformer like this thing couldn't, you know, take the goods up an elevator, you know, like that,

2:49:48.000 --> 2:49:59.000
 like slowly expand what it means to move goods and expand more and more of the world into a robotics problem.

2:49:59.000 --> 2:50:05.000
 Well, that's right. And you start to like think of it as an end end robotics problem from like loading from, you know, from everything else.

2:50:05.000 --> 2:50:13.000
 And even like the truck itself, you know, today's generation is integrating into today's understanding of what a vehicle is, right?

2:50:13.000 --> 2:50:17.000
 The Pacifica Jaguar, the Freightliners from Daimler.

2:50:17.000 --> 2:50:34.000
 There's nothing that stops these us from like down the road after like starting to get to scale to like expand these partnerships to really rethink what would the next generation of a truck look like that is actually optimized for autonomy, not for today's world.

2:50:34.000 --> 2:50:37.000
 And maybe that means a very different type of trailer.

2:50:37.000 --> 2:50:42.000
 Maybe that like there's a lot of things you could rethink on that front, which is on its own very, very exciting.

2:50:42.000 --> 2:50:48.000
 Let me ask you, like I said, you went to the Mecca of robotics, which is CMU, Carnegie Mellon University.

2:50:48.000 --> 2:51:03.000
 You got a PhD there. So maybe by way of advice and maybe by way of story and memories, what does it take to get a PhD in robotics at CMU?

2:51:03.000 --> 2:51:15.000
 And maybe you can throw in there some advice for people who are thinking about doing work in artificial intelligence and robotics and are thinking about whether to get a PhD.

2:51:15.000 --> 2:51:28.000
 I actually went, I was at CMU for undergrad as well and didn't know anything about robotics coming in and was doing electrical computer engineering, computer science, and really got more and more into kind of AI and then fell in love with autonomous driving.

2:51:28.000 --> 2:51:36.000
 And at that point, that was just by a big margin, such an incredible central spot of investment in that area.

2:51:36.000 --> 2:51:41.000
 And so what I would say is that robotics, for all the progress that's happened, is still a really young field.

2:51:41.000 --> 2:51:53.000
 There's a huge amount of opportunity. Now that opportunity shifted where something like autonomous driving has moved from being very research and academics driven to being commercial driven where you see the investments happening in commercial.

2:51:53.000 --> 2:52:03.000
 Now there's other areas that are much younger and you see like kind of grasping and manipulation, making kind of the same sort of journey that like autonomy made and there's other areas as well.

2:52:03.000 --> 2:52:15.000
 What I would say is the space moves very quickly. Anything you do a PhD in, like it is in most areas, will evolve and change as technology changes and constraints change and hardware changes and the world changes.

2:52:15.000 --> 2:52:24.000
 And so the beautiful thing about robotics is it's super broad. It's not a narrow space at all and it could be a million different things in a million different industries.

2:52:24.000 --> 2:52:34.000
 And so it's a great opportunity to come in and get a broad foundation on AI, machine learning, computer vision, systems, hardware, sensors, all these separate things.

2:52:34.000 --> 2:52:46.000
 You do need to go deep and find something that you're really, really passionate about. Obviously, just like any PhD, this is like a five, six year kind of endeavor.

2:52:46.000 --> 2:52:57.000
 And you have to love it enough to go super deep to learn all the things necessary to be super deeply functioning in that area and then contribute to it in a way that hasn't been done before.

2:52:57.000 --> 2:53:05.000
 And in robotics, that probably means more breadth because robotics is rarely kind of like one particular kind of narrow technology.

2:53:05.000 --> 2:53:23.000
 And it means being able to collaborate with teams where like one of the coolest aspects of like the experience that I kind of cherish in our PhD is that we actually had a pretty large AV project that for that time was like a pretty serious initiative where you got to like partner with a larger team.

2:53:23.000 --> 2:53:28.000
 And you had the experts in perception and the experts in planning and the staff and the mechanical engineers.

2:53:28.000 --> 2:53:35.000
 So I was working on a project called UPI back then, which was basically the off road version of the DARPA challenge.

2:53:35.000 --> 2:53:44.000
 It was a DARPA funded project for basically like a large off road vehicle that you would like drop and then give it a waypoint 10 kilometers away and it would have to navigate a completely unstructured environment.

2:53:44.000 --> 2:53:45.000
 In an off road environment.

2:53:45.000 --> 2:53:54.000
 Yeah. So like forests, ditches, rocks, vegetation, and so it was like a really, really interesting kind of a hard problem where like wheels would be off to my shoulders. It's like gigantic, right?

2:53:54.000 --> 2:53:56.000
 Yeah. By the way, AV for people stands for autonomous vehicles.

2:53:56.000 --> 2:53:59.000
 Autonomous vehicles. Yeah. Sorry.

2:53:59.000 --> 2:54:09.000
 And so what I think is like the beauty of robotics, but also kind of like the expectation is that there's spaces in computer science where you can be very, very narrow and deep.

2:54:09.000 --> 2:54:18.000
 Robotics, the necessity, but also the beauty of it is that it forces you to be excited about that breadth and that partnership across different disciplines that enable it.

2:54:18.000 --> 2:54:27.000
 But that also opens up so many more doors where you can go and you can do robotics and almost any category where robotics isn't really an industry.

2:54:27.000 --> 2:54:29.000
 It's like AI, right?

2:54:29.000 --> 2:54:47.000
 It's like the application of physical automation to all these other worlds. And so you can do robotic surgery, you can do vehicles, you can do factory automation, you can do health care, you can do like leverage the AI around the sensing to think about static sensors and scene understanding.

2:54:47.000 --> 2:54:58.000
 So I think that's got to be the expectation and the excitement and it breeds people that are probably a little bit more collaborative and more excited about working in teams.

2:54:58.000 --> 2:55:10.000
 If I could briefly comment on the fact that the robotics people I've met in my life from CMU and MIT, they're really happy people.

2:55:10.000 --> 2:55:13.000
 Yeah. Because I think it's the collaborative thing.

2:55:13.000 --> 2:55:16.000
 I think I think you don't.

2:55:16.000 --> 2:55:19.000
 You're not like sitting in like the fourth basement.

2:55:19.000 --> 2:55:29.000
 Yes, exactly. Which when you're doing machine learning purely software, it's very tempting to just disappear into your own hole and never collaborate.

2:55:29.000 --> 2:55:36.000
 And that breeds a little bit more of the silo mentality of like, I have a problem.

2:55:36.000 --> 2:55:39.000
 It's almost like negative to talk to somebody else or something like that.

2:55:39.000 --> 2:55:53.000
 But robotics folks are just very collaborative, very friendly. And there's also an energy of like you get to confront the physics of reality often, which is humbling and also exciting.

2:55:53.000 --> 2:55:57.000
 So it's humbling when it fails and exciting when it finally works.

2:55:57.000 --> 2:55:58.000
 It's like a purity of the passion.

2:55:58.000 --> 2:56:11.000
 And you've got to remember that like right now, like robotics and AI is like just all the rage and autonomous vehicles and all this, like 15 years ago and 20 years ago, like it wasn't that deeply lucrative.

2:56:11.000 --> 2:56:18.000
 People that went into robotics, they did it because they were like thought it was just the coolest thing in the world to like make physical things intelligent in the real world.

2:56:18.000 --> 2:56:22.000
 And so there's like a raw passion where they went into it for the right reasons and so forth.

2:56:22.000 --> 2:56:30.000
 And so it's really great space. And that organizational challenge, by the way, like when you think about the challenges in AV, we talk a lot about the technical challenges.

2:56:30.000 --> 2:56:42.000
 The organizational challenges through the roof where you think about what it takes to build an AV system and you have companies that are now thousands of people.

2:56:42.000 --> 2:56:47.000
 And you look at other really hard technical problems like an operating system.

2:56:47.000 --> 2:56:48.000
 It's pretty well established.

2:56:48.000 --> 2:57:00.000
 Like you kind of know that there's a file system, there's virtual memory, there's this, there's that, there's like caching and like and there's like a really reasonably well established modularity and APIs and so forth.

2:57:00.000 --> 2:57:03.000
 And so you can kind of like scale it in an efficient fashion.

2:57:03.000 --> 2:57:08.000
 That doesn't exist anywhere near to that level of maturity in autonomous driving right now.

2:57:08.000 --> 2:57:12.000
 And tech stacks are being reinvented, organizational structures are being reinvented.

2:57:12.000 --> 2:57:20.000
 You have problems like pedestrians that are not isolated problems. They're part sensing, part behavior prediction, part planning, part evaluation.

2:57:20.000 --> 2:57:36.000
 And like one of the biggest challenges is actually how do you solve these problems where the mental capacity of a human is starting to get strained on how do you organize it and think about it where you have this like multidimensional matrix that needs to all work together.

2:57:36.000 --> 2:57:45.000
 And so that makes it kind of cool as well because it's not like solved at all from like what does it take to actually scale this, right?

2:57:45.000 --> 2:57:53.000
 And then you look at like other gigantic challenges that have been successful and are way more mature, there's a stability to it.

2:57:53.000 --> 2:57:56.000
 And like maybe the autonomous vehicle space will get there.

2:57:56.000 --> 2:58:13.000
 But right now, just as many technical challenges as they are, they're like organizational challenges and how do you like solve these problems that touch on so many different areas and efficiently tackle them while like maintaining progress among all these constraints while scaling.

2:58:13.000 --> 2:58:28.000
 By way of advice, what advice would you give to somebody thinking about doing a robotics startup? You mentioned Cosmo. Somebody that wanted to carry the Cosmo flag forward, the Anki flag forward.

2:58:28.000 --> 2:58:37.000
 Looking back at your experience, looking forward to the future that will obviously have such robots. What advice would you give to that person?

2:58:37.000 --> 2:58:45.000
 Yeah, it was the greatest experience ever. And it's like there's something you there are things you learn navigating a startup that you'll never like.

2:58:45.000 --> 2:58:51.000
 It was very hard to encounter that in like a typical kind of work environment. And it's just it's wonderful. You got to be ready for it.

2:58:51.000 --> 2:58:57.000
 It's not like, you know, the glamour of a startup. There's just like just brutal emotional swings up and down.

2:58:57.000 --> 2:59:14.000
 And so having cofounders actually helps a ton. Like, I would not cannot imagine doing it solo, but having at least somebody where on your darkest days, you can kind of like really openly just like have that conversation and, you know, lean on to somebody that's that's in the thick of it with you helps a lot.

2:59:14.000 --> 2:59:28.000
 What I would say, what was the nature of darkest days and the emotional swings? Is it worried about the funding? Is it worried about whether any of your ideas are any good or ever were good? Is it like the self doubt?

2:59:28.000 --> 2:59:36.000
 Is it like facing new challenges that have nothing to do with the technology, like organizational, human resources, that kind of stuff?

2:59:36.000 --> 2:59:46.000
 Yeah, you come from a world in school where you feel that you put in a lot of effort and you'll get the right result. And input translates proportional to output.

2:59:46.000 --> 2:59:52.000
 And, you know, you need to solve the set or do whatever and just kind of get it done. Now, PhD tests out a little bit.

2:59:52.000 --> 3:00:00.000
 But at the end of the day, you put in the effort, you tend to like kind of come out with your enough results that you kind of get a PhD in the startup space.

3:00:00.000 --> 3:00:10.000
 Like, you know, like you could talk to 50 investors and they just don't see your vision. And it doesn't matter how hard you kind of tried and pitched, you could work incredibly hard and you have a manufacturing defect.

3:00:10.000 --> 3:00:16.000
 And if you don't fix it, you're going to you're out of business. You need to raise money by a certain date.

3:00:16.000 --> 3:00:20.000
 And there's a you got to have this milestone in order to like have a good pitch and you do it.

3:00:20.000 --> 3:00:32.000
 You have to have this talent and you just don't have it inside the company or, you know, you have to get 200 people or however many people kind of like along with you and kind of buy in the journey.

3:00:32.000 --> 3:00:38.000
 You're like disagreeing with an investor and they're your investors. So it's just like, you know, it's like there's no walking away from it.

3:00:38.000 --> 3:00:47.000
 Right. So and it tends to be like those things where you just kind of get clobbered in so many different ways that like things end up being harder than you expect.

3:00:47.000 --> 3:00:51.000
 And it's like such a gauntlet, but you learn so much in the process.

3:00:51.000 --> 3:00:55.000
 And there's a lot of people that actually end up rooting for you and helping you like from the outside.

3:00:55.000 --> 3:01:00.000
 And you get good, great mentors and you like get find fantastic people that step up in the company.

3:01:00.000 --> 3:01:06.000
 And you have this like magical period where everybody's like it's life or death for the company.

3:01:06.000 --> 3:01:10.000
 But like you're all fighting for the same thing. And it's the most satisfying kind of journey ever.

3:01:10.000 --> 3:01:17.000
 The things that make it easier and that I would recommend is like be really, really thoughtful about the the application.

3:01:17.000 --> 3:01:24.000
 Like there's a there's a saying of like kind of, you know, team and execution and market and like kind of how important are each of those.

3:01:24.000 --> 3:01:34.000
 And oftentimes the market wins and you come out of thinking that if you're smart enough and you work hard enough and you're like have the right talented team and so forth, like you'll always kind of find a way through.

3:01:34.000 --> 3:01:41.000
 And it's surprising how much dynamics are driven by the industry you're in and the timing of you entering that industry.

3:01:41.000 --> 3:02:00.000
 And so just Waymo is a great example of it. There is I don't know if there'll ever be another company or suite of companies that has raised and continues to spend so much money at such an early phase of revenue generation and productization.

3:02:00.000 --> 3:02:13.000
 You know, from a PNL standpoint, like it's it's an anomaly, like by any measure of any industry that's ever existed, except for maybe the US space program.

3:02:13.000 --> 3:02:24.000
 But it's like multiple trillion dollar opportunities, which is so unusual to find that size of a market that just the progress that shows the de risking of it.

3:02:24.000 --> 3:02:33.000
 You could apply whatever discounts you want off that trillion dollar market and it still justifies the investment that is happening because like being successful in that space makes all the investment feel trivial.

3:02:33.000 --> 3:02:43.000
 Now, by the same consequence, like the size of the market, the size of the target audience, the ability to capture that market share, how hard that's going to be, who the incumbents like.

3:02:43.000 --> 3:02:48.000
 That's probably one of the lessons I appreciate like more than anything else, where like those things really, really do matter.

3:02:48.000 --> 3:03:01.000
 And oftentimes can dominate the quality of the team or execution, because if you miss the timing or you do it in the wrong space, you run into like the institutional kind of headwinds of a particular environment.

3:03:01.000 --> 3:03:07.000
 Like let's say you have the greatest idea in the world, but you burrow into health care, but it takes 10 years to innovate in health care because of a lot of challenges.

3:03:07.000 --> 3:03:12.000
 Right. Like there's fundamental laws of physics that you have to think about.

3:03:12.000 --> 3:03:25.000
 And so the combination of like Anki and Waymo kind of drives that point home for me where you can do a ton if you have the right market, the right opportunity, the right way to explain it and you show the progress in the right sequence.

3:03:25.000 --> 3:03:30.000
 It actually can really significantly change the course of your journey and startup.

3:03:30.000 --> 3:03:34.000
 How much of is understanding the market and how much of is creating a new market?

3:03:34.000 --> 3:03:43.000
 So how do you think about like the space robotics is really interesting. You said exactly right. The space of applications is small.

3:03:43.000 --> 3:03:44.000
 Yeah.

3:03:44.000 --> 3:03:54.000
 You know, relative to the cost involved. So how much is like truly revolutionary thinking about like what is the application?

3:03:54.000 --> 3:04:01.000
 And then, yeah, so creating something that didn't exist, didn't really exist.

3:04:01.000 --> 3:04:07.000
 Like this is pretty obvious to me, the whole space of home robotics, just everything that Cosmo did.

3:04:07.000 --> 3:04:12.000
 I guess you could talk to it as a toy and people will understand it because it was much more than a toy.

3:04:12.000 --> 3:04:13.000
 Yeah.

3:04:13.000 --> 3:04:21.000
 And I don't think people fully understand the value of that. You have to create it and the product will communicate it.

3:04:21.000 --> 3:04:31.000
 Just like the iPhone, nobody understood the value of no keyboard and a thing that can do web browsing.

3:04:31.000 --> 3:04:34.000
 I don't think they understood the value of that until you create it.

3:04:34.000 --> 3:04:40.000
 Yeah. Having a foot in the door and an entry point still helps because at the end of the day, like an iPhone replaced your phone.

3:04:40.000 --> 3:04:43.000
 And so it had a fundamental purpose and all these things that it did better. Right.

3:04:43.000 --> 3:04:44.000
 Sure.

3:04:44.000 --> 3:04:46.000
 And so then you could do ABC on top of it.

3:04:46.000 --> 3:04:53.000
 And then you even remember the early commercials where it's always like one application of what it could do and then you get a phone call.

3:04:53.000 --> 3:04:56.000
 And so that was intentionally sending a message, something familiar.

3:04:56.000 --> 3:05:00.000
 But then you can send a text message, you can listen to music, you can surf the web.

3:05:00.000 --> 3:05:04.000
 And so autonomous driving obviously anchors on that as well.

3:05:04.000 --> 3:05:07.000
 You don't have to explain to somebody the functionality of an autonomous truck.

3:05:07.000 --> 3:05:11.000
 Like there's nuances around it, but the functionality makes sense.

3:05:11.000 --> 3:05:22.000
 In the home, you have a fundamental advantage. We always thought about this because it was so painful to explain to people what our products did and how to communicate that super cleanly, especially when something was so experiential.

3:05:22.000 --> 3:05:27.000
 And so you compare Anki to Nest.

3:05:27.000 --> 3:05:44.000
 Nest had some beautiful products where they started scaling and actually found really great success and they had really clean and beautiful marketing messaging because they anchored on reinventing existing categories where it was a smart thermostat.

3:05:44.000 --> 3:05:53.000
 And so you kind of are able to take what's familiar, anchor that understanding and then explain what's better about it.

3:05:53.000 --> 3:05:56.000
 That's funny. You're right. Cosmos is a totally new thing.

3:05:56.000 --> 3:05:58.000
 What is this thing?

3:05:58.000 --> 3:06:01.000
 We struggled. We spent a lot of money on marketing.

3:06:01.000 --> 3:06:12.000
 We actually had far greater efficiency on Cosmo than anything else because we found a way to capture the emotion in some little shorts to kind of lean into the personality in our marketing.

3:06:12.000 --> 3:06:21.000
 And it became viral where we had these kind of videos that would go and get hundreds of thousands of views and get spread and sometimes millions of views.

3:06:21.000 --> 3:06:24.000
 But it was really, really hard.

3:06:24.000 --> 3:06:31.000
 And so finding a way to kind of anchor on something that's familiar but then grow into something that's not is an advantage.

3:06:31.000 --> 3:06:34.000
 But then again, there's successes otherwise.

3:06:34.000 --> 3:06:37.000
 Alexa never had a comp.

3:06:37.000 --> 3:06:40.000
 You could argue that that's very novel and very new.

3:06:40.000 --> 3:07:01.000
 And there's a lot of other examples that kind of created a kind of a category out of like Kiva systems. I mean, they like came in and they like enterprises a little easier because if you can is less susceptible to this because if you can argue a clear value proposition, it's a more logical conversation that you can have with customers.

3:07:01.000 --> 3:07:05.000
 It's not it's a little bit less emotional and kind of subjective.

3:07:05.000 --> 3:07:15.000
 And the home you have to. Yeah, it's like a home robot. It's like, what does that mean? Yeah. And so then you really have to be crisp about the value proposition and what like really makes it worth it.

3:07:15.000 --> 3:07:29.000
 Like and we, by the way, went to that same where we almost like we almost hit a wall coming out of 2013 where we were so big on explaining why our stuff was so high tech and all the kind of like great technology in it and how cool it is and so forth.

3:07:29.000 --> 3:07:37.000
 To having to make a super hard pivot on why is it fun and why does the random kind of family of four need this, right?

3:07:37.000 --> 3:07:41.000
 Like so it's learnings, but that's that's the challenge.

3:07:41.000 --> 3:07:49.000
 And I think like robotics tends to sometimes fall into the new category problem, but then you've got to be really crisp about why it needs to exist.

3:07:49.000 --> 3:07:59.000
 Well, I think some of robotics, depending on the category, depending on the application is a little bit of a marketing this challenge.

3:07:59.000 --> 3:08:13.000
 And I don't I don't mean I mean it's it's the kind of marketing that Waymo is doing that Tesla is doing is like showing off incredible engineering, incredible technology.

3:08:13.000 --> 3:08:20.000
 But convincing, like you said, a family of four that this this this is like this is transformative for your life.

3:08:20.000 --> 3:08:23.000
 This is fun. This is they don't care how much tech is in your thing.

3:08:23.000 --> 3:08:26.000
 They don't they really don't care. They need to know why they want it.

3:08:26.000 --> 3:08:28.000
 And some of that is just marketing. Yeah.

3:08:28.000 --> 3:08:43.000
 And that's why like Roomba, like yesterday, you know, like go and have this like, you know, huge, huge ramp into like the entirety of a kind of a robotics and so forth. But like they built a really great business and in a vacuum cleaner world.

3:08:43.000 --> 3:08:48.000
 And like everybody understands where a vacuum cleaner is. Most people are annoyed by doing it.

3:08:48.000 --> 3:08:52.000
 And now you have one that like kind of does it itself.

3:08:52.000 --> 3:09:02.000
 Yeah. The various degrees of quality. But that is so compelling that like it's easy to understand. And like and they had a very kind of and I think they have like 15 percent of the vacuum cleaner market.

3:09:02.000 --> 3:09:08.000
 So it's like pretty successful. Right. I think we need more of those types of thoughtful stepping stones in robotics.

3:09:08.000 --> 3:09:14.000
 But the opportunities are becoming bigger because hardware is cheaper, computes cheaper, clouds cheaper and A.I. is better.

3:09:14.000 --> 3:09:16.000
 So there's a lot of opportunity.

3:09:16.000 --> 3:09:29.000
 If we zoom out from specifically startups and robotics, what advice do you have to high school students, college students about career and living a life that you'd be proud of?

3:09:29.000 --> 3:09:34.000
 You lived one heck of a life. You're very successful in several domains.

3:09:34.000 --> 3:09:40.000
 If you can convert that into a generalizable potion, what advice would you give?

3:09:40.000 --> 3:09:54.000
 That's a very good question. So it's very hard to go into a space that you're not passionate about and push like push hard enough to be, you know, to like maximize your potential in it.

3:09:54.000 --> 3:10:00.000
 And so there's a there's always kind of like the saying of like, OK, follow your passion.

3:10:00.000 --> 3:10:13.000
 Great. Try to find the overlap of where your passion overlaps with like a growing opportunity and need in the world where it's not too different than the startup kind of argument that we talked about, where if you are where your passion meets the market.

3:10:13.000 --> 3:10:19.000
 Right. You know, I mean, like because it's like it's a you know, that's a beautiful thing where like you can do what you love.

3:10:19.000 --> 3:10:22.000
 But it's also just opens up tons of opportunities because the world's ready for it.

3:10:22.000 --> 3:10:31.000
 Right. And so and so like if you're interested in technology, that might point to like go and study machine learning because you don't have to decide what career you're going to go into.

3:10:31.000 --> 3:10:46.000
 But it's going to be such a versatile space that's going to be at the root of like everything that's going to be in front of us that you can have eight different careers in different industries and be an absolute expert in this like kind of tool set that you wield that can go and be applied.

3:10:46.000 --> 3:10:58.000
 And that doesn't apply to just technology. Right. It's it could be the exact same thing if you want to, you know, the same thought process of price to design, to marketing, to, you know, to sales, to anything.

3:10:58.000 --> 3:11:07.000
 But that versatility where you like when you're in a space that's going to continue to grow, it's just like what company do you join?

3:11:07.000 --> 3:11:17.000
 One that just is going to grow and the growth creates opportunities where the surface area is just going to increase and the problems will never get stale. And you can have, you know, many like.

3:11:17.000 --> 3:11:27.000
 And so you go into a career where you have that sort of growth in the world that you're in, you end up having so much more opportunity that organically just appears.

3:11:27.000 --> 3:11:38.000
 And you can then have more shots on goal to find like that killer overlap of timing and passion and skill set and point in life where you can like, you know, just really be motivated and fall in love with something.

3:11:38.000 --> 3:11:45.000
 And then at the same time, like find a balance. Like there's been times in my life where I worked like a little bit too obsessively and, you know, and crazy.

3:11:45.000 --> 3:11:57.000
 And I think we kind of like tried to correct it, you know, kind of the right opportunities. But, you know, I think I probably appreciate a lot more now friendships that go way back, you know, family and things like that.

3:11:57.000 --> 3:12:06.000
 And I kind of have the personality where I could ease like I have like so much desire to really try to optimize, like, you know, what I'm working on that I can easily go to a kind of an extreme.

3:12:06.000 --> 3:12:15.000
 And now I'm trying to like kind of find that balance and make sure that I have the friendships, the family, like relationship with the kids, everything that like I don't.

3:12:15.000 --> 3:12:24.000
 I push really, really hard, but it kind of find a balance. And I think people can be happy on actually many kind of extremes on that spectrum.

3:12:24.000 --> 3:12:33.000
 But it's easy to kind of inadvertently make a choice by how you approach it that then becomes really hard to unwind.

3:12:33.000 --> 3:12:41.000
 And so being very thoughtful about kind of all of those dimensions makes a lot of sense. And so those are all interrelated.

3:12:41.000 --> 3:12:47.000
 But at the end of the day, love, passion and love, love towards, you said, family, friends, family.

3:12:47.000 --> 3:12:56.000
 And hopefully one day if your work pans out, Boris, is love towards robots.

3:12:56.000 --> 3:13:03.000
 Not the creepy kind, the good kind. Just friendship and fun. Yeah.

3:13:03.000 --> 3:13:07.000
 It's like another dimension to just how we interface with the world. Yeah.

3:13:07.000 --> 3:13:15.000
 Boris, you're one of my favorite human beings, roboticist. You've created some incredible robots and I think inspired countless people.

3:13:15.000 --> 3:13:24.000
 And like I said, I hope Cosmo, I hope your work with Anki lives on. And I can't wait to see what you do with Waymo.

3:13:24.000 --> 3:13:32.000
 I mean, that's if we're talking about artificial intelligence technology that has the potential to revolutionize so much of our world.

3:13:32.000 --> 3:13:39.000
 That's it right there. So thank you so much for the work you've done. And thank you for spending your valuable time talking with me.

3:13:39.000 --> 3:13:40.000
 Thanks, Lex.

3:13:40.000 --> 3:13:47.000
 Thanks for listening to this conversation with Boris Hoffman. To support this podcast, please check out our sponsors in the description.

3:13:47.000 --> 3:13:51.000
 And now let me leave you with some words from Isaac Asimov.

3:13:51.000 --> 3:14:01.000
 If you were to insist I was a robot, you might not consider me capable of love in some mystic human sense.

3:14:01.000 --> 3:14:22.000
 Thank you for listening and hope to see you next time.

