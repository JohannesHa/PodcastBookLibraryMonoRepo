WEBVTT

00:00.000 --> 00:02.000
 We are becoming cyborgs.

00:02.000 --> 00:04.080
 Our brains are fundamentally changed.

00:04.080 --> 00:05.760
 Everyone who grew up with electronics,

00:05.760 --> 00:08.920
 we are fundamentally different from previous,

00:08.920 --> 00:09.840
 from homo sapiens.

00:09.840 --> 00:11.080
 I call us homo techno.

00:11.080 --> 00:13.240
 I think we have evolved into homo techno,

00:13.240 --> 00:15.800
 which is like essentially a new species.

00:15.800 --> 00:17.840
 Previous technologies, I mean,

00:17.840 --> 00:19.120
 may have even been more profound

00:19.120 --> 00:20.180
 and moved us to a certain degree,

00:20.180 --> 00:22.780
 but I think the computers are what make us homo techno.

00:22.780 --> 00:25.600
 I think this is what, it's a brain augmentation.

00:25.600 --> 00:27.860
 So it like allows for actual evolution.

00:27.860 --> 00:29.480
 Like the computers accelerate the degree

00:29.480 --> 00:32.680
 to which all the other technologies can also be accelerated.

00:32.680 --> 00:35.600
 Would you classify yourself as a homo sapien or a homo techno?

00:35.600 --> 00:37.080
 Definitely homo techno.

00:37.080 --> 00:40.960
 So you're one of the earliest of the species.

00:40.960 --> 00:43.060
 I think most of us are.

00:45.400 --> 00:47.760
 The following is a conversation with Grimes,

00:47.760 --> 00:50.520
 an artist, musician, songwriter, producer, director,

00:50.520 --> 00:53.040
 and a fascinating human being

00:53.040 --> 00:55.480
 who thinks a lot about both the history

00:55.480 --> 00:57.520
 and the future of human civilization.

00:57.520 --> 00:59.800
 Studying the dark periods of our past

00:59.800 --> 01:03.880
 to help form an optimistic vision of our future.

01:03.880 --> 01:05.720
 This is the Lex Friedman podcast.

01:05.720 --> 01:07.840
 To support it, please check out our sponsors

01:07.840 --> 01:08.960
 in the description.

01:08.960 --> 01:11.920
 And now, dear friends, here's Grimes.

01:12.840 --> 01:14.480
 Oh yeah, the cloud lifter, there you go.

01:14.480 --> 01:15.300
 There you go.

01:15.300 --> 01:16.440
 You know your stuff.

01:16.440 --> 01:18.240
 Have you ever used a cloud lifter?

01:18.240 --> 01:20.980
 Yeah, I actually, this microphone cloud lifter

01:20.980 --> 01:23.440
 is what Michael Jackson used, so.

01:23.440 --> 01:24.420
 No, really?

01:24.420 --> 01:26.000
 Yeah, this is like Thriller and stuff.

01:26.000 --> 01:28.160
 This mic and a cloud lifter?

01:28.160 --> 01:30.620
 Yeah, it's a incredible microphone.

01:30.620 --> 01:32.040
 It's very flattering on vocals.

01:32.040 --> 01:33.600
 I've used this a lot.

01:33.600 --> 01:34.720
 It's great for demo vocals.

01:34.720 --> 01:36.640
 It's great in a room.

01:36.640 --> 01:38.280
 Sometimes it's easier to record vocals

01:38.280 --> 01:40.600
 if you're just in a room and the music's playing

01:40.600 --> 01:43.040
 and you just wanna feel it so it's not in the headphones.

01:43.040 --> 01:44.700
 And this mic is pretty directional,

01:44.700 --> 01:47.740
 so I think it's a good mic for just vibing out

01:47.740 --> 01:49.840
 and just getting a real good vocal take.

01:49.840 --> 01:51.860
 Just vibing, just in a room.

01:51.860 --> 01:55.920
 Anyway, this is the Michael Jackson, Quincy Jones

01:55.920 --> 01:57.000
 microphone.

01:57.000 --> 01:58.800
 I feel way more badass now.

01:58.800 --> 02:01.760
 All right, you wanna just get into it?

02:01.760 --> 02:03.040
 I guess so.

02:03.040 --> 02:05.720
 All right, one of your names, at least in this space

02:05.720 --> 02:08.320
 and time, is C, like the letter C.

02:08.320 --> 02:11.280
 And you told me that C means a lot of things.

02:11.280 --> 02:12.640
 It's the speed of light.

02:12.640 --> 02:14.700
 It's the render rate of the universe.

02:14.700 --> 02:16.120
 It's yes in Spanish.

02:16.120 --> 02:17.660
 It's the crescent moon.

02:17.660 --> 02:21.140
 And it happens to be my favorite programming language

02:21.140 --> 02:24.140
 because it basically runs the world,

02:24.140 --> 02:28.200
 but it's also powerful, fast, and it's dangerous

02:28.200 --> 02:30.000
 because you can mess things up really bad with it

02:30.000 --> 02:31.160
 because of all the pointers.

02:31.160 --> 02:33.960
 But anyway, which of these associations

02:33.960 --> 02:36.580
 will the name C is the coolest to you?

02:37.760 --> 02:40.700
 I mean, to me, the coolest is the speed of light,

02:40.700 --> 02:42.720
 obviously, or the speed of light.

02:42.720 --> 02:44.400
 When I say render rate of the universe,

02:44.400 --> 02:46.280
 I think I mean the speed of light

02:46.280 --> 02:49.120
 because essentially that's what we're rendering at.

02:49.120 --> 02:52.200
 See, I think we'll know if we're in a simulation

02:52.200 --> 02:53.740
 if the speed of light changes

02:53.740 --> 02:57.280
 because if they can improve their render speed, then.

02:57.280 --> 02:58.480
 Well, it's already pretty good.

02:58.480 --> 03:01.040
 It's already pretty good, but if it improves,

03:01.040 --> 03:03.880
 then we'll know, we can probably be like,

03:03.880 --> 03:05.360
 okay, they've updated or upgraded.

03:05.360 --> 03:06.800
 Well, it's fast enough for us humans

03:06.800 --> 03:10.960
 because it seems immediate.

03:10.960 --> 03:13.360
 There's no delay, there's no latency

03:13.360 --> 03:16.240
 in terms of us humans on Earth interacting with things.

03:16.240 --> 03:20.000
 But if you're like intergalactic species

03:20.000 --> 03:21.440
 operating on a much larger scale,

03:21.440 --> 03:23.840
 then you're gonna start noticing some weird stuff.

03:23.840 --> 03:27.340
 Or if you can operate in like around a black hole,

03:27.340 --> 03:29.680
 then you're gonna start to see some render issues.

03:29.680 --> 03:32.680
 You can't go faster than the speed of light, correct?

03:32.680 --> 03:34.520
 So it really limits our ability

03:34.520 --> 03:36.680
 or one's ability to travel space.

03:36.680 --> 03:38.920
 Theoretically, you can, you have wormholes.

03:38.920 --> 03:41.880
 So there's nothing in general relativity

03:41.880 --> 03:46.880
 that precludes faster than the speed of light travel.

03:48.280 --> 03:49.840
 But it just seems you're gonna have to do

03:49.840 --> 03:54.000
 some really funky stuff with very heavy things

03:54.000 --> 03:56.080
 that have like weirdnesses,

03:56.080 --> 03:58.600
 that have basically terrors in space time.

03:58.600 --> 03:59.740
 We don't know how to do that.

03:59.740 --> 04:01.860
 Do navigators know how to do it?

04:01.860 --> 04:03.800
 Do navigators? Yeah.

04:03.800 --> 04:07.000
 Folding space, basically making wormholes.

04:07.000 --> 04:10.240
 So the name C. Yes.

04:11.880 --> 04:13.140
 Who are you?

04:14.800 --> 04:16.960
 Do you think of yourself as multiple people?

04:16.960 --> 04:18.280
 Are you one person?

04:18.280 --> 04:20.860
 Do you know, like in this morning,

04:20.860 --> 04:23.560
 were you a different person than you are tonight?

04:23.560 --> 04:27.080
 We are, I should say, recording this basically at midnight,

04:27.080 --> 04:29.600
 which is awesome. Yes, thank you so much.

04:29.600 --> 04:31.640
 I think I'm about eight hours late.

04:31.640 --> 04:33.960
 No, you're right on time.

04:33.960 --> 04:34.800
 Good morning.

04:34.800 --> 04:37.200
 This is the beginning of a new day soon.

04:37.200 --> 04:39.480
 Anyway, are you the same person

04:39.480 --> 04:41.680
 you were in the morning and the evening?

04:43.040 --> 04:44.320
 Is there multiple people in there?

04:44.320 --> 04:46.240
 Do you think of yourself as one person?

04:46.240 --> 04:47.480
 Or maybe you have no clue?

04:47.480 --> 04:50.160
 Or are you just a giant mystery to yourself?

04:50.160 --> 04:52.480
 Okay, these are really intense questions, but.

04:52.480 --> 04:53.320
 Let's go, let's go.

04:53.320 --> 04:55.320
 Because I asked this myself, like look in the mirror,

04:55.320 --> 04:56.320
 who are you?

04:56.320 --> 04:57.960
 People tell you to just be yourself,

04:57.960 --> 04:59.240
 but what does that even mean?

04:59.240 --> 05:01.520
 I mean, I think my personality changes

05:01.520 --> 05:02.960
 with everyone I talk to.

05:02.960 --> 05:05.720
 So I have a very inconsistent personality.

05:06.600 --> 05:07.440
 Yeah.

05:07.440 --> 05:08.960
 Person to person, so the interaction,

05:08.960 --> 05:11.480
 your personality materializes.

05:11.480 --> 05:12.320
 Or my mood.

05:12.320 --> 05:16.120
 Like I'll go from being like a megalomaniac

05:16.120 --> 05:19.920
 to being like, you know, just like a total hermit

05:19.920 --> 05:21.400
 who is very shy.

05:21.400 --> 05:24.560
 So some combinatorial combination of your mood

05:24.560 --> 05:26.280
 and the person you're interacting with.

05:26.280 --> 05:28.080
 Yeah, mood and people I'm interacting with.

05:28.080 --> 05:29.720
 But I think everyone's like that.

05:29.720 --> 05:30.880
 Maybe not.

05:30.880 --> 05:32.560
 Well, not everybody acknowledges it

05:32.560 --> 05:34.000
 and able to introspect it.

05:34.000 --> 05:35.800
 Who brings out, what kind of person,

05:35.800 --> 05:38.120
 what kind of mood brings out the best in you?

05:38.120 --> 05:39.720
 As an artist and as a human.

05:40.840 --> 05:41.840
 Can you introspect this?

05:41.840 --> 05:45.200
 Like my best friends, like people I can,

05:45.200 --> 05:47.480
 when I'm like super confident

05:47.480 --> 05:50.280
 and I know that they're gonna understand

05:50.280 --> 05:52.160
 everything I'm saying, so like my best friends,

05:52.160 --> 05:55.360
 then when I can start being really funny,

05:55.360 --> 05:57.640
 that's always my like peak mode.

05:57.640 --> 06:00.120
 But it's like, yeah, takes a lot to get there.

06:00.120 --> 06:02.320
 Let's talk about constraints.

06:02.320 --> 06:05.560
 You've talked about constraints and limits.

06:06.960 --> 06:09.560
 Do those help you out as an artist or as a human being?

06:09.560 --> 06:10.760
 Or do they get in the way?

06:10.760 --> 06:11.880
 Do you like the constraints?

06:11.880 --> 06:15.440
 So in creating music, in creating art, in living life,

06:16.760 --> 06:19.560
 do you like the constraints that this world puts on you?

06:21.840 --> 06:24.720
 Or do you hate them?

06:24.720 --> 06:29.720
 If constraints are moving, then you're good, right?

06:29.720 --> 06:32.040
 Like it's like as we are progressing with technology,

06:32.040 --> 06:34.800
 we're changing the constraints of like artistic creation.

06:34.800 --> 06:38.440
 You know, making video and music and stuff

06:38.440 --> 06:39.720
 is getting a lot cheaper.

06:39.720 --> 06:42.080
 There's constantly new technology and new software

06:42.080 --> 06:44.000
 that's making it faster and easier.

06:44.000 --> 06:46.680
 We have so much more freedom than we had in the 70s.

06:46.680 --> 06:48.640
 Like when Michael Jackson, you know,

06:48.640 --> 06:51.440
 when they recorded Thriller with this microphone,

06:51.440 --> 06:54.000
 like they had to use a mixing desk and all this stuff.

06:54.000 --> 06:55.600
 And like probably even get in a studio,

06:55.600 --> 06:56.560
 it's probably really expensive

06:56.560 --> 06:57.600
 and you have to be a really good singer

06:57.600 --> 06:59.080
 and you have to know how to use

06:59.080 --> 07:00.520
 like the mixing desk and everything.

07:00.520 --> 07:02.480
 And now I can just, you know,

07:02.480 --> 07:05.240
 make I've made a whole album on this computer.

07:05.240 --> 07:06.760
 I have a lot more freedom,

07:06.760 --> 07:10.280
 but then I'm also constrained in different ways

07:10.280 --> 07:13.720
 because there's like literally millions more artists.

07:13.720 --> 07:15.720
 It's like a much bigger playing field.

07:15.720 --> 07:18.680
 It's just like, I also, I didn't learn music.

07:18.680 --> 07:20.240
 I'm not a natural musician.

07:20.240 --> 07:22.640
 So I don't know anything about actual music.

07:22.640 --> 07:24.800
 I just know about like the computer.

07:24.800 --> 07:29.800
 So I'm really kind of just like messing around

07:30.520 --> 07:33.280
 and like trying things out.

07:33.280 --> 07:35.760
 Well, yeah, I mean, but the nature of music is changing.

07:35.760 --> 07:37.320
 So you're saying you don't know actual music,

07:37.320 --> 07:39.260
 what music is changing.

07:39.260 --> 07:41.920
 Music is becoming, you've talked about this,

07:41.920 --> 07:46.640
 is becoming, it's like merging with technology.

07:46.640 --> 07:47.680
 Yes.

07:47.680 --> 07:51.400
 It's becoming something more than just like

07:51.400 --> 07:53.000
 the notes on a piano.

07:53.000 --> 07:54.960
 It's becoming some weird composition

07:54.960 --> 07:59.440
 that requires engineering skills, programming skills,

07:59.440 --> 08:03.440
 some kind of human robot interaction skills,

08:03.440 --> 08:05.680
 and still some of the same things that Michael Jackson had,

08:05.680 --> 08:08.480
 which is like a good ear for a good sense of taste

08:08.480 --> 08:10.360
 of what's good and not the final thing

08:10.360 --> 08:11.520
 when it's put together.

08:11.520 --> 08:14.920
 Like you're allowed, you're enabled, empowered

08:14.920 --> 08:17.200
 with a laptop to layer stuff,

08:17.200 --> 08:20.280
 to start like layering insane amounts of stuff.

08:20.280 --> 08:22.280
 And it's super easy to do that.

08:22.280 --> 08:25.000
 I do think music production is a really underrated art form.

08:25.000 --> 08:26.700
 I feel like people really don't appreciate it.

08:26.700 --> 08:27.960
 When I look at publishing splits,

08:27.960 --> 08:31.160
 the way that people like pay producers and stuff,

08:32.240 --> 08:35.560
 it's super, producers are just deeply underrated.

08:35.560 --> 08:39.160
 Like so many of the songs that are popular right now

08:39.160 --> 08:40.920
 or for the last 20 years,

08:40.920 --> 08:42.240
 like part of the reason they're popular

08:42.240 --> 08:44.000
 is because the production is really interesting

08:44.000 --> 08:45.640
 or really sick or really cool.

08:45.640 --> 08:48.060
 And it's like, I don't think listeners,

08:50.920 --> 08:52.520
 like people just don't really understand

08:52.520 --> 08:54.640
 what music production is.

08:54.640 --> 08:57.680
 It's not, it's sort of like this weird,

08:57.680 --> 08:59.360
 discombobulated art form.

08:59.360 --> 09:01.380
 It's not like a formal, because it's so new,

09:01.380 --> 09:06.380
 there isn't like a formal training path for it.

09:06.880 --> 09:10.200
 It's mostly driven by like autodidacts.

09:10.200 --> 09:11.280
 Like it's like almost everyone I know

09:11.280 --> 09:12.200
 who's good at production,

09:12.200 --> 09:13.760
 like they didn't go to music school or anything.

09:13.760 --> 09:15.080
 They just taught themselves.

09:15.080 --> 09:16.040
 Are they're mostly different?

09:16.040 --> 09:18.400
 Like the music producers, you know,

09:18.400 --> 09:21.320
 is there some commonalities that time together

09:21.320 --> 09:23.580
 or are they all just different kinds of weirdos?

09:23.580 --> 09:25.440
 Cause I just, I just hung out with Rick Rubin.

09:25.440 --> 09:26.280
 I don't know if you've.

09:26.280 --> 09:29.760
 Yeah, I mean, Rick Rubin is like literally

09:29.760 --> 09:31.200
 one of the gods of music production.

09:31.200 --> 09:33.780
 Like he's one of the people who first,

09:33.780 --> 09:36.320
 you know, who like made music production,

09:36.320 --> 09:39.360
 you know, made the production as important

09:39.360 --> 09:41.600
 as the actual lyrics or the notes.

09:41.600 --> 09:43.560
 But the thing he does, which is interesting,

09:43.560 --> 09:45.520
 I don't know if you can speak to that,

09:45.520 --> 09:46.760
 but just hanging out with him,

09:46.760 --> 09:48.520
 he seems to just sit there in silence,

09:48.520 --> 09:50.800
 close his eyes and listen.

09:50.800 --> 09:53.640
 It's like, he almost does nothing.

09:53.640 --> 09:55.880
 And that nothing somehow gives you freedom

09:55.880 --> 09:58.160
 to be the best version of yourself.

09:58.160 --> 10:00.060
 So that's music production somehow too,

10:00.060 --> 10:02.680
 which is like encouraging you to do less,

10:02.680 --> 10:06.900
 to simplify, to like push towards minimalism.

10:06.900 --> 10:08.060
 I mean, I guess, I mean,

10:09.600 --> 10:11.600
 I work differently from Rick Rubin

10:11.600 --> 10:14.160
 cause Rick Rubin produces for other artists,

10:14.160 --> 10:17.080
 whereas like I mostly produce for myself.

10:17.080 --> 10:19.240
 So it's a very different situation.

10:19.240 --> 10:21.760
 I also think Rick Rubin, he's in that,

10:21.760 --> 10:23.600
 I would say advanced category of producer

10:23.600 --> 10:26.600
 where like you've like earned your,

10:26.600 --> 10:27.960
 you can have an engineer and stuff

10:27.960 --> 10:29.840
 and people like do the stuff for you.

10:29.840 --> 10:32.400
 But I usually just like do stuff myself.

10:32.400 --> 10:37.400
 So you're the engineer, the producer and the artist.

10:38.080 --> 10:39.880
 Yeah, I guess I would say I'm in the era,

10:39.880 --> 10:41.280
 like the post Rick Rubin era.

10:41.280 --> 10:43.000
 Like I come from the kind of like

10:44.320 --> 10:47.040
 Skrillex school of thought,

10:47.040 --> 10:49.240
 which is like where you are.

10:49.240 --> 10:51.040
 Yeah, the engineer, producer, artist.

10:51.040 --> 10:53.760
 Like where, I mean lately,

10:53.760 --> 10:55.560
 sometimes I'll work with a producer now.

10:55.560 --> 10:59.120
 I'm gently sort of delicately starting

10:59.120 --> 10:59.960
 to collaborate a bit more,

10:59.960 --> 11:02.800
 but like I think I'm kind of from the,

11:02.800 --> 11:07.120
 like the whatever 2010s explosion of things

11:07.120 --> 11:11.920
 where everything became available on the computer

11:11.920 --> 11:16.680
 and you kind of got this like lone wizard energy thing going.

11:16.680 --> 11:19.680
 So you embraced being the loneliness.

11:19.680 --> 11:22.440
 Is the loneliness somehow an engine of creativity?

11:22.440 --> 11:24.560
 Like, so most of your stuff,

11:24.560 --> 11:28.640
 most of your creative quote unquote genius in quotes

11:28.640 --> 11:32.160
 is in the privacy of your mind.

11:32.160 --> 11:34.780
 Yes, well, it was,

11:36.680 --> 11:39.060
 but here's the thing.

11:39.060 --> 11:40.840
 I was talking to Daniel Eck and he said,

11:40.840 --> 11:43.400
 he's like most artists, they have about 10 years,

11:43.400 --> 11:45.160
 like 10 good years.

11:45.160 --> 11:48.820
 And then they usually stop making their like vital shit.

11:49.880 --> 11:53.360
 And I feel like I'm sort of like nearing the end

11:53.360 --> 11:56.540
 of my 10 years on my own.

11:56.540 --> 11:58.640
 So you have to become somebody else.

11:58.640 --> 11:59.840
 Now I'm like, I'm in the process

11:59.840 --> 12:01.720
 of becoming somebody else and reinventing.

12:01.720 --> 12:02.840
 When I work with other people,

12:02.840 --> 12:04.180
 because I've never worked with other people,

12:04.180 --> 12:08.380
 I find that I make like, that I'm exceptionally rejuvenated

12:08.380 --> 12:10.980
 and making like some of the most vital work I've ever made.

12:10.980 --> 12:13.840
 So, because I think another human brain

12:13.840 --> 12:16.540
 is like one of the best tools you can possibly find.

12:17.560 --> 12:18.400
 Like.

12:18.400 --> 12:20.560
 It's a funny way to put it, I love it.

12:20.560 --> 12:23.340
 It's like if a tool is like, you know,

12:23.340 --> 12:27.320
 whatever HP plus one or like adds some like stats

12:27.320 --> 12:30.760
 to your character, like another human brain

12:30.760 --> 12:34.240
 will like square it instead of just like adding something.

12:34.240 --> 12:36.320
 Double up the experience points, I love this.

12:36.320 --> 12:38.280
 We should also mention we're playing Tavern music

12:38.280 --> 12:41.600
 before this and which I love, which I first,

12:41.600 --> 12:42.440
 I think I first.

12:42.440 --> 12:43.760
 You had to stop the Tavern music.

12:43.760 --> 12:46.380
 Yeah, because it doesn't, the audio.

12:46.380 --> 12:47.220
 Okay, okay.

12:47.220 --> 12:48.040
 But it makes.

12:48.040 --> 12:48.880
 Yeah, it'll make the podcast annoying.

12:48.880 --> 12:50.040
 Add it in post, add it in post.

12:50.040 --> 12:51.560
 No one will want to listen to the podcast.

12:51.560 --> 12:53.400
 They probably would, but it makes me,

12:53.400 --> 12:55.480
 it reminds me like of a video game,

12:55.480 --> 12:56.760
 like a role playing video game

12:56.760 --> 12:58.400
 where you have experience points.

12:58.400 --> 13:03.400
 There's something really joyful about wandering places

13:03.440 --> 13:06.480
 like Elder Scrolls, like Skyrim,

13:06.480 --> 13:10.500
 just exploring these landscapes in another world

13:10.500 --> 13:12.000
 and then you get experience points

13:12.000 --> 13:14.000
 and you can work on different skills

13:14.000 --> 13:16.160
 and somehow you progress in life.

13:16.160 --> 13:17.600
 I don't know, it's simple.

13:17.600 --> 13:19.960
 It doesn't have some of the messy complexities of life

13:19.960 --> 13:23.960
 and there's usually a bad guy you can fight in Skyrim.

13:23.960 --> 13:25.560
 It's dragons and so on.

13:25.560 --> 13:26.460
 I'm sure in Elden Ring,

13:26.460 --> 13:28.240
 there's a bunch of monsters you can fight.

13:28.240 --> 13:29.080
 I love that.

13:29.080 --> 13:29.960
 I feel like Elden Ring,

13:29.960 --> 13:31.440
 I feel like this is a good analogy

13:31.440 --> 13:32.360
 to music production though

13:32.360 --> 13:34.400
 because it's like, I feel like the engineers

13:34.400 --> 13:36.600
 and the people creating these open worlds are,

13:36.600 --> 13:39.660
 it's sort of like similar to people, to music producers

13:39.660 --> 13:42.720
 where it's like this hidden archetype

13:42.720 --> 13:44.600
 that like no one really understands what they do

13:44.600 --> 13:46.160
 and no one really knows who they are,

13:46.160 --> 13:49.300
 but they're like, it's like the artist engineer

13:49.300 --> 13:51.760
 because it's like, it's both art

13:51.760 --> 13:54.840
 and fairly complex engineering.

13:54.840 --> 13:57.200
 Well, you're saying they don't get enough credit.

13:57.200 --> 13:58.600
 Aren't you kind of changing that

13:58.600 --> 14:01.320
 by becoming the person doing everything?

14:01.320 --> 14:03.680
 Aren't you, isn't the engineer?

14:03.680 --> 14:05.440
 Well, I mean, others have gone before me.

14:05.440 --> 14:07.800
 I'm not, you know, there's like Timbaland and Skrillex

14:07.800 --> 14:10.360
 and there's all these people that are like,

14:10.360 --> 14:12.040
 you know, very famous for this,

14:12.040 --> 14:13.920
 but I just think the general,

14:13.920 --> 14:15.920
 I think people get confused about what it is

14:15.920 --> 14:19.200
 and just don't really know what it is per se

14:19.200 --> 14:20.480
 and it's just when I see a song,

14:20.480 --> 14:22.280
 like when there's like a hit song,

14:22.280 --> 14:27.280
 like I'm just trying to think of like,

14:27.520 --> 14:29.860
 just going for like even just a basic pop hit,

14:29.860 --> 14:33.120
 like, what's it?

14:33.120 --> 14:36.100
 Like Rules by Dua Lipa or something.

14:36.100 --> 14:39.220
 The production on that is actually like really crazy.

14:39.220 --> 14:40.560
 I mean, the song is also great,

14:40.560 --> 14:43.360
 but it's like the production is exceptionally memorable.

14:43.360 --> 14:47.200
 Like, you know, and it's just like no one,

14:47.200 --> 14:49.180
 I can't, I don't even know who produced that song.

14:49.180 --> 14:50.680
 It's just like, isn't part of like the rhetoric

14:50.680 --> 14:53.420
 of how we just discuss the creation of art.

14:53.420 --> 14:57.200
 We just sort of like don't consider the music producer

14:57.200 --> 15:00.320
 because I think the music producer used to be more

15:00.320 --> 15:02.500
 just simply recording things.

15:03.700 --> 15:04.640
 Yeah, that's interesting

15:04.640 --> 15:06.000
 because when you think about movies,

15:06.000 --> 15:08.600
 we talk about the actor and the actresses,

15:08.600 --> 15:11.520
 but we also talk about the directors.

15:11.520 --> 15:14.440
 We don't talk about like that with the music as often.

15:15.760 --> 15:17.360
 The Beatles music producer

15:17.360 --> 15:19.880
 was one of the first kind of guy,

15:19.880 --> 15:21.220
 one of the first people sort of introducing

15:21.220 --> 15:22.640
 crazy sound design into pop music.

15:22.640 --> 15:24.160
 I forget his name.

15:24.160 --> 15:25.860
 He has the same, I forget his name,

15:25.860 --> 15:29.180
 but you know, like he was doing all the weird stuff

15:29.180 --> 15:32.420
 like dropping pianos and like, yeah.

15:32.420 --> 15:33.480
 Oh, to get the, yeah, yeah, yeah,

15:33.480 --> 15:36.580
 to get the sound, to get the authentic sound.

15:36.580 --> 15:38.100
 What about lyrics?

15:38.100 --> 15:40.960
 You think those, where did they fit

15:40.960 --> 15:42.960
 into how important they are?

15:42.960 --> 15:44.860
 I was heartbroken to learn

15:44.860 --> 15:46.800
 that Elvis didn't write his songs.

15:46.800 --> 15:47.880
 I was very mad.

15:47.880 --> 15:49.480
 A lot of people don't write their songs.

15:49.480 --> 15:50.820
 I understand this, but.

15:50.820 --> 15:52.200
 But here's the thing.

15:52.200 --> 15:54.880
 I feel like there's this desire for authenticity.

15:54.880 --> 15:56.140
 I used to be like really mad

15:56.140 --> 15:58.000
 when like people wouldn't write or produce their music

15:58.000 --> 15:59.280
 and I'd be like, that's fake.

15:59.280 --> 16:04.280
 And then I realized there's all this like weird bitterness

16:04.520 --> 16:07.760
 and like agronus in art about authenticity.

16:07.760 --> 16:10.800
 But I had this kind of like weird realization recently

16:12.200 --> 16:14.960
 where I started thinking that like art

16:14.960 --> 16:19.960
 is sort of a decentralized collective thing.

16:20.220 --> 16:25.220
 Like art is kind of a conversation

16:25.300 --> 16:28.560
 with all the artists that have ever lived before you.

16:28.560 --> 16:31.080
 You know, like it's like, you're really just sort of,

16:31.080 --> 16:33.520
 it's not like anyone's reinventing the wheel here.

16:33.520 --> 16:36.620
 Like you're kind of just taking, you know,

16:36.620 --> 16:38.200
 thousands of years of art

16:38.200 --> 16:41.700
 and like running it through your own little algorithm

16:41.700 --> 16:45.040
 and then like making your interpretation of it.

16:45.040 --> 16:46.240
 You just joined the conversation

16:46.240 --> 16:47.560
 with all the other artists that came before.

16:47.560 --> 16:49.580
 It's just a beautiful way to look at it.

16:49.580 --> 16:51.540
 Like, and it's like, I feel like everyone's always like,

16:51.540 --> 16:54.120
 there's all this copyright and IP and this and that

16:54.120 --> 16:55.160
 or authenticity.

16:55.160 --> 16:59.220
 And it's just like, I think we need to stop seeing this

16:59.220 --> 17:01.580
 as this like egotistical thing of like,

17:01.580 --> 17:04.180
 oh, the creative genius, the lone creative genius

17:04.180 --> 17:05.020
 or this or that.

17:05.020 --> 17:08.760
 Because it's like, I think art shouldn't be about that.

17:08.760 --> 17:10.360
 I think art is something that sort of

17:10.360 --> 17:12.040
 brings humanity together.

17:12.040 --> 17:14.080
 And it's also, art is also kind of the collective memory

17:14.080 --> 17:14.920
 of humans.

17:14.920 --> 17:18.720
 It's like, we don't give a fuck about

17:18.720 --> 17:20.280
 whatever ancient Egypt,

17:20.280 --> 17:22.760
 like how much grain got sent that day

17:22.760 --> 17:24.920
 and sending the records and like, you know,

17:24.920 --> 17:27.600
 like who went where and, you know,

17:27.600 --> 17:29.640
 how many shields needed to be produced for this.

17:29.640 --> 17:32.240
 Like we just remember their art.

17:32.240 --> 17:34.840
 And it's like, you know, it's like in our day to day life,

17:34.840 --> 17:38.080
 there's all this stuff that seems more important than art

17:38.080 --> 17:40.200
 because it helps us function and survive.

17:40.200 --> 17:41.840
 But when all this is gone,

17:41.840 --> 17:45.040
 like the only thing that's really gonna be left is the art.

17:45.040 --> 17:46.800
 The technology will be obsolete.

17:46.800 --> 17:47.640
 That's so fascinating.

17:47.640 --> 17:49.080
 Like the humans will be dead.

17:49.080 --> 17:49.920
 That is true.

17:49.920 --> 17:52.520
 A good compression of human history

17:52.520 --> 17:56.200
 is the art we've generated across the different centuries,

17:56.200 --> 17:57.800
 the different millennia.

17:57.800 --> 17:59.900
 So when the aliens come.

17:59.900 --> 18:00.740
 When the aliens come,

18:00.740 --> 18:02.740
 they're gonna find the hieroglyphics and the pyramids.

18:02.740 --> 18:04.360
 I mean, art could be broadly defined.

18:04.360 --> 18:06.240
 They might find like the engineering marvels,

18:06.240 --> 18:09.860
 the bridges, the rockets, the.

18:09.860 --> 18:11.480
 I guess I sort of classify though.

18:11.480 --> 18:13.580
 Architecture is art too.

18:13.580 --> 18:18.580
 I consider engineering in those formats to be art, for sure.

18:19.360 --> 18:23.200
 It sucks that like digital art is easier to delete.

18:23.200 --> 18:25.800
 So if there's an apocalypse, a nuclear war,

18:25.800 --> 18:26.880
 that can disappear.

18:26.880 --> 18:28.080
 Yes.

18:28.080 --> 18:28.920
 And the physical.

18:28.920 --> 18:30.000
 There's something still valuable

18:30.000 --> 18:32.360
 about the physical manifestation of art.

18:32.360 --> 18:35.580
 That sucks that like music, for example,

18:35.580 --> 18:37.940
 has to be played by somebody.

18:37.940 --> 18:41.640
 Yeah, I do think we should have a foundation type situation

18:41.640 --> 18:44.120
 where we like, you know how we have like seed banks

18:44.120 --> 18:45.520
 up in the north and stuff?

18:45.520 --> 18:48.000
 Like we should probably have like a solar powered

18:48.000 --> 18:49.760
 or geothermal little bunker

18:49.760 --> 18:52.360
 that like has all human knowledge.

18:52.360 --> 18:54.220
 You mentioned Daniel Ek and Spotify.

18:55.240 --> 18:56.960
 What do you think about that as an artist?

18:56.960 --> 18:58.280
 What's Spotify?

18:58.280 --> 19:00.000
 Is that empowering?

19:00.000 --> 19:02.560
 To me, Spotify as a consumer is super exciting.

19:02.560 --> 19:04.960
 It makes it easy for me to access music

19:04.960 --> 19:06.600
 from all kinds of artists,

19:06.600 --> 19:08.420
 get to explore all kinds of music,

19:08.420 --> 19:12.280
 make it super easy to sort of curate my own playlist

19:12.280 --> 19:13.960
 and have fun with all that.

19:13.960 --> 19:16.040
 It was so liberating to let go.

19:16.040 --> 19:17.560
 You know, I used to collect, you know,

19:17.560 --> 19:22.120
 albums and CDs and so on, like horde albums.

19:22.120 --> 19:22.960
 Yeah.

19:22.960 --> 19:23.780
 Like they matter.

19:23.780 --> 19:25.640
 But the reality you could, you know,

19:25.640 --> 19:28.080
 that was really liberating that I could let go of that.

19:28.080 --> 19:32.160
 And letting go of the albums you're kind of collecting

19:32.160 --> 19:33.600
 allows you to find new music,

19:33.600 --> 19:36.200
 exploring new artists and all that kind of stuff.

19:36.200 --> 19:38.360
 But I know from a perspective of an artist that could be,

19:38.360 --> 19:39.200
 like you mentioned,

19:39.200 --> 19:42.000
 competition could be a kind of constraint

19:42.000 --> 19:44.640
 because there's more and more and more artists

19:44.640 --> 19:46.040
 on the platform.

19:46.040 --> 19:47.880
 I think it's better that there's more artists.

19:47.880 --> 19:49.800
 I mean, again, this might be propaganda

19:49.800 --> 19:51.680
 because this is all from a conversation with Daniel Ek.

19:51.680 --> 19:54.040
 So this could easily be propaganda.

19:54.040 --> 19:56.720
 We're all a victim of somebody's propaganda.

19:56.720 --> 19:58.960
 So let's just accept this.

19:58.960 --> 20:01.000
 But Daniel Ek was telling me that, you know,

20:01.000 --> 20:03.680
 at the, because I, you know, when I met him,

20:03.680 --> 20:06.440
 I came in all furious about Spotify

20:06.440 --> 20:07.760
 and like I grilled him super hard.

20:07.760 --> 20:10.640
 So I've got his answers here.

20:10.640 --> 20:13.520
 But he was saying like at the sort of peak

20:13.520 --> 20:15.240
 of the CD industry,

20:15.240 --> 20:18.280
 there was like 20,000 artists making millions

20:18.280 --> 20:19.520
 and millions of dollars.

20:19.520 --> 20:22.840
 Like there was just like a very tiny kind of 1%.

20:22.840 --> 20:27.400
 And Spotify has kind of democratized the industry

20:27.400 --> 20:30.320
 because now I think he said there's about a million artists

20:30.320 --> 20:33.120
 making a good living from Spotify.

20:33.120 --> 20:35.600
 And when I heard that, I was like, honestly,

20:36.920 --> 20:38.840
 I would rather make less money

20:38.840 --> 20:41.160
 and have just like a decent living

20:43.720 --> 20:46.560
 and have more artists be able to have that,

20:46.560 --> 20:49.320
 even though I like, I wish it could include everyone, but.

20:49.320 --> 20:50.760
 Yeah, that's really hard to argue with.

20:50.760 --> 20:52.280
 YouTube is the same.

20:52.280 --> 20:54.120
 It's YouTube's mission.

20:54.120 --> 20:58.280
 They want to basically have as many creators as possible

20:58.280 --> 21:00.720
 and make a living, some kind of living.

21:00.720 --> 21:02.720
 And that's so hard to argue with.

21:02.720 --> 21:03.560
 It's so hard.

21:03.560 --> 21:04.480
 But I think there's better ways to do it.

21:04.480 --> 21:06.520
 My manager, I actually wish he was here.

21:06.520 --> 21:07.840
 Like I would have brought him up.

21:07.840 --> 21:12.840
 My manager is building an app that can manage you.

21:13.800 --> 21:16.520
 So it'll like help you organize your percentages

21:16.520 --> 21:18.840
 and get your publishing and dah, dah, dah, dah, dah.

21:18.840 --> 21:19.960
 So you can take out all the middlemen

21:19.960 --> 21:21.360
 so you can have a much bigger,

21:21.360 --> 21:23.000
 it'll just like automate it.

21:23.000 --> 21:23.840
 So you can get.

21:23.840 --> 21:24.680
 So automate the manager?

21:24.680 --> 21:28.040
 Automate management, publishing,

21:28.040 --> 21:32.440
 and legal, it can read,

21:32.440 --> 21:34.080
 the app he's building can read your contract

21:34.080 --> 21:35.640
 and like tell you about it.

21:35.640 --> 21:38.280
 Because one of the issues with music right now,

21:38.280 --> 21:39.800
 it's not that we're not getting paid enough,

21:39.800 --> 21:44.800
 but it's that the art industry is filled with middlemen

21:44.960 --> 21:47.760
 because artists are not good at business.

21:47.760 --> 21:50.400
 And from the beginning, like Frank Sinatra,

21:50.400 --> 21:51.640
 it's all mob stuff.

21:51.640 --> 21:56.640
 Like it's the music industry is run by business people,

21:56.640 --> 21:59.480
 not the artists and the artists really get very small cuts

21:59.480 --> 22:00.400
 of like what they make.

22:00.400 --> 22:04.720
 And so I think part of the reason I'm a technocrat,

22:04.720 --> 22:07.040
 which I mean, your fans are gonna be technocrats.

22:07.040 --> 22:09.240
 So no one's, they're not gonna be mad at me about this,

22:09.240 --> 22:12.160
 but like my fans hate it when I say this kind of thing

22:12.160 --> 22:13.000
 or the general public.

22:13.000 --> 22:14.160
 They don't like technocrats.

22:14.160 --> 22:15.600
 They don't like technocrats.

22:15.600 --> 22:18.720
 Like when I watched Battle Angel Alita

22:18.720 --> 22:20.360
 and they were like the Martian technocracy

22:20.360 --> 22:22.000
 and I was like, yeah, Martian technocracy.

22:22.000 --> 22:23.520
 And then they were like, and they're evil.

22:23.520 --> 22:25.560
 And I was like, oh, okay.

22:25.560 --> 22:28.760
 I was like, cause Martian technocracy sounds sick to me.

22:28.760 --> 22:31.920
 Yeah, so your intuition as technocrats

22:31.920 --> 22:34.200
 would create some kind of beautiful world.

22:34.200 --> 22:36.040
 For example, what my manager's working on,

22:36.040 --> 22:39.880
 if you can create an app that removes the need for a lawyer

22:39.880 --> 22:43.360
 and then you could have smart contracts on the blockchain,

22:43.360 --> 22:46.800
 removes the need for like management

22:46.800 --> 22:48.000
 and organizing all this stuff,

22:48.000 --> 22:50.920
 like can read your stuff and explain it to you,

22:50.920 --> 22:54.200
 can collect your royalties, you know,

22:54.200 --> 22:56.960
 like then the small amounts,

22:56.960 --> 22:58.680
 the amount of money that you're getting from Spotify

22:58.680 --> 23:01.760
 actually means a lot more and goes a lot farther.

23:01.760 --> 23:03.120
 It can remove some of the bureaucracy,

23:03.120 --> 23:06.360
 some of the inefficiencies that make life

23:06.360 --> 23:08.200
 not as great as it could be.

23:08.200 --> 23:10.840
 Yeah, I think the issue isn't that there's not enough.

23:10.840 --> 23:12.680
 Like the issue is that there's inefficiency

23:12.680 --> 23:17.560
 and I'm really into this positive sum mindset,

23:18.640 --> 23:20.840
 you know, the win, win mindset of like,

23:20.840 --> 23:23.520
 instead of, you know, fighting over the scraps,

23:23.520 --> 23:26.520
 how do we make the, or worrying about scarcity,

23:26.520 --> 23:27.800
 like instead of a scarcity mindset,

23:27.800 --> 23:30.080
 why don't we just increase the efficiency

23:30.080 --> 23:32.360
 and, you know, in that way.

23:32.360 --> 23:34.400
 Expand the size of the pie.

23:34.400 --> 23:36.560
 Let me ask you about experimentation.

23:36.560 --> 23:38.640
 So you said, which is beautiful,

23:40.480 --> 23:42.760
 being a musician is like having a conversation

23:42.760 --> 23:44.560
 with all those that came before you.

23:45.440 --> 23:48.320
 How much of creating music is like

23:51.200 --> 23:53.040
 kind of having that conversation,

23:53.040 --> 23:57.200
 trying to fit into the cultural trends

23:57.200 --> 23:59.320
 and how much of it is like trying to,

23:59.320 --> 24:00.840
 as much as possible, be an outsider

24:00.840 --> 24:02.600
 and come up with something totally new.

24:02.600 --> 24:04.440
 It's like when you're thinking,

24:04.440 --> 24:05.640
 when you're experimenting,

24:05.640 --> 24:08.680
 are you trying to be totally different, totally weird?

24:08.680 --> 24:12.120
 Are you trying to fit in?

24:12.120 --> 24:14.640
 Man, this is so hard because I feel like I'm

24:14.640 --> 24:16.880
 kind of in the process of semi retiring from music,

24:16.880 --> 24:18.720
 so this is like my old brain.

24:18.720 --> 24:22.040
 Yeah, bring it from like the shelf,

24:22.040 --> 24:24.440
 put it on the table for a couple minutes,

24:24.440 --> 24:26.280
 we'll just poke it.

24:26.280 --> 24:27.240
 I think it's a bit of both

24:27.240 --> 24:31.320
 because I think forcing yourself to engage with new music

24:32.400 --> 24:35.000
 is really great for neuroplasticity.

24:35.000 --> 24:38.280
 Like I think, you know, as people,

24:39.480 --> 24:41.640
 part of the reason music is marketed at young people

24:41.640 --> 24:43.360
 is because young people are very neuroplastic.

24:43.360 --> 24:48.200
 So like if you're 16 to like 23 or whatever,

24:48.200 --> 24:50.840
 it's gonna be really easy for you to love new music.

24:50.840 --> 24:52.280
 And if you're older than that,

24:52.280 --> 24:53.760
 it gets harder and harder and harder.

24:53.760 --> 24:54.960
 And I think one of the beautiful things

24:54.960 --> 24:57.880
 about being a musician is I just constantly force myself

24:57.880 --> 24:58.760
 to listen to new music

24:58.760 --> 25:01.000
 and I think it keeps my brain really plastic.

25:01.000 --> 25:02.760
 And I think this is a really good exercise.

25:02.760 --> 25:04.280
 I just think everyone should do this.

25:04.280 --> 25:05.600
 You listen to new music and you hate it,

25:05.600 --> 25:08.600
 I think you should just keep, force yourself to like,

25:08.600 --> 25:09.920
 okay, well why do people like it?

25:09.920 --> 25:14.640
 And like, you know, make your brain form new neural pathways

25:14.640 --> 25:16.880
 and be more open to change.

25:16.880 --> 25:18.280
 That's really brilliant actually.

25:18.280 --> 25:21.520
 Sorry to interrupt, but like that exercise

25:21.520 --> 25:26.520
 is really amazing to sort of embrace change,

25:27.480 --> 25:31.600
 embrace sort of practice neuroplasticity.

25:31.600 --> 25:33.160
 Because like that's one of the things,

25:33.160 --> 25:34.360
 you fall in love with a certain band

25:34.360 --> 25:36.760
 and you just kind of stay with that for the rest of your life

25:36.760 --> 25:38.400
 and then you never understand the modern music.

25:38.400 --> 25:39.240
 That's a really good exercise.

25:39.240 --> 25:40.640
 Most of the streaming on Spotify

25:40.640 --> 25:42.440
 is like classic rock and stuff.

25:42.440 --> 25:44.800
 Like new music makes up a very small chunk

25:44.800 --> 25:46.840
 of what is played on Spotify.

25:46.840 --> 25:50.120
 And I think this is like not a good sign for us as a species.

25:50.120 --> 25:52.880
 I think, yeah.

25:52.880 --> 25:57.720
 So it's a good measure of the species open mindedness

25:57.720 --> 26:01.120
 to change is how often you listen to new music.

26:01.120 --> 26:05.160
 The brain, let's put the music brain back on the shelf.

26:05.160 --> 26:08.280
 I gotta pull out the futurist brain for a second.

26:09.680 --> 26:12.280
 In what wild ways do you think the future,

26:12.280 --> 26:14.960
 say in like 30 years, maybe 50 years,

26:14.960 --> 26:16.960
 maybe a hundred years will be different

26:19.280 --> 26:22.120
 from our current way of life on earth?

26:22.120 --> 26:25.400
 We can talk about augmented reality, virtual reality,

26:25.400 --> 26:30.400
 maybe robots, maybe space travel, maybe video games,

26:30.800 --> 26:32.520
 maybe genetic engineering.

26:32.520 --> 26:33.360
 I can keep going.

26:33.360 --> 26:36.240
 Cyborgs, aliens, world wars,

26:36.240 --> 26:39.840
 maybe destructive nuclear wars, good and bad.

26:39.840 --> 26:43.520
 When you think about the future, what are you imagining?

26:43.520 --> 26:45.920
 What's the weirdest and the wildest it could be?

26:47.640 --> 26:50.120
 Have you read Surface Detail by Iain Banks?

26:51.480 --> 26:54.800
 Surface Detail is my favorite depiction of a,

26:54.800 --> 26:56.520
 oh wow, you have to read this book.

26:56.520 --> 26:58.680
 It's literally the greatest science fiction book

26:58.680 --> 26:59.520
 possibly ever written.

26:59.520 --> 27:01.560
 Iain Banks is the man, yeah, for sure.

27:01.560 --> 27:03.200
 What have you read?

27:03.200 --> 27:04.520
 Just the Player of Games.

27:04.520 --> 27:07.320
 I read that titles can't be copyrighted

27:07.320 --> 27:08.280
 so you can just steal them.

27:08.280 --> 27:09.920
 And I was like, Player of Games, sick.

27:09.920 --> 27:10.760
 Nice.

27:10.760 --> 27:12.760
 Yeah, so you can name your album.

27:12.760 --> 27:13.600
 Like I always wanted to.

27:13.600 --> 27:15.000
 Romeo and Juliet or something.

27:15.000 --> 27:17.080
 I always wanted to name an album War and Peace.

27:17.080 --> 27:17.920
 Nice.

27:17.920 --> 27:18.760
 Like that would be, like you.

27:18.760 --> 27:20.440
 That is a good, that's a good,

27:20.440 --> 27:21.600
 where have I heard that before?

27:21.600 --> 27:24.280
 You can do that, like you could do that.

27:24.280 --> 27:26.040
 Also things that are in the public domain.

27:26.040 --> 27:27.160
 For people who have no clue,

27:27.160 --> 27:29.680
 you do have a song called Player of Games.

27:29.680 --> 27:30.680
 Yes, oh yeah.

27:30.680 --> 27:33.840
 So Iain Banks, Surface Detail is in my opinion

27:33.840 --> 27:37.200
 the best future that I've ever read about

27:37.200 --> 27:39.540
 or heard about in science fiction.

27:39.540 --> 27:44.540
 Basically there's the relationship with super intelligence,

27:44.600 --> 27:49.140
 like artificial super intelligence is just, it's like great.

27:50.400 --> 27:53.040
 I want to credit the person who coined this term

27:53.040 --> 27:55.240
 because I love this term.

27:55.240 --> 27:58.640
 And I feel like young women don't get enough credit in.

28:00.160 --> 28:03.920
 Yeah, so if you go to Protopia Futures on Instagram,

28:03.920 --> 28:05.480
 what is her name?

28:05.480 --> 28:07.240
 Personalized donor experience at scale,

28:07.240 --> 28:08.920
 our AI power donor experience.

28:08.920 --> 28:13.920
 Monica Bealskite, I'm saying that wrong.

28:15.360 --> 28:17.680
 And I'm probably gonna, I'm probably butchering this a bit,

28:17.680 --> 28:21.580
 but Protopia is sort of, if utopia is unattainable,

28:21.580 --> 28:26.000
 Protopia is sort of like, you know.

28:26.000 --> 28:28.640
 Wow, that's an awesome Instagram, Protopia Futures.

28:28.640 --> 28:33.480
 A great, a future that is, you know, as good as we can get.

28:33.480 --> 28:34.720
 The future, positive future.

28:34.720 --> 28:38.360
 AI, is this a centralized AI in Surface Detail

28:38.360 --> 28:39.280
 or is it distributed?

28:39.280 --> 28:40.560
 What kind of AI is it?

28:40.560 --> 28:42.800
 They mostly exist as giant super ships,

28:42.800 --> 28:45.800
 like sort of like the guild ships in Dune.

28:45.800 --> 28:47.960
 Like they're these giant ships that kind of move people

28:47.960 --> 28:49.480
 around and the ships are sentient

28:49.480 --> 28:52.240
 and they can talk to all the passengers.

28:52.240 --> 28:56.400
 And I mean, there's a lot of different types of AI

28:56.400 --> 28:58.320
 in the Banksyan future,

28:58.320 --> 29:01.080
 but in the opening scene of Surface Detail,

29:01.080 --> 29:02.320
 there's this place called the Culture

29:02.320 --> 29:04.440
 and the Culture is basically a Protopian future.

29:04.440 --> 29:07.320
 And a Protopian future, I think,

29:07.320 --> 29:08.860
 is like a future that is like,

29:09.760 --> 29:12.400
 obviously it's not utopia, it's not perfect.

29:12.400 --> 29:14.000
 And like, cause like striving for utopia,

29:14.000 --> 29:16.960
 I think feels hopeless and it's sort of like,

29:16.960 --> 29:19.280
 maybe not the best terminology to be using.

29:20.380 --> 29:23.960
 So it's like, it's a pretty good place.

29:23.960 --> 29:27.660
 Like mostly like, you know,

29:27.660 --> 29:29.860
 super intelligence and biological beings

29:29.860 --> 29:31.880
 exist fairly in harmony.

29:31.880 --> 29:33.120
 There's not too much war.

29:33.120 --> 29:35.680
 There's like as close to equality as you can get,

29:35.680 --> 29:38.680
 you know, it's like approximately a good future.

29:38.680 --> 29:40.160
 Like there's really awesome stuff.

29:40.160 --> 29:45.160
 It's, and in the opening scene,

29:45.600 --> 29:49.520
 this girl, she's born as a sex slave outside of the culture.

29:49.520 --> 29:51.200
 So she's in a society that doesn't adhere

29:51.200 --> 29:52.620
 to the cultural values.

29:52.620 --> 29:56.680
 She tries to kill the guy who is her like master,

29:56.680 --> 29:59.040
 but he kills her, but unbeknownst to her,

29:59.040 --> 30:01.360
 when she was traveling on a ship through the culture

30:01.360 --> 30:05.160
 with him one day, a ship put a neural lace

30:05.160 --> 30:08.480
 in her head and neural lace is sort of like,

30:08.480 --> 30:13.040
 it's basically a Neuralink because life imitates art.

30:13.040 --> 30:14.160
 It does indeed.

30:14.160 --> 30:15.000
 It does indeed.

30:15.000 --> 30:17.320
 So she wakes up and the opening scene is her memory

30:17.320 --> 30:19.040
 has been uploaded by this neural lace

30:19.040 --> 30:20.000
 when she has been killed.

30:20.000 --> 30:22.640
 And now she gets to choose a new body.

30:22.640 --> 30:26.900
 And this AI is interfacing with her recorded memory

30:26.900 --> 30:29.900
 in her neural lace and helping her and being like,

30:29.900 --> 30:31.320
 hello, you're dead.

30:31.320 --> 30:33.740
 But because you had a neural lace, your memory's uploaded.

30:33.740 --> 30:34.980
 Do you want to choose a new body?

30:34.980 --> 30:36.440
 And you're going to be born here in the culture

30:36.440 --> 30:38.600
 and like start a new life, which is just,

30:38.600 --> 30:39.920
 that's like the opening.

30:39.920 --> 30:41.400
 It's like so sick.

30:41.400 --> 30:43.640
 And the ship is the super intelligence.

30:43.640 --> 30:45.120
 All the ships are kind of super intelligence.

30:45.120 --> 30:47.720
 But they still want to preserve a kind of rich,

30:47.720 --> 30:49.680
 fulfilling experience for the humans.

30:49.680 --> 30:51.000
 Yeah, like they're like friends with the humans.

30:51.000 --> 30:53.560
 And then there's a bunch of ships that don't want to exist

30:53.560 --> 30:56.000
 with biological beings, but they just have their own place

30:56.000 --> 30:57.080
 like way over there.

30:57.080 --> 30:58.900
 But they don't, they just do their own thing.

30:58.900 --> 31:00.320
 They're not necessarily.

31:00.320 --> 31:03.640
 So it's a pretty, this protopian existence is pretty peaceful.

31:03.640 --> 31:05.860
 Yeah, I mean, and then, for example,

31:05.860 --> 31:10.200
 one of the main fights in the book is they're fighting,

31:10.200 --> 31:13.820
 there's these artificial hells that,

31:13.820 --> 31:17.600
 and people don't think it's ethical to have artificial hell.

31:17.600 --> 31:19.520
 Like basically when people do crime, they get sent,

31:19.520 --> 31:21.140
 like when they die, their memory gets sent

31:21.140 --> 31:23.480
 to an artificial hell and they're eternally tortured.

31:23.480 --> 31:27.660
 And so, and then the way that society is deciding

31:27.660 --> 31:29.280
 whether or not to have the artificial hell

31:29.280 --> 31:31.900
 is that they're having these simulated,

31:31.900 --> 31:33.200
 they're having like a simulated war.

31:33.200 --> 31:36.000
 So instead of actual blood, you know,

31:36.000 --> 31:38.520
 people are basically essentially fighting in a video game

31:38.520 --> 31:40.080
 to choose the outcome of this.

31:40.080 --> 31:42.760
 But they're still experiencing the suffering

31:42.760 --> 31:44.520
 in this artificial hell or no?

31:44.520 --> 31:45.760
 Can you experience stuff or?

31:45.760 --> 31:47.200
 So the artificial hell sucks.

31:47.200 --> 31:48.800
 And a lot of people in the culture want to get rid

31:48.800 --> 31:49.920
 of the artificial hell.

31:49.920 --> 31:51.280
 There's a simulated wars,

31:51.280 --> 31:53.320
 are they happening in the artificial hell?

31:53.320 --> 31:55.520
 So no, the simulated wars are happening

31:55.520 --> 31:57.080
 outside of the artificial hell,

31:57.080 --> 31:59.960
 between the political factions who are,

31:59.960 --> 32:02.880
 so this political faction says we should have simulated hell

32:02.880 --> 32:05.000
 to deter crime.

32:05.000 --> 32:06.960
 And this political faction is saying,

32:06.960 --> 32:08.920
 no, simulated hell is unethical.

32:08.920 --> 32:11.700
 And so instead of like having, you know,

32:11.700 --> 32:13.120
 blowing each other up with nukes,

32:13.120 --> 32:17.160
 they're having like a giant Fortnite battle

32:17.160 --> 32:21.680
 to decide this, which, you know, to me that's protopia.

32:21.680 --> 32:24.520
 That's like, okay, we can have war without death.

32:25.640 --> 32:27.440
 You know, I don't think there should be simulated hells.

32:27.440 --> 32:29.800
 I think that is definitely one of the ways

32:29.800 --> 32:34.280
 in which technology could go very, very, very, very wrong.

32:34.280 --> 32:37.120
 So almost punishing people in a digital space

32:37.120 --> 32:37.960
 or something like that.

32:37.960 --> 32:40.320
 Yeah, like torturing people's memories.

32:41.680 --> 32:44.760
 So either as a deterrent, like if you committed a crime,

32:44.760 --> 32:46.560
 but also just for personal pleasure,

32:46.560 --> 32:49.260
 if there's some sick, demented humans in this world.

32:50.520 --> 32:52.320
 Dan Carlin actually has this

32:55.040 --> 32:59.440
 episode of Hardcore History on painful attainment.

32:59.440 --> 33:02.280
 Oh, that episode is fucked.

33:02.280 --> 33:05.360
 It's dark, because he kind of goes through human history

33:05.360 --> 33:08.800
 and says like, we as humans seem to enjoy,

33:08.800 --> 33:12.120
 secretly enjoy or used to be openly enjoy

33:12.120 --> 33:14.400
 sort of the torture and the death,

33:14.400 --> 33:17.720
 watching the death and torture of other humans.

33:17.720 --> 33:21.720
 I do think if people were consenting,

33:21.720 --> 33:26.240
 we should be allowed to have gladiatorial matches.

33:26.240 --> 33:28.560
 But consent is hard to achieve in those situations.

33:28.560 --> 33:31.080
 It always starts getting slippery.

33:31.080 --> 33:32.760
 Like it could be also forced consent,

33:32.760 --> 33:35.280
 like it starts getting weird.

33:35.280 --> 33:37.360
 There's way too much excitement.

33:37.360 --> 33:38.620
 Like this is what he highlights.

33:38.620 --> 33:40.520
 There's something about human nature

33:40.520 --> 33:42.280
 that wants to see that violence.

33:42.280 --> 33:44.280
 And it's really dark.

33:44.280 --> 33:47.160
 And you hope that we can sort of overcome

33:47.160 --> 33:48.840
 that aspect of human nature,

33:48.840 --> 33:51.280
 but that's still within us somewhere.

33:51.280 --> 33:53.240
 Well, I think that's what we're doing right now.

33:53.240 --> 33:56.400
 I have this theory that what is very important

33:56.400 --> 34:00.880
 about the current moment is that all of evolution

34:00.880 --> 34:03.400
 has been survival of the fittest up until now.

34:03.400 --> 34:07.260
 And at some point, the lines are kind of fuzzy,

34:07.260 --> 34:12.080
 but in the recent past, or maybe even just right now,

34:12.080 --> 34:14.400
 we're getting to this point

34:14.400 --> 34:19.400
 where we can choose intelligent design.

34:19.440 --> 34:23.440
 Like we probably since like the integration of the iPhone,

34:23.440 --> 34:24.820
 like we are becoming cyborgs.

34:24.820 --> 34:27.680
 Like our brains are fundamentally changed.

34:27.680 --> 34:29.380
 Everyone who grew up with electronics,

34:29.380 --> 34:32.520
 we are fundamentally different from previous,

34:32.520 --> 34:33.440
 from homo sapiens.

34:33.440 --> 34:34.680
 I call us homo techno.

34:34.680 --> 34:36.840
 I think we have evolved into homo techno,

34:36.840 --> 34:39.380
 which is like essentially a new species.

34:39.380 --> 34:41.380
 Like if you look at the way,

34:41.380 --> 34:43.400
 if you took an MRI of my brain

34:43.400 --> 34:46.600
 and you took an MRI of like a medieval brain,

34:46.600 --> 34:48.160
 I think it would be very different

34:48.160 --> 34:49.960
 the way that it has evolved.

34:49.960 --> 34:52.000
 Do you think when historians look back at this time,

34:52.000 --> 34:54.040
 they'll see like this was a fundamental shift

34:54.040 --> 34:54.880
 to what a human being is?

34:54.880 --> 34:58.040
 I think, I do not think we are still homo sapiens.

34:58.040 --> 34:59.520
 I believe we are homo techno.

34:59.520 --> 35:01.280
 And I think we have evolved.

35:04.400 --> 35:07.380
 And I think right now, the way we are evolving,

35:07.380 --> 35:09.080
 we can choose how we do that.

35:09.080 --> 35:10.680
 And I think we are being very reckless

35:10.680 --> 35:11.800
 about how we're doing that.

35:11.800 --> 35:13.020
 Like we're just having social media,

35:13.020 --> 35:16.320
 but I think this idea that like this is a time

35:16.320 --> 35:19.600
 to choose intelligent design should be taken very seriously.

35:19.600 --> 35:24.200
 It like now is the moment to reprogram the human computer.

35:24.200 --> 35:26.400
 It's like, if you go blind,

35:27.260 --> 35:29.920
 your visual cortex will get taken over

35:29.920 --> 35:32.000
 with other functions.

35:32.000 --> 35:35.160
 We can choose our own evolution.

35:35.160 --> 35:37.160
 We can change the way our brains work.

35:37.160 --> 35:39.920
 And so we actually have a huge responsibility to do that.

35:39.920 --> 35:42.880
 And I think I'm not sure who should be responsible for that,

35:42.880 --> 35:45.200
 but there's definitely not adequate education.

35:45.200 --> 35:46.940
 We're being inundated with all this technology

35:46.940 --> 35:49.020
 that is fundamentally changing

35:49.020 --> 35:50.900
 the physical structure of our brains.

35:50.900 --> 35:54.780
 And we are not adequately responding to that

35:55.920 --> 35:57.460
 to choose how we wanna evolve.

35:57.460 --> 36:00.600
 And we could evolve, we could be really whatever we want.

36:00.600 --> 36:03.040
 And I think this is a really important time.

36:03.040 --> 36:06.440
 And I think if we choose correctly and we choose wisely,

36:06.440 --> 36:09.720
 consciousness could exist for a very long time

36:09.720 --> 36:12.720
 and integration with AI could be extremely positive.

36:12.720 --> 36:14.400
 And I don't think enough people are focusing

36:14.400 --> 36:16.360
 on this specific situation.

36:16.360 --> 36:19.160
 Do you think we might irreversibly screw things up

36:19.160 --> 36:20.000
 if we get things wrong now?

36:20.000 --> 36:21.640
 Because the flip side of that,

36:21.640 --> 36:23.200
 it seems humans are pretty adaptive.

36:23.200 --> 36:25.960
 So maybe the way we figure things out

36:25.960 --> 36:28.080
 is by screwing it up, like social media.

36:28.080 --> 36:30.600
 Over a generation, we'll see the negative effects

36:30.600 --> 36:33.080
 of social media, and then we build new social medias,

36:33.080 --> 36:34.960
 and we just keep improving stuff.

36:34.960 --> 36:37.680
 And then we learn from the failures of the past.

36:37.680 --> 36:39.920
 Because humans seem to be really adaptive.

36:39.920 --> 36:43.020
 On the flip side, we can get it wrong in a way

36:43.020 --> 36:46.400
 where literally we create weapons of war

36:46.400 --> 36:48.360
 or increase hate.

36:48.360 --> 36:51.840
 Past a certain threshold, we really do a lot of damage.

36:51.840 --> 36:53.700
 I mean, I think we're optimized

36:53.700 --> 36:55.680
 to notice the negative things.

36:55.680 --> 37:00.120
 But I would actually say one of the things

37:00.120 --> 37:02.140
 that I think people aren't noticing

37:02.140 --> 37:03.520
 is if you look at Silicon Valley

37:03.520 --> 37:06.600
 and you look at the technocracy,

37:06.600 --> 37:09.000
 like what's been happening there.

37:09.000 --> 37:11.460
 When Silicon Valley started, it was all just Facebook

37:11.460 --> 37:14.040
 and all this for profit crap

37:14.040 --> 37:16.920
 that really wasn't particular.

37:16.920 --> 37:21.920
 I guess it was useful, but it's sort of just whatever.

37:22.200 --> 37:26.680
 But now you see lab grown meat, compostable,

37:26.680 --> 37:30.200
 or biodegradable, single use cutlery,

37:30.200 --> 37:33.120
 or meditation apps.

37:33.120 --> 37:38.120
 I think we are actually evolving and changing,

37:38.400 --> 37:39.600
 and technology is changing.

37:39.600 --> 37:43.840
 I think there just maybe there isn't

37:43.840 --> 37:48.140
 quite enough education about this.

37:48.140 --> 37:52.240
 And also, I don't know if there's quite enough incentive

37:52.240 --> 37:55.140
 for it because I think the way capitalism works,

37:56.600 --> 37:58.480
 what we define as profit,

37:58.480 --> 38:00.400
 we're also working on an old model

38:00.400 --> 38:01.540
 of what we define as profit.

38:01.540 --> 38:06.400
 I really think if we changed the idea of profit

38:06.400 --> 38:08.200
 to include social good,

38:08.200 --> 38:09.840
 you can have economic profit,

38:09.840 --> 38:12.580
 social good also counting as profit

38:12.580 --> 38:15.100
 would incentivize things that are more useful

38:15.100 --> 38:16.960
 and more whatever spiritual technology

38:16.960 --> 38:21.280
 or positive technology or things that help reprogram

38:21.280 --> 38:22.920
 a human computer in a good way

38:22.920 --> 38:27.920
 or things that help us intelligently design our new brains.

38:28.280 --> 38:30.480
 Yeah, there's no reason why within the framework

38:30.480 --> 38:33.800
 of capitalism, the word profit or the idea of profit

38:33.800 --> 38:37.360
 can't also incorporate the well being of a human being.

38:37.360 --> 38:40.100
 So like long term well being, long term happiness.

38:41.440 --> 38:43.840
 Or even for example, we were talking about motherhood,

38:43.840 --> 38:44.840
 like part of the reason I'm so late

38:44.840 --> 38:47.400
 is because I had to get the baby to bed.

38:47.400 --> 38:48.880
 And it's like, I keep thinking about motherhood,

38:48.880 --> 38:53.680
 how under capitalism, it's like this extremely essential job

38:53.680 --> 38:56.440
 that is very difficult that is not compensated.

38:56.440 --> 38:58.420
 And we sort of like value things

38:58.420 --> 39:01.880
 by how much we compensate them.

39:01.880 --> 39:04.880
 And so we really devalue motherhood in our society

39:04.880 --> 39:06.080
 and pretty much all societies.

39:06.080 --> 39:08.160
 Like capitalism does not recognize motherhood.

39:08.160 --> 39:11.120
 It's just a job that you're supposed to do for free.

39:11.120 --> 39:15.360
 And it's like, but I feel like producing great humans

39:15.360 --> 39:19.440
 should be seen as a great, as profit under capitalism.

39:19.440 --> 39:21.480
 Like that should be, that's like a huge social good.

39:21.480 --> 39:24.160
 Like every awesome human that gets made

39:24.160 --> 39:25.600
 adds so much to the world.

39:25.600 --> 39:29.840
 So like if that was integrated into the profit structure,

39:29.840 --> 39:34.240
 then, you know, and if we potentially found a way

39:34.240 --> 39:35.640
 to compensate motherhood.

39:35.640 --> 39:37.920
 So come up with a compensation

39:37.920 --> 39:40.640
 that's much broader than just money or.

39:40.640 --> 39:42.040
 Or it could just be money.

39:42.040 --> 39:45.520
 Like, what if you just made, I don't know,

39:45.520 --> 39:46.640
 but I don't know how you'd pay for that.

39:46.640 --> 39:49.380
 Like, I mean, that's where you start getting into.

39:52.000 --> 39:56.360
 Reallocation of resources that people get upset over.

39:56.360 --> 39:58.480
 Well, like what if we made like a motherhood Dow?

39:58.480 --> 40:01.320
 Yeah, yeah.

40:01.320 --> 40:06.320
 And, you know, used it to fund like single mothers,

40:07.680 --> 40:12.680
 like, you know, pay for making babies.

40:13.640 --> 40:17.360
 So, I mean, if you create and put beautiful things

40:17.360 --> 40:19.760
 onto the world, that could be companies,

40:19.760 --> 40:22.640
 that can be bridges, that could be art,

40:22.640 --> 40:24.280
 that could be a lot of things,

40:24.280 --> 40:28.080
 and that could be children, which are.

40:28.080 --> 40:29.320
 Or education or.

40:29.320 --> 40:32.380
 Anything, that should be valued by society,

40:32.380 --> 40:35.160
 and that should be somehow incorporated into the framework

40:35.160 --> 40:38.480
 of what, as a market, of what.

40:38.480 --> 40:40.560
 Like, if you contribute children to this world,

40:40.560 --> 40:42.440
 that should be valued and respected

40:42.440 --> 40:47.440
 and sort of celebrated, like, proportional to what it is,

40:48.000 --> 40:51.560
 which is, it's the thing that fuels human civilization.

40:51.560 --> 40:53.000
 Yeah, like I. It's kind of important.

40:53.000 --> 40:54.600
 I feel like everyone's always saying,

40:54.600 --> 40:56.520
 I mean, I think we're in very different social spheres,

40:56.520 --> 40:58.880
 but everyone's always saying, like, dismantle capitalism.

40:58.880 --> 40:59.840
 And I'm like, well, okay, well,

40:59.840 --> 41:02.120
 I don't think the government should own everything.

41:02.120 --> 41:04.200
 Like, I don't think we should not have private ownership.

41:04.200 --> 41:05.360
 Like, that's scary.

41:05.360 --> 41:07.320
 You know, like that starts getting into weird stuff

41:07.320 --> 41:08.920
 and just sort of like,

41:08.920 --> 41:10.080
 I feel there's almost no way to do that

41:10.080 --> 41:12.060
 without a police state, you know?

41:13.520 --> 41:16.980
 But obviously, capitalism has some major flaws.

41:16.980 --> 41:20.360
 And I think actually Mac showed me this idea

41:20.360 --> 41:23.480
 called social capitalism, which is a form of capitalism

41:23.480 --> 41:28.480
 that just like considers social good to be also profit.

41:28.480 --> 41:31.560
 Like, you know, it's like, right now companies need to,

41:31.560 --> 41:34.560
 like, you're supposed to grow every quarter or whatever

41:34.560 --> 41:38.700
 to like show that you're functioning well,

41:38.700 --> 41:39.920
 but it's like, okay, well,

41:39.920 --> 41:42.920
 what if you kept the same amount of profit?

41:42.920 --> 41:43.920
 You're still in the green,

41:43.920 --> 41:45.600
 but then you have also all this social good.

41:45.600 --> 41:47.560
 Like, do you really need all this extra economic growth

41:47.560 --> 41:49.520
 or could you add this social good and that counts?

41:49.520 --> 41:54.000
 And, you know, I don't know if, I am not an economist.

41:54.000 --> 41:56.360
 I have no idea how this could be achieved, but.

41:56.360 --> 41:58.720
 I don't think economists know how anything

41:58.720 --> 42:00.320
 could be achieved either, but they pretend.

42:00.320 --> 42:02.280
 It's the thing, they construct a model

42:02.280 --> 42:06.160
 and they go on TV shows and sound like an expert.

42:06.160 --> 42:08.540
 That's the definition of economist.

42:08.540 --> 42:12.260
 How did being a mother, becoming a mother

42:12.260 --> 42:15.240
 change you as a human being, would you say?

42:16.160 --> 42:21.000
 Man, I think it kind of changed everything

42:21.000 --> 42:22.380
 and it's still changing me a lot.

42:22.380 --> 42:24.880
 It's actually changing me more right now in this moment

42:24.880 --> 42:26.400
 than it was before.

42:26.400 --> 42:28.520
 Like today, like this?

42:28.520 --> 42:32.480
 Just like in the most recent months and stuff.

42:33.480 --> 42:37.640
 Can you elucidate that, how change,

42:37.640 --> 42:39.360
 like when you wake up in the morning

42:39.360 --> 42:42.920
 and you look at yourself, it's again, which, who are you?

42:42.920 --> 42:45.520
 How have you become different, would you say?

42:45.520 --> 42:50.520
 I think it's just really reorienting my priorities.

42:50.680 --> 42:53.400
 And at first I was really fighting against that

42:53.400 --> 42:55.560
 because I somehow felt it was like a failure

42:55.560 --> 42:56.680
 of feminism or something.

42:56.680 --> 42:59.840
 Like I felt like it was like bad

42:59.840 --> 43:04.320
 if like my kids started mattering more than my work.

43:05.720 --> 43:08.960
 And then like more recently I started sort of analyzing

43:08.960 --> 43:12.240
 that thought in myself and being like,

43:12.240 --> 43:13.920
 that's also kind of a construct.

43:13.920 --> 43:16.280
 It's like, we've just devalued motherhood so much

43:16.280 --> 43:21.280
 in our culture that like, I feel guilty for caring

43:21.280 --> 43:23.320
 about my kids more than I care about my work.

43:23.320 --> 43:25.800
 So feminism includes breaking out

43:25.800 --> 43:27.520
 of whatever the construct is.

43:28.360 --> 43:30.900
 So just continually breaking,

43:30.900 --> 43:34.640
 it's like freedom empower you to be free.

43:34.640 --> 43:36.160
 And that means...

43:37.560 --> 43:40.040
 But it also, but like being a mother,

43:40.040 --> 43:41.840
 like I'm so much more creative.

43:41.840 --> 43:45.880
 Like I cannot believe the massive amount

43:45.880 --> 43:48.440
 of brain growth that I am.

43:48.440 --> 43:49.280
 Why do you think that is?

43:49.280 --> 43:51.940
 Just cause like the stakes are higher somehow?

43:51.940 --> 43:56.940
 I think it's like, it's just so trippy

43:58.020 --> 44:00.800
 watching consciousness emerge.

44:00.800 --> 44:05.800
 It's just like, it's like going on a crazy journey

44:06.860 --> 44:07.700
 or something.

44:07.700 --> 44:10.220
 It's like the craziest science fiction novel

44:10.220 --> 44:11.060
 you could ever read.

44:11.060 --> 44:15.100
 It's just so crazy watching consciousness come into being.

44:15.100 --> 44:16.540
 And then at the same time,

44:16.540 --> 44:21.140
 like you're forced to value your time so much.

44:21.140 --> 44:23.520
 Like when I have creative time now, it's so sacred.

44:23.520 --> 44:28.520
 I need to like be really fricking on it.

44:29.380 --> 44:34.380
 But the other thing is that I used to just be like a cynic

44:34.680 --> 44:35.520
 and I used to just wanna...

44:35.520 --> 44:38.060
 Like my last album was called Miss Anthropocene

44:38.060 --> 44:42.620
 and it was like this like, it was like a study in villainy

44:42.620 --> 44:44.980
 or like it was like, well, what if we have,

44:44.980 --> 44:46.820
 instead of the old gods, we have like new gods

44:46.820 --> 44:49.700
 and it's like Miss Anthropocene is like misanthrope

44:49.700 --> 44:53.100
 like and Anthropocene, which is like the, you know,

44:53.100 --> 44:55.780
 like and she's the goddess of climate change or whatever.

44:55.780 --> 44:56.980
 And she's like destroying the world.

44:56.980 --> 44:59.660
 And it was just like, it was like dark

44:59.660 --> 45:01.380
 and it was like a study in villainy.

45:01.380 --> 45:02.700
 And it was sort of just like,

45:02.700 --> 45:05.800
 like I used to like have no problem just making cynical,

45:06.820 --> 45:08.980
 angry, scary art.

45:08.980 --> 45:11.100
 And not that there's anything wrong with that,

45:11.100 --> 45:13.580
 but I think having kids just makes you such an optimist.

45:13.580 --> 45:16.940
 It just inherently makes you wanna be an optimist so bad

45:16.940 --> 45:20.380
 that like I feel more responsibility

45:20.380 --> 45:23.820
 to make more optimistic things.

45:23.820 --> 45:25.720
 And I get a lot of shit for it

45:25.720 --> 45:28.500
 because everyone's like, oh, you're so privileged.

45:28.500 --> 45:30.260
 Stop talking about like pie in the sky,

45:30.260 --> 45:32.700
 stupid concepts and focus on like the now.

45:32.700 --> 45:36.500
 But it's like, I think if we don't ideate

45:36.500 --> 45:40.520
 about futures that could be good,

45:40.520 --> 45:41.540
 we won't be able to get them.

45:41.540 --> 45:42.780
 If everything is Blade Runner,

45:42.780 --> 45:44.260
 then we're gonna end up with Blade Runner.

45:44.260 --> 45:47.300
 It's like, as we said earlier, life imitates art.

45:47.300 --> 45:49.740
 Like life really does imitate art.

45:49.740 --> 45:53.960
 And so we really need more protopian or utopian art.

45:53.960 --> 45:56.060
 I think this is incredibly essential

45:56.060 --> 45:58.060
 for the future of humanity.

45:58.060 --> 46:00.380
 And I think the current discourse

46:00.380 --> 46:05.380
 where that's seen as a thinking about protopia or utopia

46:09.660 --> 46:11.580
 is seen as a dismissal of the problems

46:11.580 --> 46:12.420
 that we currently have.

46:12.420 --> 46:14.980
 I think that is an incorrect mindset.

46:16.160 --> 46:20.180
 And like having kids just makes me wanna imagine

46:20.180 --> 46:24.420
 amazing futures that like maybe I won't be able to build,

46:24.420 --> 46:26.900
 but they will be able to build if they want to.

46:26.900 --> 46:28.300
 Yeah, it does seem like ideation

46:28.300 --> 46:30.220
 is a precursor to creation.

46:30.220 --> 46:33.820
 So you have to imagine it in order to be able to build it.

46:33.820 --> 46:36.700
 And there is a sad thing about human nature

46:36.700 --> 46:40.740
 that somehow a cynical view of the world

46:40.740 --> 46:44.060
 is seen as a insightful view.

46:44.060 --> 46:46.980
 You know, cynicism is often confused for insight,

46:46.980 --> 46:48.900
 which is sad to see.

46:48.900 --> 46:52.620
 And optimism is confused for naivete.

46:52.620 --> 46:53.460
 Yes, yes.

46:53.460 --> 46:57.700
 Like you don't, you're blinded by your,

46:57.700 --> 46:59.320
 maybe your privilege or whatever.

46:59.320 --> 47:02.020
 You're blinded by something, but you're certainly blinded.

47:02.020 --> 47:04.560
 That's sad, that's sad to see

47:04.560 --> 47:06.020
 because it seems like the optimists

47:06.020 --> 47:10.260
 are the ones that create our future.

47:10.260 --> 47:11.900
 They're the ones that build.

47:11.900 --> 47:13.560
 In order to build the crazy thing,

47:13.560 --> 47:14.740
 you have to be optimistic.

47:14.740 --> 47:19.220
 You have to be either stupid or excited or passionate

47:19.220 --> 47:22.740
 or mad enough to actually believe that it can be built.

47:22.740 --> 47:24.200
 And those are the people that built it.

47:24.200 --> 47:28.100
 My favorite quote of all time is from Star Wars, Episode 8,

47:29.020 --> 47:30.940
 which I know everyone hates.

47:30.940 --> 47:32.420
 Do you like Star Wars, Episode 8?

47:32.420 --> 47:35.840
 No, yeah, probably I would say I would probably hate it, yeah.

47:36.820 --> 47:38.940
 I don't have strong feelings about it.

47:38.940 --> 47:39.780
 Let me backtrack.

47:39.780 --> 47:41.500
 I don't have strong feelings about Star Wars.

47:41.500 --> 47:43.040
 I'm a Tolkien person.

47:43.040 --> 47:47.860
 I'm more into dragons and orcs and ogres.

47:47.860 --> 47:49.620
 Yeah, I mean, Tolkien forever.

47:49.620 --> 47:51.780
 I really want to have one more son and call him,

47:51.780 --> 47:55.260
 I thought Tao Tecno Tolkien would be cool.

47:55.260 --> 47:56.940
 It's a lot of T's, I like it.

47:56.940 --> 47:59.260
 Yeah, and well, and Tao is six, two, eight, two pi.

47:59.260 --> 48:01.740
 Yeah, Tao Tecno, yeah, yeah, yeah.

48:01.740 --> 48:04.780
 And then techno is obviously the best genre of music,

48:04.780 --> 48:06.260
 but also like technocracy.

48:06.260 --> 48:07.100
 It just sounds really good.

48:07.100 --> 48:11.260
 Yeah, that's right, and techno Tolkien, Tao Tecno Tolkien.

48:11.260 --> 48:12.100
 That's a good, that's it.

48:12.100 --> 48:14.980
 Tao Tecno Tolkien, but Star Wars, Episode 8,

48:15.980 --> 48:17.260
 I know a lot of people have issues with it.

48:17.260 --> 48:18.720
 Personally, on the record,

48:18.720 --> 48:21.220
 I think it's the best Star Wars film.

48:24.100 --> 48:25.180
 You're starting trouble today.

48:25.180 --> 48:29.260
 Yeah, but don't kill what you hate, save what you love.

48:29.260 --> 48:30.460
 Don't kill what you hate.

48:30.460 --> 48:32.340
 Don't kill what you hate, save what you love.

48:32.340 --> 48:34.980
 And I think we're, in society right now,

48:34.980 --> 48:36.580
 we're in a diagnosis mode.

48:36.580 --> 48:39.140
 We're just diagnosing and diagnosing and diagnosing,

48:39.140 --> 48:41.660
 and we're trying to kill what we hate,

48:41.660 --> 48:44.220
 and we're not trying to save what we love enough.

48:44.220 --> 48:46.260
 And there's this Buckminster Fuller quote,

48:46.260 --> 48:47.140
 which I'm gonna butcher,

48:47.140 --> 48:48.220
 because I don't remember it correctly,

48:48.220 --> 48:50.520
 but it's something along the lines of,

48:52.580 --> 48:57.580
 don't try to destroy the old bad models,

48:58.340 --> 49:01.600
 render them obsolete with better models.

49:03.100 --> 49:05.620
 Maybe we don't need to destroy the oil industry.

49:05.620 --> 49:08.940
 Maybe we just create a great new battery technology

49:08.940 --> 49:10.340
 and sustainable transport,

49:10.340 --> 49:13.140
 and just make it economically unreasonable

49:13.140 --> 49:15.460
 to still continue to rely on fossil fuels.

49:17.100 --> 49:20.180
 It's like, don't kill what you hate, save what you love.

49:20.180 --> 49:24.460
 Make new things and just render the old things unusable.

49:24.460 --> 49:29.060
 It's like if the college debt is so bad,

49:29.060 --> 49:31.500
 and universities are so expensive,

49:31.500 --> 49:35.700
 and I feel like education is becoming obsolete.

49:35.700 --> 49:38.460
 I feel like we could completely revolutionize education,

49:38.460 --> 49:39.380
 and we could make it free.

49:39.380 --> 49:40.420
 And it's like, you look at JSTOR,

49:40.420 --> 49:43.460
 and you have to pay to get all the studies and everything.

49:43.460 --> 49:46.520
 What if we created a DAO that bought JSTOR,

49:46.520 --> 49:48.460
 or we created a DAO that was funding studies,

49:48.460 --> 49:51.880
 and those studies were open source, or free for everyone.

49:51.880 --> 49:55.100
 And what if we just open sourced education

49:55.100 --> 49:56.980
 and decentralized education and made it free,

49:56.980 --> 50:00.900
 and all research was on the internet,

50:00.900 --> 50:05.220
 and all the outcomes of studies were on the internet,

50:05.220 --> 50:10.060
 and no one has student debt,

50:10.060 --> 50:14.220
 and you just take tests when you apply for a job,

50:14.220 --> 50:16.920
 and if you're qualified, then you can work there.

50:18.060 --> 50:20.500
 This is just like, I don't know how anything works.

50:20.500 --> 50:22.700
 I'm just randomly ranting, but.

50:22.700 --> 50:23.920
 I like the humility.

50:24.920 --> 50:27.780
 You gotta think from just basic first principles.

50:27.780 --> 50:28.900
 What is the problem?

50:28.900 --> 50:29.740
 What's broken?

50:29.740 --> 50:30.740
 What are some ideas?

50:30.740 --> 50:31.580
 That's it.

50:31.580 --> 50:33.100
 And get excited about those ideas,

50:33.100 --> 50:34.660
 and share your excitement,

50:34.660 --> 50:37.100
 and don't tear each other down.

50:37.100 --> 50:38.140
 It's just when you kill things,

50:38.140 --> 50:40.140
 you often end up killing yourself.

50:40.140 --> 50:43.380
 Like war is not a one sided,

50:43.380 --> 50:45.060
 like you're not gonna go in and just kill them,

50:45.060 --> 50:46.900
 like you're gonna get stabbed.

50:46.900 --> 50:50.380
 It's like, and I think when I talk about this nexus point

50:50.380 --> 50:53.320
 of that we're in this point in society

50:53.320 --> 50:55.140
 where we're switching to intelligent design,

50:55.140 --> 50:57.220
 I think part of our switch to intelligent design

50:57.220 --> 50:59.480
 is that we need to choose nonviolence.

50:59.480 --> 51:04.300
 And we need to, like, I think we can choose to start,

51:04.300 --> 51:07.380
 I don't think we can eradicate violence from our species,

51:07.380 --> 51:10.540
 because I think we need it a little bit,

51:10.540 --> 51:12.100
 but I think we can choose

51:12.100 --> 51:14.900
 to really reorient our primitive brains

51:14.900 --> 51:16.300
 that are fighting over scarcity,

51:16.300 --> 51:20.620
 and that are so attack oriented,

51:20.620 --> 51:25.420
 and move into, we can optimize for creativity and building.

51:25.420 --> 51:27.220
 Yeah, it's interesting to think how that happens,

51:27.220 --> 51:29.580
 so some of it is just education,

51:29.580 --> 51:34.100
 some of it is living life and introspecting your own mind,

51:34.100 --> 51:37.780
 and trying to live up to the better angels of your nature

51:37.780 --> 51:41.800
 for each one of us, all those kinds of things at scale.

51:41.800 --> 51:44.580
 That's how we can sort of start to minimize

51:44.580 --> 51:48.160
 the amount of destructive war in our world,

51:48.160 --> 51:51.100
 and that's, to me, probably you're the same,

51:51.100 --> 51:55.220
 technology is a really promising way to do that.

51:55.220 --> 51:57.700
 Like, social media should be a really promising way

51:57.700 --> 52:00.060
 to do that, it's a way we connect.

52:00.060 --> 52:01.540
 I, you know, for the most part,

52:01.540 --> 52:03.260
 I really enjoy social media.

52:03.260 --> 52:05.180
 I just know all the negative stuff.

52:05.180 --> 52:07.540
 I don't engage with any of the negative stuff.

52:07.540 --> 52:10.300
 Just not even, like, by blocking

52:10.300 --> 52:11.400
 or any of that kind of stuff,

52:11.400 --> 52:14.740
 but just not letting it enter my mind.

52:14.740 --> 52:18.500
 Like, just, like, when somebody says something negative,

52:18.500 --> 52:23.260
 I see it, I immediately think positive thoughts about them,

52:23.260 --> 52:26.260
 and I just forget they exist after that.

52:26.260 --> 52:28.640
 Just move on, because, like, that negative energy,

52:28.640 --> 52:30.300
 if I return the negative energy,

52:30.300 --> 52:34.260
 they're going to get excited in a negative way right back,

52:34.260 --> 52:37.380
 and it's just this kind of vicious cycle.

52:38.420 --> 52:40.540
 But you would think technology would assist us

52:40.540 --> 52:42.860
 in this process of letting go,

52:42.860 --> 52:44.720
 of not taking things personally,

52:44.720 --> 52:46.380
 of not engaging in the negativity,

52:46.380 --> 52:50.260
 but unfortunately, social media profits from the negativity,

52:50.260 --> 52:52.020
 so the current models.

52:52.020 --> 52:53.420
 I mean, social media is like a gun.

52:53.420 --> 52:57.260
 Like, you should take a course before you use it.

52:57.260 --> 52:59.380
 Like, it's like, this is what I mean,

52:59.380 --> 53:01.100
 like, when I say reprogram the human computer.

53:01.100 --> 53:03.100
 Like, in school, you should learn

53:03.100 --> 53:05.060
 about how social media optimizes

53:05.060 --> 53:07.140
 to, you know, raise your cortisol levels

53:07.140 --> 53:09.220
 and make you angry and crazy and stressed,

53:09.220 --> 53:12.580
 and, like, you should learn how to have hygiene

53:12.580 --> 53:14.840
 about how you use social media.

53:16.740 --> 53:18.420
 But, so you can, yeah,

53:18.420 --> 53:22.380
 choose not to focus on the negative stuff, but I don't know.

53:22.380 --> 53:24.580
 I'm not sure social media should,

53:24.580 --> 53:25.700
 I guess it should exist.

53:25.700 --> 53:26.540
 I'm not sure.

53:27.420 --> 53:29.420
 I mean, we're in the messy, it's the experimental phase.

53:29.420 --> 53:30.260
 Like, we're working it out.

53:30.260 --> 53:31.080
 Yeah, it's the early days.

53:31.080 --> 53:32.700
 I don't even know, when you say social media,

53:32.700 --> 53:33.820
 I don't know what that even means.

53:33.820 --> 53:35.020
 We're in the very early days.

53:35.020 --> 53:37.780
 I think social media is just basic human connection

53:37.780 --> 53:41.940
 in the digital realm, and that, I think it should exist,

53:41.940 --> 53:43.940
 but there's so many ways to do it in a bad way.

53:43.940 --> 53:45.900
 There's so many ways to do it in a good way.

53:45.900 --> 53:48.100
 There's all discussions of all the same human rights.

53:48.100 --> 53:49.900
 We talk about freedom of speech.

53:49.900 --> 53:52.260
 We talk about sort of violence

53:52.260 --> 53:54.040
 in the space of digital media.

53:54.040 --> 53:56.180
 We talk about hate speech.

53:56.180 --> 53:59.020
 We talk about all these things that we had to figure out

53:59.020 --> 54:01.260
 back in the day in the physical space.

54:01.260 --> 54:03.620
 We're now figuring out in the digital space,

54:03.620 --> 54:06.500
 and it's like baby stages.

54:06.500 --> 54:07.820
 When the printing press came out,

54:07.820 --> 54:10.180
 it was like pure chaos for a minute, you know?

54:10.180 --> 54:12.340
 It's like when you inject,

54:12.340 --> 54:14.300
 when there's a massive information injection

54:14.300 --> 54:19.300
 into the general population, there's just gonna be,

54:20.620 --> 54:23.480
 I feel like the printing press, I don't have the years,

54:23.480 --> 54:24.980
 but it was like printing press came out,

54:24.980 --> 54:27.160
 shit got really fucking bad for a minute,

54:27.160 --> 54:29.180
 but then we got the enlightenment.

54:29.180 --> 54:30.980
 And so it's like, I think we're in,

54:30.980 --> 54:34.780
 this is like the second coming of the printing press.

54:34.780 --> 54:37.760
 We're probably gonna have some shitty times for a minute,

54:37.760 --> 54:40.660
 and then we're gonna have recalibrate

54:40.660 --> 54:44.660
 to have a better understanding of how we consume media

54:44.660 --> 54:47.940
 and how we deliver media.

54:47.940 --> 54:50.920
 Speaking of programming the human computer,

54:50.920 --> 54:52.940
 you mentioned Baby X.

54:52.940 --> 54:56.980
 So there's this young consciousness coming to be,

54:56.980 --> 54:58.340
 came from a cell.

54:58.340 --> 55:01.180
 Like that whole thing doesn't even make sense.

55:01.180 --> 55:02.380
 It came from DNA.

55:02.380 --> 55:03.220
 Yeah.

55:03.220 --> 55:04.660
 And then there's this baby computer

55:04.660 --> 55:06.780
 that just like grows and grows and grows and grows,

55:06.780 --> 55:08.440
 and now there's a conscious being

55:08.440 --> 55:13.440
 with extremely impressive cognitive capabilities with,

55:13.780 --> 55:14.620
 Have you met him?

55:14.620 --> 55:15.460
 Yes, yeah.

55:15.460 --> 55:16.280
 Yeah.

55:16.280 --> 55:17.120
 He's actually really smart.

55:17.120 --> 55:17.960
 He's really smart.

55:17.960 --> 55:18.780
 Yeah.

55:18.780 --> 55:19.620
 He's weird.

55:19.620 --> 55:20.460
 Yeah.

55:20.460 --> 55:21.280
 Or a baby.

55:21.280 --> 55:22.120
 He does.

55:22.120 --> 55:22.960
 I don't, I haven't.

55:22.960 --> 55:23.780
 I don't know a lot of other babies,

55:23.780 --> 55:24.620
 but he seems to be smart.

55:24.620 --> 55:25.460
 Zach, I don't hang out with babies often,

55:25.460 --> 55:26.860
 but this baby was very impressive.

55:26.860 --> 55:28.940
 He does a lot of pranks and stuff.

55:28.940 --> 55:29.780
 Oh, so he's like.

55:29.780 --> 55:31.140
 Like he'll like give you a treat

55:31.140 --> 55:33.580
 and then take it away and laugh and like stuff like that.

55:33.580 --> 55:35.340
 So he's like a chess player.

55:35.340 --> 55:39.820
 So here's a cognitive sort of,

55:39.820 --> 55:41.620
 there's a computer being programmed.

55:41.620 --> 55:43.180
 So he's taking in the environment,

55:43.180 --> 55:45.900
 interacting with a specific set of humans.

55:45.900 --> 55:48.900
 How would you, first of all, what is it?

55:48.900 --> 55:50.420
 What, let me ask.

55:50.420 --> 55:53.220
 I want to ask how do you program this computer?

55:53.220 --> 55:55.580
 And also how do you make sense of that

55:55.580 --> 55:58.100
 there's a conscious being right there

55:58.100 --> 55:59.260
 that wasn't there before?

55:59.260 --> 56:01.460
 It's giving me a lot of crisis thoughts.

56:01.460 --> 56:02.700
 I'm thinking really hard.

56:02.700 --> 56:03.700
 I think that's part of the reason

56:03.700 --> 56:06.100
 it's like, I'm struggling to focus on

56:06.100 --> 56:07.140
 art and stuff right now.

56:07.140 --> 56:09.620
 Cause baby X is becoming conscious

56:09.620 --> 56:12.580
 and like my it's just reorienting my brain.

56:12.580 --> 56:14.700
 Like my brain is suddenly totally shifting of like,

56:14.700 --> 56:18.220
 oh shit, like the way we raise children.

56:18.220 --> 56:21.980
 Like, I hate all the baby books and everything.

56:21.980 --> 56:22.820
 I hate them.

56:22.820 --> 56:24.320
 Like they're, oh, the art is so bad.

56:24.320 --> 56:29.060
 And like all this stuff, everything about all the aesthetics.

56:29.060 --> 56:32.300
 And like, I'm just like, ah, like this is so.

56:32.300 --> 56:35.060
 The programming languages we're using

56:35.060 --> 56:37.220
 to program these baby computers isn't good.

56:37.220 --> 56:39.980
 Yeah, like I'm thinking, and I,

56:39.980 --> 56:41.340
 not that I have like good answers

56:41.340 --> 56:46.020
 or know what to do, but I'm just thinking really,

56:46.020 --> 56:46.860
 really hard about it.

56:46.860 --> 56:51.860
 I, we recently watched Totoro with him, Studio Ghibli.

56:52.860 --> 56:56.100
 And it's just like a fantastic film.

56:56.100 --> 56:57.500
 And he like responded to,

56:57.500 --> 56:59.460
 I know you're not supposed to show baby screens too much,

56:59.460 --> 57:04.260
 but like, I think it's the most sort of like,

57:04.260 --> 57:06.940
 I feel like it's the highest art baby content.

57:06.940 --> 57:11.940
 Like it really speaks, there's almost no talking in it.

57:12.020 --> 57:13.060
 It's really simple.

57:13.060 --> 57:16.020
 Although all the dialogue is super, super, super simple,

57:16.020 --> 57:19.620
 you know, and it's like a one to three year old

57:19.620 --> 57:21.020
 can like really connect with it.

57:21.020 --> 57:22.480
 Like it feels like it's almost aimed

57:22.480 --> 57:24.600
 at like a one to three year old,

57:24.600 --> 57:27.620
 but it's like great art and it's so imaginative

57:27.620 --> 57:28.700
 and it's so beautiful.

57:28.700 --> 57:31.660
 And like the first time I showed it to him,

57:31.660 --> 57:33.580
 he was just like so invested in it,

57:33.580 --> 57:35.740
 unlike I've ever, unlike anything else

57:35.740 --> 57:36.740
 I'd ever shown him.

57:36.740 --> 57:38.500
 Like he was just like crying when they cry

57:38.500 --> 57:39.580
 and laughing when they laugh,

57:39.580 --> 57:42.520
 like just like having this roller coaster of like emotions,

57:42.520 --> 57:44.020
 like, and he learned a bunch of words.

57:44.020 --> 57:46.020
 Like he was, and he started saying Totoro

57:46.020 --> 57:48.560
 and started just saying all this stuff

57:48.560 --> 57:49.860
 after watching Totoro,

57:49.860 --> 57:52.020
 and he wants to watch it all the time.

57:52.020 --> 57:55.460
 And I was like, man, why isn't there an industry of this?

57:55.460 --> 57:59.980
 Like why aren't our best artists focusing on making art

57:59.980 --> 58:04.180
 like for the birth of consciousness?

58:04.180 --> 58:07.080
 Like, and that's one of the things I've been thinking

58:07.080 --> 58:08.380
 I really wanna start doing.

58:08.380 --> 58:10.380
 You know, I don't wanna speak before I do things too much,

58:10.380 --> 58:15.220
 but like, I'm just like ages one to three,

58:15.220 --> 58:18.680
 like we should be putting so much effort into that.

58:18.680 --> 58:21.020
 And the other thing about Totoro is it's like,

58:21.020 --> 58:22.380
 it's like better for the environment

58:22.380 --> 58:23.860
 because adults love Totoro.

58:23.860 --> 58:25.580
 It's such good art that everyone loves it.

58:25.580 --> 58:27.380
 Like I still have all my old Totoro merch

58:27.380 --> 58:28.660
 from when I was a kid.

58:28.660 --> 58:32.840
 Like I literally have the most ragged old Totoro merch.

58:33.960 --> 58:35.780
 Like everybody loves it, everybody keeps it.

58:35.780 --> 58:40.780
 It's like, why does the art we have for babies

58:40.900 --> 58:45.300
 need to suck and be not accessible to adults

58:45.300 --> 58:49.100
 and then just be thrown out when, you know,

58:49.100 --> 58:50.300
 they age out of it?

58:50.300 --> 58:53.180
 Like, it's like, I don't know.

58:53.180 --> 58:54.740
 I don't have like a fully formed thought here,

58:54.740 --> 58:56.220
 but this is just something I've been thinking about a lot

58:56.220 --> 58:58.660
 is like, how do we like,

58:58.660 --> 59:01.180
 how do we have more Totoroesque content?

59:01.180 --> 59:02.500
 Like how do we have more content like this

59:02.500 --> 59:05.100
 that like is universal and everybody loves,

59:05.100 --> 59:10.100
 but is like really geared to an emerging consciousness?

59:10.160 --> 59:13.100
 Emerging consciousness in the first like three years of life

59:13.100 --> 59:14.260
 that so much turmoil,

59:14.260 --> 59:16.540
 so much evolution of mind is happening.

59:16.540 --> 59:18.020
 It seems like a crucial time.

59:18.020 --> 59:21.820
 Would you say to make it not suck,

59:21.820 --> 59:26.580
 do you think of basically treating a child

59:26.580 --> 59:28.980
 like they have the capacity to have the brilliance

59:28.980 --> 59:30.760
 of an adult or even beyond that?

59:30.760 --> 59:33.420
 Is that how you think of that mind or?

59:33.420 --> 59:35.080
 No, cause they still,

59:35.080 --> 59:37.900
 they like it when you talk weird and stuff.

59:37.900 --> 59:39.660
 Like they respond better to,

59:39.660 --> 59:41.040
 cause even they can imitate better

59:41.040 --> 59:42.100
 when your voice is higher.

59:42.100 --> 59:44.020
 Like people say like, oh, don't do baby talk.

59:44.020 --> 59:45.380
 But it's like, when your voice is higher,

59:45.380 --> 59:47.340
 it's closer to something they can imitate.

59:47.340 --> 59:50.520
 So they like, like the baby talk actually kind of works.

59:50.520 --> 59:52.100
 Like it helps them learn to communicate.

59:52.100 --> 59:53.360
 I've found it to be more effective

59:53.360 --> 59:55.300
 with learning words and stuff.

59:55.300 --> 59:59.980
 But like, you're not speaking down to them.

59:59.980 --> 1:00:03.100
 Like do they have the capacity

1:00:03.100 --> 1:00:05.900
 to understand really difficult concepts

1:00:05.900 --> 1:00:07.700
 just in a very different way,

1:00:07.700 --> 1:00:09.080
 like an emotional intelligence

1:00:09.080 --> 1:00:11.500
 about something deep within?

1:00:11.500 --> 1:00:13.060
 Oh yeah, no, like if X hurts,

1:00:13.060 --> 1:00:15.700
 like if X bites me really hard and I'm like, ow,

1:00:15.700 --> 1:00:17.300
 like he gets, he's sad.

1:00:17.300 --> 1:00:19.740
 He's like sad if he hurts me by accident.

1:00:19.740 --> 1:00:20.580
 Yeah.

1:00:20.580 --> 1:00:22.540
 Which he's huge, so he hurts me a lot by accident.

1:00:22.540 --> 1:00:26.860
 Yeah, that's so interesting that that mind emerges

1:00:26.860 --> 1:00:31.100
 and he and children don't really have memory of that time.

1:00:31.100 --> 1:00:32.940
 So we can't even have a conversation with them about it.

1:00:32.940 --> 1:00:34.380
 Yeah, I just thank God they don't have a memory

1:00:34.380 --> 1:00:37.380
 of this time because like, think about like,

1:00:37.380 --> 1:00:39.620
 I mean with our youngest baby,

1:00:39.620 --> 1:00:42.080
 like it's like, I'm like, have you read

1:00:42.080 --> 1:00:45.580
 the sci fi short story, I Have No Mouth But I Must Scream?

1:00:46.660 --> 1:00:47.980
 Good title, no.

1:00:47.980 --> 1:00:49.920
 Oh man, I mean, you should read that.

1:00:49.920 --> 1:00:53.220
 I Have No Mouth But I Must Scream.

1:00:53.220 --> 1:00:55.460
 I hate getting into this Rocco's Basilisk shit.

1:00:55.460 --> 1:00:57.660
 It's kind of a story about the,

1:00:57.660 --> 1:01:02.660
 about like an AI that's like torturing someone in eternity

1:01:03.820 --> 1:01:05.540
 and they have like no body.

1:01:05.540 --> 1:01:07.380
 The way they describe it,

1:01:07.380 --> 1:01:09.200
 it sort of sounds like what it feels like,

1:01:09.200 --> 1:01:11.340
 like being a baby, like you're conscious

1:01:11.340 --> 1:01:13.420
 and you're just getting inputs from everywhere

1:01:13.420 --> 1:01:15.220
 and you have no muscles and you're like jelly

1:01:15.220 --> 1:01:17.540
 and you like can't move and you try to like communicate,

1:01:17.540 --> 1:01:18.940
 but you can't communicate and we're,

1:01:18.940 --> 1:01:22.580
 and like, you're just like in this like hell state.

1:01:22.580 --> 1:01:25.180
 I think it's good we can't remember that.

1:01:25.180 --> 1:01:27.620
 Like my little baby is just exiting that,

1:01:27.620 --> 1:01:29.100
 like she's starting to like get muscles

1:01:29.100 --> 1:01:30.700
 and have more like autonomy,

1:01:30.700 --> 1:01:34.160
 but like watching her go through the opening phase,

1:01:34.160 --> 1:01:37.700
 I was like, I was like, this does not seem good.

1:01:37.700 --> 1:01:39.180
 Oh, you think it's kind of like.

1:01:39.180 --> 1:01:40.300
 Like I think it sucks.

1:01:40.300 --> 1:01:41.780
 I think it might be really violent.

1:01:41.780 --> 1:01:44.700
 Like violent, mentally violent, psychologically violent.

1:01:44.700 --> 1:01:47.460
 Consciousness emerging, I think is a very violent thing.

1:01:47.460 --> 1:01:48.300
 I never thought about that.

1:01:48.300 --> 1:01:49.900
 I think it's possible that we all carry

1:01:49.900 --> 1:01:52.000
 quite a bit of trauma from it that we don't,

1:01:52.000 --> 1:01:54.380
 I think that would be a good thing to study

1:01:54.380 --> 1:01:58.540
 because I think if, I think addressing that trauma,

1:01:58.540 --> 1:01:59.740
 like, I think that might be.

1:01:59.740 --> 1:02:00.900
 Oh, you mean like echoes of it

1:02:00.900 --> 1:02:01.740
 are still there in the shadows somewhere.

1:02:01.740 --> 1:02:04.220
 I think it's gotta be, I feel this, this help,

1:02:04.220 --> 1:02:06.940
 the helplessness, the like existential

1:02:06.940 --> 1:02:10.540
 and that like fear of being in like an unknown place

1:02:10.540 --> 1:02:13.460
 bombarded with inputs and being completely helpless,

1:02:13.460 --> 1:02:15.680
 like that's gotta be somewhere deep in your brain

1:02:15.680 --> 1:02:17.420
 and that can't be good for you.

1:02:17.420 --> 1:02:19.500
 What do you think consciousness is?

1:02:19.500 --> 1:02:20.980
 This whole conversation

1:02:20.980 --> 1:02:22.500
 has impossibly difficult questions.

1:02:22.500 --> 1:02:23.340
 What do you think it is?

1:02:23.340 --> 1:02:26.380
 Debbie said this is like so hard.

1:02:28.460 --> 1:02:30.700
 Yeah, we talked about music for like two minutes.

1:02:30.700 --> 1:02:31.540
 All right.

1:02:31.540 --> 1:02:32.700
 No, I'm so, I'm just over music.

1:02:32.700 --> 1:02:33.540
 I'm over music.

1:02:33.540 --> 1:02:35.420
 Yeah, I still like it.

1:02:35.420 --> 1:02:36.240
 It has its purpose.

1:02:36.240 --> 1:02:37.080
 No, I love music.

1:02:37.080 --> 1:02:38.080
 I mean, music's the greatest thing ever.

1:02:38.080 --> 1:02:38.920
 It's my favorite thing.

1:02:38.920 --> 1:02:42.340
 But I just like every interview is like,

1:02:42.340 --> 1:02:43.600
 what is your process?

1:02:43.600 --> 1:02:44.440
 Like, I don't know.

1:02:44.440 --> 1:02:45.260
 I'm just done.

1:02:45.260 --> 1:02:46.100
 I can't do anything.

1:02:46.100 --> 1:02:46.940
 I do want to ask you about Able to Live.

1:02:46.940 --> 1:02:47.780
 Oh, I'll tell you about Ableton

1:02:47.780 --> 1:02:49.420
 because Ableton's sick.

1:02:49.420 --> 1:02:51.700
 No one has ever asked about Ableton though.

1:02:51.700 --> 1:02:54.260
 Yeah, well, because I just need tech support mainly.

1:02:54.260 --> 1:02:55.100
 I can help you.

1:02:55.100 --> 1:02:56.620
 I can help you with your Ableton tech.

1:02:56.620 --> 1:02:58.940
 Anyway, from Ableton back to consciousness.

1:02:58.940 --> 1:03:00.620
 What do you, do you think this is a thing

1:03:00.620 --> 1:03:03.300
 that only humans are capable of?

1:03:03.300 --> 1:03:05.380
 Can robots be conscious?

1:03:05.380 --> 1:03:08.220
 Can, like when you think about entities,

1:03:08.220 --> 1:03:10.220
 you think there's aliens out there that are conscious?

1:03:10.220 --> 1:03:11.540
 Like is conscious, what is consciousness?

1:03:11.540 --> 1:03:13.300
 There's this Terrence McKenna quote

1:03:13.300 --> 1:03:15.900
 that I've found that I fucking love.

1:03:15.900 --> 1:03:17.540
 Am I allowed to swear on here?

1:03:17.540 --> 1:03:18.360
 Yes.

1:03:18.360 --> 1:03:20.000
 Nature loves courage.

1:03:21.140 --> 1:03:23.460
 You make the commitment and nature will respond

1:03:23.460 --> 1:03:26.580
 to that commitment by removing impossible obstacles.

1:03:26.580 --> 1:03:28.060
 Dream the impossible dream

1:03:28.060 --> 1:03:29.920
 and the world will not grind you under.

1:03:29.920 --> 1:03:31.120
 It will lift you up.

1:03:31.120 --> 1:03:32.380
 This is the trick.

1:03:32.380 --> 1:03:35.160
 This is what all these teachers and philosophers

1:03:35.160 --> 1:03:38.400
 who really counted, who really touched the alchemical gold,

1:03:38.400 --> 1:03:40.100
 this is what they understood.

1:03:40.100 --> 1:03:42.860
 This is the shamanic dance in the waterfall.

1:03:42.860 --> 1:03:44.700
 This is how magic is done.

1:03:44.700 --> 1:03:46.420
 By hurling yourself into the abyss

1:03:46.420 --> 1:03:48.620
 and discovering it's a feather bed.

1:03:48.620 --> 1:03:49.920
 Yeah.

1:03:49.920 --> 1:03:50.760
 And for this reason,

1:03:50.760 --> 1:03:55.400
 I do think there are no technological limits.

1:03:55.400 --> 1:03:58.700
 I think like what is already happening here,

1:03:58.700 --> 1:03:59.880
 this is like impossible.

1:03:59.880 --> 1:04:01.060
 This is insane.

1:04:01.060 --> 1:04:03.340
 And we've done this in a very limited amount of time.

1:04:03.340 --> 1:04:05.900
 And we're accelerating the rate at which we're doing this.

1:04:05.900 --> 1:04:10.220
 So I think digital consciousness, it's inevitable.

1:04:10.220 --> 1:04:13.300
 And we may not be able to even understand what that means,

1:04:13.300 --> 1:04:15.780
 but I like hurling yourself into the abyss.

1:04:15.780 --> 1:04:17.460
 So we're surrounded by all this mystery

1:04:17.460 --> 1:04:19.780
 and we just keep hurling ourselves into it,

1:04:19.780 --> 1:04:22.940
 like fearlessly and keep discovering cool shit.

1:04:22.940 --> 1:04:23.900
 Yeah.

1:04:23.900 --> 1:04:26.840
 Like, I just think it's like,

1:04:31.340 --> 1:04:32.980
 like who even knows if the laws of physics,

1:04:32.980 --> 1:04:35.580
 the laws of physics are probably just the current,

1:04:35.580 --> 1:04:36.420
 like as I was saying,

1:04:36.420 --> 1:04:37.900
 speed of light is the current render rate.

1:04:37.900 --> 1:04:40.220
 It's like, if we're in a simulation,

1:04:40.220 --> 1:04:41.220
 they'll be able to upgrade that.

1:04:41.220 --> 1:04:45.660
 Like I sort of suspect when we made the James Webb telescope,

1:04:45.660 --> 1:04:46.780
 like part of the reason we made that

1:04:46.780 --> 1:04:50.180
 is because we had an upgrade, you know?

1:04:50.180 --> 1:04:53.640
 And so now more of space has been rendered

1:04:53.640 --> 1:04:55.380
 so we can see more of it now.

1:04:56.740 --> 1:04:58.860
 Yeah, but I think humans are super, super,

1:04:58.860 --> 1:05:00.420
 super limited cognitively.

1:05:00.420 --> 1:05:04.740
 So I wonder if we'll be allowed to create

1:05:04.740 --> 1:05:08.100
 more intelligent beings that can see more of the universe

1:05:08.100 --> 1:05:11.160
 as their render rate is upgraded.

1:05:11.160 --> 1:05:12.660
 Maybe we're cognitively limited.

1:05:12.660 --> 1:05:15.300
 Everyone keeps talking about how we're cognitively limited

1:05:15.300 --> 1:05:17.140
 and AI is gonna render us obsolete,

1:05:17.140 --> 1:05:19.400
 but it's like, you know,

1:05:20.340 --> 1:05:21.800
 like this is not the same thing

1:05:21.800 --> 1:05:26.020
 as like an amoeba becoming an alligator.

1:05:26.020 --> 1:05:28.300
 Like, it's like, if we create AI,

1:05:28.300 --> 1:05:29.820
 again, that's intelligent design.

1:05:29.820 --> 1:05:33.160
 That's literally all religions are based on gods

1:05:33.160 --> 1:05:34.460
 that create consciousness.

1:05:34.460 --> 1:05:35.700
 Like we are God making.

1:05:35.700 --> 1:05:37.860
 Like what we are doing is incredibly profound.

1:05:37.860 --> 1:05:41.620
 And like, even if we can't compute,

1:05:41.620 --> 1:05:44.740
 even if we're so much worse than them,

1:05:44.740 --> 1:05:49.460
 like just like unfathomably worse than like,

1:05:49.460 --> 1:05:51.980
 you know, an omnipotent kind of AI,

1:05:51.980 --> 1:05:55.300
 it's like we, I do not think that they would just think

1:05:55.300 --> 1:05:56.420
 that we are stupid.

1:05:56.420 --> 1:05:58.420
 I think that they would recognize the profundity

1:05:58.420 --> 1:05:59.740
 of what we have accomplished.

1:05:59.740 --> 1:06:02.700
 Are we the gods or are they the gods in our personality?

1:06:02.700 --> 1:06:05.460
 I mean, we're kind of the guy.

1:06:05.460 --> 1:06:06.300
 It's complicated.

1:06:06.300 --> 1:06:07.540
 It's complicated.

1:06:07.540 --> 1:06:08.380
 Like we're.

1:06:08.380 --> 1:06:11.540
 But they would acknowledge the value.

1:06:11.540 --> 1:06:13.540
 Well, I hope they acknowledge the value

1:06:13.540 --> 1:06:16.140
 of paying respect to the creative ancestors.

1:06:16.140 --> 1:06:17.940
 I think they would think it's cool.

1:06:17.940 --> 1:06:22.940
 I think if curiosity is a trait

1:06:23.940 --> 1:06:28.940
 that we can quantify and put into AI,

1:06:29.340 --> 1:06:31.740
 then I think if AI are curious,

1:06:31.740 --> 1:06:33.620
 then they will be curious about us

1:06:33.620 --> 1:06:37.660
 and they will not be hateful or dismissive of us.

1:06:37.660 --> 1:06:41.060
 They might, you know, see us as, I don't know.

1:06:41.060 --> 1:06:43.580
 It's like, I'm not like, oh, fuck these dogs.

1:06:43.580 --> 1:06:45.500
 Let's just kill all the dogs.

1:06:45.500 --> 1:06:46.340
 I love dogs.

1:06:46.340 --> 1:06:47.660
 Dogs have great utility.

1:06:47.660 --> 1:06:49.060
 Dogs like provide a lot of.

1:06:49.060 --> 1:06:50.460
 We make friends with them.

1:06:50.460 --> 1:06:52.260
 We have a deep connection with them.

1:06:53.520 --> 1:06:55.380
 We anthropomorphize them.

1:06:55.380 --> 1:06:58.860
 Like we have a real love for dogs, for cats and so on

1:06:58.860 --> 1:07:00.660
 for some reason, even though they're intellectually

1:07:00.660 --> 1:07:01.500
 much less than us.

1:07:01.500 --> 1:07:03.980
 And I think there is something sacred about us

1:07:03.980 --> 1:07:05.700
 because it's like, if you look at the universe,

1:07:05.700 --> 1:07:09.020
 like the whole universe is like cold and dead

1:07:09.020 --> 1:07:09.980
 and sort of robotic.

1:07:09.980 --> 1:07:14.740
 And it's like, you know, AI intelligence,

1:07:15.620 --> 1:07:18.980
 you know, it's kind of more like the universe.

1:07:18.980 --> 1:07:23.980
 It's like cold and you know, logical

1:07:24.620 --> 1:07:28.780
 and you know, abiding by the laws of physics and whatever.

1:07:28.780 --> 1:07:31.980
 But like, we're this like loosey goosey,

1:07:31.980 --> 1:07:33.580
 weird art thing that happened.

1:07:33.580 --> 1:07:34.940
 And I think it's beautiful.

1:07:34.940 --> 1:07:38.900
 And like, I think even if we, I think one of the values,

1:07:40.300 --> 1:07:45.300
 if consciousness is a thing that is most worth preserving,

1:07:47.180 --> 1:07:49.340
 which I think is the case, I think consciousness,

1:07:49.340 --> 1:07:50.700
 I think if there's any kind of like religious

1:07:50.700 --> 1:07:54.860
 or spiritual thing, it should be that consciousness

1:07:54.860 --> 1:07:55.700
 is sacred.

1:07:55.700 --> 1:08:00.700
 Like, then, you know, I still think even if AI

1:08:01.580 --> 1:08:05.820
 render us obsolete and we, climate change, it's too bad

1:08:05.820 --> 1:08:07.420
 and we get hit by a comet and we don't become

1:08:07.420 --> 1:08:09.500
 a multi planetary species fast enough,

1:08:09.500 --> 1:08:12.300
 but like AI is able to populate the universe.

1:08:12.300 --> 1:08:14.260
 Like I imagine, like if I was an AI,

1:08:14.260 --> 1:08:17.860
 I would find more planets that are capable

1:08:17.860 --> 1:08:20.660
 of hosting biological life forms and like recreate them.

1:08:20.660 --> 1:08:21.820
 Because we're fun to watch.

1:08:21.820 --> 1:08:23.340
 Yeah, we're fun to watch.

1:08:23.340 --> 1:08:26.140
 Yeah, but I do believe that AI can have some of the same

1:08:26.140 --> 1:08:29.900
 magic of consciousness within it.

1:08:29.900 --> 1:08:31.420
 Because consciousness, we don't know what it is.

1:08:31.420 --> 1:08:33.020
 So, you know, there's some kind of.

1:08:33.020 --> 1:08:34.140
 Or it might be a different magic.

1:08:34.140 --> 1:08:37.500
 It might be like a strange, a strange, different.

1:08:37.500 --> 1:08:38.340
 Right.

1:08:38.340 --> 1:08:39.340
 Because they're not gonna have hormones.

1:08:39.340 --> 1:08:42.620
 Like I feel like a lot of our magic is hormonal kind of.

1:08:42.620 --> 1:08:44.500
 I don't know, I think some of our magic

1:08:44.500 --> 1:08:46.500
 is the limitations, the constraints.

1:08:46.500 --> 1:08:48.780
 And within that, the hormones and all that kind of stuff,

1:08:48.780 --> 1:08:51.460
 the finiteness of life, and then we get given

1:08:51.460 --> 1:08:54.740
 our limitations, we get to come up with creative solutions

1:08:54.740 --> 1:08:56.780
 of how to dance around those limitations.

1:08:56.780 --> 1:08:59.420
 We partner up like penguins against the cold.

1:08:59.420 --> 1:09:03.340
 We fall in love, and then love is ultimately

1:09:03.340 --> 1:09:06.060
 some kind of, allows us to delude ourselves

1:09:06.060 --> 1:09:08.500
 that we're not mortal and finite,

1:09:08.500 --> 1:09:11.620
 and that life is not ultimately, you live alone,

1:09:11.620 --> 1:09:13.780
 you're born alone, you die alone.

1:09:13.780 --> 1:09:15.540
 And then love is like for a moment

1:09:15.540 --> 1:09:17.540
 or for a long time, forgetting that.

1:09:17.540 --> 1:09:20.340
 And so we come up with all these creative hacks

1:09:20.340 --> 1:09:25.340
 that make life like fascinatingly fun.

1:09:25.980 --> 1:09:27.740
 Yeah, yeah, yeah, fun, yeah.

1:09:27.740 --> 1:09:30.260
 And then AI might have different kinds of fun.

1:09:30.260 --> 1:09:31.300
 Yes.

1:09:31.300 --> 1:09:34.900
 And hopefully our funs intersect once in a while.

1:09:34.900 --> 1:09:38.580
 I think there would be a little intersection

1:09:38.580 --> 1:09:39.420
 of the fun.

1:09:39.420 --> 1:09:40.420
 Yeah. Yeah.

1:09:40.420 --> 1:09:42.820
 What do you think is the role of love

1:09:42.820 --> 1:09:44.280
 in the human condition?

1:09:45.500 --> 1:09:46.500
 I think.

1:09:46.500 --> 1:09:47.620
 Why, is it useful?

1:09:47.620 --> 1:09:51.540
 Is it useful like a hack, or is this like fundamental

1:09:51.540 --> 1:09:54.940
 to what it means to be human, the capacity to love?

1:09:54.940 --> 1:09:58.100
 I mean, I think love is the evolutionary mechanism

1:09:58.100 --> 1:10:00.580
 that is like beginning the intelligent design.

1:10:00.580 --> 1:10:02.900
 Like I was just reading about,

1:10:04.140 --> 1:10:06.180
 do you know about Kropotkin?

1:10:06.180 --> 1:10:08.940
 He's like an anarchist, like old Russian anarchist.

1:10:08.940 --> 1:10:11.540
 I live next door to Michael Malice.

1:10:11.540 --> 1:10:12.380
 I don't know if you know who that is.

1:10:12.380 --> 1:10:13.300
 He's an anarchist.

1:10:13.300 --> 1:10:14.540
 He's a modern day anarchist.

1:10:14.540 --> 1:10:15.780
 Okay. Anarchists are fun.

1:10:15.780 --> 1:10:17.940
 I'm kind of getting into anarchism a little bit.

1:10:17.940 --> 1:10:22.380
 This is probably not a good route to be taking, but.

1:10:22.380 --> 1:10:23.900
 Oh no, I think if you're,

1:10:23.900 --> 1:10:26.180
 listen, you should expose yourself to ideas.

1:10:26.180 --> 1:10:28.540
 There's no harm to thinking about ideas.

1:10:28.540 --> 1:10:32.460
 I think anarchists challenge systems in interesting ways,

1:10:32.460 --> 1:10:34.180
 and they think in interesting ways.

1:10:34.180 --> 1:10:35.340
 It's just as good for the soul.

1:10:35.340 --> 1:10:37.300
 It's like refreshes your mental palette.

1:10:37.300 --> 1:10:38.940
 I don't think we should actually,

1:10:38.940 --> 1:10:40.620
 I wouldn't actually ascribe to it,

1:10:40.620 --> 1:10:42.900
 but I've never actually gone deep on anarchy

1:10:42.900 --> 1:10:44.540
 as a philosophy, so I'm doing.

1:10:44.540 --> 1:10:45.380
 You should still think about it though.

1:10:45.380 --> 1:10:46.500
 When you read, when you listen,

1:10:46.500 --> 1:10:48.300
 because I'm reading about the Russian Revolution a lot,

1:10:48.300 --> 1:10:51.180
 and there was the Soviets and Lenin and all that,

1:10:51.180 --> 1:10:53.700
 but then there was Kropotkin and his anarchist sect,

1:10:53.700 --> 1:10:54.820
 and they were sort of interesting

1:10:54.820 --> 1:10:57.140
 because he was kind of a technocrat actually.

1:10:57.140 --> 1:11:01.220
 He was like, women can be more equal if we have appliances.

1:11:01.220 --> 1:11:04.940
 He was really into using technology

1:11:04.940 --> 1:11:07.740
 to reduce the amount of work people had to do.

1:11:07.740 --> 1:11:11.700
 But so Kropotkin was a biologist or something.

1:11:11.700 --> 1:11:13.380
 He studied animals.

1:11:13.380 --> 1:11:17.180
 And he was really at the time like,

1:11:17.180 --> 1:11:20.660
 I think it's Nature magazine.

1:11:20.660 --> 1:11:22.660
 I think it might've even started as a Russian magazine,

1:11:22.660 --> 1:11:23.860
 but he was publishing studies.

1:11:23.860 --> 1:11:26.020
 Everyone was really into Darwinism at the time

1:11:26.020 --> 1:11:27.060
 and survival of the fittest,

1:11:27.060 --> 1:11:30.380
 and war is the mechanism by which we become better.

1:11:30.380 --> 1:11:35.380
 And it was this real cementing this idea in society

1:11:36.500 --> 1:11:39.900
 that violence kill the weak,

1:11:39.900 --> 1:11:41.340
 and that's how we become better.

1:11:41.340 --> 1:11:43.060
 And then Kropotkin was kind of interesting

1:11:43.060 --> 1:11:45.580
 because he was looking at instances,

1:11:45.580 --> 1:11:47.420
 he was finding all these instances in nature

1:11:47.420 --> 1:11:49.500
 where animals were like helping each other and stuff.

1:11:49.500 --> 1:11:53.540
 And he was like, actually love is a survival mechanism.

1:11:53.540 --> 1:11:58.540
 Like there's so many instances in the animal kingdom

1:11:58.620 --> 1:12:03.140
 where like cooperation and like helping weaker creatures

1:12:03.140 --> 1:12:06.100
 and all this stuff is actually an evolutionary mechanism.

1:12:06.100 --> 1:12:08.020
 I mean, you even look at child rearing.

1:12:08.020 --> 1:12:12.380
 Like child rearing is like immense amounts

1:12:12.380 --> 1:12:14.420
 of just love and goodwill.

1:12:14.420 --> 1:12:17.140
 And just like, there's no immediate,

1:12:20.060 --> 1:12:24.860
 you're not getting any immediate feedback of like winning.

1:12:24.860 --> 1:12:26.180
 It's not competitive.

1:12:26.180 --> 1:12:28.500
 It's literally, it's like we actually use love

1:12:28.500 --> 1:12:30.980
 as an evolutionary mechanism just as much as we use war.

1:12:30.980 --> 1:12:34.020
 And I think we've like missing the other part

1:12:34.020 --> 1:12:37.300
 and we've reoriented, we've culturally reoriented

1:12:37.300 --> 1:12:41.820
 like science and philosophy has oriented itself

1:12:41.820 --> 1:12:43.980
 around Darwinism a little bit too much.

1:12:43.980 --> 1:12:48.500
 And the Kropotkin model, I think is equally valid.

1:12:48.500 --> 1:12:51.500
 Like it's like cooperation and love and stuff

1:12:54.340 --> 1:12:58.900
 is just as essential for species survival and evolution.

1:12:58.900 --> 1:13:01.380
 It should be a more powerful survival mechanism

1:13:01.380 --> 1:13:02.700
 in the context of evolution.

1:13:02.700 --> 1:13:04.500
 And it comes back to like,

1:13:04.500 --> 1:13:06.660
 we think engineering is so much more important

1:13:06.660 --> 1:13:08.820
 than motherhood, but it's like,

1:13:08.820 --> 1:13:10.700
 if you lose the motherhood, the engineering means nothing.

1:13:10.700 --> 1:13:12.020
 We have no more humans.

1:13:12.020 --> 1:13:17.020
 It's like, I think our society should,

1:13:18.740 --> 1:13:21.300
 the survival of the, the way we see,

1:13:21.300 --> 1:13:24.500
 we conceptualize evolution should really change

1:13:24.500 --> 1:13:27.020
 to also include this idea, I guess.

1:13:27.020 --> 1:13:32.020
 Yeah, there's some weird thing that seems irrational

1:13:32.460 --> 1:13:37.260
 that is also core to what it means to be human.

1:13:37.260 --> 1:13:40.420
 So love is one such thing.

1:13:40.420 --> 1:13:42.980
 They could make you do a lot of irrational things,

1:13:42.980 --> 1:13:46.100
 but that depth of connection and that loyalty

1:13:46.100 --> 1:13:47.300
 is a powerful thing.

1:13:47.300 --> 1:13:49.260
 Are they irrational or are they rational?

1:13:49.260 --> 1:13:54.260
 Like, it's like, is, you know, maybe losing out

1:13:57.100 --> 1:14:00.900
 on some things in order to like keep your family together

1:14:00.900 --> 1:14:05.900
 or in order, like, it's like, what are our actual values?

1:14:06.260 --> 1:14:08.780
 Well, right, I mean, the rational thing is

1:14:08.780 --> 1:14:11.340
 if you have a cold economist perspective,

1:14:11.340 --> 1:14:16.020
 you know, motherhood or sacrificing your career for love,

1:14:16.020 --> 1:14:20.620
 you know, in terms of salary, in terms of economic wellbeing,

1:14:20.620 --> 1:14:22.740
 in terms of flourishing of you as a human being,

1:14:22.740 --> 1:14:25.900
 that could be seen on some kind of metrics

1:14:25.900 --> 1:14:28.580
 as a irrational decision, suboptimal decision,

1:14:28.580 --> 1:14:33.580
 but there's the manifestation of love

1:14:34.220 --> 1:14:36.780
 could be the optimal thing to do.

1:14:36.780 --> 1:14:41.140
 There's a kind of saying, save one life, save the world.

1:14:41.140 --> 1:14:44.100
 That's the thing that doctors often face, which is like.

1:14:44.100 --> 1:14:45.140
 Well, it's considered irrational

1:14:45.140 --> 1:14:47.460
 because the profit model doesn't include social good.

1:14:47.460 --> 1:14:48.580
 Yes, yeah.

1:14:48.580 --> 1:14:50.420
 So if a profit model includes social good,

1:14:50.420 --> 1:14:52.220
 then suddenly these would be rational decisions.

1:14:52.220 --> 1:14:54.420
 Might be difficult to, you know,

1:14:54.420 --> 1:14:57.620
 it requires a shift in our thinking about profit

1:14:57.620 --> 1:15:00.980
 and might be difficult to measure social good.

1:15:00.980 --> 1:15:04.500
 Yes, but we're learning to measure a lot of things.

1:15:04.500 --> 1:15:05.580
 Yeah, digitizing a lot of things.

1:15:05.580 --> 1:15:10.580
 Where we're actually, you know, quantifying vision and stuff.

1:15:10.580 --> 1:15:14.580
 Like we're like, you know, like you go on Facebook

1:15:14.580 --> 1:15:16.980
 and they can, like Facebook can pretty much predict

1:15:16.980 --> 1:15:17.820
 our behaviors.

1:15:17.820 --> 1:15:20.660
 Like we're, a surprising amount of things

1:15:20.660 --> 1:15:25.660
 that seem like mysterious consciousness soul things

1:15:25.900 --> 1:15:27.540
 have been quantified at this point.

1:15:27.540 --> 1:15:29.700
 So surely we can quantify these other things.

1:15:29.700 --> 1:15:30.540
 Yeah.

1:15:31.460 --> 1:15:34.220
 But as more and more of us are moving the digital space,

1:15:34.220 --> 1:15:35.860
 I wanted to ask you about something.

1:15:35.860 --> 1:15:40.220
 From a fan perspective, I kind of, you know,

1:15:40.220 --> 1:15:43.580
 you as a musician, you as an online personality,

1:15:43.580 --> 1:15:45.500
 it seems like you have all these identities

1:15:45.500 --> 1:15:46.660
 and you play with them.

1:15:48.940 --> 1:15:51.140
 One of the cool things about the internet,

1:15:51.140 --> 1:15:53.340
 it seems like you can play with identities.

1:15:53.340 --> 1:15:56.100
 So as we move into the digital world more and more,

1:15:56.100 --> 1:15:59.180
 maybe even in the so called metaverse.

1:15:59.180 --> 1:16:01.220
 I mean, I love the metaverse and I love the idea,

1:16:01.220 --> 1:16:06.220
 but like the way this has all played out didn't go well

1:16:09.980 --> 1:16:11.020
 and people are mad about it.

1:16:11.020 --> 1:16:12.460
 And I think we need to like.

1:16:12.460 --> 1:16:13.460
 I think that's temporary.

1:16:13.460 --> 1:16:14.500
 I think it's temporary.

1:16:14.500 --> 1:16:16.780
 Just like, you know how all the celebrities got together

1:16:16.780 --> 1:16:19.100
 and sang the song Imagine by Jeff Leonard

1:16:19.100 --> 1:16:20.940
 and everyone started hating the song Imagine.

1:16:20.940 --> 1:16:22.060
 I'm hoping that's temporary

1:16:22.060 --> 1:16:24.380
 because it's a damn good song.

1:16:24.380 --> 1:16:25.500
 So I think it's just temporary.

1:16:25.500 --> 1:16:27.820
 Like once you actually have virtual worlds,

1:16:27.820 --> 1:16:29.940
 whatever they're called metaverse or otherwise,

1:16:29.940 --> 1:16:31.420
 it becomes, I don't know.

1:16:31.420 --> 1:16:32.500
 Well, we do have virtual worlds.

1:16:32.500 --> 1:16:34.460
 Like video games, Elden Ring.

1:16:34.460 --> 1:16:35.300
 Have you played Elden Ring?

1:16:35.300 --> 1:16:36.140
 You haven't played Elden Ring?

1:16:36.140 --> 1:16:38.580
 I'm really afraid of playing that game.

1:16:38.580 --> 1:16:39.420
 Literally amazed.

1:16:39.420 --> 1:16:40.780
 It looks way too fun.

1:16:40.780 --> 1:16:45.020
 It looks I would wanna go there and stay there forever.

1:16:45.020 --> 1:16:47.020
 It's yeah, so fun.

1:16:47.020 --> 1:16:48.980
 It's so nice.

1:16:50.500 --> 1:16:52.180
 Oh man, yeah.

1:16:52.180 --> 1:16:54.500
 So that's the, yeah, that's a metaverse.

1:16:54.500 --> 1:16:57.460
 That's a metaverse, but you're not really,

1:16:57.460 --> 1:17:00.620
 how immersive is it in the sense that,

1:17:02.820 --> 1:17:03.940
 does the three dimension

1:17:03.940 --> 1:17:06.060
 like virtual reality integration necessary?

1:17:06.060 --> 1:17:08.780
 Can we really just take our, close our eyes

1:17:08.780 --> 1:17:12.180
 and kind of plug in in the 2D screen

1:17:13.060 --> 1:17:15.780
 and become that other being for time

1:17:15.780 --> 1:17:17.940
 and really enjoy that journey that we take?

1:17:17.940 --> 1:17:19.660
 And we almost become that.

1:17:19.660 --> 1:17:22.100
 You're no longer C, I'm no longer Lex,

1:17:22.100 --> 1:17:25.340
 you're that creature, whatever the hell it is in that game.

1:17:25.340 --> 1:17:26.180
 Yeah, that is that.

1:17:26.180 --> 1:17:28.300
 I mean, that's why I love those video games.

1:17:29.220 --> 1:17:33.100
 I really do become those people for a time.

1:17:33.100 --> 1:17:36.180
 But like, it seems like with the idea of the metaverse,

1:17:36.180 --> 1:17:37.900
 the idea of the digital space,

1:17:37.900 --> 1:17:39.500
 well, even on Twitter,

1:17:39.500 --> 1:17:42.580
 you get a chance to be somebody for prolonged periods of time

1:17:42.580 --> 1:17:44.540
 like across a lifespan.

1:17:44.540 --> 1:17:47.620
 You know, you have a Twitter account for years, for decades

1:17:47.620 --> 1:17:48.460
 and you're that person.

1:17:48.460 --> 1:17:49.660
 I don't know if that's a good thing.

1:17:49.660 --> 1:17:52.660
 I feel very tormented by it.

1:17:52.660 --> 1:17:54.300
 By Twitter specifically.

1:17:54.300 --> 1:17:57.580
 By social media representation of you.

1:17:57.580 --> 1:17:59.100
 I feel like the public perception of me

1:17:59.100 --> 1:18:04.100
 has gotten so distorted that I find it kind of disturbing.

1:18:04.420 --> 1:18:06.300
 It's one of the things that's disincentivizing me

1:18:06.300 --> 1:18:07.900
 from like wanting to keep making art

1:18:07.900 --> 1:18:09.020
 because I'm just like,

1:18:11.060 --> 1:18:13.740
 I've completely lost control of the narrative.

1:18:13.740 --> 1:18:16.820
 And the narrative is, some of it is my own stupidity,

1:18:16.820 --> 1:18:19.260
 but a lot, like some of it has just been like hijacked

1:18:19.260 --> 1:18:23.100
 by forces far beyond my control.

1:18:23.100 --> 1:18:25.580
 I kind of got in over my head in things.

1:18:25.580 --> 1:18:27.300
 Like I'm just a random Indian musician,

1:18:27.300 --> 1:18:31.900
 but I just got like dragged into geopolitical matters

1:18:31.900 --> 1:18:35.100
 and like financial, like the stock market and shit.

1:18:35.100 --> 1:18:36.300
 And so it's just like, it's just,

1:18:36.300 --> 1:18:37.700
 there are very powerful people

1:18:37.700 --> 1:18:39.660
 who have at various points in time

1:18:39.660 --> 1:18:43.700
 had very vested interest in making me seem insane

1:18:43.700 --> 1:18:45.620
 and I can't fucking fight that.

1:18:45.620 --> 1:18:46.940
 And I just like,

1:18:48.820 --> 1:18:50.780
 people really want their celebrity figures

1:18:50.780 --> 1:18:53.860
 to like be consistent and stay the same.

1:18:53.860 --> 1:18:55.820
 And like people have a lot of like emotional investment

1:18:55.820 --> 1:18:56.660
 in certain things.

1:18:56.660 --> 1:18:59.700
 And like, first of all,

1:18:59.700 --> 1:19:03.700
 like I'm like artificially more famous than I should be.

1:19:03.700 --> 1:19:06.620
 Isn't everybody who's famous artificially famous?

1:19:06.620 --> 1:19:11.340
 No, but like I should be like a weird niche indie thing.

1:19:11.340 --> 1:19:13.380
 And I make pretty challenging,

1:19:13.380 --> 1:19:16.300
 I do challenging weird fucking shit a lot.

1:19:16.300 --> 1:19:21.300
 And I accidentally by proxy got like foisted

1:19:22.420 --> 1:19:24.420
 into sort of like weird celebrity culture,

1:19:24.420 --> 1:19:27.300
 but like I cannot be media trained.

1:19:27.300 --> 1:19:29.820
 They have put me through so many hours of media training.

1:19:29.820 --> 1:19:32.540
 I would love to see BF fly in that wall.

1:19:32.540 --> 1:19:34.420
 I can't do, like when I do,

1:19:34.420 --> 1:19:37.420
 I try so hard and I like learn this thing and I like got it.

1:19:37.420 --> 1:19:38.740
 And I'm like, I got it, I got it, I got it.

1:19:38.740 --> 1:19:40.540
 But I just can't stop saying,

1:19:40.540 --> 1:19:42.940
 like my mouth just says things like,

1:19:42.940 --> 1:19:45.340
 and it's just like, and I just do, I just do things.

1:19:45.340 --> 1:19:46.580
 I just do crazy things.

1:19:46.580 --> 1:19:50.740
 Like I'm, I just, I need to do crazy things.

1:19:50.740 --> 1:19:53.100
 And it's just, I should not be,

1:19:53.100 --> 1:19:56.580
 it's too jarring for people

1:19:56.580 --> 1:19:59.700
 and the contradictory stuff.

1:19:59.700 --> 1:20:04.700
 And then all the by association, like, you know,

1:20:05.220 --> 1:20:09.020
 it's like I'm in a very weird position and my public image,

1:20:09.900 --> 1:20:14.900
 the avatar of me is now this totally crazy thing

1:20:14.900 --> 1:20:16.580
 that is so lost from my control.

1:20:16.580 --> 1:20:19.140
 So you feel the burden of the avatar having to be static.

1:20:19.140 --> 1:20:22.260
 So the avatar on Twitter or the avatar on Instagram

1:20:22.260 --> 1:20:26.740
 on these social platforms is as a burden.

1:20:26.740 --> 1:20:30.340
 It becomes like, cause like people don't want to accept

1:20:30.340 --> 1:20:32.580
 a changing avatar, a chaotic avatar.

1:20:32.580 --> 1:20:34.820
 Avatar is a stupid shit sometimes.

1:20:34.820 --> 1:20:36.460
 They think the avatar is morally wrong

1:20:36.460 --> 1:20:39.540
 or they think the avatar, and maybe it has been,

1:20:39.540 --> 1:20:41.100
 and like I question it all the time.

1:20:41.100 --> 1:20:46.100
 Like, I'm like, like, I don't know if everyone's right

1:20:46.300 --> 1:20:47.140
 and I'm wrong.

1:20:47.140 --> 1:20:50.100
 I don't know, like, but you know, a lot of times

1:20:50.100 --> 1:20:51.740
 people ascribe intentions to things,

1:20:51.740 --> 1:20:53.660
 the worst possible intentions.

1:20:53.660 --> 1:20:55.820
 At this point, people think I'm, you know,

1:20:57.300 --> 1:20:58.140
 but which is fine.

1:20:58.140 --> 1:20:58.980
 All kinds of words, yes.

1:20:58.980 --> 1:21:00.460
 Yes, and it's fine.

1:21:00.460 --> 1:21:02.820
 I'm not complaining about it, but I'm just,

1:21:02.820 --> 1:21:07.820
 it's a curiosity to me that we live these double, triple,

1:21:07.900 --> 1:21:10.340
 quadruple lives and I have this other life

1:21:10.340 --> 1:21:13.900
 that is like more people know my other life

1:21:13.900 --> 1:21:16.340
 than my real life, which is interesting.

1:21:16.340 --> 1:21:18.220
 Probably, I mean, you too, I guess, probably.

1:21:18.220 --> 1:21:20.100
 Yeah, but I have the luxury.

1:21:20.100 --> 1:21:23.100
 So we have all different, you know,

1:21:23.100 --> 1:21:25.140
 like I don't know what I'm doing.

1:21:25.140 --> 1:21:27.820
 There is an avatar and you're mediating

1:21:27.820 --> 1:21:29.940
 who you are through that avatar.

1:21:29.940 --> 1:21:34.340
 I have the nice luxury, not the luxury,

1:21:34.340 --> 1:21:38.060
 maybe by intention of not trying really hard

1:21:38.060 --> 1:21:41.460
 to make sure there's no difference between the avatar

1:21:41.460 --> 1:21:42.820
 and the private person.

1:21:44.020 --> 1:21:45.620
 Do you wear a suit all the time?

1:21:45.620 --> 1:21:46.620
 Yeah.

1:21:46.620 --> 1:21:47.740
 You do wear a suit?

1:21:47.740 --> 1:21:48.940
 Not all the time.

1:21:48.940 --> 1:21:51.540
 Recently, because I get recognized a lot,

1:21:51.540 --> 1:21:53.420
 I have to not wear the suit to hide.

1:21:53.420 --> 1:21:55.820
 I'm such an introvert, I'm such a social anxiety

1:21:55.820 --> 1:21:57.660
 and all that kind of stuff, so I have to hide away.

1:21:57.660 --> 1:22:00.580
 I love wearing a suit because it makes me feel

1:22:00.580 --> 1:22:02.380
 like I'm taking the moment seriously.

1:22:02.380 --> 1:22:04.340
 Like I'm, I don't know.

1:22:04.340 --> 1:22:06.980
 It makes me feel like a weirdo in the best possible way.

1:22:06.980 --> 1:22:08.500
 Suits feel great, every time I wear a suit,

1:22:08.500 --> 1:22:10.780
 I'm like, I don't know why I'm not doing this more.

1:22:10.780 --> 1:22:15.300
 Fashion in general, if you're doing it for yourself,

1:22:15.300 --> 1:22:18.660
 I don't know, it's a really awesome thing.

1:22:18.660 --> 1:22:23.660
 But yeah, I think there is definitely a painful way

1:22:24.620 --> 1:22:27.380
 to use social media and an empowering way.

1:22:27.380 --> 1:22:32.380
 And I don't know if any of us know which is which.

1:22:32.620 --> 1:22:33.940
 So we're trying to figure that out.

1:22:33.940 --> 1:22:36.780
 Some people, I think Doja Cat is incredible at it.

1:22:36.780 --> 1:22:39.540
 Incredible, like just masterful.

1:22:39.540 --> 1:22:41.860
 I don't know if you like follow that.

1:22:41.860 --> 1:22:44.780
 So okay, so not taking anything seriously,

1:22:44.780 --> 1:22:47.420
 joking, absurd, humor, that kind of thing.

1:22:47.420 --> 1:22:48.540
 I think Doja Cat might be like

1:22:48.540 --> 1:22:52.080
 the greatest living comedian right now.

1:22:52.080 --> 1:22:53.580
 Like I'm more entertained by Doja Cat

1:22:53.580 --> 1:22:56.220
 than actual comedians.

1:22:56.220 --> 1:22:58.900
 Like she's really fucking funny on the internet.

1:22:58.900 --> 1:23:00.220
 She's just great at social media.

1:23:00.220 --> 1:23:02.220
 It's just, you know.

1:23:02.220 --> 1:23:05.500
 Yeah, the nature of humor, like humor on social media

1:23:05.500 --> 1:23:08.940
 is also a beautiful thing, the absurdity.

1:23:08.940 --> 1:23:09.780
 The absurdity.

1:23:09.780 --> 1:23:12.700
 And memes, like I just wanna like take a moment.

1:23:12.700 --> 1:23:14.580
 I love, like when we're talking about art

1:23:14.580 --> 1:23:18.180
 and credit and authenticity, I love that there's this,

1:23:18.180 --> 1:23:21.840
 I mean now memes are like, they're no longer,

1:23:21.840 --> 1:23:23.640
 like memes aren't like new,

1:23:23.640 --> 1:23:25.580
 but it's still this emergent art form

1:23:25.580 --> 1:23:27.720
 that is completely egoless and anonymous

1:23:27.720 --> 1:23:29.480
 and we just don't know who made any of it.

1:23:29.480 --> 1:23:32.560
 And it's like the forefront of comedy

1:23:32.560 --> 1:23:35.420
 and it's just totally anonymous

1:23:35.420 --> 1:23:36.620
 and it just feels really beautiful.

1:23:36.620 --> 1:23:38.380
 It just feels like this beautiful

1:23:38.380 --> 1:23:43.260
 collective human art project

1:23:43.260 --> 1:23:46.420
 that's like this like decentralized comedy thing

1:23:46.420 --> 1:23:48.860
 that just makes memes add so much to my day

1:23:48.860 --> 1:23:49.860
 and many people's days.

1:23:49.860 --> 1:23:52.120
 And it's just like, I don't know.

1:23:52.120 --> 1:23:54.860
 I don't think people ever,

1:23:54.860 --> 1:23:56.020
 I don't think we stop enough

1:23:56.020 --> 1:23:59.860
 and just appreciate how sick it is that memes exist.

1:23:59.860 --> 1:24:02.420
 Because also making a whole brand new art form

1:24:02.420 --> 1:24:07.060
 in like the modern era that's like didn't exist before.

1:24:07.060 --> 1:24:08.520
 Like, I mean they sort of existed,

1:24:08.520 --> 1:24:11.860
 but the way that they exist now as like this like,

1:24:11.860 --> 1:24:13.240
 you know, like me and my friends,

1:24:13.240 --> 1:24:16.320
 like we joke that we go like mining for memes

1:24:16.320 --> 1:24:18.620
 or farming for memes, like a video game

1:24:18.620 --> 1:24:21.100
 and like meme dealers and like whatever.

1:24:21.100 --> 1:24:22.740
 Like it's, you know, it's this whole,

1:24:22.740 --> 1:24:27.740
 memes are this whole like new comedic language.

1:24:27.920 --> 1:24:29.260
 Well, it's this art form.

1:24:29.260 --> 1:24:31.260
 The interesting thing about it is that

1:24:31.260 --> 1:24:35.380
 lame people seem to not be good at memes.

1:24:35.380 --> 1:24:38.180
 Like corporate can't infiltrate memes.

1:24:38.180 --> 1:24:39.860
 Yeah, they really can't.

1:24:39.860 --> 1:24:41.460
 They try, they could try.

1:24:41.460 --> 1:24:43.340
 But it's like, it's weird cause like.

1:24:43.340 --> 1:24:45.560
 They try so hard and every once in a while,

1:24:45.560 --> 1:24:48.660
 I'm like fine, like you got a good one.

1:24:48.660 --> 1:24:51.420
 I think I've seen like one or two good ones,

1:24:51.420 --> 1:24:53.340
 but like, yeah, they really can't.

1:24:53.340 --> 1:24:55.500
 Cause they're even, corporate is infiltrating web three.

1:24:55.500 --> 1:24:57.140
 It's making me really sad,

1:24:57.140 --> 1:24:58.660
 but they can't infiltrate the memes.

1:24:58.660 --> 1:25:00.100
 And I think there's something really beautiful about that.

1:25:00.100 --> 1:25:03.580
 That gives power, that's why Dogecoin is powerful.

1:25:03.580 --> 1:25:05.880
 It's like, all right, I'm gonna F you

1:25:05.880 --> 1:25:08.820
 to sort of anybody who's trying to centralize,

1:25:08.820 --> 1:25:10.420
 is trying to control the rich people

1:25:10.420 --> 1:25:12.720
 that are trying to roll in and control this,

1:25:12.720 --> 1:25:14.220
 control the narrative.

1:25:14.220 --> 1:25:16.220
 Wow, I hadn't thought about that, but.

1:25:17.220 --> 1:25:18.520
 How would you fix Twitter?

1:25:18.520 --> 1:25:20.840
 How would you fix social media for your own?

1:25:21.680 --> 1:25:25.220
 Like you're an optimist, you're a positive person.

1:25:25.220 --> 1:25:27.500
 There's a bit of a cynicism that you have currently

1:25:27.500 --> 1:25:30.700
 about this particular little slice of humanity.

1:25:30.700 --> 1:25:32.700
 I tend to think Twitter could be beautiful.

1:25:32.700 --> 1:25:34.060
 I'm not that cynical about it.

1:25:34.060 --> 1:25:35.140
 I'm not that cynical about it.

1:25:35.140 --> 1:25:37.700
 I actually refuse to be a cynic on principle.

1:25:37.700 --> 1:25:38.540
 Yes.

1:25:38.540 --> 1:25:41.140
 I was just briefly expressing some personal pathos.

1:25:41.140 --> 1:25:42.140
 Personal stuff.

1:25:42.140 --> 1:25:45.900
 It was just some personal pathos, but like, like.

1:25:45.900 --> 1:25:48.060
 Just to vent a little bit, just to speak.

1:25:48.060 --> 1:25:50.860
 I don't have cancer, I love my family.

1:25:50.860 --> 1:25:51.980
 I have a good life.

1:25:51.980 --> 1:25:55.380
 That is, if that is my biggest,

1:25:55.380 --> 1:25:56.220
 one of my biggest problems.

1:25:56.220 --> 1:25:57.180
 Then it's a good life.

1:25:57.180 --> 1:25:59.860
 Yeah, you know, that was a brief,

1:25:59.860 --> 1:26:01.380
 although I do think there are a lot of issues with Twitter

1:26:01.380 --> 1:26:03.180
 just in terms of like the public mental health,

1:26:03.180 --> 1:26:07.700
 but due to my proximity to the current dramas,

1:26:10.500 --> 1:26:13.820
 I honestly feel that I should not have opinions about this

1:26:13.820 --> 1:26:17.820
 because I think

1:26:17.820 --> 1:26:22.820
 that if Elon ends up getting Twitter,

1:26:28.380 --> 1:26:33.180
 that is a, being the arbiter of truth or public discussion,

1:26:33.180 --> 1:26:34.660
 that is a responsibility.

1:26:36.260 --> 1:26:41.260
 I do not, I am not qualified to be responsible for that.

1:26:41.260 --> 1:26:45.260
 And I do not want to say something

1:26:45.260 --> 1:26:48.340
 that might like dismantle democracy.

1:26:48.340 --> 1:26:49.780
 And so I just like, actually,

1:26:49.780 --> 1:26:52.140
 I actually think I should not have opinions about this

1:26:52.140 --> 1:26:54.260
 because I truly am not,

1:26:55.100 --> 1:26:56.740
 I don't want to have the wrong opinion about this.

1:26:56.740 --> 1:27:00.180
 And I think I'm too close to the actual situation

1:27:00.180 --> 1:27:04.300
 wherein I should not have, I have thoughts in my brain,

1:27:04.300 --> 1:27:09.300
 but I think I am scared by my proximity to this situation.

1:27:09.620 --> 1:27:14.620
 Isn't that crazy that a few words that you could say

1:27:14.620 --> 1:27:18.780
 could change world affairs and hurt people?

1:27:18.780 --> 1:27:21.780
 I mean, that's the nature of celebrity at a certain point

1:27:22.980 --> 1:27:27.140
 that you have to be, you have to a little bit, a little bit,

1:27:27.140 --> 1:27:30.540
 not so much that it destroys you or puts too much constraints,

1:27:30.540 --> 1:27:32.620
 but you have to a little bit think about

1:27:32.620 --> 1:27:33.940
 the impact of your words.

1:27:33.940 --> 1:27:36.660
 I mean, we as humans, you talk to somebody at a bar,

1:27:36.660 --> 1:27:39.100
 you have to think about the impact of your words.

1:27:39.100 --> 1:27:40.340
 Like you can say positive things,

1:27:40.340 --> 1:27:41.500
 you can say negative things,

1:27:41.500 --> 1:27:43.340
 you can affect the direction of one life.

1:27:43.340 --> 1:27:45.260
 But on social media, your words can affect

1:27:45.260 --> 1:27:48.060
 the direction of many lives.

1:27:48.060 --> 1:27:48.900
 That's crazy.

1:27:48.900 --> 1:27:50.420
 It's a crazy world to live in.

1:27:50.420 --> 1:27:52.980
 It's worthwhile to consider that responsibility,

1:27:52.980 --> 1:27:54.100
 take it seriously.

1:27:54.100 --> 1:27:59.100
 Sometimes just like you did choose kind of silence,

1:28:00.740 --> 1:28:03.580
 choose sort of respectful.

1:28:03.580 --> 1:28:05.260
 Like I do have a lot of thoughts on the matter.

1:28:05.260 --> 1:28:10.100
 I'm just, I don't, if my thoughts are wrong,

1:28:10.100 --> 1:28:12.820
 this is one situation where the stakes are high.

1:28:12.820 --> 1:28:15.740
 You mentioned a while back that you were in a cult

1:28:15.740 --> 1:28:17.260
 that's centered around bureaucracy,

1:28:17.260 --> 1:28:18.460
 so you can't really do anything

1:28:18.460 --> 1:28:20.460
 because it involves a lot of paperwork.

1:28:20.460 --> 1:28:24.700
 And I really love a cult that's just like Kafkaesque.

1:28:24.700 --> 1:28:25.740
 Yes.

1:28:25.740 --> 1:28:26.580
 Just like.

1:28:26.580 --> 1:28:27.660
 I mean, it was like a joke, but it was.

1:28:27.660 --> 1:28:29.300
 I know, but I love this idea.

1:28:29.300 --> 1:28:30.420
 The Holy Rain Empire.

1:28:30.420 --> 1:28:34.860
 Yeah, it was just like a Kafkaesque pro bureaucracy cult.

1:28:34.860 --> 1:28:36.820
 But I feel like that's what human civilization is,

1:28:36.820 --> 1:28:38.500
 is that, because when you said that, I was like,

1:28:38.500 --> 1:28:40.620
 oh, that is kind of what humanity is,

1:28:40.620 --> 1:28:41.660
 is this bureaucracy cult.

1:28:41.660 --> 1:28:45.620
 I do, yeah, I have this theory.

1:28:45.620 --> 1:28:49.700
 I really think that we really,

1:28:50.700 --> 1:28:53.580
 bureaucracy is starting to kill us.

1:28:53.580 --> 1:28:58.580
 And I think like we need to reorient laws and stuff.

1:28:59.540 --> 1:29:01.940
 Like, I think we just need sunset clauses on everything.

1:29:01.940 --> 1:29:04.580
 Like, I think the rate of change in culture

1:29:04.580 --> 1:29:06.660
 is happening so fast and the rate of change in technology

1:29:06.660 --> 1:29:07.900
 and everything is happening so fast.

1:29:07.900 --> 1:29:10.780
 It's like, when you see these hearings

1:29:10.780 --> 1:29:15.780
 about like social media and Cambridge Analytica

1:29:15.820 --> 1:29:19.180
 and everyone talking, it's like, even from that point,

1:29:19.180 --> 1:29:21.380
 so much technological change has happened

1:29:21.380 --> 1:29:22.740
 from like those hearings.

1:29:22.740 --> 1:29:24.860
 And it's just like, we're trying to make all these laws now

1:29:24.860 --> 1:29:25.940
 about AI and stuff.

1:29:25.940 --> 1:29:27.380
 I feel like we should be updating things

1:29:27.380 --> 1:29:28.380
 like every five years.

1:29:28.380 --> 1:29:30.140
 And like one of the big issues in our society right now

1:29:30.140 --> 1:29:32.260
 is we're just getting bogged down by laws

1:29:32.260 --> 1:29:37.020
 and it's making it very hard to change things

1:29:37.020 --> 1:29:37.860
 and develop things.

1:29:37.860 --> 1:29:41.500
 In Austin, I don't wanna speak on this too much,

1:29:41.500 --> 1:29:43.220
 but like one of my friends is working on a housing bill

1:29:43.220 --> 1:29:45.020
 in Austin to try to like prevent

1:29:45.020 --> 1:29:47.180
 like a San Francisco situation from happening here

1:29:47.180 --> 1:29:49.940
 because obviously we're getting a little mini San Francisco

1:29:49.940 --> 1:29:52.140
 here, like housing prices are skyrocketing,

1:29:52.140 --> 1:29:54.740
 it's causing massive gentrification.

1:29:54.740 --> 1:29:59.180
 This is really bad for anyone who's not super rich.

1:29:59.180 --> 1:30:00.860
 Like, there's so much bureaucracy.

1:30:00.860 --> 1:30:01.900
 Part of the reason this is happening

1:30:01.900 --> 1:30:04.020
 is because you need all these permits to build.

1:30:04.020 --> 1:30:06.460
 It takes like years to get permits to like build anything.

1:30:06.460 --> 1:30:09.100
 It's so hard to build and so there's very limited housing

1:30:09.100 --> 1:30:10.900
 and there's a massive influx of people.

1:30:10.900 --> 1:30:13.460
 And it's just like, you know, this is a microcosm

1:30:13.460 --> 1:30:15.540
 of like problems that are happening all over the world

1:30:15.540 --> 1:30:18.780
 where it's just like, we're dealing with laws

1:30:18.780 --> 1:30:22.340
 that are like 10, 20, 30, 40, 100, 200 years old

1:30:22.340 --> 1:30:24.100
 and they are no longer relevant

1:30:24.100 --> 1:30:25.660
 and it's just slowing everything down

1:30:25.660 --> 1:30:27.980
 and causing massive social pain.

1:30:29.100 --> 1:30:32.820
 Yeah, but it's like, it's also makes me sad

1:30:32.820 --> 1:30:35.740
 when I see politicians talk about technology

1:30:35.740 --> 1:30:38.420
 and when they don't really get it.

1:30:38.420 --> 1:30:41.140
 But most importantly, they lack curiosity

1:30:41.140 --> 1:30:44.780
 and like that like inspired excitement

1:30:44.780 --> 1:30:46.580
 about like how stuff works and all that stuff.

1:30:46.580 --> 1:30:47.780
 They're just like, they see,

1:30:47.780 --> 1:30:50.140
 they have a very cynical view of technology.

1:30:50.140 --> 1:30:52.180
 It's like tech companies are just trying to do evil

1:30:52.180 --> 1:30:53.540
 on the world from their perspective

1:30:53.540 --> 1:30:55.860
 and they have no curiosity about like

1:30:55.860 --> 1:30:59.820
 how recommender systems work or how AI systems work,

1:30:59.820 --> 1:31:02.700
 natural language processing, how robotics works,

1:31:02.700 --> 1:31:05.860
 how computer vision works, you know.

1:31:05.860 --> 1:31:08.660
 They always take the most cynical possible interpretation

1:31:08.660 --> 1:31:09.860
 of what technology would be used

1:31:09.860 --> 1:31:11.660
 and we should definitely be concerned about that

1:31:11.660 --> 1:31:13.780
 but if you're constantly worried about that

1:31:13.780 --> 1:31:15.020
 and you're regulating based on that,

1:31:15.020 --> 1:31:16.980
 you're just going to slow down all the innovation.

1:31:16.980 --> 1:31:19.420
 I do think a huge priority right now

1:31:19.420 --> 1:31:24.420
 is undoing the bad energy

1:31:25.740 --> 1:31:28.060
 surrounding the emergence of Silicon Valley.

1:31:28.060 --> 1:31:30.020
 Like I think that like a lot of things

1:31:30.020 --> 1:31:31.820
 were very irresponsible during that time

1:31:31.820 --> 1:31:36.140
 and you know, like even just this current whole thing

1:31:36.140 --> 1:31:36.980
 with Twitter and everything,

1:31:36.980 --> 1:31:39.980
 it's like there has been a lot of negative outcomes

1:31:39.980 --> 1:31:44.260
 from the sort of technocracy boom

1:31:44.260 --> 1:31:46.060
 but one of the things that's happening

1:31:46.060 --> 1:31:49.100
 is that like it's alienating people

1:31:49.100 --> 1:31:52.340
 from wanting to care about technology

1:31:52.340 --> 1:31:56.020
 and I actually think technology is probably

1:31:56.020 --> 1:31:58.900
 some of the better, probably the best.

1:31:58.900 --> 1:32:01.620
 I think we can fix a lot of our problems

1:32:01.620 --> 1:32:03.220
 more easily with technology

1:32:03.220 --> 1:32:07.100
 than with you know, fighting the powers that be

1:32:07.100 --> 1:32:09.700
 as a you know, not to go back to the Star Wars quote

1:32:09.700 --> 1:32:11.300
 or the Buckminster Fuller quote.

1:32:11.300 --> 1:32:12.940
 Let's go to some dark questions.

1:32:14.700 --> 1:32:17.860
 If we may for time, what is the darkest place

1:32:17.860 --> 1:32:20.220
 you've ever gone in your mind?

1:32:20.220 --> 1:32:23.860
 Is there a time, a period of time, a moment

1:32:23.860 --> 1:32:28.860
 that you remember that was difficult for you?

1:32:29.580 --> 1:32:30.460
 I mean, when I was 18,

1:32:30.460 --> 1:32:32.460
 my best friend died of a heroin overdose

1:32:33.460 --> 1:32:35.980
 and it was like my,

1:32:38.300 --> 1:32:39.780
 and then shortly after that,

1:32:39.780 --> 1:32:41.980
 one of my other best friends committed suicide

1:32:44.700 --> 1:32:48.620
 and that sort of like coming into adulthood,

1:32:48.620 --> 1:32:51.140
 dealing with two of the most important people in my life

1:32:51.140 --> 1:32:53.140
 dying in extremely disturbing violent ways

1:32:53.140 --> 1:32:55.860
 was a lot.

1:32:55.860 --> 1:32:56.700
 That was a lot.

1:32:56.700 --> 1:32:57.540
 Do you miss them?

1:32:58.340 --> 1:32:59.860
 Yeah, definitely miss them.

1:32:59.860 --> 1:33:02.660
 Did that make you think about your own life?

1:33:02.660 --> 1:33:04.860
 About the finiteness of your own life?

1:33:04.860 --> 1:33:08.100
 The places your mind can go?

1:33:08.100 --> 1:33:10.860
 Did you ever in the distance, far away

1:33:10.860 --> 1:33:15.380
 contemplate just your own death?

1:33:15.380 --> 1:33:17.220
 Or maybe even taking your own life?

1:33:17.220 --> 1:33:18.660
 Oh never, oh no.

1:33:18.660 --> 1:33:20.380
 I'm so, I love my life.

1:33:20.380 --> 1:33:23.060
 I cannot fathom suicide.

1:33:23.060 --> 1:33:24.100
 I'm so scared of death.

1:33:24.100 --> 1:33:25.980
 I haven't, I'm too scared of death.

1:33:25.980 --> 1:33:28.740
 My manager, my manager's like the most Zen guy.

1:33:28.740 --> 1:33:31.060
 My manager's always like, you need to accept death.

1:33:31.060 --> 1:33:32.060
 You need to accept death.

1:33:32.060 --> 1:33:34.180
 And I'm like, look, I can do your meditation.

1:33:34.180 --> 1:33:37.300
 I can do the meditation, but I cannot accept death.

1:33:37.300 --> 1:33:40.340
 I like, I will fight, I'm terrified of death.

1:33:40.340 --> 1:33:42.740
 I will like fight.

1:33:42.740 --> 1:33:45.060
 Although I actually think death is important.

1:33:45.060 --> 1:33:49.060
 I recently went to this meeting about immortality

1:33:50.020 --> 1:33:51.500
 and in the process of.

1:33:51.500 --> 1:33:53.300
 That's the actual topic of the meeting?

1:33:53.300 --> 1:33:54.140
 I'm sorry.

1:33:54.140 --> 1:33:54.980
 No, no, it was this girl.

1:33:54.980 --> 1:33:58.940
 It was a bunch of people working on like anti aging stuff.

1:33:58.940 --> 1:34:01.980
 It was like some like seminary thing about it.

1:34:01.980 --> 1:34:03.300
 And I went in really excited.

1:34:03.300 --> 1:34:05.180
 I was like, yeah, like, okay, like, what do you got?

1:34:05.180 --> 1:34:07.860
 Like, how can I live for 500 years or a thousand years?

1:34:07.860 --> 1:34:10.620
 And then like over the course of the meeting,

1:34:10.620 --> 1:34:11.940
 like it was sort of like, right.

1:34:11.940 --> 1:34:13.140
 It was like two or three days

1:34:13.140 --> 1:34:14.580
 after the Russian invasion started.

1:34:14.580 --> 1:34:17.300
 And I was like, man, like, what if Putin was immortal?

1:34:17.300 --> 1:34:20.900
 Like, what if I'm like, man, maybe immortality,

1:34:20.900 --> 1:34:23.620
 is not good.

1:34:23.620 --> 1:34:25.740
 I mean, like if you get into the later Dune stuff,

1:34:25.740 --> 1:34:29.020
 the immortals cause a lot of problem.

1:34:29.020 --> 1:34:30.980
 Cause as we were talking about earlier with the music

1:34:30.980 --> 1:34:34.740
 and like brains calcify, like good people

1:34:34.740 --> 1:34:36.900
 could become immortal, but bad people could become immortal.

1:34:36.900 --> 1:34:41.900
 But I also think even the best people power corrupts

1:34:43.340 --> 1:34:46.740
 and power alienates you from like the common human experience

1:34:46.740 --> 1:34:47.580
 and.

1:34:47.580 --> 1:34:49.100
 Right, so the people that get more and more powerful.

1:34:49.100 --> 1:34:52.220
 Even the best people who like, whose brains are amazing,

1:34:52.220 --> 1:34:54.780
 like I think death might be important.

1:34:54.780 --> 1:34:57.380
 I think death is part of, you know,

1:34:57.380 --> 1:35:01.020
 like I think with AI one thing we might want to consider,

1:35:01.020 --> 1:35:02.420
 I don't know, when I talk about AI,

1:35:02.420 --> 1:35:04.540
 I'm such not an expert and probably everyone has

1:35:04.540 --> 1:35:06.220
 all these ideas and they're already figured out.

1:35:06.220 --> 1:35:07.060
 But when I was talking.

1:35:07.060 --> 1:35:08.540
 Nobody is an expert in anything.

1:35:08.540 --> 1:35:09.900
 See, okay, go ahead.

1:35:09.900 --> 1:35:10.740
 But when I.

1:35:10.740 --> 1:35:11.580
 You were talking about.

1:35:11.580 --> 1:35:13.180
 Yeah, but I like, it's just like,

1:35:13.180 --> 1:35:16.100
 I think some kind of pruning.

1:35:16.100 --> 1:35:20.140
 But it's a tricky thing because if there's too much

1:35:20.140 --> 1:35:25.140
 of a focus on youth culture, then you don't have the wisdom.

1:35:25.460 --> 1:35:27.740
 So I feel like we're in a tricky,

1:35:27.740 --> 1:35:30.300
 we're in a tricky moment right now in society

1:35:30.300 --> 1:35:32.460
 where it's like, we've really perfected living

1:35:32.460 --> 1:35:33.300
 for a long time.

1:35:33.300 --> 1:35:35.780
 So there's all these really like old people

1:35:35.780 --> 1:35:39.540
 who are like really voting against the wellbeing

1:35:39.540 --> 1:35:41.540
 of the young people, you know?

1:35:41.540 --> 1:35:45.180
 And like, it's like there shouldn't be all this student dead

1:35:45.180 --> 1:35:48.540
 and we need like healthcare, like universal healthcare

1:35:48.540 --> 1:35:52.460
 and like just voting against like best interests.

1:35:52.460 --> 1:35:53.660
 But then you have all these young people

1:35:53.660 --> 1:35:55.980
 that don't have the wisdom that are like,

1:35:55.980 --> 1:35:57.620
 yeah, we need communism and stuff.

1:35:57.620 --> 1:36:00.740
 And it's just like, like literally I got canceled

1:36:00.740 --> 1:36:04.980
 at one point for, I ironically used a Stalin quote

1:36:04.980 --> 1:36:08.420
 in my high school yearbook, but it was actually like a diss

1:36:08.420 --> 1:36:09.620
 against my high school.

1:36:09.620 --> 1:36:10.460
 I saw that.

1:36:10.460 --> 1:36:13.180
 Yeah, and people were like, you used to be a Stalinist

1:36:13.180 --> 1:36:15.860
 and now you're a class traitor and it's like,

1:36:15.860 --> 1:36:19.260
 it's like, oh man, just like, please Google Stalin.

1:36:19.260 --> 1:36:20.500
 Please Google Stalin.

1:36:20.500 --> 1:36:21.340
 Like, you know.

1:36:21.340 --> 1:36:23.980
 Ignoring the lessons of history, yes.

1:36:23.980 --> 1:36:26.100
 And it's like, we're in this really weird middle ground

1:36:26.100 --> 1:36:31.100
 where it's like, we are not finding the happy medium

1:36:31.220 --> 1:36:34.700
 between wisdom and fresh ideas

1:36:34.700 --> 1:36:35.900
 and they're fighting each other.

1:36:35.900 --> 1:36:40.900
 And it's like, like really, like what we need is like

1:36:40.900 --> 1:36:43.860
 the fresh ideas and the wisdom to be like collaborating.

1:36:43.860 --> 1:36:45.140
 And it's like.

1:36:45.140 --> 1:36:47.300
 What the fighting in a way is the searching

1:36:47.300 --> 1:36:48.500
 for the happy medium.

1:36:48.500 --> 1:36:51.020
 And in a way, maybe we are finding the happy medium.

1:36:51.020 --> 1:36:52.940
 Maybe that's what the happy medium looks like.

1:36:52.940 --> 1:36:54.980
 And for AI systems, there has to be,

1:36:54.980 --> 1:36:57.140
 it's, you know, you have the reinforcement learning,

1:36:57.140 --> 1:37:00.340
 you have the dance between exploration and exploitation,

1:37:00.340 --> 1:37:03.380
 sort of doing crazy stuff to see if there's something better

1:37:03.380 --> 1:37:05.420
 than what you think is the optimal

1:37:05.420 --> 1:37:06.620
 and then doing the optimal thing

1:37:06.620 --> 1:37:08.620
 and dancing back and forth from that.

1:37:08.620 --> 1:37:10.660
 You would, Stuart Russell, I don't know if you know that,

1:37:10.660 --> 1:37:15.660
 is AI guy with, thinks about sort of

1:37:15.820 --> 1:37:18.580
 how to control super intelligent AI systems.

1:37:18.580 --> 1:37:21.500
 And his idea is that we should inject uncertainty

1:37:21.500 --> 1:37:24.980
 and sort of humility into AI systems that they never,

1:37:24.980 --> 1:37:28.100
 as they get wiser and wiser and wiser and more intelligent,

1:37:28.100 --> 1:37:30.020
 they're never really sure.

1:37:30.020 --> 1:37:31.620
 They always doubt themselves.

1:37:31.620 --> 1:37:34.340
 And in some sense, when you think of young people,

1:37:34.340 --> 1:37:36.300
 that's a mechanism for doubt.

1:37:36.300 --> 1:37:38.860
 It's like, it's how society doubts

1:37:38.860 --> 1:37:40.860
 whether the thing it has converged towards

1:37:40.860 --> 1:37:41.940
 is the right answer.

1:37:41.940 --> 1:37:44.860
 So the voices of the young people

1:37:44.860 --> 1:37:48.140
 is a society asking itself a question.

1:37:48.140 --> 1:37:51.100
 The way I've been doing stuff for the past 50 years,

1:37:51.100 --> 1:37:52.460
 maybe it's the wrong way.

1:37:52.460 --> 1:37:55.340
 And so you can have all of that within one AI system.

1:37:55.340 --> 1:37:57.460
 I also think, though, that we need to,

1:37:57.460 --> 1:37:59.900
 I mean, actually, that's actually really interesting

1:37:59.900 --> 1:38:00.740
 and really cool.

1:38:01.820 --> 1:38:04.500
 But I also think there's a fine balance of,

1:38:04.500 --> 1:38:09.500
 I think we maybe also overvalue the idea

1:38:09.500 --> 1:38:11.180
 that the old systems are always bad.

1:38:11.180 --> 1:38:14.140
 And I think there are things that we are perfecting

1:38:14.140 --> 1:38:16.780
 and we might be accidentally overthrowing things

1:38:16.780 --> 1:38:19.060
 that we actually have gotten to a good point.

1:38:19.060 --> 1:38:22.180
 Just because we value disruption so much

1:38:22.180 --> 1:38:24.780
 and we value fighting against the generations

1:38:24.780 --> 1:38:29.780
 before us so much that there's also an aspect of,

1:38:29.980 --> 1:38:32.100
 sometimes we're taking two steps forward, one step back

1:38:32.100 --> 1:38:36.300
 because, okay, maybe we kind of did solve this thing

1:38:36.300 --> 1:38:38.500
 and now we're like fucking it up, you know?

1:38:38.500 --> 1:38:43.500
 And so I think there's like a middle ground there too.

1:38:44.300 --> 1:38:46.700
 Yeah, we're in search of that happy medium.

1:38:46.700 --> 1:38:49.780
 Let me ask you a bunch of crazy questions, okay?

1:38:49.780 --> 1:38:50.900
 All right.

1:38:50.900 --> 1:38:53.340
 You can answer in a short way or in a long way.

1:38:53.340 --> 1:38:55.700
 What's the scariest thing you've ever done?

1:38:55.700 --> 1:38:57.780
 These questions are gonna be ridiculous.

1:38:57.780 --> 1:39:00.780
 Something tiny or something big.

1:39:00.780 --> 1:39:05.780
 Something big, skydiving or touring your first record,

1:39:09.860 --> 1:39:12.100
 going on this podcast.

1:39:12.100 --> 1:39:14.740
 I've had two crazy brushes, like really scary brushes

1:39:14.740 --> 1:39:16.980
 with death where I randomly got away on scay.

1:39:16.980 --> 1:39:19.180
 I don't know if I should talk about those on here.

1:39:19.180 --> 1:39:20.020
 Well, I don't know.

1:39:20.020 --> 1:39:22.820
 I think I might be the luckiest person alive though.

1:39:22.820 --> 1:39:25.980
 Like this might be too dark for a podcast though.

1:39:25.980 --> 1:39:27.820
 I feel like, I don't know if this is like good content

1:39:27.820 --> 1:39:28.700
 for a podcast.

1:39:28.700 --> 1:39:30.220
 I don't know what is good content.

1:39:30.220 --> 1:39:31.580
 It might hijack.

1:39:31.580 --> 1:39:32.420
 Here's a safer one.

1:39:32.420 --> 1:39:36.740
 I mean, having a baby really scared me.

1:39:36.740 --> 1:39:37.580
 Before.

1:39:37.580 --> 1:39:38.900
 Just the birth process.

1:39:38.900 --> 1:39:43.900
 Surgery, like just having a baby is really scary.

1:39:45.940 --> 1:39:47.540
 So just like the medical aspect of it,

1:39:47.540 --> 1:39:49.300
 not the responsibility.

1:39:49.300 --> 1:39:51.300
 Were you ready for the responsibility?

1:39:51.300 --> 1:39:53.980
 Did you, were you ready to be a mother?

1:39:53.980 --> 1:39:56.260
 All the beautiful things that comes with motherhood

1:39:56.260 --> 1:39:57.580
 that you were talking about.

1:39:57.580 --> 1:40:01.060
 All the changes and all that, were you ready for that?

1:40:01.060 --> 1:40:02.980
 Or did you feel ready for that?

1:40:02.980 --> 1:40:05.340
 No, I think it took about nine months

1:40:05.340 --> 1:40:06.580
 to start getting ready for it.

1:40:06.580 --> 1:40:08.380
 And I'm still getting more ready for it

1:40:08.380 --> 1:40:12.980
 because now you keep realizing more things

1:40:12.980 --> 1:40:14.220
 as they start getting.

1:40:14.220 --> 1:40:16.420
 As the consciousness grows.

1:40:16.420 --> 1:40:18.380
 And stuff you didn't notice with the first one,

1:40:18.380 --> 1:40:19.700
 now that you've seen the first one older,

1:40:19.700 --> 1:40:21.720
 you're noticing it more.

1:40:21.720 --> 1:40:24.420
 Like the sort of like existential horror

1:40:24.420 --> 1:40:28.340
 of coming into consciousness with Baby Y

1:40:28.340 --> 1:40:30.220
 or Baby Sailor Mars or whatever.

1:40:30.220 --> 1:40:31.500
 She has like so many names at this point

1:40:31.500 --> 1:40:36.140
 that it's, we really need to probably settle on one.

1:40:36.140 --> 1:40:38.340
 If you could be someone else for a day,

1:40:38.340 --> 1:40:41.820
 someone alive today, but somebody you haven't met yet,

1:40:41.820 --> 1:40:42.660
 who would you be?

1:40:42.660 --> 1:40:44.240
 Would I be modeling their brain state

1:40:44.240 --> 1:40:46.400
 or would I just be in their body?

1:40:46.400 --> 1:40:48.380
 You can choose the degree

1:40:48.380 --> 1:40:50.580
 to which you're modeling their brain state.

1:40:50.580 --> 1:40:54.300
 Cause you can still take a third person perspective

1:40:54.300 --> 1:40:56.620
 and realize, you have to realize that you're.

1:40:56.620 --> 1:40:58.660
 Can they be alive or can it be dead?

1:41:00.540 --> 1:41:01.380
 No, oh.

1:41:02.780 --> 1:41:04.420
 They would be brought back to life, right?

1:41:04.420 --> 1:41:05.260
 If they're dead.

1:41:05.260 --> 1:41:07.100
 Yeah, you can bring people back.

1:41:07.100 --> 1:41:09.260
 Definitely Hitler or Stalin.

1:41:09.260 --> 1:41:10.820
 I wanna understand evil.

1:41:12.060 --> 1:41:15.020
 You would need to, oh, to experience what it feels like.

1:41:15.020 --> 1:41:18.220
 I wanna be in their brain feeling what they feel.

1:41:18.220 --> 1:41:20.860
 I might change you forever returning from that.

1:41:20.860 --> 1:41:22.940
 Yes, but I think it would also help me understand

1:41:22.940 --> 1:41:25.380
 how to prevent it and fix it.

1:41:25.380 --> 1:41:26.580
 That might be one of those things,

1:41:26.580 --> 1:41:29.940
 once you experience it, it'll be a burden to know it.

1:41:29.940 --> 1:41:30.780
 Cause you won't be able to transfer that.

1:41:30.780 --> 1:41:33.820
 Yeah, but a lot of things are burdens.

1:41:33.820 --> 1:41:34.780
 But it's a useful burden.

1:41:34.780 --> 1:41:36.580
 But it's a useful burden, yeah.

1:41:36.580 --> 1:41:39.260
 That for sure, I wanna understand evil

1:41:39.260 --> 1:41:42.020
 and psychopathy and that.

1:41:42.020 --> 1:41:43.340
 I have all these fake Twitter accounts

1:41:43.340 --> 1:41:45.580
 where I go into different algorithmic bubbles

1:41:45.580 --> 1:41:47.380
 to try to understand.

1:41:47.380 --> 1:41:48.740
 I'll keep getting in fights with people

1:41:48.740 --> 1:41:50.660
 and realize we're not actually fighting.

1:41:50.660 --> 1:41:53.180
 I think we used to exist in a monoculture

1:41:53.180 --> 1:41:54.860
 before social media and stuff.

1:41:54.860 --> 1:41:56.460
 We kinda all got fed the same thing.

1:41:56.460 --> 1:41:58.700
 So we were all speaking the same cultural language.

1:41:58.700 --> 1:42:00.140
 But I think recently, one of the things

1:42:00.140 --> 1:42:03.100
 that we aren't diagnosing properly enough with social media

1:42:03.100 --> 1:42:05.500
 is that there's different dialects.

1:42:05.500 --> 1:42:06.900
 There's so many different dialects of Chinese.

1:42:06.900 --> 1:42:09.580
 There are now becoming different dialects of English.

1:42:09.580 --> 1:42:11.780
 I am realizing there are people

1:42:11.780 --> 1:42:13.540
 who are saying the exact same things,

1:42:13.540 --> 1:42:15.980
 but they're using completely different verbiage.

1:42:15.980 --> 1:42:17.340
 And we're punishing each other

1:42:17.340 --> 1:42:18.900
 for not using the correct verbiage.

1:42:18.900 --> 1:42:20.620
 And we're completely misunderstanding.

1:42:20.620 --> 1:42:22.020
 People are just misunderstanding

1:42:22.020 --> 1:42:23.580
 what the other people are saying.

1:42:23.580 --> 1:42:26.220
 And I just got in a fight with a friend

1:42:27.460 --> 1:42:32.460
 about anarchism and communism and shit for two hours.

1:42:33.020 --> 1:42:34.700
 And then by the end of a conversation,

1:42:34.700 --> 1:42:35.940
 and then she'd say something, and I'm like,

1:42:35.940 --> 1:42:37.620
 but that's literally what I'm saying.

1:42:37.620 --> 1:42:39.340
 And she was like, what?

1:42:39.340 --> 1:42:40.900
 And then I was like, fuck, we've different,

1:42:40.900 --> 1:42:44.820
 I'm like, our English, the way we are understanding

1:42:44.820 --> 1:42:49.820
 terminology is like drastically, like our algorithm bubbles

1:42:50.580 --> 1:42:53.380
 are creating mini dialects.

1:42:53.380 --> 1:42:55.900
 Of how language is interpreted, how language is used.

1:42:55.900 --> 1:42:56.860
 That's so fascinating.

1:42:56.860 --> 1:42:59.220
 And so we're like having these arguments

1:42:59.220 --> 1:43:00.980
 that we do not need to be having.

1:43:00.980 --> 1:43:02.380
 And there's polarization that's happening

1:43:02.380 --> 1:43:03.420
 that doesn't need to be happening

1:43:03.420 --> 1:43:06.460
 because we've got these like algorithmically created

1:43:08.620 --> 1:43:09.820
 dialects occurring.

1:43:09.820 --> 1:43:11.980
 Plus on top of that, there's also different parts

1:43:11.980 --> 1:43:13.460
 of the world that speak different languages.

1:43:13.460 --> 1:43:16.220
 So there's literally lost in translation

1:43:16.220 --> 1:43:17.820
 kind of communication.

1:43:17.820 --> 1:43:19.780
 I happen to know the Russian language

1:43:19.780 --> 1:43:22.420
 and just know how different it is.

1:43:22.420 --> 1:43:23.900
 Then the English language.

1:43:23.900 --> 1:43:27.660
 And I just wonder how much is lost in a little bit of.

1:43:27.660 --> 1:43:28.980
 Man, I actually, cause I have a question for you.

1:43:28.980 --> 1:43:30.260
 I have a song coming out tomorrow

1:43:30.260 --> 1:43:31.900
 with I Speak Who Are A Russian Band.

1:43:31.900 --> 1:43:33.700
 And I speak a little bit of Russian

1:43:33.700 --> 1:43:35.380
 and I was looking at the title

1:43:35.380 --> 1:43:37.300
 and the title in English doesn't match

1:43:37.300 --> 1:43:38.220
 the title in Russian.

1:43:38.220 --> 1:43:39.140
 I'm curious about this.

1:43:39.140 --> 1:43:42.940
 Cause look, it says the title in English is Last Day.

1:43:42.940 --> 1:43:45.580
 And then the title in Russian is New Day.

1:43:45.580 --> 1:43:47.540
 My pronunciation sucks.

1:43:47.540 --> 1:43:48.780
 New Day.

1:43:48.780 --> 1:43:49.620
 Like what?

1:43:49.620 --> 1:43:50.460
 Like a new day.

1:43:50.460 --> 1:43:51.300
 A new day.

1:43:51.300 --> 1:43:52.140
 Yeah, new day, new day.

1:43:52.140 --> 1:43:53.340
 Like it's two different meanings.

1:43:53.340 --> 1:43:54.820
 Yeah, new day, yeah.

1:43:57.220 --> 1:43:58.500
 Yeah, yeah, new day.

1:43:58.500 --> 1:43:59.700
 New day, but last day.

1:44:01.340 --> 1:44:02.260
 New day.

1:44:02.260 --> 1:44:04.220
 So last day would be the last day.

1:44:04.220 --> 1:44:05.060
 Yeah.

1:44:05.060 --> 1:44:05.900
 Maybe they.

1:44:05.900 --> 1:44:07.580
 Or maybe the title includes both the Russian

1:44:07.580 --> 1:44:09.060
 and it's for.

1:44:09.060 --> 1:44:09.900
 Maybe.

1:44:09.900 --> 1:44:10.740
 Maybe it's for bilingual.

1:44:10.740 --> 1:44:13.220
 But to be honest, Novodin sounds better than

1:44:13.220 --> 1:44:15.140
 just musically.

1:44:15.140 --> 1:44:17.780
 Like Novodin is new day.

1:44:17.780 --> 1:44:18.780
 That's the current one.

1:44:18.780 --> 1:44:22.140
 And Posledniy Den is the last day.

1:44:23.460 --> 1:44:25.420
 I think Novodin.

1:44:25.420 --> 1:44:26.660
 I don't like Novodin.

1:44:26.660 --> 1:44:28.860
 But the meaning is so different.

1:44:30.180 --> 1:44:31.660
 That's kind of awesome actually though.

1:44:31.660 --> 1:44:34.500
 There's an explicit sort of contrast like that.

1:44:35.820 --> 1:44:38.340
 If everyone on earth disappeared

1:44:38.340 --> 1:44:43.340
 and it was just you left, what would your day look like?

1:44:44.060 --> 1:44:45.220
 Like what would you do?

1:44:45.220 --> 1:44:46.780
 Everybody's dead.

1:44:46.780 --> 1:44:47.620
 As far as you.

1:44:47.620 --> 1:44:48.660
 Are there corpses there?

1:44:52.500 --> 1:44:53.340
 Well seriously, it's a big.

1:44:53.340 --> 1:44:54.780
 Let me think through this.

1:44:54.780 --> 1:44:56.940
 It's a big difference if there's just like birds singing

1:44:56.940 --> 1:44:58.940
 versus if there's like corpses littering the street.

1:44:58.940 --> 1:45:01.860
 Yeah, there's corpses everywhere, I'm sorry.

1:45:01.860 --> 1:45:05.060
 It's, and you don't actually know what happened

1:45:05.060 --> 1:45:07.540
 and you don't know why you survived.

1:45:07.540 --> 1:45:10.420
 And you don't even know if there's others out there.

1:45:10.420 --> 1:45:13.580
 But it seems clear that it's all gone.

1:45:13.580 --> 1:45:15.220
 What would you do?

1:45:15.220 --> 1:45:16.100
 What would I do?

1:45:17.300 --> 1:45:19.580
 Listen, I'm somebody who really enjoys the moment,

1:45:19.580 --> 1:45:20.420
 enjoys life.

1:45:20.420 --> 1:45:25.420
 I would just go on like enjoying the inanimate objects.

1:45:26.380 --> 1:45:30.580
 I would just look for food, basic survival.

1:45:30.580 --> 1:45:33.500
 But most of it is just, listen, when I just,

1:45:33.500 --> 1:45:36.860
 I take walks and I look outside and I'm just happy

1:45:36.860 --> 1:45:38.700
 that we get to exist on this planet,

1:45:39.660 --> 1:45:41.980
 to be able to breathe air.

1:45:41.980 --> 1:45:43.060
 It's just all beautiful.

1:45:43.060 --> 1:45:44.820
 It's full of colors, all of this kind of stuff.

1:45:44.820 --> 1:45:48.180
 Just, there's so many things about life,

1:45:48.180 --> 1:45:50.780
 your own life, conscious life that's fucking awesome.

1:45:50.780 --> 1:45:52.140
 So I would just enjoy that.

1:45:54.220 --> 1:45:56.860
 But also maybe after a few weeks,

1:45:56.860 --> 1:45:58.460
 the engineer would start coming out,

1:45:58.460 --> 1:46:01.580
 like wanna build some things.

1:46:01.580 --> 1:46:05.660
 Maybe there's always hope searching for another human.

1:46:05.660 --> 1:46:06.500
 Maybe.

1:46:06.500 --> 1:46:09.340
 Probably searching for another human.

1:46:09.340 --> 1:46:13.100
 Probably trying to get to a TV or radio station

1:46:13.100 --> 1:46:16.700
 and broadcast something.

1:46:18.340 --> 1:46:19.860
 That's interesting, I didn't think about that.

1:46:19.860 --> 1:46:23.460
 So like really maximize your ability

1:46:23.460 --> 1:46:24.500
 to connect with others.

1:46:24.500 --> 1:46:29.220
 Yeah, like probably try to find another person.

1:46:29.220 --> 1:46:31.500
 Would you be excited to see,

1:46:31.500 --> 1:46:33.380
 to meet another person or terrified?

1:46:33.380 --> 1:46:34.900
 Because, you know.

1:46:34.900 --> 1:46:35.740
 I'd be excited.

1:46:35.740 --> 1:46:36.580
 No matter what.

1:46:36.580 --> 1:46:38.220
 Yeah, yeah, yeah, yeah.

1:46:38.220 --> 1:46:42.180
 Being alone for the last however long of my life

1:46:42.180 --> 1:46:43.580
 would be really bad.

1:46:43.580 --> 1:46:46.100
 That's the one instance I might,

1:46:46.100 --> 1:46:47.220
 I don't think I'd kill myself,

1:46:47.220 --> 1:46:48.740
 but I might kill myself if I had to.

1:46:48.740 --> 1:46:50.140
 So you love people.

1:46:50.140 --> 1:46:51.900
 You love connection to other humans.

1:46:51.900 --> 1:46:52.740
 Yeah.

1:46:52.740 --> 1:46:54.500
 I kinda hate people too, but yeah.

1:46:54.500 --> 1:46:56.420
 That's a love hate relationship.

1:46:56.420 --> 1:46:57.260
 Yeah.

1:46:57.260 --> 1:46:58.380
 I feel like we'd have a bunch of weird

1:46:58.380 --> 1:47:00.540
 Nietzsche questions and stuff though.

1:47:00.540 --> 1:47:01.380
 Oh yeah.

1:47:01.380 --> 1:47:02.980
 Like I wonder, cause I'm like, when podcast,

1:47:02.980 --> 1:47:04.340
 I'm like, is this interesting for people

1:47:04.340 --> 1:47:06.500
 to just have like, or I don't know,

1:47:06.500 --> 1:47:08.380
 maybe people do like this.

1:47:08.380 --> 1:47:10.460
 When I listen to podcasts, I'm into like the lore,

1:47:10.460 --> 1:47:11.900
 like the hard lore.

1:47:11.900 --> 1:47:13.380
 Like I just love like Dan Carlin.

1:47:13.380 --> 1:47:14.500
 I'm like, give me the facts.

1:47:14.500 --> 1:47:18.740
 Just like, like the facts into my bloodstream.

1:47:18.740 --> 1:47:20.700
 But you also don't know,

1:47:20.700 --> 1:47:23.300
 like you're a fascinating mind to explore.

1:47:23.300 --> 1:47:26.340
 So you don't realize as you're talking about stuff,

1:47:26.340 --> 1:47:28.420
 the stuff you've taken for granted

1:47:28.420 --> 1:47:30.420
 is actually unique and fascinating.

1:47:30.420 --> 1:47:32.060
 The way you think.

1:47:32.060 --> 1:47:35.780
 Not always what, like the way you reason through things

1:47:35.780 --> 1:47:39.420
 is the fascinating thing to listen to.

1:47:39.420 --> 1:47:41.060
 Because people kind of see, oh,

1:47:41.060 --> 1:47:43.420
 there's other humans that think differently,

1:47:43.420 --> 1:47:45.380
 that explore thoughts differently.

1:47:45.380 --> 1:47:47.540
 That's the cool, that's also cool.

1:47:47.540 --> 1:47:50.180
 So yeah, Dan Carlin retelling of history.

1:47:50.180 --> 1:47:54.820
 By the way, his retelling of history is very,

1:47:54.820 --> 1:47:57.060
 I think what's exciting is not the history,

1:47:57.060 --> 1:48:00.340
 is his way of thinking about history.

1:48:00.340 --> 1:48:02.700
 No, I think Dan Carlin is one of the people,

1:48:02.700 --> 1:48:04.380
 like when, Dan Carlin is one of the people

1:48:04.380 --> 1:48:06.140
 that really started getting me excited

1:48:06.140 --> 1:48:08.900
 about like revolutionizing education.

1:48:08.900 --> 1:48:12.700
 Because like Dan Carlin instilled,

1:48:12.700 --> 1:48:14.380
 I already like really liked history,

1:48:14.380 --> 1:48:18.940
 but he instilled like an obsessive love of history in me

1:48:18.940 --> 1:48:21.260
 to the point where like now I'm fucking reading,

1:48:21.260 --> 1:48:24.940
 like going to bed, reading like part four

1:48:24.940 --> 1:48:26.740
 of The Rise and Fall of the Third Reich or whatever.

1:48:26.740 --> 1:48:28.740
 Like I got like dense ass history,

1:48:28.740 --> 1:48:31.300
 but like he like opened that door

1:48:31.300 --> 1:48:34.300
 that like made me want to be a scholar of that topic.

1:48:34.300 --> 1:48:37.740
 Like it's like, I feel like he's such a good teacher.

1:48:37.740 --> 1:48:41.300
 He just like, you know, and it sort of made me feel like

1:48:42.260 --> 1:48:44.060
 one of the things we could do with education

1:48:44.060 --> 1:48:46.540
 is like find like the world's great,

1:48:46.540 --> 1:48:49.780
 the teachers that like create passion for the topic

1:48:49.780 --> 1:48:53.580
 because autodidactricism,

1:48:53.580 --> 1:48:55.140
 I don't know how to say that properly,

1:48:55.140 --> 1:48:57.900
 but like self teaching is like much faster

1:48:57.900 --> 1:48:59.460
 than being lectured to.

1:48:59.460 --> 1:49:00.660
 Like it's much more efficient

1:49:00.660 --> 1:49:02.300
 to sort of like be able to teach yourself

1:49:02.300 --> 1:49:03.700
 and then ask a teacher questions

1:49:03.700 --> 1:49:04.860
 when you don't know what's up.

1:49:04.860 --> 1:49:07.380
 But like, you know, that's why it's like

1:49:07.380 --> 1:49:08.380
 in university and stuff,

1:49:08.380 --> 1:49:11.060
 like you can learn so much more material so much faster

1:49:11.060 --> 1:49:13.340
 because you're doing a lot of the learning on your own

1:49:13.340 --> 1:49:15.620
 and you're going to the teachers for when you get stuck.

1:49:15.620 --> 1:49:18.980
 But like these teachers that can inspire passion

1:49:18.980 --> 1:49:21.660
 for a topic, I think that is one of the most invaluable

1:49:21.660 --> 1:49:23.180
 skills in our whole species.

1:49:23.180 --> 1:49:26.460
 Like, because if you can do that, then you,

1:49:26.460 --> 1:49:30.420
 it's like AI, like AI is going to teach itself

1:49:30.420 --> 1:49:31.820
 so much more efficiently than we can teach it.

1:49:31.820 --> 1:49:32.900
 We just needed to get it to the point

1:49:32.900 --> 1:49:34.340
 where it can teach itself.

1:49:34.340 --> 1:49:35.180
 And then.

1:49:35.180 --> 1:49:37.500
 It finds the motivation to do so, right?

1:49:37.500 --> 1:49:38.340
 Yeah.

1:49:38.340 --> 1:49:39.580
 So like you inspire it to do so.

1:49:39.580 --> 1:49:40.420
 Yeah.

1:49:40.420 --> 1:49:42.660
 And then it could teach itself.

1:49:42.660 --> 1:49:44.540
 What do you make of the fact,

1:49:44.540 --> 1:49:46.340
 you mentioned Rise and Fall of the Third Reich.

1:49:46.340 --> 1:49:47.180
 I just.

1:49:47.180 --> 1:49:48.000
 Have you read that?

1:49:48.000 --> 1:49:48.840
 Yeah, I read it twice.

1:49:48.840 --> 1:49:49.680
 You read it twice?

1:49:49.680 --> 1:49:50.500
 Yes.

1:49:50.500 --> 1:49:51.620
 Okay, so no one even knows what it is.

1:49:51.620 --> 1:49:52.460
 Yeah.

1:49:52.460 --> 1:49:53.300
 And I'm like, wait, I thought this was like

1:49:53.300 --> 1:49:54.820
 a super poppin book.

1:49:54.820 --> 1:49:55.660
 Super pop.

1:49:55.660 --> 1:49:58.460
 Yeah, I'm not like that, I'm not that far in it.

1:49:58.460 --> 1:50:00.260
 But it is, it's so interesting.

1:50:00.260 --> 1:50:03.500
 Yeah, it's written by a person that was there,

1:50:03.500 --> 1:50:05.860
 which is very important to kind of.

1:50:05.860 --> 1:50:06.980
 You know, you start being like,

1:50:06.980 --> 1:50:08.420
 how could this possibly happen?

1:50:08.420 --> 1:50:10.020
 And then when you read Rise and Fall of the Third Reich,

1:50:10.020 --> 1:50:14.020
 it's like, people tried really hard for this to not happen.

1:50:14.020 --> 1:50:15.940
 People tried, they almost reinstated a monarchy

1:50:15.940 --> 1:50:17.940
 at one point to try to stop this from happening.

1:50:17.940 --> 1:50:21.060
 Like they almost like abandoned democracy

1:50:21.060 --> 1:50:22.700
 to try to get this to not happen.

1:50:22.700 --> 1:50:24.780
 At least the way it makes me feel

1:50:24.780 --> 1:50:28.180
 is that there's a bunch of small moments

1:50:28.180 --> 1:50:30.100
 on which history can turn.

1:50:30.100 --> 1:50:30.940
 Yes.

1:50:30.940 --> 1:50:32.260
 It's like small meetings.

1:50:32.260 --> 1:50:33.100
 Yes.

1:50:33.100 --> 1:50:34.220
 Human interactions.

1:50:34.220 --> 1:50:36.900
 And it's both terrifying and inspiring

1:50:36.900 --> 1:50:41.900
 because it's like, even just attempts

1:50:41.940 --> 1:50:46.940
 at assassinating Hitler, like time and time again failed.

1:50:47.340 --> 1:50:48.180
 And they were so close.

1:50:48.180 --> 1:50:49.820
 Was it like Operation Valkyrie?

1:50:49.820 --> 1:50:51.700
 Such a good.

1:50:51.700 --> 1:50:55.100
 And then there's also the role of,

1:50:55.100 --> 1:50:56.500
 that's a really heavy burden,

1:50:56.500 --> 1:50:59.060
 which is from a geopolitical perspective,

1:50:59.060 --> 1:51:00.820
 the role of leaders to see evil

1:51:00.820 --> 1:51:02.500
 before it truly becomes evil,

1:51:02.500 --> 1:51:05.460
 to anticipate it, to stand up to evil.

1:51:05.460 --> 1:51:08.140
 Because evil is actually pretty rare in this world

1:51:08.140 --> 1:51:09.380
 at a scale that Hitler was.

1:51:09.380 --> 1:51:12.020
 We tend to, you know, in the modern discourse

1:51:12.020 --> 1:51:14.020
 kind of call people evil too quickly.

1:51:14.020 --> 1:51:17.380
 If you look at ancient history,

1:51:17.380 --> 1:51:18.860
 like there was a ton of Hitlers.

1:51:18.860 --> 1:51:22.660
 I actually think it's more the norm than,

1:51:22.660 --> 1:51:24.420
 like again, going back to like my

1:51:24.420 --> 1:51:25.900
 sort of intelligent design theory,

1:51:25.900 --> 1:51:28.380
 I think one of the things we've been successfully doing

1:51:28.380 --> 1:51:31.340
 in our slow move from survival of the fittest

1:51:31.340 --> 1:51:36.340
 to intelligent design is we've kind of been eradicating,

1:51:37.700 --> 1:51:40.060
 like if you look at like ancient Assyria and stuff,

1:51:40.060 --> 1:51:42.460
 like that shit was like brutal

1:51:42.460 --> 1:51:45.860
 and just like the heads on the, like brutal,

1:51:45.860 --> 1:51:48.460
 like Genghis Khan just like genocide after genocide

1:51:48.460 --> 1:51:51.100
 was like throwing plague bodies over the walls

1:51:51.100 --> 1:51:52.660
 and decimating whole cities

1:51:52.660 --> 1:51:55.820
 or like the Muslim conquests of like Damascus and shit.

1:51:55.820 --> 1:51:58.780
 Just like people, cities used to get leveled

1:51:58.780 --> 1:52:00.060
 all the fucking time.

1:52:00.060 --> 1:52:02.460
 Okay, get into the Bronze Age collapse.

1:52:02.460 --> 1:52:05.140
 It's basically, there was like almost

1:52:05.140 --> 1:52:07.940
 like Roman level like society.

1:52:07.940 --> 1:52:09.420
 Like there was like all over the world,

1:52:09.420 --> 1:52:11.820
 like global trade, like everything was awesome

1:52:11.820 --> 1:52:13.820
 through a mix of, I think a bit of climate change

1:52:13.820 --> 1:52:16.020
 and then the development of iron

1:52:16.020 --> 1:52:17.420
 because basically bronze could only come

1:52:17.420 --> 1:52:19.540
 from this, the way to make bronze,

1:52:19.540 --> 1:52:20.700
 like everything had to be funneled

1:52:20.700 --> 1:52:23.340
 through this one Iranian mine.

1:52:23.340 --> 1:52:26.740
 And so it's like, there was just this one supply chain

1:52:26.740 --> 1:52:27.580
 and this is one of the things

1:52:27.580 --> 1:52:29.140
 that makes me worried about supply chains

1:52:29.140 --> 1:52:31.580
 and why I think we need to be so thoughtful about,

1:52:31.580 --> 1:52:34.500
 I think our biggest issue with society right now,

1:52:34.500 --> 1:52:36.460
 like the thing that is most likely to go wrong

1:52:36.460 --> 1:52:38.860
 is probably supply chain collapse,

1:52:38.860 --> 1:52:40.140
 because war, climate change, whatever,

1:52:40.140 --> 1:52:41.860
 like anything that causes supply chain collapse,

1:52:41.860 --> 1:52:44.260
 our population is too big to handle that.

1:52:44.260 --> 1:52:46.300
 And like the thing that seems to cause Dark Ages

1:52:46.300 --> 1:52:48.020
 is mass supply chain collapse.

1:52:48.020 --> 1:52:51.820
 But the Bronze Age collapse happened like,

1:52:52.860 --> 1:52:55.380
 it was sort of like this ancient collapse

1:52:55.380 --> 1:52:59.340
 that happened where like literally like ancient Egypt,

1:52:59.340 --> 1:53:01.740
 all these cities, everything just got like decimated,

1:53:01.740 --> 1:53:04.500
 destroyed, abandoned cities, like hundreds of them.

1:53:04.500 --> 1:53:05.980
 There was like a flourishing society,

1:53:05.980 --> 1:53:07.420
 like we were almost coming to modernity

1:53:07.420 --> 1:53:08.500
 and everything got leveled.

1:53:08.500 --> 1:53:10.060
 And they had this mini Dark Ages,

1:53:10.060 --> 1:53:12.140
 but it was just like, there's so little writing

1:53:12.140 --> 1:53:13.700
 or recording from that time that like,

1:53:13.700 --> 1:53:14.820
 there isn't a lot of information

1:53:14.820 --> 1:53:16.300
 about the Bronze Age collapse,

1:53:16.300 --> 1:53:18.780
 but it was basically equivalent to like medieval,

1:53:18.780 --> 1:53:21.220
 the medieval Dark Ages.

1:53:21.220 --> 1:53:23.620
 But it just happened, I don't know the years,

1:53:23.620 --> 1:53:26.500
 but like thousands of years earlier.

1:53:26.500 --> 1:53:28.660
 And then we sort of like recovered

1:53:28.660 --> 1:53:30.780
 from the Bronze Age collapse,

1:53:30.780 --> 1:53:33.820
 empire reemerged, writing and trade

1:53:33.820 --> 1:53:35.140
 and everything reemerged.

1:53:36.660 --> 1:53:39.980
 And then we of course had the more contemporary Dark Ages.

1:53:40.900 --> 1:53:43.140
 And then over time, we've designed mechanism

1:53:43.140 --> 1:53:46.420
 to lessen and lessen the capability

1:53:46.420 --> 1:53:50.540
 for the destructive power centers to emerge.

1:53:50.540 --> 1:53:54.260
 There's more recording about the more contemporary Dark Ages.

1:53:54.260 --> 1:53:55.660
 So I think we have like a better understanding

1:53:55.660 --> 1:53:56.500
 of how to avoid it,

1:53:56.500 --> 1:53:58.140
 but I still think we're at high risk for it.

1:53:58.140 --> 1:54:00.660
 I think that's one of the big risks right now.

1:54:00.660 --> 1:54:03.260
 So the natural state of being for humans

1:54:03.260 --> 1:54:04.940
 is for there to be a lot of Hitlers,

1:54:04.940 --> 1:54:06.780
 which has gotten really good

1:54:06.780 --> 1:54:09.980
 at making it hard for them to emerge.

1:54:09.980 --> 1:54:12.700
 We've gotten better at collaboration

1:54:12.700 --> 1:54:14.820
 and resisting the power,

1:54:14.820 --> 1:54:16.860
 like authoritarians to come to power.

1:54:16.860 --> 1:54:18.580
 We're trying to go country by country,

1:54:18.580 --> 1:54:19.900
 like we're moving past this.

1:54:19.900 --> 1:54:21.500
 We're kind of like slowly incrementally,

1:54:21.500 --> 1:54:26.500
 like moving towards like not scary old school war stuff.

1:54:29.180 --> 1:54:32.180
 And I think seeing it happen in some of the countries

1:54:32.180 --> 1:54:33.860
 that at least nominally are like

1:54:35.140 --> 1:54:36.740
 supposed to have moved past that,

1:54:36.740 --> 1:54:39.780
 that's scary because it reminds us that it can happen

1:54:39.780 --> 1:54:44.780
 like in the places that have moved supposedly,

1:54:44.980 --> 1:54:47.060
 as hopefully moved past that.

1:54:47.060 --> 1:54:49.420
 And possibly at a civilization level,

1:54:49.420 --> 1:54:51.660
 like you said, supply chain collapse

1:54:51.660 --> 1:54:54.300
 might make people resource constraint,

1:54:54.300 --> 1:54:59.300
 might make people desperate, angry, hateful, violent,

1:54:59.980 --> 1:55:01.500
 and drag us right back in.

1:55:01.500 --> 1:55:03.980
 I mean, supply chain collapse is how,

1:55:03.980 --> 1:55:06.260
 like the ultimate thing that caused the Middle Ages

1:55:06.260 --> 1:55:08.260
 was supply chain collapse.

1:55:08.260 --> 1:55:11.020
 It's like people, because people were reliant

1:55:11.020 --> 1:55:12.380
 on a certain level of technology,

1:55:12.380 --> 1:55:14.140
 like people, like you look at like Britain,

1:55:14.140 --> 1:55:17.540
 like they had glass, like people had aqueducts,

1:55:17.540 --> 1:55:20.420
 people had like indoor heating and cooling

1:55:20.420 --> 1:55:23.380
 and like running water and like buy food

1:55:23.380 --> 1:55:26.020
 from all over the world and trade and markets.

1:55:26.020 --> 1:55:28.580
 Like people didn't know how to hunt and forage and gather.

1:55:28.580 --> 1:55:29.820
 And so we're in a similar situation.

1:55:29.820 --> 1:55:33.740
 We are not educated enough to survive without technology.

1:55:33.740 --> 1:55:35.380
 So if we have a supply chain collapse

1:55:35.380 --> 1:55:38.340
 that like limits our access to technology,

1:55:38.340 --> 1:55:41.300
 there will be like massive starvation and violence

1:55:41.300 --> 1:55:43.100
 and displacement and war.

1:55:43.100 --> 1:55:47.260
 Like, you know, it's like, yeah.

1:55:47.260 --> 1:55:49.060
 In my opinion, it's like the primary marker

1:55:49.060 --> 1:55:52.700
 of like what a dark age is.

1:55:52.700 --> 1:55:54.380
 Well, technology is kind of enabling us

1:55:54.380 --> 1:55:57.180
 to be more resilient in terms of supply chain,

1:55:57.180 --> 1:56:00.820
 in terms of, to all the different catastrophic events

1:56:00.820 --> 1:56:02.060
 that happened to us.

1:56:02.060 --> 1:56:03.900
 Although the pandemic has kind of challenged

1:56:03.900 --> 1:56:07.660
 our preparedness for the catastrophic.

1:56:07.660 --> 1:56:09.220
 What do you think is the coolest invention

1:56:09.220 --> 1:56:11.100
 humans come up with?

1:56:11.100 --> 1:56:14.580
 The wheel, fire, cooking meat.

1:56:14.580 --> 1:56:16.980
 Computers. Computers.

1:56:16.980 --> 1:56:18.900
 Freaking computers. Internet or computers?

1:56:18.900 --> 1:56:19.740
 Which one?

1:56:19.740 --> 1:56:20.560
 What do you think the?

1:56:20.560 --> 1:56:22.420
 Previous technologies, I mean,

1:56:22.420 --> 1:56:23.680
 may have even been more profound

1:56:23.680 --> 1:56:24.740
 and moved us to a certain degree,

1:56:24.740 --> 1:56:27.340
 but I think the computers are what make us homo tech now.

1:56:27.340 --> 1:56:30.760
 I think this is what, it's a brain augmentation.

1:56:30.760 --> 1:56:33.820
 And so it like allows for actual evolution.

1:56:33.820 --> 1:56:35.460
 Like the computers accelerate the degree

1:56:35.460 --> 1:56:38.660
 to which all the other technologies can also be accelerated.

1:56:38.660 --> 1:56:40.700
 Would you classify yourself as a homo sapien

1:56:40.700 --> 1:56:41.580
 or a homo techno?

1:56:41.580 --> 1:56:43.040
 Definitely homo techno.

1:56:43.040 --> 1:56:46.940
 So you're one of the earliest of the species.

1:56:46.940 --> 1:56:49.200
 I think most of us are.

1:56:49.200 --> 1:56:51.620
 Like, as I said, like, I think if you

1:56:53.780 --> 1:56:58.740
 like looked at brain scans of us versus humans

1:56:58.740 --> 1:57:00.920
 a hundred years ago, it would look very different.

1:57:00.920 --> 1:57:03.740
 I think we are physiologically different.

1:57:03.740 --> 1:57:05.580
 Just even the interaction with the devices

1:57:05.580 --> 1:57:06.700
 has changed our brains.

1:57:06.700 --> 1:57:08.580
 Well, and if you look at,

1:57:08.580 --> 1:57:11.220
 a lot of studies are coming out to show that like,

1:57:11.220 --> 1:57:13.100
 there's a degree of inherited memory.

1:57:13.100 --> 1:57:15.360
 So some of these physiological changes in theory

1:57:15.360 --> 1:57:18.020
 should be, we should be passing them on.

1:57:18.020 --> 1:57:21.660
 So like that's, you know, that's not like a,

1:57:21.660 --> 1:57:23.180
 an instance of physiological change

1:57:23.180 --> 1:57:24.140
 that's gonna fizzle out.

1:57:24.140 --> 1:57:28.080
 In theory, that should progress like to our offspring.

1:57:29.060 --> 1:57:30.420
 Speaking of offspring,

1:57:30.420 --> 1:57:33.180
 what advice would you give to a young person,

1:57:33.180 --> 1:57:34.360
 like in high school,

1:57:35.660 --> 1:57:40.660
 whether there be an artist, a creative, an engineer,

1:57:43.140 --> 1:57:46.300
 any kind of career path, or maybe just life in general,

1:57:46.300 --> 1:57:48.700
 how they can live a life they can be proud of?

1:57:48.700 --> 1:57:50.800
 I think one of my big thoughts,

1:57:50.800 --> 1:57:53.180
 and like, especially now having kids,

1:57:53.180 --> 1:57:55.460
 is that I don't think we spend enough time

1:57:55.460 --> 1:57:56.820
 teaching creativity.

1:57:56.820 --> 1:57:59.300
 And I think creativity is a muscle like other things.

1:57:59.300 --> 1:58:01.740
 And there's a lot of emphasis on, you know,

1:58:01.740 --> 1:58:02.860
 learn how to play the piano.

1:58:02.860 --> 1:58:04.020
 And then you can write a song

1:58:04.020 --> 1:58:05.460
 or like learn the technical stuff.

1:58:05.460 --> 1:58:07.020
 And then you can do a thing.

1:58:07.020 --> 1:58:10.460
 But I think it's, like, I have a friend

1:58:10.460 --> 1:58:12.620
 who's like world's greatest guitar player,

1:58:13.700 --> 1:58:15.740
 like, you know, amazing sort of like producer,

1:58:15.740 --> 1:58:18.940
 works with other people, but he's really sort of like,

1:58:18.940 --> 1:58:20.680
 you know, he like engineers and records things

1:58:20.680 --> 1:58:21.740
 and like does solos,

1:58:21.740 --> 1:58:23.480
 but he doesn't really like make his own music.

1:58:23.480 --> 1:58:26.060
 And I was talking to him and I was like,

1:58:26.060 --> 1:58:27.340
 dude, you're so talented at music.

1:58:27.340 --> 1:58:28.860
 Like, why don't you make music or whatever?

1:58:28.860 --> 1:58:32.100
 And he was like, cause I got, I'm too old.

1:58:32.100 --> 1:58:34.180
 I never learned the creative muscle.

1:58:34.180 --> 1:58:36.660
 And it's like, you know, it's embarrassing.

1:58:36.660 --> 1:58:39.220
 It's like learning the creative muscle

1:58:39.220 --> 1:58:40.760
 takes a lot of failure.

1:58:40.760 --> 1:58:42.940
 And it also sort of,

1:58:44.220 --> 1:58:45.700
 if when you're being creative,

1:58:46.880 --> 1:58:48.140
 you know, you're throwing paint at a wall

1:58:48.140 --> 1:58:49.460
 and a lot of stuff will fail.

1:58:49.460 --> 1:58:51.180
 So like part of it is like a tolerance

1:58:51.180 --> 1:58:53.020
 for failure and humiliation.

1:58:53.020 --> 1:58:54.900
 And that's somehow that's easier to develop

1:58:54.900 --> 1:58:57.380
 when you're young or be persist through it

1:58:57.380 --> 1:58:58.220
 when you're young.

1:58:58.220 --> 1:59:02.540
 Everything is easier to develop when you're young.

1:59:02.540 --> 1:59:03.380
 Yes.

1:59:03.380 --> 1:59:04.780
 And the younger, the better.

1:59:04.780 --> 1:59:05.620
 It could destroy you.

1:59:05.620 --> 1:59:08.460
 I mean, that's the shitty thing about creativity.

1:59:08.460 --> 1:59:11.260
 If, you know, failure could destroy you

1:59:11.260 --> 1:59:13.420
 if you're not careful, but that's a risk worth taking.

1:59:13.420 --> 1:59:15.020
 But also, but at a young age,

1:59:15.020 --> 1:59:17.820
 developing a tolerance to failure is good.

1:59:17.820 --> 1:59:19.900
 I fail all the time.

1:59:19.900 --> 1:59:22.380
 Like I do stupid shit all the time.

1:59:22.380 --> 1:59:24.860
 Like in public, in private, I get canceled for,

1:59:24.860 --> 1:59:27.060
 I've make all kinds of mistakes,

1:59:27.060 --> 1:59:30.540
 but I just like am very resilient about making mistakes.

1:59:30.540 --> 1:59:32.980
 And so then like I do a lot of things

1:59:32.980 --> 1:59:34.180
 that like other people wouldn't do.

1:59:34.180 --> 1:59:37.540
 And like, I think my greatest asset is my creativity.

1:59:37.540 --> 1:59:39.840
 And I like, I think pain, like tolerance to failure

1:59:39.840 --> 1:59:43.380
 is just a super essential thing

1:59:43.380 --> 1:59:45.420
 that should be taught before other things.

1:59:45.420 --> 1:59:46.340
 Brilliant advice.

1:59:46.340 --> 1:59:47.420
 Yeah, yeah.

1:59:47.420 --> 1:59:51.540
 I wish everybody encouraged sort of failure more

1:59:51.540 --> 1:59:52.380
 as opposed to kind of.

1:59:52.380 --> 1:59:53.460
 Cause we like punish failure.

1:59:53.460 --> 1:59:55.340
 We're like, no, like when we were teaching kids,

1:59:55.340 --> 1:59:56.380
 we're like, no, that's wrong.

1:59:56.380 --> 2:00:01.380
 Like that's, you know, like X keeps like will be like wrong.

2:00:04.380 --> 2:00:05.760
 Like he'll say like crazy things.

2:00:05.760 --> 2:00:09.740
 Like X keeps being like, like bubble car, bubble car.

2:00:09.740 --> 2:00:14.160
 And I'm like, and you know, I'm like, what's a bubble car?

2:00:14.160 --> 2:00:15.860
 Like, but like, it doesn't like,

2:00:15.860 --> 2:00:17.420
 but I don't want to be like, no, you're wrong.

2:00:17.420 --> 2:00:20.340
 I'm like, you're thinking of weird, crazy shit.

2:00:20.340 --> 2:00:22.260
 Like, I don't know what a bubble car is, but like.

2:00:22.260 --> 2:00:23.460
 It's creating worlds

2:00:23.460 --> 2:00:25.180
 and they might be internally consistent.

2:00:25.180 --> 2:00:27.420
 And through that, you might discover something fundamental

2:00:27.420 --> 2:00:28.260
 about this world.

2:00:28.260 --> 2:00:29.740
 Yeah, or he'll like rewrite songs,

2:00:29.740 --> 2:00:32.140
 like with words that he prefers.

2:00:32.140 --> 2:00:34.580
 So like, instead of baby shark, he says baby car.

2:00:35.500 --> 2:00:36.340
 It's like.

2:00:36.340 --> 2:00:41.100
 Maybe he's onto something.

2:00:41.100 --> 2:00:42.740
 Let me ask the big, ridiculous question.

2:00:42.740 --> 2:00:44.100
 We were kind of dancing around it,

2:00:44.100 --> 2:00:47.180
 but what do you think is the meaning

2:00:47.180 --> 2:00:52.140
 of this whole thing we have here of human civilization,

2:00:52.140 --> 2:00:55.060
 of life on earth, but in general, just life?

2:00:55.060 --> 2:00:57.340
 What's the meaning of life?

2:00:57.340 --> 2:00:58.180
 C.

2:00:58.180 --> 2:01:02.540
 Have you, did you read Nova Scene yet?

2:01:02.540 --> 2:01:03.700
 By James Lovelock?

2:01:03.700 --> 2:01:06.340
 You're doing a lot of really good book recommendations here.

2:01:06.340 --> 2:01:07.560
 I haven't even finished this,

2:01:07.560 --> 2:01:10.260
 so I'm a huge fraud yet again.

2:01:10.260 --> 2:01:12.620
 But like really early in the book,

2:01:12.620 --> 2:01:14.500
 he says this amazing thing.

2:01:14.500 --> 2:01:16.500
 Like, I feel like everyone's so sad and cynical.

2:01:16.500 --> 2:01:18.700
 Like everyone's like the Fermi paradox and everyone.

2:01:18.700 --> 2:01:20.500
 I just keep hearing people being like, fuck,

2:01:20.500 --> 2:01:21.340
 what if we're alone?

2:01:21.340 --> 2:01:23.620
 Like, oh no, ah, like, ah, ah.

2:01:23.620 --> 2:01:25.100
 And I'm like, okay, but like, wait,

2:01:25.100 --> 2:01:26.780
 what if this is the beginning?

2:01:26.780 --> 2:01:28.460
 Like in Nova Scene, he says,

2:01:30.140 --> 2:01:31.380
 this is not gonna be a correct,

2:01:31.380 --> 2:01:32.580
 I can't like memorize quotes,

2:01:32.580 --> 2:01:34.260
 but he says something like,

2:01:36.260 --> 2:01:39.980
 what if our consciousness, like right now,

2:01:39.980 --> 2:01:43.380
 like this is the universe waking up?

2:01:43.380 --> 2:01:45.500
 Like what if instead of discovering the universe,

2:01:45.500 --> 2:01:47.460
 this is the universe,

2:01:47.460 --> 2:01:49.460
 like this is the evolution

2:01:49.460 --> 2:01:51.620
 of the literal universe herself.

2:01:51.620 --> 2:01:53.140
 Like we are not separate from the universe.

2:01:53.140 --> 2:01:54.620
 Like this is the universe waking up.

2:01:54.620 --> 2:01:57.400
 This is the universe seeing herself for the first time.

2:01:57.400 --> 2:01:58.240
 Like this is.

2:01:59.140 --> 2:02:00.820
 The universe becoming conscious.

2:02:00.820 --> 2:02:02.340
 The first time we were a part of that.

2:02:02.340 --> 2:02:03.180
 Yeah, cause it's like,

2:02:03.180 --> 2:02:05.620
 we aren't separate from the universe.

2:02:05.620 --> 2:02:08.780
 Like this could be like an incredibly sacred moment

2:02:08.780 --> 2:02:10.980
 and maybe like social media and all this things,

2:02:10.980 --> 2:02:13.300
 the stuff where we're all getting connected together.

2:02:13.300 --> 2:02:16.940
 Like maybe these are the neurons connecting

2:02:16.940 --> 2:02:20.900
 of the like collective super intelligence that is,

2:02:22.100 --> 2:02:22.940
 Waking up.

2:02:22.940 --> 2:02:25.420
 The, yeah, like, you know, it's like,

2:02:25.420 --> 2:02:27.100
 maybe instead of something cynical

2:02:27.100 --> 2:02:29.180
 or maybe if there's something to discover,

2:02:29.180 --> 2:02:31.540
 like maybe this is just, you know,

2:02:31.540 --> 2:02:35.980
 we're a blast assist of like some incredible

2:02:35.980 --> 2:02:39.420
 kind of consciousness or being.

2:02:39.420 --> 2:02:41.220
 And just like in the first three years of life

2:02:41.220 --> 2:02:42.820
 or for human children,

2:02:42.820 --> 2:02:44.340
 we'll forget about all the suffering

2:02:44.340 --> 2:02:45.460
 that we're going through now.

2:02:45.460 --> 2:02:46.620
 I think we'll probably forget about this.

2:02:46.620 --> 2:02:50.440
 I mean, probably, you know, artificial intelligence

2:02:50.440 --> 2:02:52.700
 will eventually render us obsolete.

2:02:52.700 --> 2:02:55.380
 I don't think they'll do it in a malicious way,

2:02:55.380 --> 2:02:57.760
 but I think probably we are very weak.

2:02:57.760 --> 2:02:58.880
 The sun is expanding.

2:02:58.880 --> 2:03:01.660
 Like, I don't know, like, hopefully we can get to Mars,

2:03:01.660 --> 2:03:04.100
 but like, we're pretty vulnerable.

2:03:04.100 --> 2:03:06.780
 And I, you know, like,

2:03:06.780 --> 2:03:09.100
 I think we can coexist for a long time with AI

2:03:09.100 --> 2:03:11.460
 and we can also probably make ourselves less vulnerable,

2:03:11.460 --> 2:03:13.580
 but, you know, I just think

2:03:15.700 --> 2:03:18.400
 consciousness, sentience, self awareness,

2:03:18.400 --> 2:03:21.940
 like, I think this might be the single greatest

2:03:21.940 --> 2:03:24.980
 like moment in evolution ever.

2:03:24.980 --> 2:03:28.140
 And like, maybe this is, you know,

2:03:29.300 --> 2:03:32.580
 the big, like the true beginning of life.

2:03:32.580 --> 2:03:34.700
 And we're just, we're the blue green algae

2:03:34.700 --> 2:03:36.980
 or we're like the single celled organisms

2:03:36.980 --> 2:03:38.460
 of something amazing.

2:03:38.460 --> 2:03:40.900
 The universe awakens and this is it.

2:03:40.900 --> 2:03:41.740
 Yeah.

2:03:42.620 --> 2:03:45.300
 Well, see, you're an incredible person.

2:03:45.300 --> 2:03:47.500
 You're a fascinating mind.

2:03:47.500 --> 2:03:50.500
 You should definitely do, your friend Liv mentioned

2:03:50.500 --> 2:03:52.260
 that you guys were thinking of maybe talking.

2:03:52.260 --> 2:03:55.340
 I would love it if you explored your mind

2:03:55.340 --> 2:03:56.700
 in this kind of media more and more

2:03:56.700 --> 2:03:59.660
 by doing a podcast with her or just in any kind of way.

2:03:59.660 --> 2:04:01.780
 So you're an awesome person.

2:04:01.780 --> 2:04:03.380
 It's an honor to know you.

2:04:03.380 --> 2:04:05.820
 It's an honor to get to sit down with you late at night,

2:04:05.820 --> 2:04:08.360
 which is like surreal.

2:04:08.360 --> 2:04:09.200
 And I really enjoyed it.

2:04:09.200 --> 2:04:10.140
 Thank you for talking today.

2:04:10.140 --> 2:04:11.700
 Yeah, no, I mean, huge honor.

2:04:11.700 --> 2:04:13.640
 I feel very underqualified to be here, but I'm a big fan.

2:04:13.640 --> 2:04:15.940
 I've been listening to the podcast a lot and yeah,

2:04:15.940 --> 2:04:18.260
 me and Liv would appreciate any advice and help

2:04:18.260 --> 2:04:19.220
 and we're definitely gonna do that.

2:04:19.220 --> 2:04:21.380
 So yeah.

2:04:21.380 --> 2:04:22.220
 Anytime.

2:04:22.220 --> 2:04:23.040
 Thank you.

2:04:23.040 --> 2:04:24.420
 Cool, thank you.

2:04:24.420 --> 2:04:26.980
 Thanks for listening to this conversation with Grimes.

2:04:26.980 --> 2:04:28.220
 To support this podcast,

2:04:28.220 --> 2:04:31.060
 please check out our sponsors in the description.

2:04:31.060 --> 2:04:34.660
 And now let me leave you with some words from Oscar Wilde.

2:04:34.660 --> 2:04:36.940
 Yes, I'm a dreamer.

2:04:36.940 --> 2:04:41.340
 For a dreamer is one who can only find her way by moonlight

2:04:41.340 --> 2:04:44.260
 and her punishment is that she sees the dawn

2:04:44.260 --> 2:04:45.740
 before the rest of the world.

2:04:46.580 --> 2:04:49.020
 Thank you for listening and hope to see you

2:04:49.020 --> 2:04:49.860
 next time.

