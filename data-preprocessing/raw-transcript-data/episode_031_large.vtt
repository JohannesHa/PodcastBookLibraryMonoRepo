WEBVTT

00:00.000 --> 00:02.480
 The following is a conversation with George Hotz.

00:02.480 --> 00:04.440
 He's the founder of Kama AI,

00:04.440 --> 00:07.360
 a machine learning based vehicle automation company.

00:07.360 --> 00:10.160
 He is most certainly an outspoken personality

00:10.160 --> 00:13.120
 in the field of AI and technology in general.

00:13.120 --> 00:16.200
 He first gained recognition for being the first person

00:16.200 --> 00:18.360
 to carry or unlock an iPhone.

00:18.360 --> 00:21.240
 And since then, he's done quite a few interesting things

00:21.240 --> 00:24.360
 at the intersection of hardware and software.

00:24.360 --> 00:27.400
 This is the Artificial Intelligence Podcast.

00:27.400 --> 00:29.560
 If you enjoy it, subscribe on YouTube,

00:29.560 --> 00:32.880
 give it five stars on iTunes, support it on Patreon,

00:32.880 --> 00:34.880
 or simply connect with me on Twitter

00:34.880 --> 00:39.120
 at Lex Friedman, spelled F R I D M A N.

00:39.120 --> 00:40.960
 And I'd like to give a special thank you

00:40.960 --> 00:43.240
 to Jennifer from Canada

00:43.240 --> 00:45.840
 for her support of the podcast on Patreon.

00:45.840 --> 00:47.680
 Merci beaucoup, Jennifer.

00:47.680 --> 00:50.600
 She's been a friend and an engineering colleague

00:50.600 --> 00:52.760
 for many years since I was in grad school.

00:52.760 --> 00:54.320
 Your support means a lot

00:54.320 --> 00:57.880
 and inspires me to keep this series going.

00:57.880 --> 01:01.560
 And now, here's my conversation with George Hotz.

01:02.680 --> 01:04.840
 Do you think we're living in a simulation?

01:06.440 --> 01:10.040
 Yes, but it may be unfalsifiable.

01:10.040 --> 01:12.400
 What do you mean by unfalsifiable?

01:12.400 --> 01:16.800
 So if the simulation is designed in such a way

01:16.800 --> 01:19.600
 that they did like a formal proof

01:19.600 --> 01:22.280
 to show that no information can get in and out,

01:22.280 --> 01:24.040
 and if their hardware is designed

01:24.040 --> 01:25.960
 for the anything in the simulation

01:25.960 --> 01:27.840
 to always keep the hardware in spec,

01:27.840 --> 01:29.440
 it may be impossible to prove

01:29.440 --> 01:31.280
 whether we're in a simulation or not.

01:32.560 --> 01:35.640
 So they've designed it such that it's a closed system

01:35.640 --> 01:37.160
 you can't get outside the system.

01:37.160 --> 01:38.760
 Well, maybe it's one of three worlds.

01:38.760 --> 01:41.360
 We're either in a simulation which can be exploited,

01:41.360 --> 01:44.160
 we're in a simulation which not only can't be exploited,

01:44.160 --> 01:46.400
 but like the same thing's true about VMs.

01:46.400 --> 01:48.120
 A really well designed VM,

01:48.120 --> 01:51.360
 you can't even detect if you're in a VM or not.

01:51.360 --> 01:52.480
 That's brilliant.

01:52.480 --> 01:56.760
 So the simulation is running on a virtual machine.

01:56.760 --> 01:59.400
 But now in reality, all VMs have ways to detect.

01:59.400 --> 02:00.240
 That's the point.

02:00.240 --> 02:04.800
 I mean, you've done quite a bit of hacking yourself.

02:04.800 --> 02:08.600
 So you should know that really any complicated system

02:08.600 --> 02:10.960
 will have ways in and out.

02:10.960 --> 02:14.200
 So this isn't necessarily true going forward.

02:15.240 --> 02:18.040
 I spent my time away from Comma,

02:18.040 --> 02:21.800
 I learned Coq, it's a dependently typed,

02:21.800 --> 02:24.320
 it's a language for writing math proofs in.

02:24.320 --> 02:28.160
 And if you write code that compiles in a language like that,

02:28.160 --> 02:30.800
 it is correct by definition.

02:30.800 --> 02:33.520
 The types check its correctness.

02:33.520 --> 02:34.960
 So it's possible that the simulation

02:34.960 --> 02:39.600
 is written in a language like this, in which case, yeah.

02:39.600 --> 02:42.640
 Yeah, but that can't be sufficiently expressive

02:42.640 --> 02:43.720
 a language like that.

02:43.720 --> 02:44.560
 Oh, it can.

02:44.560 --> 02:45.400
 It can be?

02:45.400 --> 02:46.240
 Oh, yeah.

02:46.240 --> 02:48.880
 Okay, well, so all right, so.

02:48.880 --> 02:50.600
 The simulation doesn't have to be Turing complete

02:50.600 --> 02:52.280
 if it has a scheduled end date.

02:52.280 --> 02:54.560
 Looks like it does actually with entropy.

02:54.560 --> 02:58.560
 I mean, I don't think that a simulation

02:58.560 --> 03:02.200
 that results in something as complicated as the universe

03:03.040 --> 03:07.280
 would have a form of proof of correctness, right?

03:08.240 --> 03:09.800
 It's possible, of course.

03:09.800 --> 03:12.720
 We have no idea how good their tooling is.

03:12.720 --> 03:14.600
 And we have no idea how complicated

03:14.600 --> 03:16.240
 the universe computer really is.

03:16.240 --> 03:17.880
 It may be quite simple.

03:17.880 --> 03:19.640
 It's just very large, right?

03:19.640 --> 03:22.120
 It's very, it's definitely very large.

03:22.120 --> 03:24.440
 But the fundamental rules might be super simple.

03:24.440 --> 03:26.200
 Yeah, Conway's getting a life kind of stuff.

03:26.200 --> 03:27.040
 Right.

03:28.040 --> 03:30.280
 So if you could hack,

03:30.280 --> 03:32.360
 so imagine a simulation that is hackable,

03:32.360 --> 03:33.600
 if you could hack it,

03:35.040 --> 03:37.880
 what would you change about the,

03:37.880 --> 03:40.520
 like how would you approach hacking a simulation?

03:41.640 --> 03:44.320
 The reason I gave that talk.

03:44.320 --> 03:46.640
 By the way, I'm not familiar with the talk you gave.

03:46.640 --> 03:50.120
 I just read that you talked about escaping the simulation

03:50.120 --> 03:51.240
 or something like that.

03:51.240 --> 03:53.640
 So maybe you can tell me a little bit about the theme

03:53.640 --> 03:55.320
 and the message there too.

03:55.320 --> 03:57.640
 It wasn't a very practical talk

03:57.640 --> 04:00.560
 about how to actually escape a simulation.

04:00.560 --> 04:03.280
 It was more about a way of restructuring

04:03.280 --> 04:05.080
 an us versus them narrative.

04:05.080 --> 04:05.920
 If

04:08.160 --> 04:12.320
 we continue on the path we're going with technology,

04:12.320 --> 04:14.120
 I think we're in big trouble,

04:14.120 --> 04:16.720
 like as a species and not just as a species,

04:16.720 --> 04:19.440
 but even as me as an individual member of the species.

04:19.440 --> 04:22.080
 So if we could change rhetoric

04:22.080 --> 04:24.880
 to be more like to think upwards,

04:26.200 --> 04:29.040
 like to think about that we're in a simulation

04:29.040 --> 04:30.320
 and how we could get out,

04:30.320 --> 04:32.560
 already we'd be on the right path.

04:32.560 --> 04:34.760
 What you actually do once you do that,

04:34.760 --> 04:37.320
 well, I assume I would have acquired way more intelligence

04:37.320 --> 04:38.440
 in the process of doing that.

04:38.440 --> 04:39.720
 So I'll just ask that.

04:39.720 --> 04:42.040
 So the thinking upwards,

04:42.040 --> 04:43.720
 what kind of ideas,

04:43.720 --> 04:44.800
 what kind of breakthrough ideas

04:44.800 --> 04:47.280
 do you think thinking in that way could inspire?

04:47.280 --> 04:49.760
 And why did you say upwards?

04:49.760 --> 04:50.600
 Upwards.

04:50.600 --> 04:51.440
 Into space?

04:51.440 --> 04:54.040
 Are you thinking sort of exploration in all forms?

04:54.040 --> 04:56.120
 The space narrative

04:57.400 --> 04:59.800
 that held for the modernist generation

04:59.800 --> 05:02.520
 doesn't hold as well for the postmodern generation.

05:04.480 --> 05:05.400
 What's the space narrative?

05:05.400 --> 05:06.440
 Are we talking about the same space,

05:06.440 --> 05:07.280
 the three dimensional space?

05:07.280 --> 05:08.720
 No, no, no, space, like going on space,

05:08.720 --> 05:09.960
 like building like Elon Musk,

05:09.960 --> 05:11.080
 like we're going to build rockets,

05:11.080 --> 05:11.960
 we're going to go to Mars,

05:11.960 --> 05:13.440
 we're going to colonize the universe.

05:13.440 --> 05:14.640
 And the narrative you're referring,

05:14.640 --> 05:15.960
 I was born in the Soviet Union,

05:15.960 --> 05:17.960
 you're referring to the race to space.

05:17.960 --> 05:18.880
 The race to space, yeah.

05:18.880 --> 05:19.720
 Explore, okay.

05:19.720 --> 05:21.760
 That was a great modernist narrative.

05:21.760 --> 05:23.320
 Yeah.

05:23.320 --> 05:26.640
 It doesn't seem to hold the same weight in today's culture.

05:27.640 --> 05:32.120
 I'm hoping for good postmodern narratives that replace it.

05:32.120 --> 05:35.520
 So let's think, so you work a lot with AI.

05:35.520 --> 05:39.040
 So AI is one formulation of that narrative.

05:39.040 --> 05:40.040
 There could be also,

05:40.040 --> 05:42.280
 I don't know how much you do in VR and AR.

05:42.280 --> 05:43.120
 Yeah.

05:43.120 --> 05:45.120
 That's another, I know less about it,

05:45.120 --> 05:47.600
 but every time I play with it in our research,

05:47.600 --> 05:49.600
 it's fascinating, that virtual world.

05:49.600 --> 05:51.800
 Are you interested in the virtual world?

05:51.800 --> 05:54.160
 I would like to move to virtual reality.

05:55.280 --> 05:56.400
 In terms of your work?

05:56.400 --> 05:58.720
 No, I would like to physically move there.

05:58.720 --> 06:00.200
 The apartment I can rent in the cloud

06:00.200 --> 06:01.120
 is way better than the apartment

06:01.120 --> 06:03.200
 I can rent in the real world.

06:03.200 --> 06:04.720
 Well, it's all relative, isn't it?

06:04.720 --> 06:07.240
 Because others will have very nice apartments too,

06:07.240 --> 06:09.080
 so you'll be inferior in the virtual world as well.

06:09.080 --> 06:11.280
 No, but that's not how I view the world, right?

06:11.280 --> 06:12.400
 I don't view the world,

06:12.400 --> 06:15.600
 I mean, it's a very almost zero sum ish way

06:15.600 --> 06:16.440
 to view the world.

06:16.440 --> 06:18.760
 Say like, my great apartment isn't great

06:18.760 --> 06:20.360
 because my neighbor has one too.

06:20.360 --> 06:21.600
 No, my great apartment is great

06:21.600 --> 06:24.280
 because look at this dishwasher, man.

06:24.280 --> 06:26.640
 You just touch the dish and it's washed, right?

06:26.640 --> 06:28.680
 And that is great in and of itself

06:28.680 --> 06:30.080
 if I have the only apartment

06:30.080 --> 06:31.480
 or if everybody had the apartment.

06:31.480 --> 06:32.360
 I don't care.

06:32.360 --> 06:34.720
 So you have fundamental gratitude.

06:34.720 --> 06:39.080
 The world first learned of George Hots

06:39.080 --> 06:42.240
 in August 2007, maybe before then,

06:42.240 --> 06:44.040
 but certainly in August 2007

06:44.040 --> 06:46.760
 when you were the first person to unlock,

06:46.760 --> 06:48.840
 carry unlock an iPhone.

06:48.840 --> 06:50.480
 How did you get into hacking?

06:50.480 --> 06:51.520
 What was the first system

06:51.520 --> 06:55.000
 you discovered vulnerabilities for and broke into?

06:56.200 --> 07:01.200
 So that was really kind of the first thing.

07:01.600 --> 07:06.600
 I had a book in 2006 called Grey Hat Hacking.

07:06.600 --> 07:11.600
 And I guess I realized that if you acquired

07:12.240 --> 07:15.320
 these sort of powers, you could control the world.

07:16.160 --> 07:18.960
 But I didn't really know that much

07:18.960 --> 07:20.560
 about computers back then.

07:20.560 --> 07:22.160
 I started with electronics.

07:22.160 --> 07:24.200
 The first iPhone hack was physical.

07:24.200 --> 07:25.040
 Cardware.

07:25.040 --> 07:28.160
 You had to open it up and pull an address line high.

07:28.160 --> 07:29.960
 And it was because I didn't really know

07:29.960 --> 07:31.360
 about software exploitation.

07:31.360 --> 07:32.960
 I learned that all in the next few years

07:32.960 --> 07:33.920
 and I got very good at it.

07:33.920 --> 07:37.640
 But back then I knew about like how memory chips

07:37.640 --> 07:38.960
 are connected to processors and stuff.

07:38.960 --> 07:40.960
 You knew about software and programming.

07:40.960 --> 07:43.160
 You just didn't know.

07:43.160 --> 07:44.000
 Oh really?

07:44.000 --> 07:46.800
 So your view of the world and computers

07:46.800 --> 07:49.280
 was physical, was hardware.

07:49.280 --> 07:51.760
 Actually, if you read the code that I released

07:51.760 --> 07:55.720
 with that in August 2007, it's atrocious.

07:55.720 --> 07:56.720
 What language was it?

07:56.720 --> 07:57.560
 C.

07:57.560 --> 07:58.400
 C, nice.

07:58.400 --> 08:01.440
 And in a broken sort of state machine ask C.

08:01.440 --> 08:02.920
 I didn't know how to program.

08:02.920 --> 08:04.040
 Yeah.

08:04.040 --> 08:06.480
 So how did you learn to program?

08:07.400 --> 08:08.320
 What was your journey?

08:08.320 --> 08:10.000
 Cause I mean, we'll talk about it.

08:10.000 --> 08:12.640
 You've live streamed some of your programming.

08:12.640 --> 08:14.360
 This chaotic, beautiful mess.

08:14.360 --> 08:16.440
 How did you arrive at that?

08:16.440 --> 08:18.600
 Years and years of practice.

08:18.600 --> 08:22.720
 I interned at Google after the summer

08:22.720 --> 08:24.760
 after the iPhone unlock.

08:24.760 --> 08:27.960
 And I did a contract for them where I built hardware

08:27.960 --> 08:30.640
 for Street View and I wrote a software library

08:30.640 --> 08:31.760
 to interact with it.

08:31.760 --> 08:34.360
 And it was terrible code.

08:34.360 --> 08:36.440
 And for the first time I got feedback from people

08:36.440 --> 08:40.600
 who I respected saying, no, like don't write code like this.

08:42.120 --> 08:45.120
 Now, of course, just getting that feedback is not enough.

08:45.120 --> 08:50.120
 The way that I really got good was I wanted to write

08:51.080 --> 08:56.080
 this thing like that could emulate and then visualize

08:56.480 --> 08:57.880
 like arm binaries.

08:57.880 --> 08:59.480
 Cause I wanted to hack the iPhone better.

08:59.480 --> 09:01.120
 And I didn't like that I couldn't like see

09:01.120 --> 09:03.720
 what the, I couldn't single step through the processor

09:03.720 --> 09:05.120
 because I had no debugger on there,

09:05.120 --> 09:06.560
 especially for the low level things like the boot rum

09:06.560 --> 09:07.480
 and the bootloader.

09:07.480 --> 09:09.400
 So I tried to build this tool to do it.

09:10.880 --> 09:13.400
 And I built the tool once and it was terrible.

09:13.400 --> 09:15.080
 I built the tool a second time, it was terrible.

09:15.080 --> 09:16.320
 I built the tool a third time.

09:16.320 --> 09:18.600
 This was by the time I was at Facebook, it was kind of okay.

09:18.600 --> 09:20.520
 And then I built the tool a fourth time

09:20.520 --> 09:22.520
 when I was a Google intern again in 2014.

09:22.520 --> 09:24.320
 And that was the first time I was like,

09:24.320 --> 09:25.840
 this is finally usable.

09:25.840 --> 09:27.080
 How do you pronounce this Kira?

09:27.080 --> 09:28.360
 Kira, yeah.

09:28.360 --> 09:31.800
 So it's essentially the most efficient way

09:31.800 --> 09:35.680
 to visualize the change of state of the computer

09:35.680 --> 09:37.160
 as the program is running.

09:37.160 --> 09:38.840
 That's what you mean by debugger.

09:38.840 --> 09:41.720
 Yeah, it's a timeless debugger.

09:41.720 --> 09:45.040
 So you can rewind just as easily as going forward.

09:45.040 --> 09:46.200
 Think about if you're using GDB,

09:46.200 --> 09:47.840
 you have to put a watch on a variable.

09:47.840 --> 09:49.640
 If you wanna see if that variable changes.

09:49.640 --> 09:51.480
 In Kira, you can just click on that variable

09:51.480 --> 09:53.840
 and then it shows every single time

09:53.840 --> 09:56.480
 when that variable was changed or accessed.

09:56.480 --> 09:59.760
 Think about it like Git for your computers, the run log.

09:59.760 --> 10:04.760
 So there's like a deep log of the state of the computer

10:05.600 --> 10:07.800
 as the program runs and you can rewind.

10:07.800 --> 10:11.440
 Why isn't that, maybe it is, maybe you can educate me.

10:11.440 --> 10:14.600
 Why isn't that kind of debugging used more often?

10:14.600 --> 10:16.280
 Cause the tooling's bad.

10:16.280 --> 10:17.120
 Well, two things.

10:17.120 --> 10:19.320
 One, if you're trying to debug Chrome,

10:19.320 --> 10:22.840
 Chrome is a 200 megabyte binary

10:22.840 --> 10:25.400
 that runs slowly on desktops.

10:25.400 --> 10:27.640
 So that's gonna be really hard to use for that.

10:27.640 --> 10:30.080
 But it's really good to use for like CTFs

10:30.080 --> 10:33.120
 and for boot roms and for small parts of code.

10:33.120 --> 10:36.280
 So it's hard if you're trying to debug like massive systems.

10:36.280 --> 10:38.120
 What's a CTF and what's a boot rom?

10:38.120 --> 10:40.400
 A boot rom is the first code that executes

10:40.400 --> 10:42.160
 the minute you give power to your iPhone.

10:42.160 --> 10:43.440
 Okay.

10:43.440 --> 10:45.520
 And CTF where these competitions

10:45.520 --> 10:46.880
 that I played capture the flag.

10:46.880 --> 10:48.480
 Capture the flag, I was gonna ask you about that.

10:48.480 --> 10:49.840
 What are those, look at,

10:49.840 --> 10:51.320
 I watched a couple of videos on YouTube,

10:51.320 --> 10:52.840
 those look fascinating.

10:52.840 --> 10:54.760
 What have you learned about maybe

10:54.760 --> 10:56.680
 at the high level of vulnerability of systems

10:56.680 --> 10:57.880
 from these competitions?

11:00.760 --> 11:04.160
 I feel like in the heyday of CTFs,

11:04.160 --> 11:08.080
 you had all of the best security people in the world

11:08.080 --> 11:10.640
 challenging each other and coming up

11:10.640 --> 11:13.600
 with new toy exploitable things over here.

11:13.600 --> 11:15.320
 And then everybody, okay, who can break it?

11:15.320 --> 11:17.080
 And when you break it, you get like,

11:17.080 --> 11:19.280
 there's like a file on the server called flag.

11:19.280 --> 11:20.920
 And then there's a program running,

11:20.920 --> 11:22.600
 listening on a socket that's vulnerable.

11:22.600 --> 11:24.920
 So you write an exploit, you get a shell,

11:24.920 --> 11:27.080
 and then you cat flag, and then you type the flag

11:27.080 --> 11:29.440
 into like a web based scoreboard and you get points.

11:29.440 --> 11:31.520
 So the goal is essentially,

11:31.520 --> 11:32.920
 to find an exploit in the system

11:32.920 --> 11:35.200
 that allows you to run shell,

11:35.200 --> 11:37.960
 to run arbitrary code on that system.

11:37.960 --> 11:40.120
 That's one of the categories.

11:40.120 --> 11:41.880
 That's like the pwnable category.

11:43.480 --> 11:44.320
 Pwnable?

11:44.320 --> 11:45.160
 Yeah, pwnable.

11:45.160 --> 11:47.520
 It's like, you know, you pwn the program.

11:47.520 --> 11:48.920
 It's a program that's, yeah.

11:48.920 --> 11:53.920
 Yeah, you know, first of all, I apologize.

11:54.160 --> 11:56.240
 I'm gonna say it's because I'm Russian,

11:56.240 --> 11:59.080
 but maybe you can help educate me.

12:00.080 --> 12:02.760
 Some video game like misspelled own way back in the day.

12:02.760 --> 12:06.280
 Yeah, and it's just, I wonder if there's a definition.

12:06.280 --> 12:08.240
 I'll have to go to Urban Dictionary for it.

12:08.240 --> 12:09.720
 It'll be interesting to see what it says.

12:09.720 --> 12:12.720
 Okay, so what was the heyday of CTF, by the way?

12:12.720 --> 12:15.440
 But was it, what decade are we talking about?

12:15.440 --> 12:18.360
 I think like, I mean, maybe unbiased

12:18.360 --> 12:21.040
 because it's the era that I played,

12:21.040 --> 12:25.720
 but like 2011 to 2015,

12:27.120 --> 12:30.240
 because the modern CTF scene

12:30.240 --> 12:32.560
 is similar to the modern competitive programming scene.

12:32.560 --> 12:34.200
 You have people who like do drills.

12:34.200 --> 12:35.800
 You have people who practice.

12:35.800 --> 12:36.920
 And then once you've done that,

12:36.920 --> 12:39.960
 you've turned it less into a game of generic computer skill

12:39.960 --> 12:41.680
 and more into a game of, okay,

12:41.680 --> 12:44.560
 you drill on these five categories.

12:44.560 --> 12:48.880
 And then before that, it wasn't,

12:48.880 --> 12:51.480
 it didn't have like as much attention as it had.

12:52.760 --> 12:53.600
 I don't know, they were like,

12:53.600 --> 12:56.040
 I won $30,000 once in Korea for one of these competitions.

12:56.040 --> 12:56.880
 Holy crap.

12:56.880 --> 12:57.880
 Yeah, they were, they were, that was.

12:57.880 --> 12:59.480
 So that means, I mean, money is money,

12:59.480 --> 13:02.240
 but that means there was probably good people there.

13:02.240 --> 13:03.520
 Exactly, yeah.

13:03.520 --> 13:06.720
 Are the challenges human constructed

13:06.720 --> 13:10.720
 or are they grounded in some real flaws and real systems?

13:10.720 --> 13:13.000
 Usually they're human constructed,

13:13.000 --> 13:15.720
 but they're usually inspired by real flaws.

13:15.720 --> 13:17.240
 What kind of systems are imagined

13:17.240 --> 13:19.040
 is really focused on mobile.

13:19.040 --> 13:20.880
 Like what has vulnerabilities these days?

13:20.880 --> 13:25.080
 Is it primarily mobile systems like Android?

13:25.080 --> 13:26.480
 Oh, everything does.

13:26.480 --> 13:28.040
 Still. Yeah, of course.

13:28.040 --> 13:29.320
 The price has kind of gone up

13:29.320 --> 13:31.200
 because less and less people can find them.

13:31.200 --> 13:32.760
 And what's happened in security

13:32.760 --> 13:34.480
 is now if you want to like jailbreak an iPhone,

13:34.480 --> 13:36.840
 you don't need one exploit anymore, you need nine.

13:37.880 --> 13:39.600
 Nine chained together, what would it mean?

13:39.600 --> 13:40.560
 Yeah, wow.

13:40.560 --> 13:42.680
 Okay, so it's really,

13:42.680 --> 13:46.120
 what's the benefit speaking higher level

13:46.120 --> 13:48.160
 philosophically about hacking?

13:48.160 --> 13:50.320
 I mean, it sounds from everything I've seen about you,

13:50.320 --> 13:51.840
 you just love the challenge

13:51.840 --> 13:54.960
 and you don't want to do anything.

13:54.960 --> 13:58.040
 You don't want to bring that exploit out into the world

13:58.040 --> 14:01.600
 and do any actual, let it run wild.

14:01.600 --> 14:02.680
 You just want to solve it

14:02.680 --> 14:05.320
 and then you go on to the next thing.

14:05.320 --> 14:08.360
 Oh yeah, I mean, doing criminal stuff's not really worth it.

14:08.360 --> 14:10.440
 And I'll actually use the same argument

14:10.440 --> 14:13.600
 for why I don't do defense for why I don't do crime.

14:15.320 --> 14:16.720
 If you want to defend a system,

14:16.720 --> 14:19.160
 say the system has 10 holes, right?

14:19.160 --> 14:22.120
 If you find nine of those holes as a defender,

14:22.120 --> 14:23.800
 you still lose because the attacker

14:23.800 --> 14:25.400
 gets in through the last one.

14:25.400 --> 14:26.240
 If you're an attacker,

14:26.240 --> 14:28.600
 you only have to find one out of the 10.

14:28.600 --> 14:30.680
 But if you're a criminal,

14:30.680 --> 14:34.680
 if you log on with a VPN nine out of the 10 times,

14:34.680 --> 14:37.640
 but one time you forget, you're done.

14:37.640 --> 14:39.240
 Because you're caught, okay.

14:39.240 --> 14:41.040
 Because you only have to mess up once

14:41.040 --> 14:42.760
 to be caught as a criminal.

14:42.760 --> 14:44.160
 That's why I'm not a criminal.

14:45.800 --> 14:46.960
 But okay, let me,

14:46.960 --> 14:49.400
 because I was having a discussion with somebody

14:49.400 --> 14:52.640
 just at a high level about nuclear weapons actually,

14:52.640 --> 14:56.120
 why we're having blown ourselves up yet.

14:56.120 --> 14:59.680
 And my feeling is all the smart people in the world,

14:59.680 --> 15:04.000
 if you look at the distribution of smart people,

15:04.000 --> 15:06.600
 smart people are generally good.

15:06.600 --> 15:07.920
 And then this other person I was talking to,

15:07.920 --> 15:09.320
 Sean Carroll, the physicist,

15:09.320 --> 15:11.280
 and he was saying, no, good and bad people

15:11.280 --> 15:13.960
 are evenly distributed amongst everybody.

15:13.960 --> 15:17.960
 My sense was good hackers are in general good people

15:17.960 --> 15:20.280
 and they don't want to mess with the world.

15:20.280 --> 15:21.640
 What's your sense?

15:21.640 --> 15:24.560
 I'm not even sure about that.

15:25.800 --> 15:26.640
 Like,

15:28.880 --> 15:30.400
 I have a nice life.

15:30.400 --> 15:32.000
 Crime wouldn't get me anything.

15:34.160 --> 15:36.400
 But if you're good and you have these skills,

15:36.400 --> 15:38.600
 you probably have a nice life too, right?

15:38.600 --> 15:40.040
 Right, you can use it for other things.

15:40.040 --> 15:41.000
 But is there an ethical,

15:41.000 --> 15:44.080
 is there a little voice in your head that says,

15:46.000 --> 15:48.920
 well, yeah, if you could hack something

15:48.920 --> 15:50.600
 to where you could hurt people

15:52.720 --> 15:54.840
 and you could earn a lot of money doing it though,

15:54.840 --> 15:56.200
 not hurt physically perhaps,

15:56.200 --> 15:58.880
 but disrupt their life in some kind of way,

16:00.080 --> 16:02.200
 isn't there a little voice that says?

16:03.240 --> 16:04.440
 Well, two things.

16:04.440 --> 16:06.680
 One, I don't really care about money.

16:06.680 --> 16:08.600
 So like the money wouldn't be an incentive.

16:08.600 --> 16:10.560
 The thrill might be an incentive.

16:10.560 --> 16:14.320
 But when I was 19, I read Crime and Punishment.

16:14.320 --> 16:16.040
 And that was another great one

16:16.040 --> 16:18.360
 that talked me out of ever really doing crime.

16:19.320 --> 16:21.640
 Cause it's like, that's gonna be me.

16:21.640 --> 16:25.000
 I'd get away with it, but it would just run through my head.

16:25.000 --> 16:26.400
 Even if I got away with it, you know?

16:26.400 --> 16:27.560
 And then you do crime for long enough,

16:27.560 --> 16:28.880
 you'll never get away with it.

16:28.880 --> 16:29.720
 That's right.

16:29.720 --> 16:32.600
 In the end, that's a good reason to be good.

16:32.600 --> 16:33.440
 I wouldn't say I'm good.

16:33.440 --> 16:34.840
 I would just say I'm not bad.

16:34.840 --> 16:38.080
 You're a talented programmer and a hacker

16:38.080 --> 16:40.920
 in a good positive sense of the word.

16:40.920 --> 16:42.400
 You've played around,

16:42.400 --> 16:44.720
 found vulnerabilities in various systems.

16:44.720 --> 16:46.120
 What have you learned broadly

16:46.120 --> 16:49.480
 about the design of systems and so on

16:49.480 --> 16:51.520
 from that whole process?

16:53.280 --> 16:58.280
 You learn to not take things

16:59.280 --> 17:02.000
 for what people say they are,

17:02.000 --> 17:05.280
 but you look at things for what they actually are.

17:07.000 --> 17:07.880
 Yeah.

17:07.880 --> 17:10.040
 I understand that's what you tell me it is,

17:10.040 --> 17:11.440
 but what does it do?

17:11.440 --> 17:12.920
 Right.

17:12.920 --> 17:14.560
 And you have nice visualization tools

17:14.560 --> 17:16.680
 to really know what it's really doing.

17:16.680 --> 17:17.760
 Oh, I wish.

17:17.760 --> 17:20.040
 I'm a better programmer now than I was in 2014.

17:20.040 --> 17:21.840
 I said, Kira, that was the first tool

17:21.840 --> 17:23.400
 that I wrote that was usable.

17:23.400 --> 17:25.320
 I wouldn't say the code was great.

17:25.320 --> 17:27.160
 I still wouldn't say my code is great.

17:28.800 --> 17:31.480
 So how was your evolution as a programmer except practice?

17:31.480 --> 17:33.840
 So you started with C.

17:33.840 --> 17:35.520
 At which point did you pick up Python?

17:35.520 --> 17:37.040
 Because you're pretty big in Python now.

17:37.040 --> 17:39.920
 Now, yeah, in college.

17:39.920 --> 17:42.480
 I went to Carnegie Mellon when I was 22.

17:42.480 --> 17:43.320
 I went back.

17:43.320 --> 17:44.160
 I'm like, all right,

17:44.160 --> 17:46.600
 I'm gonna take all your hardest CS courses.

17:46.600 --> 17:47.600
 We'll see how I do, right?

17:47.600 --> 17:48.520
 Like, did I miss anything

17:48.520 --> 17:51.480
 by not having a real undergraduate education?

17:51.480 --> 17:54.200
 Took operating systems, compilers, AI,

17:54.200 --> 17:56.840
 and they're like a freshman wheat or math course.

17:58.560 --> 18:00.480
 And...

18:00.480 --> 18:02.120
 Operating systems, some of those classes

18:02.120 --> 18:04.160
 you mentioned are pretty tough, actually.

18:04.160 --> 18:05.560
 They're great.

18:05.560 --> 18:08.600
 At least the 2012, circa 2012,

18:08.600 --> 18:12.200
 operating systems and compilers were two of the,

18:12.200 --> 18:14.360
 they were the best classes I've ever taken in my life.

18:14.360 --> 18:15.560
 Because you write an operating system

18:15.560 --> 18:16.800
 and you write a compiler.

18:18.040 --> 18:19.720
 I wrote my operating system in C

18:19.720 --> 18:21.320
 and I wrote my compiler in Haskell,

18:21.320 --> 18:26.320
 but somehow I picked up Python that semester as well.

18:26.360 --> 18:28.040
 I started using it for the CTFs, actually.

18:28.040 --> 18:30.280
 That's when I really started to get into CTFs

18:30.280 --> 18:33.320
 and CTFs, you're all, it's a race against the clock.

18:33.320 --> 18:35.080
 So I can't write things in C.

18:35.080 --> 18:36.200
 Oh, there's a clock component.

18:36.200 --> 18:38.000
 So you really want to use the programming languages

18:38.000 --> 18:38.920
 so you can be fastest.

18:38.920 --> 18:41.400
 48 hours, pwn as many of these challenges as you can.

18:41.400 --> 18:42.240
 Pwn.

18:42.240 --> 18:43.920
 Yeah, you got like a hundred points of challenge.

18:43.920 --> 18:45.360
 Whatever team gets the most.

18:46.280 --> 18:50.200
 You were both at Facebook and Google for a brief stint.

18:50.200 --> 18:51.040
 Yeah.

18:51.040 --> 18:54.880
 With Project Zero actually at Google for five months

18:54.880 --> 18:56.920
 where you developed Kira.

18:56.920 --> 18:59.840
 What was Project Zero about in general?

18:59.840 --> 19:03.960
 What, I'm just curious about the security efforts

19:03.960 --> 19:05.160
 in these companies.

19:05.160 --> 19:08.760
 Well, Project Zero started the same time I went there.

19:08.760 --> 19:10.040
 What years are there?

19:11.080 --> 19:12.320
 2015.

19:12.320 --> 19:13.160
 2015.

19:13.160 --> 19:15.040
 So that was right at the beginning of Project Zero.

19:15.040 --> 19:16.200
 It's small.

19:16.200 --> 19:18.840
 It's Google's offensive security team.

19:21.840 --> 19:25.640
 I'll try to give the best public facing explanation

19:25.640 --> 19:26.480
 that I can.

19:26.480 --> 19:31.480
 So the idea is basically these vulnerabilities

19:31.760 --> 19:33.200
 exist in the world.

19:33.200 --> 19:35.200
 Nation states have them.

19:35.200 --> 19:37.440
 Some high powered bad actors have them.

19:39.800 --> 19:44.160
 Sometime people will find these vulnerabilities

19:44.160 --> 19:47.800
 and submit them in bug bounties to the companies.

19:47.800 --> 19:49.480
 But a lot of the companies don't really care.

19:49.480 --> 19:51.160
 They don't even fix the bug.

19:51.160 --> 19:53.840
 It doesn't hurt for there to be a vulnerability.

19:53.840 --> 19:55.920
 So Project Zero is like, we're going to do it different.

19:55.920 --> 19:57.880
 We're going to announce a vulnerability

19:57.880 --> 19:59.680
 and we're going to give them 90 days to fix it.

19:59.680 --> 20:00.840
 And then whether they fix it or not,

20:00.840 --> 20:03.240
 we're going to drop the zero day.

20:03.240 --> 20:04.120
 Oh, wow.

20:04.120 --> 20:04.960
 We're going to drop the weapon.

20:04.960 --> 20:05.920
 That's so cool.

20:05.920 --> 20:07.520
 That is so cool.

20:07.520 --> 20:09.240
 I love the deadlines.

20:09.240 --> 20:10.080
 Oh, that's so cool.

20:10.080 --> 20:10.920
 Give them real deadlines.

20:10.920 --> 20:12.360
 Yeah.

20:12.360 --> 20:15.800
 And I think it's done a lot for moving the industry forward.

20:15.800 --> 20:18.920
 I watched your coding sessions on the streamed online.

20:20.360 --> 20:22.720
 You code things up, the basic projects,

20:22.720 --> 20:24.000
 usually from scratch.

20:24.000 --> 20:28.200
 I would say sort of as a programmer myself,

20:28.200 --> 20:30.360
 just watching you that you type really fast

20:30.360 --> 20:34.520
 and your brain works in both brilliant and chaotic ways.

20:34.520 --> 20:35.800
 I don't know if that's always true,

20:35.800 --> 20:37.600
 but certainly for the live streams.

20:37.600 --> 20:40.360
 So it's interesting to me because I'm more,

20:40.360 --> 20:43.520
 I'm much slower and systematic and careful.

20:43.520 --> 20:44.920
 And you just move, I mean,

20:44.920 --> 20:46.960
 probably in order of magnitude faster.

20:48.040 --> 20:51.080
 So I'm curious, is there a method to your madness?

20:51.080 --> 20:53.040
 Is it just who you are?

20:53.040 --> 20:54.720
 There's pros and cons.

20:54.720 --> 20:58.080
 There's pros and cons to my programming style.

20:58.080 --> 20:59.440
 And I'm aware of them.

20:59.440 --> 21:03.560
 Like if you ask me to like get something up

21:03.560 --> 21:05.400
 and working quickly with like an API

21:05.400 --> 21:06.760
 that's kind of undocumented,

21:06.760 --> 21:08.160
 I will do this super fast

21:08.160 --> 21:10.200
 because I will throw things at it until it works.

21:10.200 --> 21:14.720
 If you ask me to take a vector and rotate it 90 degrees

21:14.720 --> 21:17.400
 and then flip it over the XY plane,

21:19.320 --> 21:22.320
 I'll spam program for two hours and won't get it.

21:22.320 --> 21:23.920
 Oh, because it's something that you could do

21:23.920 --> 21:26.280
 with a sheet of paper, think through design,

21:26.280 --> 21:30.440
 and then just, do you really just throw stuff at the wall

21:30.440 --> 21:34.640
 and you get so good at it that it usually works?

21:34.640 --> 21:36.960
 I should become better at the other kind as well.

21:36.960 --> 21:39.440
 Sometimes I'll do things methodically.

21:39.440 --> 21:41.160
 It's nowhere near as entertaining on the Twitch streams.

21:41.160 --> 21:43.520
 I do exaggerate it a bit on the Twitch streams as well.

21:43.520 --> 21:44.680
 The Twitch streams, I mean,

21:44.680 --> 21:45.840
 what do you want to see a game or you want to see

21:45.840 --> 21:46.840
 actions per minute, right?

21:46.840 --> 21:48.160
 I'll show you APM for programming too.

21:48.160 --> 21:50.280
 Yeah, I recommend people go to it.

21:50.280 --> 21:53.400
 I think I watched, I watched probably several hours

21:53.400 --> 21:56.240
 of you, like I've actually left you programming

21:56.240 --> 21:59.080
 in the background while I was programming

21:59.080 --> 22:02.040
 because you made me, it was like watching

22:02.040 --> 22:03.160
 a really good gamer.

22:03.160 --> 22:06.280
 It's like energizes you because you're like moving so fast.

22:06.280 --> 22:07.600
 It's so, it's awesome.

22:07.600 --> 22:11.240
 It's inspiring and it made me jealous that like,

22:12.320 --> 22:14.320
 because my own programming is inadequate

22:14.320 --> 22:15.520
 in terms of speed.

22:15.520 --> 22:17.000
 Oh, I was like.

22:17.000 --> 22:20.520
 So I'm twice as frantic on the live streams

22:20.520 --> 22:22.680
 as I am when I code without them.

22:22.680 --> 22:23.760
 It's super entertaining.

22:23.760 --> 22:26.440
 So I wasn't even paying attention to what you were coding,

22:26.440 --> 22:27.280
 which is great.

22:27.280 --> 22:30.840
 It's just watching you switch windows and Vim I guess

22:30.840 --> 22:31.680
 is the most.

22:31.680 --> 22:33.080
 Yeah, there's Vim on screen.

22:33.080 --> 22:34.440
 I've developed the workload at Facebook

22:34.440 --> 22:35.640
 and stuck with it.

22:35.640 --> 22:37.360
 How do you learn new programming tools,

22:37.360 --> 22:39.480
 ideas, techniques these days?

22:39.480 --> 22:42.120
 What's your like a methodology for learning new things?

22:42.120 --> 22:47.120
 So I wrote for comma, the distributed file systems

22:48.800 --> 22:50.720
 out in the world are extremely complex.

22:50.720 --> 22:55.280
 Like if you want to install something like like like Ceph,

22:55.280 --> 22:58.760
 Ceph is I think the like open infrastructure

22:58.760 --> 23:00.320
 distributed file system,

23:00.320 --> 23:04.000
 or there's like newer ones like seaweed FS,

23:04.000 --> 23:06.880
 but these are all like 10,000 plus line projects.

23:06.880 --> 23:09.480
 I think some of them are even a hundred thousand line

23:09.480 --> 23:11.120
 and just configuring them as a nightmare.

23:11.120 --> 23:16.120
 So I wrote, I wrote one, it's 200 lines

23:16.440 --> 23:18.880
 and it's, it uses like NGINX and volume servers

23:18.880 --> 23:21.640
 and has this little master server that I wrote in Go.

23:21.640 --> 23:24.200
 And the way I go, this,

23:24.200 --> 23:27.240
 if I would say that I'm proud per line of any code I wrote,

23:27.240 --> 23:29.160
 maybe there's some exploits that I think are beautiful.

23:29.160 --> 23:31.320
 And then this, this is 200 lines.

23:31.320 --> 23:33.720
 And just the way that I thought about it,

23:33.720 --> 23:34.600
 I think was very good.

23:34.600 --> 23:35.880
 And the reason it's very good is because

23:35.880 --> 23:37.600
 that was the fourth version of it that I wrote.

23:37.600 --> 23:39.320
 And I had three versions that I threw away.

23:39.320 --> 23:40.960
 You mentioned, did you say Go?

23:40.960 --> 23:41.800
 I wrote in Go, yeah.

23:41.800 --> 23:42.640
 In Go.

23:42.640 --> 23:43.840
 Is that a functional language?

23:43.840 --> 23:45.240
 I forget what Go is.

23:45.240 --> 23:47.120
 Go is Google's language.

23:47.120 --> 23:48.200
 Right.

23:48.200 --> 23:49.440
 It's not functional.

23:49.440 --> 23:54.440
 It's some, it's like in a way it's C++, but easier.

23:56.160 --> 23:58.160
 It's, it's strongly typed.

23:58.160 --> 23:59.720
 It has a nice ecosystem around it.

23:59.720 --> 24:02.680
 When I first looked at it, I was like, this is like Python,

24:02.680 --> 24:04.560
 but it takes twice as long to do anything.

24:04.560 --> 24:05.560
 Yeah.

24:05.560 --> 24:09.560
 Now that I've, OpenPilot is migrating to C,

24:09.560 --> 24:10.960
 but it still has large Python components.

24:10.960 --> 24:12.720
 I now understand why Python doesn't work

24:12.720 --> 24:15.800
 for large code bases and why you want something like Go.

24:15.800 --> 24:16.640
 Interesting.

24:16.640 --> 24:18.640
 So why, why doesn't Python work for,

24:18.640 --> 24:21.680
 so even most, speaking for myself at least,

24:21.680 --> 24:23.360
 like we do a lot of stuff,

24:23.360 --> 24:26.480
 basically demo level work with autonomous vehicles

24:26.480 --> 24:28.240
 and most of the work is Python.

24:28.240 --> 24:29.200
 Yeah.

24:29.200 --> 24:32.400
 Why doesn't Python work for large code bases?

24:32.400 --> 24:37.400
 Because, well, lack of type checking is a big part.

24:37.960 --> 24:39.360
 So errors creep in.

24:39.360 --> 24:40.200
 Yeah.

24:40.200 --> 24:41.920
 And like, you don't know,

24:41.920 --> 24:45.320
 the compiler can tell you like nothing, right?

24:45.320 --> 24:47.600
 So everything is either, you know,

24:48.440 --> 24:49.880
 like, like syntax errors, fine.

24:49.880 --> 24:51.800
 But if you misspell a variable in Python,

24:51.800 --> 24:53.000
 the compiler won't catch that.

24:53.000 --> 24:56.600
 There's like linters that can catch it some of the time.

24:56.600 --> 24:57.560
 There's no types.

24:57.560 --> 25:00.520
 This is really the biggest downside.

25:00.520 --> 25:02.640
 And then, well, Python's slow, but that's not related to it.

25:02.640 --> 25:04.800
 Well, maybe it's kind of related to it, so it's lack of.

25:04.800 --> 25:06.600
 So what's, what's in your toolbox these days?

25:06.600 --> 25:07.440
 Is it Python?

25:07.440 --> 25:08.280
 What else?

25:08.280 --> 25:10.120
 I need to move to something else.

25:10.120 --> 25:12.840
 My adventure into dependently typed languages,

25:12.840 --> 25:14.200
 I love these languages.

25:14.200 --> 25:17.480
 They just have like syntax from the 80s.

25:18.480 --> 25:21.080
 What do you think about JavaScript?

25:21.080 --> 25:23.960
 ES6, like the modern, or TypeScript?

25:23.960 --> 25:26.080
 JavaScript is,

25:26.080 --> 25:28.960
 the whole ecosystem is unbelievably confusing.

25:28.960 --> 25:29.800
 Right.

25:29.800 --> 25:32.800
 NPM updates a package from 0.2.2 to 0.2.5,

25:32.800 --> 25:34.520
 and that breaks your Babel linter,

25:34.520 --> 25:37.040
 which translates your ES5 into ES6,

25:37.040 --> 25:39.920
 which doesn't run on, so.

25:39.920 --> 25:42.440
 Why do I have to compile my JavaScript again, huh?

25:42.440 --> 25:44.000
 It may be the future, though.

25:44.000 --> 25:45.760
 You think about, I mean,

25:45.760 --> 25:47.360
 I've embraced JavaScript recently,

25:47.360 --> 25:52.280
 just because, just like I've continually embraced PHP,

25:52.280 --> 25:54.840
 it seems that these worst possible languages

25:54.840 --> 25:57.440
 live on for the longest, like cockroaches never die.

25:57.440 --> 25:58.480
 Yeah.

25:58.480 --> 26:00.720
 Well, it's in the browser, and it's fast.

26:00.720 --> 26:01.680
 It's fast.

26:01.680 --> 26:02.520
 Yeah.

26:02.520 --> 26:04.880
 It's in the browser, and compute might stay,

26:04.880 --> 26:06.440
 become, you know, the browser.

26:06.440 --> 26:09.000
 It's unclear what the role of the browser is

26:09.000 --> 26:12.320
 in terms of distributed computation in the future, so.

26:13.600 --> 26:15.240
 JavaScript is definitely here to stay.

26:15.240 --> 26:16.080
 Yeah.

26:16.080 --> 26:18.160
 It's interesting if autonomous vehicles

26:18.160 --> 26:19.480
 will run on JavaScript one day.

26:19.480 --> 26:21.800
 I mean, you have to consider these possibilities.

26:21.800 --> 26:24.280
 Well, all our debug tools are JavaScript.

26:24.280 --> 26:26.040
 We actually just open sourced them.

26:26.040 --> 26:27.400
 We have a tool, Explorer,

26:27.400 --> 26:29.200
 which you can annotate your disengagements,

26:29.200 --> 26:30.080
 and we have a tool, Cabana,

26:30.080 --> 26:32.920
 which lets you analyze the can traffic from the car.

26:32.920 --> 26:35.240
 So basically, anytime you're visualizing something

26:35.240 --> 26:37.720
 about the log, you're using JavaScript.

26:37.720 --> 26:41.280
 Well, the web is the best UI toolkit by far, so.

26:41.280 --> 26:42.120
 And then, you know what?

26:42.120 --> 26:42.960
 You're coding in JavaScript.

26:42.960 --> 26:43.800
 We have a React guy.

26:43.800 --> 26:44.640
 He's good.

26:44.640 --> 26:46.080
 React, nice.

26:46.080 --> 26:46.920
 Let's get into it.

26:46.920 --> 26:48.800
 So let's talk autonomous vehicles.

26:48.800 --> 26:49.640
 Yeah.

26:49.640 --> 26:50.600
 You founded Comma AI.

26:51.760 --> 26:54.920
 Let's, at a high level,

26:54.920 --> 26:57.840
 how did you get into the world of vehicle automation?

26:57.840 --> 26:59.880
 Can you also just, for people who don't know,

26:59.880 --> 27:01.360
 tell the story of Comma AI?

27:01.360 --> 27:02.880
 Sure.

27:02.880 --> 27:06.080
 So I was working at this AI startup,

27:06.080 --> 27:08.160
 and a friend approached me,

27:08.160 --> 27:12.040
 and he's like, dude, I don't know where this is going,

27:12.040 --> 27:15.160
 but the coolest applied AI problem today

27:15.160 --> 27:16.480
 is self driving cars.

27:16.480 --> 27:17.800
 I'm like, well, absolutely.

27:18.800 --> 27:20.520
 You want to meet with Elon Musk,

27:20.520 --> 27:24.560
 and he's looking for somebody to build a vision system

27:24.560 --> 27:27.560
 for autopilot.

27:27.560 --> 27:29.320
 This is when they were still on AP1.

27:29.320 --> 27:30.840
 They were still using Mobileye.

27:30.840 --> 27:33.680
 Elon, back then, was looking for a replacement,

27:33.680 --> 27:36.160
 and he brought me in,

27:36.160 --> 27:37.320
 and we talked about a contract

27:37.320 --> 27:39.040
 where I would deliver something

27:39.040 --> 27:41.360
 that meets Mobileye level performance.

27:41.360 --> 27:43.920
 I would get paid $12 million if I could deliver it tomorrow,

27:43.920 --> 27:45.280
 and I would lose $1 million

27:45.280 --> 27:46.720
 for every month I didn't deliver.

27:46.720 --> 27:47.720
 Yeah.

27:47.720 --> 27:49.080
 So I was like, okay, this is a great deal.

27:49.080 --> 27:50.880
 This is a super exciting challenge.

27:52.360 --> 27:53.200
 You know what?

27:53.200 --> 27:54.400
 Even if it takes me 10 months,

27:54.400 --> 27:55.360
 I get $2 million.

27:55.360 --> 27:56.200
 It's good.

27:56.200 --> 27:57.120
 Maybe I can finish up in five.

27:57.120 --> 27:58.120
 Maybe I don't finish it at all,

27:58.120 --> 27:58.960
 and I get paid nothing,

27:58.960 --> 28:00.840
 and I can still work for 12 months for free.

28:00.840 --> 28:02.920
 So maybe just take a pause on that.

28:02.920 --> 28:04.240
 I'm also curious about this

28:04.240 --> 28:06.200
 because I've been working in robotics for a long time,

28:06.200 --> 28:07.640
 and I'm curious to see a person like you

28:07.640 --> 28:11.040
 just step in and sort of somewhat naive,

28:11.040 --> 28:11.960
 but brilliant, right?

28:11.960 --> 28:13.960
 So that's the best place to be

28:13.960 --> 28:17.200
 because you basically full steam take on a problem.

28:17.200 --> 28:19.680
 How confident, how, from that time,

28:19.680 --> 28:21.280
 because you know a lot more now,

28:21.280 --> 28:23.440
 at that time, how hard do you think it is

28:23.440 --> 28:25.840
 to solve all of autonomous driving?

28:25.840 --> 28:30.560
 I remember I suggested to Elon in the meeting

28:30.560 --> 28:33.080
 putting a GPU behind each camera

28:33.080 --> 28:35.120
 to keep the compute local.

28:35.120 --> 28:38.000
 This is an incredibly stupid idea.

28:38.000 --> 28:39.400
 I leave the meeting 10 minutes later,

28:39.400 --> 28:41.520
 and I'm like, I could have spent a little bit of time

28:41.520 --> 28:42.760
 thinking about this problem before I went in.

28:42.760 --> 28:44.160
 Why is it a stupid idea?

28:44.160 --> 28:46.240
 Oh, just send all your cameras to one big GPU.

28:46.240 --> 28:48.200
 You're much better off doing that.

28:48.200 --> 28:49.040
 Oh, sorry.

28:49.040 --> 28:50.200
 You said behind every camera have a GPU.

28:50.200 --> 28:51.360
 Every camera have a small GPU.

28:51.360 --> 28:52.720
 I was like, oh, I'll put the first few layers

28:52.720 --> 28:54.040
 of my comms there.

28:54.040 --> 28:56.040
 Ugh, why'd I say that?

28:56.040 --> 28:56.880
 That's possible.

28:56.880 --> 28:58.960
 It's possible, but it's a bad idea.

28:58.960 --> 29:00.440
 It's not obviously a bad idea.

29:00.440 --> 29:01.280
 Pretty obviously bad,

29:01.280 --> 29:02.920
 but whether it's actually a bad idea or not,

29:02.920 --> 29:05.240
 I left that meeting with Elon, beating myself up.

29:05.240 --> 29:07.000
 I'm like, why'd I say something stupid?

29:07.000 --> 29:10.720
 Yeah, you haven't at least thought through

29:10.720 --> 29:12.200
 every aspect of it, yeah.

29:12.200 --> 29:13.360
 He's very sharp too.

29:13.360 --> 29:15.760
 Usually in life, I get away with saying stupid things

29:15.760 --> 29:16.920
 and then kind of course,

29:16.920 --> 29:18.520
 oh, right away he called me out about it.

29:18.520 --> 29:21.080
 And usually in life, I get away with saying stupid things

29:21.080 --> 29:26.080
 and then a lot of times people don't even notice

29:26.080 --> 29:28.200
 and I'll correct it and bring the conversation back.

29:28.200 --> 29:31.840
 But with Elon, it was like, nope, okay, well.

29:31.840 --> 29:33.520
 That's not at all why the contract fell through.

29:33.520 --> 29:35.520
 I was much more prepared the second time I met him.

29:35.520 --> 29:39.640
 Yeah, but in general, how hard did you think it is?

29:39.640 --> 29:43.680
 Like 12 months is a tough timeline.

29:43.680 --> 29:45.720
 Oh, I just thought I'd clone Mobileye IQ3.

29:45.720 --> 29:47.560
 I didn't think I'd solve level five self driving

29:47.560 --> 29:48.400
 or anything.

29:48.400 --> 29:52.760
 So the goal there was to do lane keeping, good lane keeping.

29:52.760 --> 29:55.480
 I saw, my friend showed me the outputs from a Mobileye

29:55.480 --> 29:57.080
 and the outputs from a Mobileye was just basically

29:57.080 --> 29:59.360
 two lanes at a position of a lead car.

29:59.360 --> 30:02.160
 I'm like, I can gather a data set and train this net

30:02.160 --> 30:04.760
 in weeks and I did.

30:04.760 --> 30:07.520
 Well, first time I tried the implementation of Mobileye

30:07.520 --> 30:10.360
 in a Tesla, I was really surprised how good it is.

30:11.200 --> 30:12.240
 It's going incredibly good.

30:12.240 --> 30:14.280
 Cause I thought it's just cause I've done a lot

30:14.280 --> 30:17.960
 of computer vision, I thought it'd be a lot harder

30:17.960 --> 30:20.000
 to create a system that that's stable.

30:20.960 --> 30:24.200
 So I was personally surprised, you know,

30:24.200 --> 30:25.040
 have to admit it.

30:25.040 --> 30:27.800
 Cause I was kind of skeptical before trying it.

30:27.800 --> 30:31.160
 Cause I thought it would go in and out a lot more.

30:31.160 --> 30:34.960
 It would get disengaged a lot more and it's pretty robust.

30:36.160 --> 30:41.160
 So what, how hard is the problem when you tackled it?

30:42.080 --> 30:44.480
 So I think AP1 was great.

30:44.480 --> 30:49.000
 Like Elon talked about disengagements on the 405 down in LA

30:49.000 --> 30:51.000
 with like the lane marks are kind of faded

30:51.000 --> 30:52.960
 and the Mobileye system would drop out.

30:53.920 --> 30:57.760
 Like I had something up and working that I would say

30:57.760 --> 31:01.400
 was like the same quality in three months.

31:02.480 --> 31:04.720
 Same quality, but how do you know?

31:04.720 --> 31:07.360
 You say stuff like that confidently, but you can't,

31:07.360 --> 31:11.080
 and I love it, but the question is you can't,

31:12.080 --> 31:14.400
 you're kind of going by feel cause you test it out.

31:14.400 --> 31:15.440
 Absolutely, absolutely.

31:15.440 --> 31:18.320
 Like I would take, I borrowed my friend's Tesla.

31:18.320 --> 31:20.600
 I would take AP1 out for a drive

31:20.600 --> 31:22.160
 and then I would take my system out for a drive.

31:22.160 --> 31:24.280
 And it seems reasonably like the same.

31:25.920 --> 31:30.320
 So the 405, how hard is it to create something

31:30.320 --> 31:34.040
 that could actually be a product that's deployed?

31:34.040 --> 31:37.120
 I mean, I've read an article where Elon,

31:37.120 --> 31:40.640
 this respondent said something about you saying

31:40.640 --> 31:45.640
 that to build autopilot is more complicated

31:46.920 --> 31:51.720
 than a single George Hodge level job.

31:51.720 --> 31:55.360
 How hard is that job to create something

31:55.360 --> 31:57.280
 that would work across globally?

31:58.800 --> 32:00.480
 Why don't think globally is the challenge?

32:00.480 --> 32:02.080
 But Elon followed that up by saying

32:02.080 --> 32:04.760
 it's gonna take two years in a company of 10 people.

32:04.760 --> 32:07.760
 And here I am four years later with a company of 12 people.

32:07.760 --> 32:09.800
 And I think we still have another two to go.

32:09.800 --> 32:11.160
 Two years, so yeah.

32:11.160 --> 32:15.840
 So what do you think about how Tesla is progressing

32:15.840 --> 32:19.080
 with autopilot of V2, V3?

32:19.080 --> 32:23.000
 I think we've kept pace with them pretty well.

32:23.960 --> 32:26.720
 I think navigate and autopilot is terrible.

32:26.720 --> 32:31.000
 We had some demo features internally of the same stuff

32:31.000 --> 32:32.080
 and we would test it.

32:32.080 --> 32:33.320
 And I'm like, I'm not shipping this

32:33.320 --> 32:35.160
 even as like open source software to people.

32:35.160 --> 32:37.280
 Why do you think it's terrible?

32:37.280 --> 32:39.480
 Consumer Reports does a great job of describing it.

32:39.480 --> 32:41.160
 Like when it makes a lane change,

32:41.160 --> 32:43.520
 it does it worse than a human.

32:43.520 --> 32:46.880
 You shouldn't ship things like autopilot, open pilot.

32:46.880 --> 32:49.680
 They lane keep better than a human.

32:49.680 --> 32:53.360
 If you turn it on for a stretch of a highway,

32:53.360 --> 32:56.600
 like an hour long, it's never gonna touch a lane line.

32:56.600 --> 32:58.960
 Human will touch probably a lane line twice.

32:58.960 --> 33:00.000
 You just inspired me.

33:00.000 --> 33:02.120
 I don't know if you're grounded in data on that.

33:02.120 --> 33:03.200
 I read your paper.

33:03.200 --> 33:05.320
 Okay, but that's interesting.

33:05.320 --> 33:10.320
 I wonder actually how often we touch lane lines

33:10.560 --> 33:11.960
 in general, like a little bit,

33:11.960 --> 33:13.440
 because it is.

33:13.440 --> 33:14.920
 I could answer that question pretty easily

33:14.920 --> 33:15.760
 with the common data set.

33:15.760 --> 33:16.960
 Yeah, I'm curious.

33:16.960 --> 33:17.800
 I've never answered it.

33:17.800 --> 33:18.640
 I don't know.

33:18.640 --> 33:19.960
 I just, two is like my personal.

33:19.960 --> 33:21.720
 It feels right.

33:21.720 --> 33:22.560
 That's interesting.

33:22.560 --> 33:23.800
 Because every time you touch a lane,

33:23.800 --> 33:26.720
 that's a source of a little bit of stress

33:26.720 --> 33:29.280
 and kind of lane keeping is removing that stress.

33:29.280 --> 33:32.320
 That's ultimately the biggest value add honestly

33:32.320 --> 33:35.520
 is just removing the stress of having to stay in lane.

33:35.520 --> 33:39.000
 And I think honestly, I don't think people fully realize,

33:39.000 --> 33:41.920
 first of all, that that's a big value add,

33:41.920 --> 33:44.960
 but also that that's all it is.

33:44.960 --> 33:48.560
 And that not only, I find it a huge value add.

33:48.560 --> 33:50.400
 I drove down when we moved to San Diego,

33:50.400 --> 33:53.320
 I drove down in a enterprise rental car and I missed it.

33:53.320 --> 33:55.440
 So I missed having the system so much.

33:55.440 --> 34:00.280
 It's so much more tiring to drive without it.

34:00.280 --> 34:02.920
 It is that lane centering.

34:02.920 --> 34:04.800
 That's the key feature.

34:04.800 --> 34:05.640
 Yeah.

34:06.560 --> 34:08.920
 And in a way, it's the only feature

34:08.920 --> 34:11.000
 that actually adds value to people's lives

34:11.000 --> 34:12.160
 in autonomous vehicles today.

34:12.160 --> 34:13.800
 Waymo does not add value to people's lives.

34:13.800 --> 34:15.840
 It's a more expensive, slower Uber.

34:15.840 --> 34:18.600
 Maybe someday it'll be this big cliff where it adds value,

34:18.600 --> 34:19.440
 but I don't usually believe it.

34:19.440 --> 34:20.280
 It is fascinating.

34:20.280 --> 34:22.520
 I haven't talked to, this is good.

34:22.520 --> 34:25.760
 Cause I haven't, I have intuitively,

34:25.760 --> 34:28.240
 but I think we're making it explicit now.

34:28.240 --> 34:33.240
 I actually believe that really good lane keeping

34:35.440 --> 34:37.200
 is a reason to buy a car.

34:37.200 --> 34:39.680
 Will be a reason to buy a car and it's a huge value add.

34:39.680 --> 34:41.720
 I've never, until we just started talking about it,

34:41.720 --> 34:43.840
 I haven't really quite realized it.

34:43.840 --> 34:48.840
 That I've felt with Elon's chase of level four

34:49.400 --> 34:52.320
 is not the correct chase.

34:52.320 --> 34:55.920
 It was on, cause you should just say Tesla has the best

34:55.920 --> 34:58.280
 as if from a Tesla perspective, say,

34:58.280 --> 35:00.560
 Tesla has the best lane keeping.

35:00.560 --> 35:04.120
 Comma AI should say, Comma AI is the best lane keeping.

35:04.120 --> 35:05.560
 And that is it.

35:05.560 --> 35:06.400
 Yeah. Yeah.

35:06.400 --> 35:07.960
 So do you think?

35:07.960 --> 35:09.880
 You have to do the longitudinal as well.

35:09.880 --> 35:10.880
 You can't just lane keep.

35:10.880 --> 35:12.880
 You have to do ACC,

35:12.880 --> 35:15.760
 but ACC is much more forgiving than lane keep,

35:15.760 --> 35:17.360
 especially on the highway.

35:17.360 --> 35:21.920
 By the way, are you Comma AI's camera only, correct?

35:21.920 --> 35:23.680
 No, we use the radar.

35:23.680 --> 35:25.440
 From the car, you're able to get the, okay.

35:25.440 --> 35:26.960
 Hmm?

35:26.960 --> 35:28.800
 We can do a camera only now.

35:28.800 --> 35:29.640
 It's gotten to the point,

35:29.640 --> 35:33.440
 but we leave the radar there as like a, it's fusion now.

35:33.440 --> 35:36.520
 Okay, so let's maybe talk through some of the system specs

35:36.520 --> 35:37.920
 on the hardware.

35:37.920 --> 35:42.880
 What's the hardware side of what you're providing?

35:42.880 --> 35:44.720
 What's the capabilities on the software side

35:44.720 --> 35:46.800
 with OpenPilot and so on?

35:46.800 --> 35:51.800
 So OpenPilot, as the box that we sell, that it runs on,

35:52.200 --> 35:54.440
 it's a phone in a plastic case.

35:54.440 --> 35:55.280
 It's nothing special.

35:55.280 --> 35:56.680
 We sell it without the software.

35:56.680 --> 35:59.360
 So you buy the phone, it's just easy.

35:59.360 --> 36:02.160
 It'll be easy set up, but it's sold with no software.

36:03.960 --> 36:07.040
 OpenPilot right now is about to be 0.6.

36:07.040 --> 36:08.280
 When it gets to 1.0,

36:08.280 --> 36:10.120
 I think we'll be ready for a consumer product.

36:10.120 --> 36:11.600
 We're not gonna add any new features.

36:11.600 --> 36:14.120
 We're just gonna make the lane keeping really, really good.

36:14.120 --> 36:15.560
 Okay, I got it.

36:15.560 --> 36:16.560
 So what do we have right now?

36:16.560 --> 36:18.600
 It's a Snapdragon 820.

36:20.000 --> 36:24.080
 It's a Sony IMX 298 forward facing camera.

36:24.080 --> 36:26.040
 Driver monitoring camera,

36:26.040 --> 36:27.960
 it's just a selfie camera on the phone.

36:27.960 --> 36:31.640
 And a CAN transceiver,

36:31.640 --> 36:33.840
 maybe there's a little thing called PANDAS.

36:33.840 --> 36:36.560
 And they talk over USB to the phone

36:36.560 --> 36:37.720
 and then they have three CAN buses

36:37.720 --> 36:39.000
 that they talk to the car.

36:39.960 --> 36:42.280
 One of those CAN buses is the radar CAN bus.

36:42.280 --> 36:44.320
 One of them is the main car CAN bus

36:44.320 --> 36:46.240
 and the other one is the proxy camera CAN bus.

36:46.240 --> 36:48.400
 We leave the existing camera in place

36:48.400 --> 36:50.720
 so we don't turn AEB off.

36:50.720 --> 36:52.320
 Right now, we still turn AEB off

36:52.320 --> 36:53.600
 if you're using our longitudinal,

36:53.600 --> 36:55.600
 but we're gonna fix that before 1.0.

36:55.600 --> 36:56.440
 Got it.

36:56.440 --> 36:57.280
 Wow, that's cool.

36:57.280 --> 36:59.040
 And it's CAN both ways.

36:59.040 --> 37:03.320
 So how are you able to control vehicles?

37:03.320 --> 37:05.440
 So we proxy,

37:05.440 --> 37:06.760
 the vehicles that we work with

37:06.760 --> 37:10.160
 already have a lane keeping assist system.

37:10.160 --> 37:13.800
 So lane keeping assist can mean a huge variety of things.

37:13.800 --> 37:17.800
 It can mean it will apply a small torque to the wheel

37:17.800 --> 37:21.160
 after you've already crossed a lane line by a foot,

37:21.160 --> 37:23.920
 which is the system in the older Toyotas

37:23.920 --> 37:26.520
 versus like, I think Tesla still calls it

37:26.520 --> 37:27.560
 lane keeping assist,

37:27.560 --> 37:28.840
 where it'll keep you perfectly

37:28.840 --> 37:31.060
 in the center of the lane on the highway.

37:32.320 --> 37:35.080
 You can control, like with the joystick, the car.

37:35.080 --> 37:37.920
 So these cars already have the capability of drive by wire.

37:37.920 --> 37:42.920
 So is it trivial to convert a car that it operates with?

37:45.400 --> 37:47.560
 OpenPILOT is able to control the steering?

37:48.480 --> 37:49.720
 Oh, a new car or a car that we,

37:49.720 --> 37:52.800
 so we have support now for 45 different makes of cars.

37:52.800 --> 37:54.880
 What are the cars in general?

37:54.880 --> 37:56.360
 Mostly Hondas and Toyotas.

37:56.360 --> 38:00.620
 We support almost every Honda and Toyota made this year.

38:01.680 --> 38:04.480
 And then a bunch of GMs, a bunch of Subarus,

38:04.480 --> 38:05.320
 a bunch of Chevys.

38:05.320 --> 38:06.160
 It doesn't have to be like a Prius,

38:06.160 --> 38:07.320
 it could be a Corolla as well.

38:07.320 --> 38:10.760
 Oh, the 2020 Corolla is the best car with OpenPILOT.

38:10.760 --> 38:11.720
 It just came out.

38:11.720 --> 38:14.160
 The actuator has less lag than the older Corolla.

38:15.800 --> 38:18.240
 I think I started watching a video with your,

38:18.240 --> 38:21.400
 I mean, the way you make videos is awesome.

38:21.400 --> 38:24.220
 You're just literally at the dealership streaming.

38:24.220 --> 38:26.060
 Yeah, I had my friend on the phone,

38:26.060 --> 38:27.520
 I'm like, bro, you wanna stream for an hour?

38:27.520 --> 38:31.100
 Yeah, and basically, like if stuff goes a little wrong,

38:31.100 --> 38:33.120
 you're just like, you just go with it.

38:33.120 --> 38:33.940
 Yeah, I love it.

38:33.940 --> 38:34.780
 Well, it's real.

38:34.780 --> 38:35.600
 Yeah, it's real.

38:35.600 --> 38:39.760
 That's so beautiful and it's so in contrast

38:39.760 --> 38:42.960
 to the way other companies

38:42.960 --> 38:44.680
 would put together a video like that.

38:44.680 --> 38:46.080
 Kind of why I like to do it like that.

38:46.080 --> 38:46.920
 Good.

38:46.920 --> 38:49.840
 I mean, if you become super rich one day and successful,

38:49.840 --> 38:50.800
 I hope you keep it that way

38:50.800 --> 38:53.200
 because I think that's actually what people love,

38:53.200 --> 38:54.760
 that kind of genuine.

38:54.760 --> 38:56.520
 Oh, it's all that has value to me.

38:56.520 --> 38:59.920
 Money has no, if I sell out to like make money,

38:59.920 --> 39:01.320
 I sold out, it doesn't matter.

39:01.320 --> 39:02.160
 What do I get?

39:02.160 --> 39:03.000
 Yacht?

39:03.000 --> 39:04.560
 I don't want a yacht.

39:04.560 --> 39:09.240
 And I think Tesla's actually has a small inkling

39:09.240 --> 39:11.320
 of that as well with Autonomy Day.

39:11.320 --> 39:14.080
 They did reveal more than, I mean, of course,

39:14.080 --> 39:15.760
 there's marketing communications, you could tell,

39:15.760 --> 39:17.720
 but it's more than most companies would reveal,

39:17.720 --> 39:21.440
 which is, I hope they go towards that direction more,

39:21.440 --> 39:23.080
 other companies, GM, Ford.

39:23.080 --> 39:25.440
 Oh, Tesla's gonna win level five.

39:25.440 --> 39:26.600
 They really are.

39:26.600 --> 39:27.840
 So let's talk about it.

39:27.840 --> 39:32.280
 You think, you're focused on level two currently?

39:32.280 --> 39:33.120
 Currently.

39:33.120 --> 39:36.200
 We're gonna be one to two years behind Tesla

39:36.200 --> 39:37.200
 getting to level five.

39:37.200 --> 39:38.560
 Okay.

39:38.560 --> 39:39.400
 We're Android, right?

39:39.400 --> 39:40.220
 We're Android.

39:40.220 --> 39:41.060
 You're Android.

39:41.060 --> 39:42.280
 I'm just saying, once Tesla gets it,

39:42.280 --> 39:43.800
 we're one to two years behind.

39:43.800 --> 39:45.640
 I'm not making any timeline on when Tesla's

39:45.640 --> 39:46.480
 gonna get it. That's right.

39:46.480 --> 39:47.300
 You did, that was brilliant.

39:47.300 --> 39:48.400
 I'm sorry, Tesla investors,

39:48.400 --> 39:49.880
 if you think you're gonna have an autonomous

39:49.880 --> 39:52.460
 Robo Taxi fleet by the end of the year.

39:52.460 --> 39:53.300
 Yeah, so that's.

39:53.300 --> 39:54.960
 I'll bet against that.

39:54.960 --> 39:57.740
 So what do you think about this?

39:57.740 --> 39:59.840
 The most level four companies

40:02.000 --> 40:07.000
 are kind of just doing their usual safety driver,

40:07.280 --> 40:08.800
 doing full autonomy kind of testing.

40:08.800 --> 40:12.000
 And then Tesla does basically trying to go

40:12.000 --> 40:15.600
 from lane keeping to full autonomy.

40:15.600 --> 40:16.840
 What do you think about that approach?

40:16.840 --> 40:18.400
 How successful would it be?

40:18.400 --> 40:20.720
 It's a ton better approach.

40:20.720 --> 40:23.980
 Because Tesla is gathering data on a scale

40:23.980 --> 40:25.240
 that none of them are.

40:25.240 --> 40:29.560
 They're putting real users behind the wheel of the cars.

40:29.560 --> 40:32.260
 It's, I think, the only strategy that works.

40:33.120 --> 40:34.480
 The incremental.

40:34.480 --> 40:36.980
 Well, so there's a few components to Tesla approach

40:36.980 --> 40:38.920
 that's more than just the incrementalists.

40:38.920 --> 40:41.440
 What you spoke with is the ones, the software,

40:41.440 --> 40:43.760
 so over the air software updates.

40:43.760 --> 40:44.840
 Necessity.

40:44.840 --> 40:46.480
 I mean Waymo crews have those too.

40:46.480 --> 40:47.660
 Those aren't.

40:47.660 --> 40:48.500
 But.

40:48.500 --> 40:49.880
 Those differentiate from the automakers.

40:49.880 --> 40:52.040
 Right, no lane keeping systems have,

40:52.040 --> 40:54.840
 no cars with lane keeping system have that except Tesla.

40:54.840 --> 40:55.800
 Yeah.

40:55.800 --> 40:59.840
 And the other one is the data, the other direction,

40:59.840 --> 41:01.920
 which is the ability to query the data.

41:01.920 --> 41:03.560
 I don't think they're actually collecting

41:03.560 --> 41:04.580
 as much data as people think,

41:04.580 --> 41:08.180
 but the ability to turn on collection and turn it off.

41:09.520 --> 41:12.120
 So I'm both in the robotics world

41:12.120 --> 41:15.080
 and the psychology human factors world.

41:15.080 --> 41:18.540
 Many people believe that level two autonomy is problematic

41:18.540 --> 41:20.120
 because of the human factor.

41:20.120 --> 41:23.380
 Like the more the task is automated,

41:23.380 --> 41:26.080
 the more there's a vigilance decrement.

41:26.080 --> 41:27.240
 You start to fall asleep.

41:27.240 --> 41:28.600
 You start to become complacent,

41:28.600 --> 41:30.560
 start texting more and so on.

41:30.560 --> 41:32.320
 Do you worry about that?

41:32.320 --> 41:35.080
 Cause if we're talking about transition from lane keeping

41:35.080 --> 41:39.880
 to full autonomy, if you're spending 80% of the time,

41:39.880 --> 41:42.840
 not supervising the machine,

41:42.840 --> 41:45.480
 do you worry about what that means

41:45.480 --> 41:47.140
 to the safety of the drivers?

41:47.140 --> 41:49.640
 One, we don't consider open pilot to be 1.0

41:49.640 --> 41:52.360
 until we have 100% driver monitoring.

41:52.360 --> 41:55.040
 You can cheat right now, our driver monitoring system.

41:55.040 --> 41:56.080
 There's a few ways to cheat it.

41:56.080 --> 41:57.280
 They're pretty obvious.

41:58.200 --> 41:59.720
 We're working on making that better.

41:59.720 --> 42:02.560
 Before we ship a consumer product that can drive cars,

42:02.560 --> 42:04.240
 I want to make sure that I have driver monitoring

42:04.240 --> 42:05.480
 that you can't cheat.

42:05.480 --> 42:07.840
 What's like a successful driver monitoring system look like?

42:07.840 --> 42:11.720
 Is it all about just keeping your eyes on the road?

42:11.720 --> 42:12.760
 Well, a few things.

42:12.760 --> 42:16.640
 So that's what we went with at first for driver monitoring.

42:16.640 --> 42:18.040
 I'm checking, I'm actually looking at

42:18.040 --> 42:19.040
 where your head is looking.

42:19.040 --> 42:20.440
 The camera's not that high resolution.

42:20.440 --> 42:21.880
 Eyes are a little bit hard to get.

42:21.880 --> 42:22.920
 Well, head is this big.

42:22.920 --> 42:23.760
 I mean, that's.

42:23.760 --> 42:24.680
 Head is good.

42:24.680 --> 42:28.740
 And actually a lot of it, just psychology wise,

42:28.740 --> 42:30.760
 to have that monitor constantly there,

42:30.760 --> 42:33.480
 it reminds you that you have to be paying attention.

42:33.480 --> 42:35.120
 But we want to go further.

42:35.120 --> 42:36.400
 We just hired someone full time

42:36.400 --> 42:37.960
 to come on to do the driver monitoring.

42:37.960 --> 42:40.400
 I want to detect phone in frame

42:40.400 --> 42:42.600
 and I want to make sure you're not sleeping.

42:42.600 --> 42:44.880
 How much does the camera see of the body?

42:44.880 --> 42:47.480
 This one, not enough.

42:47.480 --> 42:48.440
 Not enough.

42:48.440 --> 42:50.760
 The next one, everything.

42:50.760 --> 42:51.600
 Well, it's interesting, Fisheye,

42:51.600 --> 42:55.240
 because we're doing just data collection, not real time.

42:55.240 --> 42:57.600
 But Fisheye is a beautiful,

42:57.600 --> 42:59.080
 being able to capture the body.

42:59.080 --> 43:03.280
 And the smartphone is really like the biggest problem.

43:03.280 --> 43:04.120
 I'll show you.

43:04.120 --> 43:06.360
 I can show you one of the pictures from our new system.

43:06.360 --> 43:09.680
 Awesome, so you're basically saying

43:09.680 --> 43:13.120
 the driver monitoring will be the answer to that.

43:13.120 --> 43:14.320
 I think the other point

43:14.320 --> 43:16.960
 that you raised in your paper is good as well.

43:16.960 --> 43:20.480
 You're not asking a human to supervise a machine

43:20.480 --> 43:21.680
 without giving them the,

43:21.680 --> 43:23.220
 they can take over at any time.

43:23.220 --> 43:24.060
 Right.

43:24.060 --> 43:25.800
 Our safety model, you can take over.

43:25.800 --> 43:27.880
 We disengage on both the gas or the brake.

43:27.880 --> 43:28.900
 We don't disengage on steering.

43:28.900 --> 43:30.020
 I don't feel you have to.

43:30.020 --> 43:31.760
 But we disengage on gas or brake.

43:31.760 --> 43:34.320
 So it's very easy for you to take over

43:34.320 --> 43:36.440
 and it's very easy for you to reengage.

43:36.440 --> 43:39.380
 That switching should be super cheap.

43:39.380 --> 43:40.240
 The cars that require,

43:40.240 --> 43:42.440
 even autopilot requires a double press.

43:42.440 --> 43:44.400
 That's almost, I see, I don't like that.

43:44.400 --> 43:48.080
 And then the cancel, to cancel in autopilot,

43:48.080 --> 43:49.040
 you either have to press cancel,

43:49.040 --> 43:51.040
 which no one knows what that is, so they press the brake.

43:51.040 --> 43:52.120
 But a lot of times you don't actually want

43:52.120 --> 43:53.380
 to press the brake.

43:53.380 --> 43:54.560
 You want to press the gas.

43:54.560 --> 43:55.920
 So you should cancel on gas.

43:55.920 --> 43:57.960
 Or wiggle the steering wheel, which is bad as well.

43:57.960 --> 43:58.920
 Wow, that's brilliant.

43:58.920 --> 44:01.440
 I haven't heard anyone articulate that point.

44:01.440 --> 44:03.480
 Oh, this is all I think about.

44:03.480 --> 44:05.880
 It's the, because I think,

44:06.960 --> 44:09.800
 I think actually Tesla has done a better job

44:09.800 --> 44:12.920
 than most automakers at making that frictionless.

44:12.920 --> 44:15.520
 But you just described that it could be even better.

44:16.600 --> 44:21.160
 I love Super Cruise as an experience once it's engaged.

44:21.160 --> 44:22.040
 I don't know if you've used it,

44:22.040 --> 44:24.040
 but getting the thing to try to engage.

44:25.040 --> 44:27.520
 Yeah, I've used the, I've driven Super Cruise a lot.

44:27.520 --> 44:29.440
 So what's your thoughts on the Super Cruise system?

44:29.440 --> 44:32.680
 You disengage Super Cruise and it falls back to ACC.

44:32.680 --> 44:34.640
 So my car's like still accelerating.

44:34.640 --> 44:36.280
 It feels weird.

44:36.280 --> 44:39.040
 Otherwise, when you actually have Super Cruise engaged

44:39.040 --> 44:41.200
 on the highway, it is phenomenal.

44:41.200 --> 44:42.320
 We bought that Cadillac.

44:42.320 --> 44:43.320
 We just sold it.

44:43.320 --> 44:45.620
 But we bought it just to like experience this.

44:45.620 --> 44:47.320
 And I wanted everyone in the office to be like,

44:47.320 --> 44:49.400
 this is what we're striving to build.

44:49.400 --> 44:51.540
 GM pioneering with the driver monitoring.

44:52.800 --> 44:55.000
 You like their driver monitoring system?

44:55.000 --> 44:56.400
 It has some bugs.

44:56.400 --> 45:00.280
 If there's a sun shining back here, it'll be blind to you.

45:00.280 --> 45:01.100
 Right.

45:01.960 --> 45:03.340
 But overall, mostly, yeah.

45:03.340 --> 45:05.920
 That's so cool that you know all this stuff.

45:05.920 --> 45:08.460
 I don't often talk to people that,

45:08.460 --> 45:10.980
 because it's such a rare car, unfortunately, currently.

45:10.980 --> 45:12.700
 We bought one explicitly for this.

45:12.700 --> 45:15.020
 We lost like 25K in the deprecation,

45:15.020 --> 45:16.700
 but I feel it's worth it.

45:16.700 --> 45:21.260
 I was very pleasantly surprised that GM system

45:21.260 --> 45:26.260
 was so innovative and really wasn't advertised much,

45:26.320 --> 45:27.460
 wasn't talked about much.

45:27.460 --> 45:28.460
 Yeah.

45:28.460 --> 45:30.420
 And I was nervous that it would die,

45:30.420 --> 45:31.860
 that it would disappear.

45:31.860 --> 45:33.500
 Well, they put it on the wrong car.

45:33.500 --> 45:34.580
 They should have put it on the Bolt

45:34.580 --> 45:36.620
 and not some weird Cadillac that nobody bought.

45:36.620 --> 45:38.420
 I think that's gonna be into,

45:38.420 --> 45:40.020
 they're saying at least it's gonna be

45:40.020 --> 45:41.820
 into their entire fleet.

45:41.820 --> 45:43.820
 So what do you think about,

45:43.820 --> 45:45.940
 as long as we're on the driver monitoring,

45:45.940 --> 45:49.280
 what do you think about Elon Musk's claim

45:49.280 --> 45:51.940
 that driver monitoring is not needed?

45:51.940 --> 45:53.700
 Normally, I love his claims.

45:53.700 --> 45:55.560
 That one is stupid.

45:55.560 --> 45:56.580
 That one is stupid.

45:56.580 --> 46:00.320
 And, you know, he's not gonna have his level five fleet

46:00.320 --> 46:01.340
 by the end of the year.

46:01.340 --> 46:04.900
 Hopefully he's like, okay, I was wrong.

46:04.900 --> 46:06.260
 I'm gonna add driver monitoring.

46:06.260 --> 46:08.260
 Because when these systems get to the point

46:08.260 --> 46:10.340
 that they're only messing up once every thousand miles,

46:10.340 --> 46:12.260
 you absolutely need driver monitoring.

46:14.060 --> 46:15.900
 So let me play, cause I agree with you,

46:15.900 --> 46:17.340
 but let me play devil's advocate.

46:17.340 --> 46:22.340
 One possibility is that without driver monitoring,

46:22.340 --> 46:26.420
 people are able to monitor, self regulate,

46:26.420 --> 46:28.260
 monitor themselves.

46:28.260 --> 46:30.500
 You know, that, so your idea is.

46:30.500 --> 46:32.860
 You've seen all the people sleeping in Teslas?

46:33.860 --> 46:37.340
 Yeah, well, I'm a little skeptical

46:37.340 --> 46:38.860
 of all the people sleeping in Teslas

46:38.860 --> 46:43.860
 because I've stopped paying attention to that kind of stuff

46:44.260 --> 46:45.660
 because I want to see real data.

46:45.660 --> 46:47.180
 It's too much glorified.

46:47.180 --> 46:48.660
 It doesn't feel scientific to me.

46:48.660 --> 46:52.500
 So I want to know how many people are really sleeping

46:52.500 --> 46:54.620
 in Teslas versus sleeping.

46:54.620 --> 46:58.060
 I was driving here sleep deprived in a car

46:58.060 --> 46:59.420
 with no automation.

46:59.420 --> 47:00.980
 I was falling asleep.

47:00.980 --> 47:02.060
 I agree that it's hypey.

47:02.060 --> 47:04.780
 It's just like, you know what?

47:04.780 --> 47:06.020
 If you want to put driver monitoring,

47:06.020 --> 47:08.420
 I rented a, my last autopilot experience

47:08.420 --> 47:12.140
 was I rented a model three in March and drove it around.

47:12.140 --> 47:13.500
 The wheel thing is annoying.

47:13.500 --> 47:15.340
 And the reason the wheel thing is annoying,

47:15.340 --> 47:16.700
 we use the wheel thing as well,

47:16.700 --> 47:18.620
 but we don't disengage on wheel.

47:18.620 --> 47:21.620
 For Tesla, you have to touch the wheel just enough

47:21.620 --> 47:25.260
 to trigger the torque sensor, to tell it that you're there,

47:25.260 --> 47:27.420
 but not enough as to disengage it,

47:28.340 --> 47:30.380
 which don't use it for two things.

47:30.380 --> 47:31.300
 Don't disengage on wheel.

47:31.300 --> 47:32.340
 You don't have to.

47:32.340 --> 47:35.300
 That whole experience, wow, beautifully put.

47:35.300 --> 47:36.300
 All of those elements,

47:36.300 --> 47:38.180
 even if you don't have driver monitoring,

47:38.180 --> 47:41.060
 that whole experience needs to be better.

47:41.060 --> 47:43.700
 Driver monitoring, I think would make,

47:43.700 --> 47:46.140
 I mean, I think Super Cruise is a better experience

47:46.140 --> 47:48.340
 once it's engaged over autopilot.

47:48.340 --> 47:50.900
 I think Super Cruise is a transition

47:50.900 --> 47:53.900
 to engagement and disengagement are significantly worse.

47:53.900 --> 47:54.900
 Yeah.

47:54.900 --> 47:56.340
 Well, there's a tricky thing,

47:56.340 --> 47:58.780
 because if I were to criticize Super Cruise is,

47:59.660 --> 48:00.740
 it's a little too crude.

48:00.740 --> 48:03.580
 And I think like six seconds or something,

48:03.580 --> 48:05.980
 if you look off road, it'll start warning you.

48:05.980 --> 48:09.020
 It's some ridiculously long period of time.

48:09.020 --> 48:11.340
 And just the way,

48:12.740 --> 48:15.740
 I think it's basically, it's a binary.

48:15.740 --> 48:17.180
 It should be adaptive.

48:17.180 --> 48:19.820
 Yeah, it needs to learn more about you.

48:19.820 --> 48:22.980
 It needs to communicate what it sees about you more.

48:24.380 --> 48:27.100
 Tesla shows what it sees about the external world.

48:27.100 --> 48:29.060
 It would be nice if Super Cruise would tell us

48:29.060 --> 48:30.780
 what it sees about the internal world.

48:30.780 --> 48:31.900
 It's even worse than that.

48:31.900 --> 48:33.260
 You press the button to engage

48:33.260 --> 48:35.380
 and it just says Super Cruise unavailable.

48:35.380 --> 48:36.220
 Yeah. Why?

48:36.220 --> 48:37.740
 Why?

48:37.740 --> 48:41.420
 Yeah, that transparency is good.

48:41.420 --> 48:45.300
 We've renamed the driver monitoring packet to driver state.

48:45.300 --> 48:46.140
 Driver state.

48:46.140 --> 48:48.220
 We have car state packet, which has the state of the car.

48:48.220 --> 48:49.380
 And you have driver state packet,

48:49.380 --> 48:50.940
 which has the state of the driver.

48:50.940 --> 48:52.060
 So what is the...

48:52.060 --> 48:53.980
 Estimate their BAC.

48:53.980 --> 48:54.820
 What's BAC?

48:54.820 --> 48:55.860
 Blood alcohol content.

48:57.260 --> 48:59.100
 You think that's possible with computer vision?

48:59.100 --> 48:59.940
 Absolutely.

49:03.300 --> 49:04.420
 To me, it's an open question.

49:04.420 --> 49:06.580
 I haven't looked into it too much.

49:06.580 --> 49:08.380
 Actually, I quite seriously looked at the literature.

49:08.380 --> 49:10.780
 It's not obvious to me that from the eyes and so on,

49:10.780 --> 49:11.620
 you can tell.

49:11.620 --> 49:13.140
 You might need stuff from the car as well.

49:13.140 --> 49:13.980
 Yeah.

49:13.980 --> 49:15.700
 You might need how they're controlling the car, right?

49:15.700 --> 49:17.340
 And that's fundamentally at the end of the day,

49:17.340 --> 49:18.620
 what you care about.

49:18.620 --> 49:21.620
 But I think, especially when people are really drunk,

49:21.620 --> 49:23.620
 they're not controlling the car nearly as smoothly

49:23.620 --> 49:25.460
 as they would look at them walking, right?

49:25.460 --> 49:27.220
 The car is like an extension of the body.

49:27.220 --> 49:29.380
 So I think you could totally detect.

49:29.380 --> 49:31.340
 And if you could fix people who are drunk, distracted,

49:31.340 --> 49:32.820
 asleep, if you fix those three.

49:32.820 --> 49:35.460
 Yeah, that's huge.

49:35.460 --> 49:38.220
 So what are the current limitations of open pilot?

49:38.220 --> 49:41.700
 What are the main problems that still need to be solved?

49:41.700 --> 49:45.420
 We're hopefully fixing a few of them in 06.

49:45.420 --> 49:49.460
 We're not as good as autopilot at stop cars.

49:49.460 --> 49:55.180
 So if you're coming up to a red light at 55,

49:55.180 --> 49:57.060
 so it's the radar stopped car problem, which

49:57.060 --> 49:59.180
 is responsible for two autopilot accidents,

49:59.180 --> 50:03.580
 it's hard to differentiate a stopped car from a signpost.

50:03.580 --> 50:05.300
 Yeah, a static object.

50:05.300 --> 50:06.300
 So you have to fuse.

50:06.300 --> 50:07.500
 You have to do this visually.

50:07.500 --> 50:09.580
 There's no way from the radar data to tell the difference.

50:09.580 --> 50:11.540
 Maybe you can make a map, but I don't really

50:11.540 --> 50:13.820
 believe in mapping at all anymore.

50:13.820 --> 50:16.020
 Wait, wait, wait, what, you don't believe in mapping?

50:16.020 --> 50:16.660
 No.

50:16.660 --> 50:20.660
 So you basically, the open pilot solution

50:20.660 --> 50:22.660
 is saying react to the environment as you see it,

50:22.660 --> 50:24.460
 just like human beings do.

50:24.460 --> 50:25.820
 And then eventually, when you want

50:25.820 --> 50:28.380
 to do navigate on open pilot, I'll

50:28.380 --> 50:29.940
 train the net to look at ways.

50:29.940 --> 50:31.460
 I'll run ways in the background, I'll

50:31.460 --> 50:32.300
 train a confident way.

50:32.300 --> 50:34.540
 Are you using GPS at all?

50:34.540 --> 50:35.940
 We use it to ground truth.

50:35.940 --> 50:38.340
 We use it to very carefully ground truth the paths.

50:38.340 --> 50:40.980
 We have a stack which can recover relative to 10

50:40.980 --> 50:42.940
 centimeters over one minute.

50:42.940 --> 50:45.020
 And then we use that to ground truth exactly where

50:45.020 --> 50:47.420
 the car went in that local part of the environment,

50:47.420 --> 50:48.700
 but it's all local.

50:48.700 --> 50:50.780
 How are you testing in general, just for yourself,

50:50.780 --> 50:53.220
 like experiments and stuff?

50:53.220 --> 50:54.940
 Where are you located?

50:54.940 --> 50:55.540
 San Diego.

50:55.540 --> 50:56.140
 San Diego.

50:56.140 --> 50:56.780
 Yeah.

50:56.780 --> 50:58.660
 OK.

50:58.660 --> 51:01.420
 So you basically drive around there, collect some data,

51:01.420 --> 51:03.060
 and watch the performance?

51:03.060 --> 51:04.300
 We have a simulator now.

51:04.300 --> 51:06.420
 And we have, our simulator is really cool.

51:06.420 --> 51:09.660
 Our simulator is not, it's not like a Unity based simulator.

51:09.660 --> 51:12.820
 Our simulator lets us load in real state.

51:12.820 --> 51:13.620
 What do you mean?

51:13.620 --> 51:16.700
 We can load in a drive and simulate

51:16.700 --> 51:20.260
 what the system would have done on the historical data.

51:20.260 --> 51:22.460
 Ooh, nice.

51:22.460 --> 51:23.460
 Interesting.

51:23.460 --> 51:24.260
 So what, yeah.

51:24.260 --> 51:26.060
 Right now we're only using it for testing,

51:26.060 --> 51:29.140
 but as soon as we start using it for training, that's it.

51:29.140 --> 51:30.780
 That's all that matters.

51:30.780 --> 51:33.020
 What's your feeling about the real world versus simulation?

51:33.020 --> 51:34.420
 Do you like simulation for training,

51:34.420 --> 51:35.700
 if this moves to training?

51:35.700 --> 51:40.020
 So we have to distinguish two types of simulators, right?

51:40.020 --> 51:44.620
 There's a simulator that is completely fake.

51:44.620 --> 51:47.740
 I could get my car to drive around in GTA.

51:47.740 --> 51:51.780
 I feel that this kind of simulator is useless.

51:51.780 --> 51:54.580
 You're never, there's so many.

51:54.580 --> 51:56.940
 My analogy here is like, OK, fine.

51:56.940 --> 51:59.860
 You're not solving the computer vision problem,

51:59.860 --> 52:02.300
 but you're solving the computer graphics problem.

52:02.300 --> 52:02.780
 Right.

52:02.780 --> 52:05.300
 And you don't think you can get very far by creating

52:05.300 --> 52:07.980
 ultra realistic graphics?

52:07.980 --> 52:10.340
 No, because you can create ultra realistic graphics

52:10.340 --> 52:13.140
 of the road, now create ultra realistic behavioral models

52:13.140 --> 52:14.500
 of the other cars.

52:14.500 --> 52:16.860
 Oh, well, I'll just use myself driving.

52:16.860 --> 52:18.180
 No, you won't.

52:18.180 --> 52:22.180
 You need actual human behavior, because that's

52:22.180 --> 52:23.860
 what you're trying to learn.

52:23.860 --> 52:25.820
 Driving does not have a spec.

52:25.820 --> 52:29.860
 The definition of driving is what humans do when they drive.

52:29.860 --> 52:32.700
 Whatever Waymo does, I don't think it's driving.

52:32.700 --> 52:33.220
 Right.

52:33.220 --> 52:36.380
 Well, I think actually Waymo and others,

52:36.380 --> 52:38.980
 if there's any use for reinforcement learning,

52:38.980 --> 52:40.340
 I've seen it used quite well.

52:40.340 --> 52:42.020
 I study pedestrians a lot, too, is

52:42.020 --> 52:45.500
 try to train models from real data of how pedestrians move,

52:45.500 --> 52:47.540
 and try to use reinforcement learning models to make

52:47.540 --> 52:49.980
 pedestrians move in human like ways.

52:49.980 --> 52:53.500
 By that point, you've already gone so many layers,

52:53.500 --> 52:55.660
 you detected a pedestrian?

52:55.660 --> 53:00.180
 Did you hand code the feature vector of their state?

53:00.180 --> 53:02.860
 Did you guys learn anything from computer vision

53:02.860 --> 53:04.580
 before deep learning?

53:04.580 --> 53:07.140
 Well, OK, I feel like this is.

53:07.140 --> 53:10.820
 So perception to you is the sticking point.

53:10.820 --> 53:13.780
 I mean, what's the hardest part of the stack here?

53:13.780 --> 53:20.500
 There is no human understandable feature vector separating

53:20.500 --> 53:23.060
 perception and planning.

53:23.060 --> 53:25.100
 That's the best way I can put that.

53:25.100 --> 53:26.780
 There is no, so it's all together,

53:26.780 --> 53:29.540
 and it's a joint problem.

53:29.540 --> 53:31.460
 So you can take localization.

53:31.460 --> 53:33.260
 Localization and planning, there is

53:33.260 --> 53:35.300
 a human understandable feature vector between these two

53:35.300 --> 53:35.980
 things.

53:35.980 --> 53:38.540
 I mean, OK, so I have like three degrees position,

53:38.540 --> 53:40.540
 three degrees orientation, and those derivatives,

53:40.540 --> 53:41.980
 maybe those second derivatives.

53:41.980 --> 53:43.140
 That's human understandable.

53:43.140 --> 53:45.460
 That's physical.

53:45.460 --> 53:50.780
 Between perception and planning, so like Waymo

53:50.780 --> 53:53.620
 has a perception stack and then a planner.

53:53.620 --> 53:55.580
 And one of the things Waymo does right

53:55.580 --> 54:00.020
 is they have a simulator that can separate those two.

54:00.020 --> 54:02.900
 They can like replay their perception data

54:02.900 --> 54:04.380
 and test their system, which is what

54:04.380 --> 54:05.380
 I'm talking about about like the two

54:05.380 --> 54:06.500
 different kinds of simulators.

54:06.500 --> 54:08.220
 There's the kind that can work on real data,

54:08.220 --> 54:10.860
 and there's the kind that can't work on real data.

54:10.860 --> 54:14.900
 Now, the problem is that I don't think you can hand code

54:14.900 --> 54:16.140
 a feature vector, right?

54:16.140 --> 54:17.740
 Like you have some list of like, oh, here's

54:17.740 --> 54:19.100
 my list of cars in the scenes.

54:19.100 --> 54:21.220
 Here's my list of pedestrians in the scene.

54:21.220 --> 54:23.180
 This isn't what humans are doing.

54:23.180 --> 54:24.860
 What are humans doing?

54:24.860 --> 54:27.180
 Global.

54:27.180 --> 54:31.860
 And you're saying that's too difficult to hand engineer.

54:31.860 --> 54:35.020
 I'm saying that there is no state vector given a perfect.

54:35.020 --> 54:37.300
 I could give you the best team of engineers in the world

54:37.300 --> 54:39.060
 to build a perception system and the best team

54:39.060 --> 54:40.580
 to build a planner.

54:40.580 --> 54:42.660
 All you have to do is define the state vector

54:42.660 --> 54:43.860
 that separates those two.

54:43.860 --> 54:48.580
 I'm missing the state vector that separates those two.

54:48.580 --> 54:49.300
 What do you mean?

54:49.300 --> 54:53.860
 So what is the output of your perception system?

54:53.860 --> 55:00.500
 Output of the perception system, it's, OK, well,

55:00.500 --> 55:01.620
 there's several ways to do it.

55:01.620 --> 55:03.780
 One is the SLAM components localization.

55:03.780 --> 55:05.780
 The other is drivable area, drivable space.

55:05.780 --> 55:06.580
 Drivable space, yeah.

55:06.580 --> 55:10.860
 And then there's the different objects in the scene.

55:10.860 --> 55:15.340
 And different objects in the scene over time,

55:15.340 --> 55:17.660
 maybe, to give you input to then try

55:17.660 --> 55:21.500
 to start modeling the trajectories of those objects.

55:21.500 --> 55:22.140
 Sure.

55:22.140 --> 55:22.740
 That's it.

55:22.740 --> 55:24.060
 I can give you a concrete example

55:24.060 --> 55:25.060
 of something you missed.

55:25.060 --> 55:25.780
 What's that?

55:25.780 --> 55:28.580
 So say there's a bush in the scene.

55:28.580 --> 55:30.860
 Humans understand that when they see this bush

55:30.860 --> 55:34.580
 that there may or may not be a car behind that bush.

55:34.580 --> 55:37.180
 Drivable area and a list of objects does not include that.

55:37.180 --> 55:40.820
 Humans are doing this constantly at the simplest intersections.

55:40.820 --> 55:44.900
 So now you have to talk about occluded area.

55:44.900 --> 55:47.740
 But even that, what do you mean by occluded?

55:47.740 --> 55:49.500
 OK, so I can't see it.

55:49.500 --> 55:51.740
 Well, if it's the other side of a house, I don't care.

55:51.740 --> 55:53.100
 What's the likelihood that there's

55:53.100 --> 55:55.180
 a car in that occluded area?

55:55.180 --> 55:57.940
 And if you say, OK, we'll add that,

55:57.940 --> 56:01.620
 I can come up with 10 more examples that you can't add.

56:01.620 --> 56:03.860
 Certainly, occluded area would be something

56:03.860 --> 56:05.860
 that Simulator would have because it's

56:05.860 --> 56:11.180
 simulating the entire occlusion is part of it.

56:11.180 --> 56:12.580
 Occlusion is part of a vision stack.

56:12.580 --> 56:16.500
 But what I'm saying is if you have a hand engineered,

56:16.500 --> 56:19.420
 if your perception system output can

56:19.420 --> 56:22.980
 be written in a spec document, it is incomplete.

56:22.980 --> 56:27.740
 Yeah, I mean, certainly, it's hard to argue with that

56:27.740 --> 56:30.100
 because in the end, that's going to be true.

56:30.100 --> 56:32.260
 Yeah, and I'll tell you what the output of our perception

56:32.260 --> 56:32.740
 system is.

56:32.740 --> 56:33.300
 What's that?

56:33.300 --> 56:37.940
 It's a 1,024 dimensional vector, trained by neural net.

56:37.940 --> 56:38.980
 Oh, you know that.

56:38.980 --> 56:43.460
 No, it's 1,024 dimensions of who knows what.

56:43.460 --> 56:45.060
 Because it's operating on real data.

56:45.060 --> 56:46.940
 Yeah.

56:46.940 --> 56:48.340
 And that's the perception.

56:48.340 --> 56:50.380
 That's the perception state.

56:50.380 --> 56:53.500
 Think about an autoencoder for faces.

56:53.500 --> 56:56.660
 If you have an autoencoder for faces and you say

56:56.660 --> 56:59.260
 it has 256 dimensions in the middle,

56:59.260 --> 57:01.260
 and I'm taking a face over here and projecting it

57:01.260 --> 57:02.820
 to a face over here.

57:02.820 --> 57:06.300
 Can you hand label all 256 of those dimensions?

57:06.300 --> 57:09.260
 Well, no, but those have to generate automatically.

57:09.260 --> 57:11.380
 But even if you tried to do it by hand,

57:11.380 --> 57:15.580
 could you come up with a spec between your encoder

57:15.580 --> 57:17.660
 and your decoder?

57:17.660 --> 57:20.740
 No, because it wasn't designed, but there.

57:20.740 --> 57:23.620
 No, no, no, but if you could design it.

57:23.620 --> 57:26.460
 If you could design a face reconstructor system,

57:26.460 --> 57:29.260
 could you come up with a spec?

57:29.260 --> 57:32.340
 No, but I think we're missing here a little bit.

57:32.340 --> 57:35.980
 I think you're just being very poetic about expressing

57:35.980 --> 57:38.940
 a fundamental problem of simulators,

57:38.940 --> 57:44.300
 that they're going to be missing so much that the feature

57:44.300 --> 57:47.500
 vector will just look fundamentally different

57:47.500 --> 57:51.260
 in the simulated world than the real world.

57:51.260 --> 57:53.820
 I'm not making a claim about simulators.

57:53.820 --> 57:57.060
 I'm making a claim about the spec division

57:57.060 --> 58:00.780
 between perception and planning, even in your system.

58:00.780 --> 58:01.980
 Just in general.

58:01.980 --> 58:03.300
 Just in general.

58:03.300 --> 58:05.620
 If you're trying to build a car that drives,

58:05.620 --> 58:08.340
 if you're trying to hand code the output of your perception

58:08.340 --> 58:10.340
 system, like saying, here's a list of all the cars

58:10.340 --> 58:11.860
 in the scene, here's a list of all the people,

58:11.860 --> 58:13.060
 here's a list of the occluded areas,

58:13.060 --> 58:16.540
 here's a vector of drivable areas, it's insufficient.

58:16.540 --> 58:17.900
 And if you start to believe that,

58:17.900 --> 58:20.780
 you realize that what Waymo and Cruz are doing is impossible.

58:20.780 --> 58:24.220
 Currently, what we're doing is the perception problem

58:24.220 --> 58:29.140
 is converting the scene into a chessboard.

58:29.140 --> 58:31.660
 And then you reason some basic reasoning

58:31.660 --> 58:33.340
 around that chessboard.

58:33.340 --> 58:38.380
 And you're saying that really, there's a lot missing there.

58:38.380 --> 58:40.180
 First of all, why are we talking about this?

58:40.180 --> 58:42.740
 Because isn't this a full autonomy?

58:42.740 --> 58:44.580
 Is this something you think about?

58:44.580 --> 58:47.540
 Oh, I want to win self driving cars.

58:47.540 --> 58:51.940
 So your definition of win includes?

58:51.940 --> 58:53.060
 Level four or five.

58:53.060 --> 58:53.900
 Level five.

58:53.900 --> 58:55.740
 I don't think level four is a real thing.

58:55.740 --> 58:59.660
 I want to build the AlphaGo of driving.

59:01.060 --> 59:06.060
 So AlphaGo is really end to end.

59:06.060 --> 59:06.900
 Yeah.

59:06.900 --> 59:09.780
 Is, yeah, it's end to end.

59:09.780 --> 59:12.420
 And do you think this whole problem,

59:12.420 --> 59:14.620
 is that also kind of what you're getting at

59:14.620 --> 59:16.580
 with the perception and the planning?

59:16.580 --> 59:19.380
 Is that this whole problem, the right way to do it

59:19.380 --> 59:21.540
 is really to learn the entire thing.

59:21.540 --> 59:23.620
 I'll argue that not only is it the right way,

59:23.620 --> 59:27.620
 it's the only way that's going to exceed human performance.

59:27.620 --> 59:28.540
 Well.

59:28.540 --> 59:29.940
 It's certainly true for Go.

59:29.940 --> 59:31.460
 Everyone who tried to hand code Go things

59:31.460 --> 59:33.420
 built human inferior things.

59:33.420 --> 59:36.180
 And then someone came along and wrote some 10,000 line thing

59:36.180 --> 59:39.780
 that doesn't know anything about Go that beat everybody.

59:39.780 --> 59:41.060
 It's 10,000 lines.

59:41.060 --> 59:44.500
 True, in that sense, the open question then

59:44.500 --> 59:49.500
 that maybe I can ask you is driving is much harder than Go.

59:53.460 --> 59:55.420
 The open question is how much harder?

59:56.260 --> 59:59.500
 So how, because I think the Elon Musk approach here

59:59.500 --> 1:00:01.620
 with planning and perception is similar

1:00:01.620 --> 1:00:02.980
 to what you're describing,

1:00:02.980 --> 1:00:07.980
 which is really turning into not some kind of modular thing,

1:00:08.300 --> 1:00:11.140
 but really do formulate it as a learning problem

1:00:11.140 --> 1:00:13.380
 and solve the learning problem with scale.

1:00:13.380 --> 1:00:17.700
 So how many years, put one is how many years

1:00:17.700 --> 1:00:18.860
 would it take to solve this problem

1:00:18.860 --> 1:00:21.660
 or just how hard is this freaking problem?

1:00:21.660 --> 1:00:26.660
 Well, the cool thing is I think there's a lot of value

1:00:27.780 --> 1:00:29.740
 that we can deliver along the way.

1:00:30.820 --> 1:00:35.820
 I think that you can build lane keeping assist actually

1:00:37.260 --> 1:00:42.260
 plus adaptive cruise control, plus, okay, looking at ways,

1:00:42.260 --> 1:00:45.980
 extends to like all of driving.

1:00:45.980 --> 1:00:47.900
 Yeah, most of driving, right?

1:00:47.900 --> 1:00:49.740
 Oh, your adaptive cruise control treats red lights

1:00:49.740 --> 1:00:51.180
 like cars, okay.

1:00:51.180 --> 1:00:52.980
 So let's jump around.

1:00:52.980 --> 1:00:55.740
 You mentioned that you didn't like navigate an autopilot.

1:00:55.740 --> 1:00:57.740
 What advice, how would you make it better?

1:00:57.740 --> 1:01:00.540
 Do you think as a feature that if it's done really well,

1:01:00.540 --> 1:01:02.340
 it's a good feature?

1:01:02.340 --> 1:01:07.340
 I think that it's too reliant on like hand coded hacks

1:01:07.460 --> 1:01:10.380
 for like, how does navigate an autopilot do a lane change?

1:01:10.380 --> 1:01:13.340
 It actually does the same lane change every time

1:01:13.340 --> 1:01:14.260
 and it feels mechanical.

1:01:14.260 --> 1:01:15.820
 Humans do different lane changes.

1:01:15.820 --> 1:01:17.300
 Humans sometime will do a slow one,

1:01:17.300 --> 1:01:18.860
 sometimes do a fast one.

1:01:18.860 --> 1:01:20.820
 Navigate an autopilot, at least every time I use it,

1:01:20.820 --> 1:01:22.980
 it is the identical lane change.

1:01:22.980 --> 1:01:24.220
 How do you learn?

1:01:24.220 --> 1:01:26.740
 I mean, this is a fundamental thing actually

1:01:26.740 --> 1:01:30.340
 is the braking and then accelerating

1:01:30.340 --> 1:01:33.900
 something that's still, Tesla probably does it better

1:01:33.900 --> 1:01:36.740
 than most cars, but it still doesn't do a great job

1:01:36.740 --> 1:01:39.900
 of creating a comfortable natural experience.

1:01:39.900 --> 1:01:42.620
 And navigate an autopilot is just lane changes

1:01:42.620 --> 1:01:44.060
 and extension of that.

1:01:44.060 --> 1:01:49.060
 So how do you learn to do a natural lane change?

1:01:49.180 --> 1:01:52.980
 So we have it and I can talk about how it works.

1:01:52.980 --> 1:01:57.980
 So I feel that we have the solution for lateral.

1:01:58.860 --> 1:02:00.700
 We don't yet have the solution for longitudinal.

1:02:00.700 --> 1:02:03.420
 There's a few reasons longitudinal is harder than lateral.

1:02:03.420 --> 1:02:05.180
 The lane change component,

1:02:05.180 --> 1:02:08.060
 the way that we train on it very simply

1:02:08.060 --> 1:02:10.900
 is like our model has an input

1:02:10.900 --> 1:02:14.100
 for whether it's doing a lane change or not.

1:02:14.100 --> 1:02:16.420
 And then when we train the end to end model,

1:02:16.420 --> 1:02:18.420
 we hand label all the lane changes,

1:02:18.420 --> 1:02:19.580
 cause you have to.

1:02:19.580 --> 1:02:22.460
 I've struggled a long time about not wanting to do that,

1:02:22.460 --> 1:02:24.300
 but I think you have to.

1:02:24.300 --> 1:02:25.340
 Or the training data.

1:02:25.340 --> 1:02:26.540
 For the training data, right?

1:02:26.540 --> 1:02:28.380
 Oh, we actually, we have an automatic ground truther

1:02:28.380 --> 1:02:30.580
 which automatically labels all the lane changes.

1:02:30.580 --> 1:02:31.700
 Was that possible?

1:02:31.700 --> 1:02:32.780
 To automatically label the lane changes?

1:02:32.780 --> 1:02:33.620
 Yeah.

1:02:33.620 --> 1:02:34.820
 Yeah, detect the lane, I see when it crosses it, right?

1:02:34.820 --> 1:02:36.700
 And I don't have to get that high percent accuracy,

1:02:36.700 --> 1:02:38.980
 but it's like 95, good enough.

1:02:38.980 --> 1:02:43.220
 Now I set the bit when it's doing the lane change

1:02:43.220 --> 1:02:44.860
 in the end to end learning.

1:02:44.860 --> 1:02:47.940
 And then I set it to zero when it's not doing a lane change.

1:02:47.940 --> 1:02:49.740
 So now if I wanted to do a lane change at test time,

1:02:49.740 --> 1:02:52.380
 I just put the bit to a one and it'll do a lane change.

1:02:52.380 --> 1:02:54.660
 Yeah, but so if you look at the space of lane change,

1:02:54.660 --> 1:02:57.340
 you know, some percentage, not a hundred percent

1:02:57.340 --> 1:03:01.140
 that we make as humans is not a pleasant experience

1:03:01.140 --> 1:03:02.860
 cause we messed some part of it up.

1:03:02.860 --> 1:03:04.940
 It's nerve wracking to change the look,

1:03:04.940 --> 1:03:06.940
 you have to see, it has to accelerate.

1:03:06.940 --> 1:03:09.940
 How do we label the ones that are natural and feel good?

1:03:09.940 --> 1:03:13.380
 You know, that's the, cause that's your ultimate criticism.

1:03:13.380 --> 1:03:15.860
 The current navigate and autopilot

1:03:15.860 --> 1:03:16.940
 just doesn't feel good.

1:03:16.940 --> 1:03:18.460
 Well, the current navigate and autopilot

1:03:18.460 --> 1:03:21.660
 is a hand coded policy written by an engineer in a room

1:03:21.660 --> 1:03:25.020
 who probably went out and tested it a few times on the 280.

1:03:25.020 --> 1:03:29.420
 Probably a more, a better version of that, but yes.

1:03:29.420 --> 1:03:31.020
 That's how we would have written it at Comma AI.

1:03:31.020 --> 1:03:31.860
 Yeah, yeah, yeah.

1:03:31.860 --> 1:03:33.420
 Maybe Tesla did, Tesla, they tested it in the end.

1:03:33.420 --> 1:03:35.100
 That might've been two engineers.

1:03:35.100 --> 1:03:36.060
 Two engineers, yeah.

1:03:37.380 --> 1:03:40.060
 No, but so if you learn the lane change,

1:03:40.060 --> 1:03:42.420
 if you learn how to do a lane change from data,

1:03:42.420 --> 1:03:44.660
 just like you have a label that says lane change

1:03:44.660 --> 1:03:46.380
 and then you put it in when you want it

1:03:46.380 --> 1:03:48.020
 to do the lane change,

1:03:48.020 --> 1:03:49.620
 it'll automatically do the lane change

1:03:49.620 --> 1:03:51.580
 that's appropriate for the situation.

1:03:51.580 --> 1:03:54.700
 Now, to get at the problem of some humans

1:03:54.700 --> 1:03:55.940
 do bad lane changes,

1:03:57.380 --> 1:03:59.900
 we haven't worked too much on this problem yet.

1:03:59.900 --> 1:04:03.100
 It's not that much of a problem in practice.

1:04:03.100 --> 1:04:06.140
 My theory is that all good drivers are good in the same way

1:04:06.140 --> 1:04:08.340
 and all bad drivers are bad in different ways.

1:04:09.340 --> 1:04:11.300
 And we've seen some data to back this up.

1:04:11.300 --> 1:04:12.380
 Well, beautifully put.

1:04:12.380 --> 1:04:16.540
 So you just basically, if that's true hypothesis,

1:04:16.540 --> 1:04:19.860
 then your task is to discover the good drivers.

1:04:19.860 --> 1:04:23.300
 The good drivers stand out because they're in one cluster

1:04:23.300 --> 1:04:25.140
 and the bad drivers are scattered all over the place

1:04:25.140 --> 1:04:27.180
 and your net learns the cluster.

1:04:27.180 --> 1:04:30.740
 Yeah, that's, so you just learn from the good drivers

1:04:30.740 --> 1:04:33.140
 and they're easy to cluster.

1:04:33.140 --> 1:04:33.980
 In fact, we learned from all of them

1:04:33.980 --> 1:04:35.780
 and the net automatically learns the policy

1:04:35.780 --> 1:04:36.860
 that's like the majority,

1:04:36.860 --> 1:04:38.500
 but we'll eventually probably have to filter them out.

1:04:38.500 --> 1:04:41.500
 If that theory is true, I hope it's true

1:04:41.500 --> 1:04:46.420
 because the counter theory is there is many clusters,

1:04:49.420 --> 1:04:53.620
 maybe arbitrarily many clusters of good drivers.

1:04:53.620 --> 1:04:55.780
 Because if there's one cluster of good drivers,

1:04:55.780 --> 1:04:57.540
 you can at least discover a set of policies.

1:04:57.540 --> 1:04:58.940
 You can learn a set of policies,

1:04:58.940 --> 1:05:00.580
 which would be good universally.

1:05:00.580 --> 1:05:01.620
 Yeah.

1:05:01.620 --> 1:05:04.540
 That would be a nice, that would be nice if it's true.

1:05:04.540 --> 1:05:06.540
 And you're saying that there is some evidence that.

1:05:06.540 --> 1:05:09.740
 Let's say lane changes can be clustered into four clusters.

1:05:09.740 --> 1:05:10.580
 Right. Right.

1:05:10.580 --> 1:05:12.020
 There's this finite level of.

1:05:12.020 --> 1:05:15.260
 I would argue that all four of those are good clusters.

1:05:15.260 --> 1:05:18.420
 All the things that are random are noise and probably bad.

1:05:18.420 --> 1:05:20.340
 And which one of the four you pick,

1:05:20.340 --> 1:05:21.900
 or maybe it's 10 or maybe it's 20.

1:05:21.900 --> 1:05:22.740
 You can learn that.

1:05:22.740 --> 1:05:23.780
 It's context dependent.

1:05:23.780 --> 1:05:24.980
 It depends on the scene.

1:05:24.980 --> 1:05:29.980
 And the hope is it's not too dependent on the driver.

1:05:31.380 --> 1:05:34.220
 Yeah. The hope is that it all washes out.

1:05:34.220 --> 1:05:36.980
 The hope is that there's, that the distribution's not bimodal.

1:05:36.980 --> 1:05:39.100
 The hope is that it's a nice Gaussian.

1:05:39.100 --> 1:05:41.660
 So what advice would you give to Tesla,

1:05:41.660 --> 1:05:44.980
 how to fix, how to improve navigating autopilot?

1:05:44.980 --> 1:05:48.260
 That's the lessons that you've learned from Comm AI?

1:05:48.260 --> 1:05:50.580
 The only real advice I would give to Tesla

1:05:50.580 --> 1:05:52.940
 is please put driver monitoring in your cars.

1:05:52.940 --> 1:05:55.100
 With respect to improving it?

1:05:55.100 --> 1:05:55.940
 You can't do that anymore.

1:05:55.940 --> 1:05:58.220
 I decided to interrupt, but you know,

1:05:58.220 --> 1:06:01.740
 there's a practical nature of many of hundreds of thousands

1:06:01.740 --> 1:06:04.180
 of cars being produced that don't have

1:06:04.180 --> 1:06:05.780
 a good driver facing camera.

1:06:05.780 --> 1:06:07.500
 The Model 3 has a selfie cam.

1:06:07.500 --> 1:06:08.660
 Is it not good enough?

1:06:08.660 --> 1:06:10.780
 Did they not put IR LEDs for night?

1:06:10.780 --> 1:06:11.620
 That's a good question.

1:06:11.620 --> 1:06:13.340
 But I do know that it's fisheye

1:06:13.340 --> 1:06:15.780
 and it's relatively low resolution.

1:06:15.780 --> 1:06:16.740
 So it's really not designed.

1:06:16.740 --> 1:06:17.580
 It wasn't.

1:06:17.580 --> 1:06:18.740
 It wasn't designed for driver monitoring.

1:06:18.740 --> 1:06:21.740
 You can hope that you can kind of scrape up

1:06:21.740 --> 1:06:24.180
 and have something from it.

1:06:24.180 --> 1:06:25.020
 Yeah.

1:06:25.020 --> 1:06:27.500
 But why didn't they put it in today?

1:06:27.500 --> 1:06:28.340
 Put it in today.

1:06:28.340 --> 1:06:29.500
 Put it in today.

1:06:29.500 --> 1:06:31.500
 Every time I've heard Karpathy talk about the problem

1:06:31.500 --> 1:06:33.220
 and talking about like software 2.0

1:06:33.220 --> 1:06:35.220
 and how the machine learning is gobbling up everything,

1:06:35.220 --> 1:06:37.420
 I think this is absolutely the right strategy.

1:06:37.420 --> 1:06:40.140
 I think that he didn't write navigate on autopilot.

1:06:40.140 --> 1:06:41.540
 I think somebody else did

1:06:41.540 --> 1:06:43.220
 and kind of hacked it on top of that stuff.

1:06:43.220 --> 1:06:45.700
 I think when Karpathy says, wait a second,

1:06:45.700 --> 1:06:47.420
 why did we hand code this lane change policy

1:06:47.420 --> 1:06:48.340
 with all these magic numbers?

1:06:48.340 --> 1:06:49.340
 We're gonna learn it from data.

1:06:49.340 --> 1:06:50.180
 They'll fix it.

1:06:50.180 --> 1:06:51.060
 They already know what to do there.

1:06:51.060 --> 1:06:53.380
 Well, that's Andrei's job

1:06:53.380 --> 1:06:55.780
 is to turn everything into a learning problem

1:06:55.780 --> 1:06:57.500
 and collect a huge amount of data.

1:06:57.500 --> 1:06:59.540
 The reality is though,

1:06:59.540 --> 1:07:02.780
 not every problem can be turned into a learning problem

1:07:02.780 --> 1:07:04.100
 in the short term.

1:07:04.100 --> 1:07:07.300
 In the end, everything will be a learning problem.

1:07:07.300 --> 1:07:12.300
 The reality is like if you wanna build L5 vehicles today,

1:07:12.940 --> 1:07:15.460
 it will likely involve no learning.

1:07:15.460 --> 1:07:17.420
 And that's the reality is,

1:07:17.420 --> 1:07:20.340
 so at which point does learning start?

1:07:20.340 --> 1:07:23.500
 It's the crutch statement that LiDAR is a crutch.

1:07:23.500 --> 1:07:24.860
 At which point will learning

1:07:24.860 --> 1:07:27.260
 get up to part of human performance?

1:07:27.260 --> 1:07:29.980
 It's over human performance on ImageNet,

1:07:30.980 --> 1:07:34.060
 classification, on driving, it's a question still.

1:07:34.060 --> 1:07:35.820
 It is a question.

1:07:35.820 --> 1:07:39.260
 I'll say this, I'm here to play for 10 years.

1:07:39.260 --> 1:07:40.340
 I'm not here to try to,

1:07:40.340 --> 1:07:43.020
 I'm here to play for 10 years and make money along the way.

1:07:43.020 --> 1:07:45.100
 I'm not here to try to promise people

1:07:45.100 --> 1:07:47.060
 that I'm gonna have my L5 taxi network

1:07:47.060 --> 1:07:48.300
 up and working in two years.

1:07:48.300 --> 1:07:49.500
 Do you think that was a mistake?

1:07:49.500 --> 1:07:50.580
 Yes.

1:07:50.580 --> 1:07:53.540
 What do you think was the motivation behind saying that?

1:07:53.540 --> 1:07:56.700
 Other companies are also promising L5 vehicles

1:07:56.700 --> 1:08:01.700
 with very different approaches in 2020, 2021, 2022.

1:08:01.940 --> 1:08:03.740
 If anybody would like to bet me

1:08:03.740 --> 1:08:06.940
 that those things do not pan out, I will bet you.

1:08:06.940 --> 1:08:09.780
 Even money, even money, I'll bet you as much as you want.

1:08:09.780 --> 1:08:10.900
 Yeah.

1:08:10.900 --> 1:08:13.660
 So are you worried about what's going to happen?

1:08:13.660 --> 1:08:16.140
 Cause you're not in full agreement on that.

1:08:16.140 --> 1:08:19.180
 What's going to happen when 2022, 21 come around

1:08:19.180 --> 1:08:22.900
 and nobody has fleets of autonomous vehicles?

1:08:22.900 --> 1:08:25.060
 Well, you can look at the history.

1:08:25.060 --> 1:08:26.740
 If you go back five years ago,

1:08:26.740 --> 1:08:29.980
 they were all promised by 2018 and 2017.

1:08:29.980 --> 1:08:32.260
 But they weren't that strong of promises.

1:08:32.260 --> 1:08:36.260
 I mean, Ford really declared pretty,

1:08:36.260 --> 1:08:40.640
 I think not many have declared as like definitively

1:08:40.640 --> 1:08:42.660
 as they have now these dates.

1:08:42.660 --> 1:08:45.100
 Well, okay, so let's separate L4 and L5.

1:08:45.100 --> 1:08:49.480
 Do I think that it's possible for Waymo to continue to kind

1:08:49.480 --> 1:08:51.020
 of like hack on their system

1:08:51.020 --> 1:08:53.460
 until it gets to level four in Chandler, Arizona?

1:08:53.460 --> 1:08:55.060
 Yes.

1:08:55.060 --> 1:08:56.860
 When there's no safety driver?

1:08:56.860 --> 1:08:57.700
 Chandler, Arizona?

1:08:57.700 --> 1:08:58.520
 Yeah.

1:08:59.580 --> 1:09:02.540
 By, sorry, which year are we talking about?

1:09:02.540 --> 1:09:06.180
 Oh, I even think that's possible by like 2020, 2021.

1:09:06.180 --> 1:09:08.460
 But level four, Chandler, Arizona,

1:09:08.460 --> 1:09:10.340
 not level five, New York City.

1:09:10.340 --> 1:09:15.340
 Level four, meaning some very defined streets,

1:09:15.980 --> 1:09:17.460
 it works out really well.

1:09:17.460 --> 1:09:18.300
 Very defined streets.

1:09:18.300 --> 1:09:20.720
 And then practically these streets are pretty empty.

1:09:20.720 --> 1:09:24.700
 If most of the streets are covered in Waymo's,

1:09:24.700 --> 1:09:28.420
 Waymo can kind of change the definition of what driving is.

1:09:28.420 --> 1:09:29.260
 Right?

1:09:29.260 --> 1:09:30.980
 If your self driving network

1:09:30.980 --> 1:09:33.460
 is the majority of cars in an area,

1:09:33.460 --> 1:09:35.740
 they only need to be safe with respect to each other

1:09:35.740 --> 1:09:38.660
 and all the humans will need to learn to adapt to them.

1:09:38.660 --> 1:09:41.140
 Now go drive in downtown New York.

1:09:41.140 --> 1:09:42.220
 Well, yeah, that's.

1:09:42.220 --> 1:09:44.780
 I mean, already you can talk about autonomy

1:09:44.780 --> 1:09:46.980
 and like on farms, it already works great

1:09:46.980 --> 1:09:49.580
 because you can really just follow the GPS line.

1:09:51.300 --> 1:09:55.640
 So what does success look like for common AI?

1:09:55.640 --> 1:09:57.900
 What are the milestones?

1:09:57.900 --> 1:09:59.820
 Like where you can sit back with some champagne

1:09:59.820 --> 1:10:02.860
 and say, we did it, boys and girls?

1:10:04.140 --> 1:10:06.260
 Well, it's never over.

1:10:06.260 --> 1:10:07.300
 Yeah, but.

1:10:07.300 --> 1:10:10.420
 You must drink champagne and celebrate.

1:10:10.420 --> 1:10:13.180
 So what is a good, what are some wins?

1:10:13.180 --> 1:10:15.940
 A big milestone that we're hoping for

1:10:17.780 --> 1:10:20.880
 by mid next year is profitability of the company.

1:10:23.580 --> 1:10:27.680
 And we're gonna have to revisit the idea

1:10:27.680 --> 1:10:30.320
 of selling a consumer product,

1:10:30.320 --> 1:10:32.740
 but it's not gonna be like the comma one.

1:10:32.740 --> 1:10:35.320
 When we do it, it's gonna be perfect.

1:10:35.320 --> 1:10:39.640
 Open pilot has gotten so much better in the last two years.

1:10:39.640 --> 1:10:41.720
 We're gonna have a few features.

1:10:41.720 --> 1:10:43.800
 We're gonna have a hundred percent driver monitoring.

1:10:43.800 --> 1:10:47.120
 We're gonna disable no safety features in the car.

1:10:47.120 --> 1:10:48.280
 Actually, I think it'd be really cool

1:10:48.280 --> 1:10:49.160
 what we're doing right now.

1:10:49.160 --> 1:10:51.640
 Our project this week is we're analyzing the data set

1:10:51.640 --> 1:10:53.240
 and looking for all the AEB triggers

1:10:53.240 --> 1:10:55.640
 from the manufacturer systems.

1:10:55.640 --> 1:10:59.440
 We have better data set on that than the manufacturers.

1:10:59.440 --> 1:11:00.920
 How much, just how many,

1:11:00.920 --> 1:11:03.360
 does Toyota have 10 million miles of real world driving

1:11:03.360 --> 1:11:05.320
 to know how many times their AEB triggered?

1:11:05.320 --> 1:11:08.400
 So let me give you, cause you asked, right?

1:11:08.400 --> 1:11:09.560
 Financial advice.

1:11:09.560 --> 1:11:10.880
 Yeah.

1:11:10.880 --> 1:11:12.400
 Cause I work with a lot of automakers

1:11:12.400 --> 1:11:15.800
 and one possible source of money for you,

1:11:15.800 --> 1:11:18.040
 which I'll be excited to see you take on

1:11:18.040 --> 1:11:23.040
 is basically selling the data.

1:11:24.600 --> 1:11:29.120
 So, which is something that most people,

1:11:29.120 --> 1:11:31.800
 and not selling in a way where here, here at Automaker,

1:11:31.800 --> 1:11:34.360
 but creating, we've done this actually at MIT,

1:11:34.360 --> 1:11:35.480
 not for money purposes,

1:11:35.480 --> 1:11:37.760
 but you could do it for significant money purposes

1:11:37.760 --> 1:11:41.360
 and make the world a better place by creating a consortia

1:11:41.360 --> 1:11:44.200
 where automakers would pay in

1:11:44.200 --> 1:11:46.960
 and then they get to have free access to the data.

1:11:46.960 --> 1:11:51.440
 And I think a lot of people are really hungry for that

1:11:52.400 --> 1:11:54.200
 and would pay significant amount of money for it.

1:11:54.200 --> 1:11:55.400
 Here's the problem with that.

1:11:55.400 --> 1:11:56.880
 I like this idea all in theory.

1:11:56.880 --> 1:11:59.660
 It'd be very easy for me to give them access to my servers

1:11:59.660 --> 1:12:01.480
 and we already have all open source tools

1:12:01.480 --> 1:12:02.320
 to access this data.

1:12:02.320 --> 1:12:03.440
 It's in a great format.

1:12:03.440 --> 1:12:04.720
 We have a great pipeline,

1:12:05.640 --> 1:12:07.120
 but they're gonna put me in the room

1:12:07.120 --> 1:12:08.920
 with some business development guy.

1:12:10.140 --> 1:12:12.560
 And I'm gonna have to talk to this guy

1:12:12.560 --> 1:12:15.200
 and he's not gonna know most of the words I'm saying.

1:12:15.200 --> 1:12:17.400
 I'm not willing to tolerate that.

1:12:17.400 --> 1:12:18.960
 Okay, Mick Jagger.

1:12:18.960 --> 1:12:19.800
 No, no, no, no, no.

1:12:19.800 --> 1:12:21.120
 I think I agree with you.

1:12:21.120 --> 1:12:23.040
 I'm the same way, but you just tell them the terms

1:12:23.040 --> 1:12:24.720
 and there's no discussion needed.

1:12:24.720 --> 1:12:28.080
 If I could just tell them the terms,

1:12:28.080 --> 1:12:28.920
 Yeah.

1:12:28.920 --> 1:12:31.720
 and like, all right, who wants access to my data?

1:12:31.720 --> 1:12:36.720
 I will sell it to you for, let's say,

1:12:36.800 --> 1:12:37.720
 you want a subscription?

1:12:37.720 --> 1:12:39.560
 I'll sell to you for 100K a month.

1:12:40.800 --> 1:12:41.640
 Anyone.

1:12:41.640 --> 1:12:42.480
 100K a month.

1:12:42.480 --> 1:12:43.300
 100K a month.

1:12:43.300 --> 1:12:45.160
 I'll give you access to this data subscription.

1:12:45.160 --> 1:12:46.000
 Yeah.

1:12:46.000 --> 1:12:46.820
 Yeah, I think that's kind of fair.

1:12:46.820 --> 1:12:48.080
 Came up with that number off the top of my head.

1:12:48.080 --> 1:12:50.200
 If somebody sends me like a three line email

1:12:50.200 --> 1:12:52.600
 where it's like, we would like to pay 100K a month

1:12:52.600 --> 1:12:54.040
 to get access to your data.

1:12:54.040 --> 1:12:56.180
 We would agree to like reasonable privacy terms

1:12:56.180 --> 1:12:58.360
 of the people who are in the data set.

1:12:58.360 --> 1:12:59.560
 I would be happy to do it,

1:12:59.560 --> 1:13:01.200
 but that's not going to be the email.

1:13:01.200 --> 1:13:02.880
 The email is going to be, hey,

1:13:02.880 --> 1:13:04.680
 do you have some time in the next month

1:13:04.680 --> 1:13:06.000
 where we can sit down and we can,

1:13:06.000 --> 1:13:06.880
 I don't have time for that.

1:13:06.880 --> 1:13:07.880
 We're moving too fast.

1:13:07.880 --> 1:13:08.720
 Yeah.

1:13:08.720 --> 1:13:10.080
 You could politely respond to that email,

1:13:10.080 --> 1:13:13.280
 but not saying, I don't have any time for your bullshit.

1:13:13.280 --> 1:13:15.480
 You say, oh, well, unfortunately these are the terms.

1:13:15.480 --> 1:13:17.720
 And so this is, we try to,

1:13:17.720 --> 1:13:19.840
 we brought the cost down for you

1:13:19.840 --> 1:13:22.480
 in order to minimize the friction and communication.

1:13:22.480 --> 1:13:23.320
 Absolutely.

1:13:23.320 --> 1:13:24.520
 Here's the, whatever it is,

1:13:24.520 --> 1:13:28.960
 one, two million dollars a year and you have access.

1:13:28.960 --> 1:13:31.460
 And it's not like I get that email from like,

1:13:31.460 --> 1:13:32.720
 but okay, am I going to reach out?

1:13:32.720 --> 1:13:34.200
 Am I going to hire a business development person

1:13:34.200 --> 1:13:35.920
 who's going to reach out to the automakers?

1:13:35.920 --> 1:13:36.740
 No way.

1:13:36.740 --> 1:13:37.580
 Yeah. Okay.

1:13:37.580 --> 1:13:38.400
 I got you.

1:13:38.400 --> 1:13:40.640
 If they reached into me, I'm not going to ignore the email.

1:13:40.640 --> 1:13:41.960
 I'll come back with something like,

1:13:41.960 --> 1:13:43.920
 yeah, if you're willing to pay 100K a month

1:13:43.920 --> 1:13:46.120
 for access to the data, I'm happy to set that up.

1:13:46.120 --> 1:13:48.240
 That's worth my engineering time.

1:13:48.240 --> 1:13:49.560
 That's actually quite insightful of you.

1:13:49.560 --> 1:13:50.480
 You're right.

1:13:50.480 --> 1:13:52.520
 Probably because many of the automakers

1:13:52.520 --> 1:13:54.200
 are quite a bit old school,

1:13:54.200 --> 1:13:57.680
 there will be a need to reach out and they want it,

1:13:57.680 --> 1:13:59.800
 but there'll need to be some communication.

1:13:59.800 --> 1:14:00.640
 You're right.

1:14:00.640 --> 1:14:04.520
 Mobileye circa 2015 had the lowest R&D spend

1:14:04.520 --> 1:14:08.360
 of any chip maker, like per, per,

1:14:08.360 --> 1:14:10.640
 and you look at all the people who work for them

1:14:10.640 --> 1:14:12.120
 and it's all business development people

1:14:12.120 --> 1:14:15.340
 because the car companies are impossible to work with.

1:14:15.340 --> 1:14:16.180
 Yeah.

1:14:16.180 --> 1:14:17.880
 So you're, you have no patience for that

1:14:17.880 --> 1:14:20.040
 and you're, you're legit Android, huh?

1:14:20.040 --> 1:14:21.400
 I have something to do, right?

1:14:21.400 --> 1:14:22.520
 Like, like it's not like, it's not like,

1:14:22.520 --> 1:14:23.760
 I don't, like, I don't mean to like be a dick

1:14:23.760 --> 1:14:25.120
 and say like, I don't have patience for that,

1:14:25.120 --> 1:14:28.280
 but it's like that stuff doesn't help us

1:14:28.280 --> 1:14:30.560
 with our goal of winning self driving cars.

1:14:30.560 --> 1:14:32.280
 If I want money in the short term,

1:14:33.800 --> 1:14:36.080
 if I showed off like the actual,

1:14:36.080 --> 1:14:38.080
 like the learning tech that we have,

1:14:38.080 --> 1:14:39.580
 it's, it's somewhat sad.

1:14:39.580 --> 1:14:42.720
 Like it's years and years ahead of everybody else's.

1:14:42.720 --> 1:14:43.720
 Not to, maybe not Tesla's.

1:14:43.720 --> 1:14:45.280
 I think Tesla has some more stuff to us actually.

1:14:45.280 --> 1:14:46.120
 Yeah.

1:14:46.120 --> 1:14:46.940
 I think Tesla has similar stuff,

1:14:46.940 --> 1:14:47.940
 but when you compare it to like

1:14:47.940 --> 1:14:49.840
 what the Toyota Research Institute has,

1:14:50.800 --> 1:14:53.480
 you're not even close to what we have.

1:14:53.480 --> 1:14:54.360
 No comments.

1:14:54.360 --> 1:14:58.480
 But I also can't, I have to take your comments.

1:14:58.480 --> 1:15:01.640
 I intuitively believe you,

1:15:01.640 --> 1:15:03.240
 but I have to take it with a grain of salt

1:15:03.240 --> 1:15:06.200
 because I mean, you are an inspiration

1:15:06.200 --> 1:15:09.040
 because you basically don't care about a lot of things

1:15:09.040 --> 1:15:10.840
 that other companies care about.

1:15:10.840 --> 1:15:15.560
 You don't try to bullshit in a sense,

1:15:15.560 --> 1:15:16.640
 like make up stuff.

1:15:16.640 --> 1:15:19.720
 So to drive up valuation, you're really very real

1:15:19.720 --> 1:15:20.920
 and you're trying to solve the problem

1:15:20.920 --> 1:15:22.280
 and admire that a lot.

1:15:22.280 --> 1:15:25.960
 What I don't necessarily fully can't trust you on,

1:15:25.960 --> 1:15:28.440
 with all due respect, is how good it is, right?

1:15:28.440 --> 1:15:32.460
 I can only, but I also know how bad others are.

1:15:32.460 --> 1:15:33.300
 And so.

1:15:33.300 --> 1:15:36.680
 I'll say two things about, trust but verify, right?

1:15:36.680 --> 1:15:38.040
 I'll say two things about that.

1:15:38.040 --> 1:15:42.360
 One is try, get in a 2020 Corolla

1:15:42.360 --> 1:15:45.420
 and try open pilot 0.6 when it comes out next month.

1:15:46.680 --> 1:15:48.400
 I think already you'll look at this

1:15:48.400 --> 1:15:51.200
 and you'll be like, this is already really good.

1:15:51.200 --> 1:15:54.280
 And then I could be doing that all with hand labelers

1:15:54.280 --> 1:15:57.960
 and all with like the same approach that Mobileye uses.

1:15:57.960 --> 1:16:01.440
 When we release a model that no longer has the lanes in it,

1:16:01.440 --> 1:16:03.420
 that only outputs a path,

1:16:04.960 --> 1:16:08.680
 then think about how we did that machine learning

1:16:08.680 --> 1:16:10.080
 and then right away when you see,

1:16:10.080 --> 1:16:11.240
 and that's gonna be an open pilot,

1:16:11.240 --> 1:16:13.000
 that's gonna be an open pilot before 1.0.

1:16:13.000 --> 1:16:14.080
 When you see that model,

1:16:14.080 --> 1:16:15.400
 you'll know that everything I'm saying is true

1:16:15.400 --> 1:16:16.840
 because how else did I get that model?

1:16:16.840 --> 1:16:17.680
 Good.

1:16:17.680 --> 1:16:19.240
 You know what I'm saying is true about the simulator.

1:16:19.240 --> 1:16:22.680
 Yeah, yeah, this is super exciting, that's super exciting.

1:16:22.680 --> 1:16:25.760
 But like, you know, I listened to your talk with Kyle

1:16:25.760 --> 1:16:30.460
 and Kyle was originally building the aftermarket system

1:16:30.460 --> 1:16:34.920
 and he gave up on it because of technical challenges,

1:16:34.920 --> 1:16:38.160
 because of the fact that he's gonna have to support

1:16:38.160 --> 1:16:40.520
 20 to 50 cars, we support 45,

1:16:40.520 --> 1:16:41.480
 because what is he gonna do

1:16:41.480 --> 1:16:43.460
 when the manufacturer ABS system triggers?

1:16:43.460 --> 1:16:45.520
 We have alerts and warnings to deal with all of that

1:16:45.520 --> 1:16:46.600
 and all the cars.

1:16:46.600 --> 1:16:48.440
 And how is he going to formally verify it?

1:16:48.440 --> 1:16:49.840
 Well, I got 10 million miles of data,

1:16:49.840 --> 1:16:50.680
 it's probably better,

1:16:50.680 --> 1:16:53.240
 it's probably better verified than the spec.

1:16:53.240 --> 1:16:57.000
 Yeah, I'm glad you're here talking to me.

1:16:57.000 --> 1:17:00.280
 This is, I'll remember this day,

1:17:00.280 --> 1:17:01.120
 because it's interesting.

1:17:01.120 --> 1:17:04.140
 If you look at Kyle's from cruise,

1:17:04.140 --> 1:17:05.320
 I'm sure they have a large number

1:17:05.320 --> 1:17:07.400
 of business development folks

1:17:07.400 --> 1:17:10.200
 and you work with, he's working with GM,

1:17:10.200 --> 1:17:13.240
 you could work with Argo AI, working with Ford.

1:17:13.240 --> 1:17:17.560
 It's interesting because chances that you fail,

1:17:17.560 --> 1:17:20.160
 business wise, like bankrupt, are pretty high.

1:17:20.160 --> 1:17:21.080
 Yeah.

1:17:21.080 --> 1:17:23.880
 And yet, it's the Android model,

1:17:23.880 --> 1:17:26.340
 is you're actually taking on the problem.

1:17:26.340 --> 1:17:28.200
 So that's really inspiring, I mean.

1:17:28.200 --> 1:17:30.920
 Well, I have a long term way for Comma to make money too.

1:17:30.920 --> 1:17:32.180
 And one of the nice things

1:17:32.180 --> 1:17:34.400
 when you really take on the problem,

1:17:34.400 --> 1:17:36.760
 which is my hope for Autopilot, for example,

1:17:36.760 --> 1:17:39.560
 is things you don't expect,

1:17:39.560 --> 1:17:41.840
 ways to make money or create value

1:17:41.840 --> 1:17:43.960
 that you don't expect will pop up.

1:17:43.960 --> 1:17:46.640
 Oh, I've known how to do it since kind of,

1:17:46.640 --> 1:17:48.520
 2017 is the first time I said it.

1:17:48.520 --> 1:17:50.440
 Which part, to know how to do which part?

1:17:50.440 --> 1:17:52.480
 Our long term plan is to be a car insurance company.

1:17:52.480 --> 1:17:55.280
 Insurance, yeah, I love it, yep, yep.

1:17:55.280 --> 1:17:56.640
 I make driving twice as safe.

1:17:56.640 --> 1:17:57.600
 Not only that, I have the best data

1:17:57.600 --> 1:17:59.840
 such to know who statistically is the safest drivers.

1:17:59.840 --> 1:18:03.700
 And oh, oh, we see you, we see you driving unsafely,

1:18:03.700 --> 1:18:05.320
 we're not gonna insure you.

1:18:05.320 --> 1:18:08.960
 And that causes a bifurcation in the market

1:18:08.960 --> 1:18:10.880
 because the only people who can't get Comma insurance

1:18:10.880 --> 1:18:12.740
 are the bad drivers, Geico can insure them,

1:18:12.740 --> 1:18:13.860
 their premiums are crazy high,

1:18:13.860 --> 1:18:15.320
 our premiums are crazy low.

1:18:15.320 --> 1:18:18.040
 We'll win car insurance, take over that whole market.

1:18:18.040 --> 1:18:19.920
 Okay, so.

1:18:19.920 --> 1:18:21.240
 If we win, if we win.

1:18:21.240 --> 1:18:22.080
 But that's what I'm saying,

1:18:22.080 --> 1:18:24.080
 how do you turn Comma into a $10 billion company?

1:18:24.080 --> 1:18:24.920
 It's that.

1:18:24.920 --> 1:18:25.740
 That's right.

1:18:25.740 --> 1:18:29.120
 So you, Elon Musk, who else?

1:18:29.960 --> 1:18:32.700
 Who else is thinking like this and working like this

1:18:32.700 --> 1:18:33.540
 in your view?

1:18:33.540 --> 1:18:34.760
 Who are the competitors?

1:18:34.760 --> 1:18:36.120
 Are there people seriously,

1:18:36.120 --> 1:18:38.280
 I don't think anyone that I'm aware of

1:18:38.280 --> 1:18:41.840
 is seriously taking on lane keeping,

1:18:42.960 --> 1:18:45.100
 like where it's a huge business

1:18:45.100 --> 1:18:47.160
 that turns eventually into full autonomy

1:18:47.160 --> 1:18:52.000
 that then creates, yeah, like that creates other businesses

1:18:52.000 --> 1:18:53.400
 on top of it and so on.

1:18:53.400 --> 1:18:56.460
 Thinks insurance, thinks all kinds of ideas like that.

1:18:56.460 --> 1:18:58.560
 Do you know anyone else thinking like this?

1:19:00.480 --> 1:19:02.140
 Not really.

1:19:02.140 --> 1:19:02.980
 That's interesting.

1:19:02.980 --> 1:19:05.320
 I mean, my sense is everybody turns to that

1:19:05.320 --> 1:19:07.760
 in like four or five years.

1:19:07.760 --> 1:19:10.400
 Like Ford, once the autonomy doesn't fall through.

1:19:10.400 --> 1:19:11.240
 Yeah.

1:19:11.240 --> 1:19:12.560
 But at this time.

1:19:12.560 --> 1:19:14.100
 Elon's the iOS.

1:19:14.100 --> 1:19:16.680
 By the way, he paved the way for all of us.

1:19:16.680 --> 1:19:17.960
 It's the iOS, true.

1:19:17.960 --> 1:19:20.840
 I would not be doing Comma AI today

1:19:20.840 --> 1:19:23.440
 if it was not for those conversations with Elon.

1:19:23.440 --> 1:19:27.080
 And if it were not for him saying like,

1:19:27.080 --> 1:19:27.900
 I think he said like,

1:19:27.900 --> 1:19:29.120
 well, obviously we're not gonna use LiDAR,

1:19:29.120 --> 1:19:31.260
 we use cameras, humans use cameras.

1:19:31.260 --> 1:19:32.560
 So what do you think about that?

1:19:32.560 --> 1:19:33.880
 How important is LiDAR?

1:19:33.880 --> 1:19:36.920
 Everybody else on L5 is using LiDAR.

1:19:36.920 --> 1:19:39.200
 What are your thoughts on his provocative statement

1:19:39.200 --> 1:19:41.320
 that LiDAR is a crutch?

1:19:41.320 --> 1:19:43.040
 See, sometimes he'll say dumb things,

1:19:43.040 --> 1:19:44.040
 like the driver monitoring thing,

1:19:44.040 --> 1:19:46.240
 but sometimes he'll say absolutely, completely,

1:19:46.240 --> 1:19:48.360
 100% obviously true things.

1:19:48.360 --> 1:19:49.780
 Of course LiDAR is a crutch.

1:19:50.800 --> 1:19:53.020
 It's not even a good crutch.

1:19:53.020 --> 1:19:53.860
 You're not even using it.

1:19:53.860 --> 1:19:56.240
 Oh, they're using it for localization.

1:19:56.240 --> 1:19:57.080
 Yeah.

1:19:57.080 --> 1:19:58.140
 Which isn't good in the first place.

1:19:58.140 --> 1:20:00.480
 If you have to localize your car to centimeters

1:20:00.480 --> 1:20:04.280
 in order to drive, like that's not driving.

1:20:04.280 --> 1:20:06.280
 Currently not doing much machine learning

1:20:06.280 --> 1:20:07.560
 I thought for LiDAR data.

1:20:07.560 --> 1:20:11.320
 Meaning like to help you in the task of,

1:20:11.320 --> 1:20:12.840
 general task of perception.

1:20:12.840 --> 1:20:15.320
 The main goal of those LiDARs on those cars

1:20:15.320 --> 1:20:18.840
 I think is actually localization more than perception.

1:20:18.840 --> 1:20:20.080
 Or at least that's what they use them for.

1:20:20.080 --> 1:20:20.920
 Yeah, that's true.

1:20:20.920 --> 1:20:22.480
 If you want to localize to centimeters,

1:20:22.480 --> 1:20:23.680
 you can't use GPS.

1:20:23.680 --> 1:20:25.120
 The fanciest GPS in the world can't do it.

1:20:25.120 --> 1:20:26.920
 Especially if you're under tree cover and stuff.

1:20:26.920 --> 1:20:28.440
 With LiDAR you can do this pretty easily.

1:20:28.440 --> 1:20:30.200
 So you really, they're not taking on,

1:20:30.200 --> 1:20:33.160
 I mean in some research they're using it for perception,

1:20:33.160 --> 1:20:35.800
 but, and they're certainly not, which is sad,

1:20:35.800 --> 1:20:38.660
 they're not fusing it well with vision.

1:20:38.660 --> 1:20:40.520
 They do use it for perception.

1:20:40.520 --> 1:20:42.360
 I'm not saying they don't use it for perception,

1:20:42.360 --> 1:20:45.440
 but the thing that, they have vision based

1:20:45.440 --> 1:20:47.640
 and radar based perception systems as well.

1:20:47.640 --> 1:20:51.400
 You could remove the LiDAR and keep around

1:20:51.400 --> 1:20:54.000
 a lot of the dynamic object perception.

1:20:54.000 --> 1:20:56.280
 You want to get centimeter accurate localization?

1:20:56.280 --> 1:20:59.080
 Good luck doing that with anything else.

1:20:59.080 --> 1:21:02.840
 So what should Cruz, Waymo do?

1:21:02.840 --> 1:21:05.320
 Like what would be your advice to them now?

1:21:06.360 --> 1:21:08.480
 I mean Waymo is actually,

1:21:08.480 --> 1:21:11.640
 they're, I mean they're doing, they're serious.

1:21:11.640 --> 1:21:14.120
 Waymo out of the ball of them are quite

1:21:14.120 --> 1:21:16.280
 so serious about the long game.

1:21:16.280 --> 1:21:20.800
 If L5 is a lot, requires 50 years,

1:21:20.800 --> 1:21:24.160
 I think Waymo will be the only one left standing at the end

1:21:24.160 --> 1:21:26.840
 with the, given the financial backing that they have.

1:21:26.840 --> 1:21:28.800
 Buku Google bucks.

1:21:28.800 --> 1:21:31.160
 I'll say nice things about both Waymo and Cruz.

1:21:32.560 --> 1:21:33.640
 Let's do it.

1:21:33.640 --> 1:21:34.480
 Nice is good.

1:21:35.880 --> 1:21:39.360
 Waymo is by far the furthest along with technology.

1:21:39.360 --> 1:21:42.920
 Waymo has a three to five year lead on all the competitors.

1:21:44.000 --> 1:21:48.720
 If that, if the Waymo looking stack works,

1:21:48.720 --> 1:21:49.760
 maybe three year lead.

1:21:49.760 --> 1:21:51.320
 If the Waymo looking stack works,

1:21:51.320 --> 1:21:52.880
 they have a three year lead.

1:21:52.880 --> 1:21:55.840
 Now I argue that Waymo has spent too much money

1:21:55.840 --> 1:21:59.280
 to recapitalize, to gain back their losses

1:21:59.280 --> 1:22:00.200
 in those three years.

1:22:00.200 --> 1:22:03.680
 Also self driving cars have no network effect like that.

1:22:03.680 --> 1:22:04.840
 Uber has a network effect.

1:22:04.840 --> 1:22:07.160
 You have a market, you have drivers and you have riders.

1:22:07.160 --> 1:22:09.960
 Self driving cars, you have capital and you have riders.

1:22:09.960 --> 1:22:11.480
 There's no network effect.

1:22:11.480 --> 1:22:13.880
 If I want to blanket a new city in self driving cars,

1:22:13.880 --> 1:22:16.080
 I buy the off the shelf Chinese knockoff self driving cars

1:22:16.080 --> 1:22:17.240
 and I buy enough of them in the city.

1:22:17.240 --> 1:22:18.400
 I can't do that with drivers.

1:22:18.400 --> 1:22:20.920
 And that's why Uber has a first mover advantage

1:22:20.920 --> 1:22:22.840
 that no self driving car company will.

1:22:24.040 --> 1:22:26.600
 Can you disentangle that a little bit?

1:22:26.600 --> 1:22:28.200
 Uber, you're not talking about Uber,

1:22:28.200 --> 1:22:29.280
 the autonomous vehicle Uber.

1:22:29.280 --> 1:22:31.640
 You're talking about the Uber car, the, yeah.

1:22:31.640 --> 1:22:32.480
 I'm Uber.

1:22:32.480 --> 1:22:36.000
 I open for business in Austin, Texas, let's say.

1:22:36.000 --> 1:22:38.880
 I need to attract both sides of the market.

1:22:38.880 --> 1:22:41.320
 I need to both get drivers on my platform

1:22:41.320 --> 1:22:42.880
 and riders on my platform.

1:22:42.880 --> 1:22:45.400
 And I need to keep them both sufficiently happy, right?

1:22:45.400 --> 1:22:46.640
 Riders aren't gonna use it

1:22:46.640 --> 1:22:49.080
 if it takes more than five minutes for an Uber to show up.

1:22:49.080 --> 1:22:50.240
 Drivers aren't gonna use it

1:22:50.240 --> 1:22:52.280
 if they have to sit around all day and there's no riders.

1:22:52.280 --> 1:22:54.600
 So you have to carefully balance a market.

1:22:54.600 --> 1:22:56.400
 And whenever you have to carefully balance a market,

1:22:56.400 --> 1:22:58.400
 there's a great first mover advantage

1:22:58.400 --> 1:23:01.120
 because there's a switching cost for everybody, right?

1:23:01.120 --> 1:23:02.240
 The drivers and the riders

1:23:02.240 --> 1:23:04.200
 would have to switch at the same time.

1:23:04.200 --> 1:23:08.960
 Let's even say that, you know, let's say a Luber shows up

1:23:08.960 --> 1:23:12.640
 and Luber somehow, you know, agrees to do things

1:23:12.640 --> 1:23:15.800
 at a bigger, you know, we're just gonna,

1:23:15.800 --> 1:23:17.520
 we've done it more efficiently, right?

1:23:17.520 --> 1:23:19.880
 Luber is only takes 5% of a cut

1:23:19.880 --> 1:23:21.680
 instead of the 10% that Uber takes.

1:23:21.680 --> 1:23:22.840
 No one is gonna switch

1:23:22.840 --> 1:23:25.000
 because the switching cost is higher than that 5%.

1:23:25.000 --> 1:23:27.280
 So you actually can, in markets like that,

1:23:27.280 --> 1:23:28.640
 you have a first mover advantage.

1:23:28.640 --> 1:23:30.240
 Yeah.

1:23:30.240 --> 1:23:32.800
 Autonomous vehicles of the level five variety

1:23:32.800 --> 1:23:34.600
 have no first mover advantage.

1:23:34.600 --> 1:23:36.840
 If the technology becomes commoditized,

1:23:36.840 --> 1:23:39.600
 say I wanna go to a new city, look at the scooters.

1:23:39.600 --> 1:23:41.560
 It's gonna look a lot more like scooters.

1:23:41.560 --> 1:23:44.080
 Every person with a checkbook

1:23:44.080 --> 1:23:45.800
 can blanket a city in scooters.

1:23:45.800 --> 1:23:47.960
 And that's why you have 10 different scooter companies.

1:23:47.960 --> 1:23:48.800
 Which one's gonna win?

1:23:48.800 --> 1:23:49.680
 It's a race to the bottom.

1:23:49.680 --> 1:23:51.120
 It's a terrible market to be in

1:23:51.120 --> 1:23:53.240
 because there's no market for scooters.

1:23:55.000 --> 1:23:56.600
 And the scooters don't get a say

1:23:56.600 --> 1:23:58.240
 in whether they wanna be bought and deployed to a city

1:23:58.240 --> 1:23:59.080
 or not. Right.

1:23:59.080 --> 1:24:00.120
 So the, yeah.

1:24:00.120 --> 1:24:01.360
 We're gonna entice the scooters

1:24:01.360 --> 1:24:03.920
 with subsidies and deals and.

1:24:03.920 --> 1:24:05.920
 So whenever you have to invest that capital,

1:24:05.920 --> 1:24:06.840
 it doesn't.

1:24:06.840 --> 1:24:07.760
 It doesn't come back.

1:24:07.760 --> 1:24:08.960
 Yeah.

1:24:08.960 --> 1:24:12.400
 That can't be your main criticism of the Waymo approach.

1:24:12.400 --> 1:24:14.920
 Oh, I'm saying even if it does technically work.

1:24:14.920 --> 1:24:17.120
 Even if it does technically work, that's a problem.

1:24:17.120 --> 1:24:18.400
 Yeah.

1:24:18.400 --> 1:24:21.000
 I don't know if I were to say,

1:24:21.000 --> 1:24:23.600
 I would say you're already there.

1:24:23.600 --> 1:24:24.640
 I haven't even thought about that,

1:24:24.640 --> 1:24:26.600
 but I would say the bigger challenge

1:24:26.600 --> 1:24:28.000
 is the technical approach.

1:24:28.000 --> 1:24:29.800
 The.

1:24:29.800 --> 1:24:31.880
 So Waymo's cruises.

1:24:31.880 --> 1:24:33.000
 And not just the technical approach,

1:24:33.000 --> 1:24:34.800
 but of creating value.

1:24:34.800 --> 1:24:39.800
 I still don't understand how you beat Uber,

1:24:40.760 --> 1:24:43.480
 the human driven cars.

1:24:43.480 --> 1:24:44.920
 In terms of financially,

1:24:44.920 --> 1:24:47.160
 it doesn't make sense to me

1:24:47.160 --> 1:24:50.120
 that people wanna get in an autonomous vehicle.

1:24:50.120 --> 1:24:52.800
 I don't understand how you make money.

1:24:52.800 --> 1:24:54.280
 In the longterm, yes.

1:24:54.280 --> 1:24:56.440
 Like real longterm.

1:24:56.440 --> 1:24:58.600
 But it just feels like there's too much

1:24:58.600 --> 1:24:59.960
 capital investment needed.

1:24:59.960 --> 1:25:01.160
 Oh, and they're gonna be worse than Ubers

1:25:01.160 --> 1:25:04.040
 because they're gonna stop for every little thing,

1:25:04.040 --> 1:25:04.880
 everywhere.

1:25:06.280 --> 1:25:07.280
 I'll say a nice thing about cruise.

1:25:07.280 --> 1:25:08.360
 That was my nice thing about Waymo.

1:25:08.360 --> 1:25:09.200
 They're three years ahead.

1:25:09.200 --> 1:25:10.040
 Wait, what was the nice?

1:25:10.040 --> 1:25:10.880
 Oh, because they're three.

1:25:10.880 --> 1:25:12.400
 They're three years technically ahead of everybody.

1:25:12.400 --> 1:25:13.880
 Their tech stack is great.

1:25:14.720 --> 1:25:17.840
 My nice thing about cruise is GM buying them

1:25:17.840 --> 1:25:19.120
 was a great move for GM.

1:25:20.520 --> 1:25:22.200
 For $1 billion,

1:25:22.200 --> 1:25:25.520
 GM bought an insurance policy against Waymo.

1:25:25.520 --> 1:25:29.960
 They put, cruise is three years behind Waymo.

1:25:30.920 --> 1:25:33.240
 That means Google will get a monopoly on the technology

1:25:33.240 --> 1:25:35.120
 for at most three years.

1:25:36.800 --> 1:25:38.800
 And if technology works,

1:25:38.800 --> 1:25:40.760
 so you might not even be right about the three years,

1:25:40.760 --> 1:25:41.800
 it might be less.

1:25:41.800 --> 1:25:42.640
 Might be less.

1:25:42.640 --> 1:25:44.240
 Cruise actually might not be that far behind.

1:25:44.240 --> 1:25:47.280
 I don't know how much Waymo has waffled around

1:25:47.280 --> 1:25:49.720
 or how much of it actually is just that long tail.

1:25:49.720 --> 1:25:50.560
 Yeah, okay.

1:25:50.560 --> 1:25:53.520
 If that's the best you could say in terms of nice things,

1:25:53.520 --> 1:25:55.160
 that's more of a nice thing for GM

1:25:55.160 --> 1:25:58.560
 that that's the smart insurance policy.

1:25:58.560 --> 1:25:59.640
 It's a smart insurance policy.

1:25:59.640 --> 1:26:01.840
 I mean, I think that's how,

1:26:01.840 --> 1:26:05.160
 I can't see cruise working out any other.

1:26:05.160 --> 1:26:07.800
 For cruise to leapfrog Waymo would really surprise me.

1:26:10.360 --> 1:26:12.000
 Yeah, so let's talk about

1:26:12.000 --> 1:26:13.600
 the underlying assumption of everything is.

1:26:13.600 --> 1:26:15.280
 We're not gonna leapfrog Tesla.

1:26:17.520 --> 1:26:19.440
 Tesla would have to seriously mess up for us

1:26:19.440 --> 1:26:20.400
 because you're.

1:26:20.400 --> 1:26:23.200
 Okay, so the way you leapfrog, right?

1:26:23.200 --> 1:26:26.080
 Is you come up with an idea

1:26:26.080 --> 1:26:28.560
 or you take a direction perhaps secretly

1:26:28.560 --> 1:26:30.640
 that the other people aren't taking.

1:26:31.640 --> 1:26:35.000
 And so the cruise, Waymo,

1:26:35.000 --> 1:26:38.080
 even Aurora.

1:26:38.080 --> 1:26:40.080
 I don't know Aurora, Zooks is the same stack as well.

1:26:40.080 --> 1:26:41.720
 They're all the same code base even.

1:26:41.720 --> 1:26:45.360
 And they're all the same DARPA Urban Challenge code base.

1:26:45.360 --> 1:26:46.800
 So the question is,

1:26:46.800 --> 1:26:48.960
 do you think there's a room for brilliance and innovation

1:26:48.960 --> 1:26:50.360
 that will change everything?

1:26:50.360 --> 1:26:53.880
 Like say, okay, so I'll give you examples.

1:26:53.880 --> 1:26:58.880
 It could be if revolution and mapping, for example,

1:26:59.600 --> 1:27:03.000
 that allow you to map things,

1:27:03.000 --> 1:27:05.800
 do HD maps of the whole world,

1:27:05.800 --> 1:27:08.040
 all weather conditions somehow really well,

1:27:08.040 --> 1:27:13.040
 or revolution and simulation

1:27:13.040 --> 1:27:18.040
 to where the all the way you said before becomes incorrect.

1:27:20.480 --> 1:27:21.320
 That kind of thing.

1:27:21.320 --> 1:27:23.200
 Any room for breakthrough innovation?

1:27:24.920 --> 1:27:25.960
 What I said before about,

1:27:25.960 --> 1:27:27.160
 oh, they actually get the whole thing.

1:27:27.160 --> 1:27:30.480
 Well, I'll say this about,

1:27:30.480 --> 1:27:32.640
 we divide driving into three problems

1:27:32.640 --> 1:27:33.800
 and I actually haven't solved the third yet,

1:27:33.800 --> 1:27:34.800
 but I haven't had you how to do it.

1:27:34.800 --> 1:27:36.120
 So there's the static.

1:27:36.120 --> 1:27:38.000
 The static driving problem is assuming

1:27:38.000 --> 1:27:40.120
 you are the only car on the road, right?

1:27:40.120 --> 1:27:41.960
 And this problem can be solved 100%

1:27:41.960 --> 1:27:43.920
 with mapping and localization.

1:27:43.920 --> 1:27:45.680
 This is why farms work the way they do.

1:27:45.680 --> 1:27:48.360
 If all you have to deal with is the static problem

1:27:48.360 --> 1:27:50.120
 and you can statically schedule your machines, right?

1:27:50.120 --> 1:27:52.640
 It's the same as like statically scheduling processes.

1:27:52.640 --> 1:27:53.960
 You can statically schedule your tractors

1:27:53.960 --> 1:27:56.080
 to never hit each other on their paths, right?

1:27:56.080 --> 1:27:57.440
 Cause they know the speed they go at.

1:27:57.440 --> 1:28:00.080
 So that's the static driving problem.

1:28:00.080 --> 1:28:03.040
 Maps only helps you with the static driving problem.

1:28:03.880 --> 1:28:06.880
 Yeah, the question about static driving,

1:28:06.880 --> 1:28:08.720
 you've just made it sound like it's really easy.

1:28:08.720 --> 1:28:11.880
 Static driving is really easy.

1:28:11.880 --> 1:28:13.040
 How easy?

1:28:13.040 --> 1:28:16.440
 How, well, cause the whole drifting out of lane,

1:28:16.440 --> 1:28:18.720
 when Tesla drifts out of lane,

1:28:18.720 --> 1:28:22.000
 it's failing on the fundamental static driving problem.

1:28:22.000 --> 1:28:24.440
 Tesla is drifting out of lane?

1:28:24.440 --> 1:28:27.720
 The static driving problem is not easy for the world.

1:28:27.720 --> 1:28:30.360
 The static driving problem is easy for one route.

1:28:31.840 --> 1:28:33.920
 One route and one weather condition

1:28:33.920 --> 1:28:37.920
 with one state of lane markings

1:28:37.920 --> 1:28:40.880
 and like no deterioration, no cracks in the road.

1:28:40.880 --> 1:28:42.600
 No, I'm assuming you have a perfect localizer.

1:28:42.600 --> 1:28:44.200
 So that's solved for the weather condition

1:28:44.200 --> 1:28:45.600
 and the lane marking condition.

1:28:45.600 --> 1:28:46.600
 But that's the problem is,

1:28:46.600 --> 1:28:48.400
 how do you have a perfect localizer?

1:28:48.400 --> 1:28:50.560
 Perfect localizers are not that hard to build.

1:28:50.560 --> 1:28:53.320
 Okay, come on now, with LIDAR?

1:28:53.320 --> 1:28:54.160
 With LIDAR, yeah.

1:28:54.160 --> 1:28:55.000
 Oh, with LIDAR, okay.

1:28:55.000 --> 1:28:56.400
 With LIDAR, yeah, but you use LIDAR, right?

1:28:56.400 --> 1:28:58.600
 Like use LIDAR, build a perfect localizer.

1:28:58.600 --> 1:29:00.880
 Building a perfect localizer without LIDAR,

1:29:02.960 --> 1:29:04.280
 it's gonna be hard.

1:29:04.280 --> 1:29:05.720
 You can get 10 centimeters without LIDAR,

1:29:05.720 --> 1:29:07.200
 you can get one centimeter with LIDAR.

1:29:07.200 --> 1:29:09.240
 I'm not even concerned about the one or 10 centimeters.

1:29:09.240 --> 1:29:11.160
 I'm concerned if every once in a while,

1:29:11.160 --> 1:29:12.640
 you're just way off.

1:29:12.640 --> 1:29:17.640
 Yeah, so this is why you have to carefully make sure

1:29:17.920 --> 1:29:19.960
 you're always tracking your position.

1:29:19.960 --> 1:29:21.680
 You wanna use LIDAR camera fusion,

1:29:21.680 --> 1:29:24.400
 but you can get the reliability of that system

1:29:24.400 --> 1:29:27.960
 up to 100,000 miles,

1:29:27.960 --> 1:29:29.640
 and then you write some fallback condition

1:29:29.640 --> 1:29:32.120
 where it's not that bad if you're way off, right?

1:29:32.120 --> 1:29:33.720
 I think that you can get it to the point,

1:29:33.720 --> 1:29:36.760
 it's like ASLD that you're never in a case

1:29:36.760 --> 1:29:38.440
 where you're way off and you don't know it.

1:29:38.440 --> 1:29:40.200
 Yeah, okay, so this is brilliant.

1:29:40.200 --> 1:29:42.240
 So that's the static. Static.

1:29:42.240 --> 1:29:45.920
 We can, especially with LIDAR and good HG maps,

1:29:45.920 --> 1:29:47.680
 you can solve that problem. Easy.

1:29:47.680 --> 1:29:50.440
 No, I just disagree with your word easy.

1:29:50.440 --> 1:29:51.760
 The static problem's so easy.

1:29:51.760 --> 1:29:54.000
 It's very typical for you to say something is easy.

1:29:54.000 --> 1:29:54.840
 I got it. No.

1:29:54.840 --> 1:29:56.880
 It's not as challenging as the other ones, okay.

1:29:56.880 --> 1:29:58.760
 Well, okay, maybe it's obvious how to solve it.

1:29:58.760 --> 1:30:00.320
 The third one's the hardest.

1:30:00.320 --> 1:30:01.880
 And a lot of people don't even think about the third one

1:30:01.880 --> 1:30:03.640
 and even see it as different from the second one.

1:30:03.640 --> 1:30:05.720
 So the second one is dynamic.

1:30:05.720 --> 1:30:08.520
 The second one is like, say there's an obvious example

1:30:08.520 --> 1:30:10.360
 is like a car stopped at a red light, right?

1:30:10.360 --> 1:30:12.520
 You can't have that car in your map

1:30:12.520 --> 1:30:13.720
 because you don't know whether that car

1:30:13.720 --> 1:30:14.880
 is gonna be there or not.

1:30:14.880 --> 1:30:17.960
 So you have to detect that car in real time

1:30:17.960 --> 1:30:20.600
 and then you have to do the appropriate action, right?

1:30:21.600 --> 1:30:24.800
 Also, that car is not a fixed object.

1:30:24.800 --> 1:30:26.600
 That car may move and you have to predict

1:30:26.600 --> 1:30:28.680
 what that car will do, right?

1:30:28.680 --> 1:30:30.840
 So this is the dynamic problem.

1:30:30.840 --> 1:30:31.680
 Yeah.

1:30:31.680 --> 1:30:32.800
 So you have to deal with this.

1:30:32.800 --> 1:30:36.640
 This involves, again, like you're gonna need models

1:30:36.640 --> 1:30:38.000
 of other people's behavior.

1:30:39.080 --> 1:30:40.320
 Are you including in that,

1:30:40.320 --> 1:30:42.320
 I don't wanna step on the third one.

1:30:42.320 --> 1:30:43.160
 Oh.

1:30:43.160 --> 1:30:46.920
 But are you including in that your influence on people?

1:30:46.920 --> 1:30:48.240
 Ah, that's the third one.

1:30:48.240 --> 1:30:49.080
 Okay.

1:30:49.080 --> 1:30:49.920
 That's the third one.

1:30:49.920 --> 1:30:51.840
 We call it the counterfactual.

1:30:51.840 --> 1:30:52.680
 Yeah, brilliant.

1:30:52.680 --> 1:30:53.520
 And that.

1:30:53.520 --> 1:30:54.360
 I just talked to Judea Pearl

1:30:54.360 --> 1:30:55.800
 who's obsessed with counterfactuals.

1:30:55.800 --> 1:30:56.640
 And the counterfactual.

1:30:56.640 --> 1:30:58.600
 Oh yeah, yeah, I read his books.

1:30:58.600 --> 1:31:00.760
 So the static and the dynamic

1:31:00.760 --> 1:31:01.960
 Yeah.

1:31:01.960 --> 1:31:04.720
 Our approach right now for lateral

1:31:04.720 --> 1:31:07.560
 will scale completely to the static and dynamic.

1:31:07.560 --> 1:31:10.720
 The counterfactual, the only way I have to do it yet,

1:31:10.720 --> 1:31:13.960
 the thing that I wanna do once we have all of these cars

1:31:13.960 --> 1:31:16.760
 is I wanna do reinforcement learning on the world.

1:31:16.760 --> 1:31:18.880
 I'm always gonna turn the exploiter up to max.

1:31:18.880 --> 1:31:20.440
 I'm not gonna have them explore.

1:31:20.440 --> 1:31:22.760
 But the only real way to get at the counterfactual

1:31:22.760 --> 1:31:24.080
 is to do reinforcement learning

1:31:24.080 --> 1:31:26.320
 because the other agents are humans.

1:31:27.760 --> 1:31:30.080
 So that's fascinating that you break it down like that.

1:31:30.080 --> 1:31:31.720
 I agree completely.

1:31:31.720 --> 1:31:33.680
 I've spent my life thinking about this problem.

1:31:33.680 --> 1:31:34.520
 It's beautiful.

1:31:34.520 --> 1:31:37.840
 And part of it, because you're slightly insane,

1:31:37.840 --> 1:31:39.080
 it's good.

1:31:39.080 --> 1:31:39.920
 Because.

1:31:41.240 --> 1:31:42.080
 Not my life.

1:31:42.080 --> 1:31:43.120
 Just the last four years.

1:31:43.120 --> 1:31:43.960
 No, no.

1:31:43.960 --> 1:31:48.920
 You have some nonzero percent of your brain

1:31:48.920 --> 1:31:51.520
 has a madman in it, which is good.

1:31:51.520 --> 1:31:52.360
 That's a really good feature.

1:31:52.360 --> 1:31:55.920
 But there's a safety component to it

1:31:55.920 --> 1:31:59.040
 that I think sort of with counterfactuals and so on

1:31:59.040 --> 1:32:00.280
 that would just freak people out.

1:32:00.280 --> 1:32:03.320
 How do you even start to think about just in general?

1:32:03.320 --> 1:32:07.600
 I mean, you've had some friction with NHTSA and so on.

1:32:07.600 --> 1:32:12.600
 I am frankly exhausted by safety engineers.

1:32:14.280 --> 1:32:19.280
 The prioritization on safety over innovation

1:32:21.360 --> 1:32:23.720
 to a degree where it kills, in my view,

1:32:23.720 --> 1:32:26.200
 kills safety in the long term.

1:32:26.200 --> 1:32:28.080
 So the counterfactual thing,

1:32:28.080 --> 1:32:31.560
 they just actually exploring this world

1:32:31.560 --> 1:32:33.880
 of how do you interact with dynamic objects and so on.

1:32:33.880 --> 1:32:34.840
 How do you think about safety?

1:32:34.840 --> 1:32:38.080
 You can do reinforcement learning without ever exploring.

1:32:38.080 --> 1:32:40.400
 And I said that, so you can think about your,

1:32:40.400 --> 1:32:41.520
 in reinforcement learning,

1:32:41.520 --> 1:32:44.280
 it's usually called a temperature parameter.

1:32:44.280 --> 1:32:45.320
 And your temperature parameter

1:32:45.320 --> 1:32:48.080
 is how often you deviate from the argmax.

1:32:48.080 --> 1:32:50.680
 I could always set that to zero and still learn.

1:32:50.680 --> 1:32:52.800
 And I feel that you'd always want that set to zero

1:32:52.800 --> 1:32:54.040
 on your actual system.

1:32:54.040 --> 1:32:54.880
 Gotcha.

1:32:54.880 --> 1:32:58.120
 But the problem is you first don't know very much.

1:32:58.120 --> 1:32:59.520
 And so you're going to make mistakes.

1:32:59.520 --> 1:33:02.360
 So the learning, the exploration happens through mistakes.

1:33:02.360 --> 1:33:03.720
 Yeah, but okay.

1:33:03.720 --> 1:33:06.080
 So the consequences of a mistake.

1:33:06.080 --> 1:33:09.400
 Open pilot and autopilot are making mistakes left and right.

1:33:09.400 --> 1:33:12.560
 We have 700 daily active users,

1:33:12.560 --> 1:33:14.040
 a thousand weekly active users.

1:33:14.040 --> 1:33:18.920
 Open pilot makes tens of thousands of mistakes a week.

1:33:18.920 --> 1:33:21.160
 These mistakes have zero consequences.

1:33:21.160 --> 1:33:22.560
 These mistakes are,

1:33:22.560 --> 1:33:26.840
 oh, I wanted to take this exit and it went straight.

1:33:26.840 --> 1:33:28.520
 So I'm just going to carefully touch the wheel.

1:33:28.520 --> 1:33:29.360
 The humans catch them.

1:33:29.360 --> 1:33:30.680
 The humans catch them.

1:33:30.680 --> 1:33:33.120
 And the human disengagement is labeling

1:33:33.120 --> 1:33:34.160
 that reinforcement learning

1:33:34.160 --> 1:33:36.200
 in a completely consequence free way.

1:33:37.280 --> 1:33:39.880
 So driver monitoring is the way you ensure they keep.

1:33:39.880 --> 1:33:40.720
 Yes.

1:33:40.720 --> 1:33:42.160
 They keep paying attention.

1:33:42.160 --> 1:33:43.280
 How is your messaging?

1:33:43.280 --> 1:33:45.280
 Say I gave you a billion dollars,

1:33:45.280 --> 1:33:47.840
 you would be scaling it now.

1:33:47.840 --> 1:33:49.760
 Oh, I couldn't scale it with any amount of money.

1:33:49.760 --> 1:33:51.680
 I'd raise money if I could, if I had a way to scale it.

1:33:51.680 --> 1:33:53.360
 Yeah, you're now not focused on scale.

1:33:53.360 --> 1:33:54.200
 I don't know how to do,

1:33:54.200 --> 1:33:55.840
 oh, like I guess I could sell it to more people,

1:33:55.840 --> 1:33:57.040
 but I want to make the system better.

1:33:57.040 --> 1:33:57.880
 Better, better.

1:33:57.880 --> 1:33:58.920
 And I don't know how to, I mean.

1:33:58.920 --> 1:34:01.160
 But what's the messaging here?

1:34:01.160 --> 1:34:06.160
 I got a chance to talk to Elon and he basically said

1:34:06.320 --> 1:34:08.160
 that the human factor doesn't matter.

1:34:09.360 --> 1:34:10.440
 You know, the human doesn't matter

1:34:10.440 --> 1:34:12.360
 because the system will perform,

1:34:12.360 --> 1:34:14.840
 there'll be sort of a, sorry to use the term,

1:34:14.840 --> 1:34:15.680
 but like a singular,

1:34:15.680 --> 1:34:17.880
 like a point where it gets just much better.

1:34:17.880 --> 1:34:20.880
 And so the human, it won't really matter.

1:34:20.880 --> 1:34:25.040
 But it seems like that human catching the system

1:34:25.040 --> 1:34:29.440
 when it gets into trouble is like the thing

1:34:29.440 --> 1:34:32.800
 which will make something like reinforcement learning work.

1:34:32.800 --> 1:34:35.680
 So how do you think messaging for Tesla,

1:34:35.680 --> 1:34:36.880
 for you should change,

1:34:36.880 --> 1:34:39.120
 for the industry in general should change?

1:34:39.120 --> 1:34:40.880
 I think our messaging is pretty clear.

1:34:40.880 --> 1:34:43.120
 At least like our messaging wasn't that clear

1:34:43.120 --> 1:34:45.240
 in the beginning and I do kind of fault myself for that.

1:34:45.240 --> 1:34:48.520
 We are proud right now to be a level two system.

1:34:48.520 --> 1:34:50.400
 We are proud to be level two.

1:34:50.400 --> 1:34:51.680
 If we talk about level four,

1:34:51.680 --> 1:34:53.240
 it's not with the current hardware.

1:34:53.240 --> 1:34:55.960
 It's not gonna be just a magical OTA upgrade.

1:34:55.960 --> 1:34:57.360
 It's gonna be new hardware.

1:34:57.360 --> 1:34:59.600
 It's gonna be very carefully thought out.

1:34:59.600 --> 1:35:01.640
 Right now, we are proud to be level two

1:35:01.640 --> 1:35:03.400
 and we have a rigorous safety model.

1:35:03.400 --> 1:35:06.680
 I mean, not like, okay, rigorous, who knows what that means,

1:35:06.680 --> 1:35:08.720
 but we at least have a safety model

1:35:08.720 --> 1:35:11.920
 and we make it explicit as in safety.md in OpenPilot.

1:35:11.920 --> 1:35:15.960
 And it says, seriously though, safety.md.

1:35:17.040 --> 1:35:18.680
 This is brilliant, this is so Android.

1:35:18.680 --> 1:35:21.880
 Well, this is the safety model

1:35:21.880 --> 1:35:23.960
 and I like to have conversations like,

1:35:25.600 --> 1:35:27.240
 sometimes people will come to you and they're like,

1:35:27.240 --> 1:35:29.320
 your system's not safe.

1:35:29.320 --> 1:35:31.160
 Okay, have you read my safety docs?

1:35:31.160 --> 1:35:32.760
 Would you like to have an intelligent conversation

1:35:32.760 --> 1:35:33.600
 about this?

1:35:33.600 --> 1:35:34.440
 And the answer is always no.

1:35:34.440 --> 1:35:37.000
 They just like scream about, it runs Python.

1:35:38.280 --> 1:35:39.120
 Okay, what?

1:35:39.120 --> 1:35:41.600
 So you're saying that because Python's not real time,

1:35:41.600 --> 1:35:44.320
 Python not being real time never causes disengagements.

1:35:44.320 --> 1:35:47.720
 Disengagements are caused by, the model is QM.

1:35:47.720 --> 1:35:49.840
 But safety.md says the following,

1:35:49.840 --> 1:35:50.680
 first and foremost,

1:35:50.680 --> 1:35:53.080
 the driver must be paying attention at all times.

1:35:55.400 --> 1:35:57.760
 I still consider the software to be alpha software

1:35:57.760 --> 1:36:00.120
 until we can actually enforce that statement,

1:36:00.120 --> 1:36:03.320
 but I feel it's very well communicated to our users.

1:36:03.320 --> 1:36:04.560
 Two more things.

1:36:04.560 --> 1:36:09.120
 One is the user must be able to easily take control

1:36:09.120 --> 1:36:10.920
 of the vehicle at all times.

1:36:10.920 --> 1:36:14.480
 So if you step on the gas or brake with OpenPilot,

1:36:14.480 --> 1:36:16.440
 it gives full manual control back to the user

1:36:16.440 --> 1:36:17.800
 or press the cancel button.

1:36:18.720 --> 1:36:23.280
 Step two, the car will never react so quickly,

1:36:23.280 --> 1:36:26.000
 we define so quickly to be about one second,

1:36:26.000 --> 1:36:27.640
 that you can't react in time.

1:36:27.640 --> 1:36:29.480
 And we do this by enforcing torque limits,

1:36:29.480 --> 1:36:31.520
 braking limits and acceleration limits.

1:36:31.520 --> 1:36:36.520
 So we have like our torque limits way lower than Tesla's.

1:36:36.520 --> 1:36:39.080
 This is another potential.

1:36:39.080 --> 1:36:40.240
 If I could tweak Autopilot,

1:36:40.240 --> 1:36:41.320
 I would lower their torque limit

1:36:41.320 --> 1:36:42.960
 and I would add driver monitoring.

1:36:42.960 --> 1:36:46.240
 Because Autopilot can jerk the wheel hard.

1:36:46.240 --> 1:36:47.080
 OpenPilot can't.

1:36:47.960 --> 1:36:52.080
 We limit, and all this code is open source, readable.

1:36:52.080 --> 1:36:54.880
 And I believe now it's all Misra C compliant.

1:36:54.880 --> 1:36:55.720
 What's that mean?

1:36:57.080 --> 1:37:00.400
 Misra is like the automotive coding standard.

1:37:00.400 --> 1:37:03.400
 At first, I've come to respect.

1:37:03.400 --> 1:37:05.000
 I've been reading like the standards lately

1:37:05.000 --> 1:37:05.880
 and I've come to respect them.

1:37:05.880 --> 1:37:07.800
 They're actually written by very smart people.

1:37:07.800 --> 1:37:09.880
 Yeah, they're brilliant people actually.

1:37:09.880 --> 1:37:11.320
 They have a lot of experience.

1:37:11.320 --> 1:37:13.360
 They're sometimes a little too cautious,

1:37:13.360 --> 1:37:16.800
 but in this case, it pays off.

1:37:16.800 --> 1:37:18.440
 Misra is written by like computer scientists.

1:37:18.440 --> 1:37:19.840
 And you can tell by the language they use.

1:37:19.840 --> 1:37:21.120
 You can tell by the language they use,

1:37:21.120 --> 1:37:24.480
 they talk about like whether certain conditions in Misra

1:37:24.480 --> 1:37:26.560
 are decidable or undecidable.

1:37:26.560 --> 1:37:28.360
 And you mean like the halting problem?

1:37:28.360 --> 1:37:31.640
 And yes, all right, you've earned my respect.

1:37:31.640 --> 1:37:33.120
 I will read carefully what you have to say

1:37:33.120 --> 1:37:35.760
 and we wanna make our code compliant with that.

1:37:35.760 --> 1:37:38.160
 All right, so you're proud level two, beautiful.

1:37:38.160 --> 1:37:42.360
 So you were the founder and I think CEO of Kama AI,

1:37:42.360 --> 1:37:44.320
 then you were the head of research.

1:37:44.320 --> 1:37:46.080
 What the heck are you now?

1:37:46.080 --> 1:37:47.440
 What's your connection to Kama AI?

1:37:47.440 --> 1:37:49.400
 I'm the president, but I'm one of those

1:37:49.400 --> 1:37:53.040
 like unelected presidents of like a small dictatorship

1:37:53.040 --> 1:37:55.160
 country, not one of those like elected presidents.

1:37:55.160 --> 1:37:57.160
 Oh, so you're like Putin when he was like the,

1:37:57.160 --> 1:37:58.280
 yeah, I got you.

1:37:59.920 --> 1:38:02.080
 So there's a, what's the governance structure?

1:38:02.080 --> 1:38:04.800
 What's the future of Kama AI?

1:38:04.800 --> 1:38:07.440
 I mean, yeah, it's a business.

1:38:07.440 --> 1:38:10.000
 Do you want, are you just focused on getting things

1:38:10.000 --> 1:38:14.880
 right now, making some small amount of money in the meantime

1:38:14.880 --> 1:38:17.520
 and then when it works, it works and you scale.

1:38:17.520 --> 1:38:20.440
 Our burn rate is about 200K a month

1:38:20.440 --> 1:38:23.000
 and our revenue is about 100K a month.

1:38:23.000 --> 1:38:24.880
 So we need to forex our revenue,

1:38:24.880 --> 1:38:28.160
 but we haven't like tried very hard at that yet.

1:38:28.160 --> 1:38:30.120
 And the revenue is basically selling stuff online.

1:38:30.120 --> 1:38:32.320
 Yeah, we sell stuff shop.kama.ai.

1:38:32.320 --> 1:38:33.880
 Is there other, well, okay,

1:38:33.880 --> 1:38:35.720
 so you'll have to figure out the revenue.

1:38:35.720 --> 1:38:37.840
 That's our only, see, but to me,

1:38:37.840 --> 1:38:40.360
 that's like respectable revenues.

1:38:40.360 --> 1:38:42.640
 We make it by selling products to consumers

1:38:42.640 --> 1:38:45.960
 who are honest and transparent about what they are.

1:38:45.960 --> 1:38:48.920
 Most actually level four companies, right?

1:38:50.680 --> 1:38:54.240
 Cause you could easily start blowing up like smoke,

1:38:54.240 --> 1:38:57.040
 like overselling the hype and feeding into,

1:38:57.040 --> 1:38:59.000
 getting some fundraisers.

1:38:59.000 --> 1:39:00.440
 Oh, you're the guy, you're a genius

1:39:00.440 --> 1:39:01.760
 because you hacked the iPhone.

1:39:01.760 --> 1:39:03.280
 Oh, I hate that, I hate that.

1:39:03.280 --> 1:39:06.640
 Yeah, well, I can trade my social capital for more money.

1:39:06.640 --> 1:39:10.280
 I did it once, I almost regret it doing it the first time.

1:39:10.280 --> 1:39:11.600
 Well, on a small tangent,

1:39:11.600 --> 1:39:16.560
 what's your, you seem to not like fame

1:39:16.560 --> 1:39:18.880
 and yet you're also drawn to fame.

1:39:18.880 --> 1:39:23.880
 Where are you on that currently?

1:39:24.560 --> 1:39:27.200
 Have you had some introspection, some soul searching?

1:39:27.200 --> 1:39:29.240
 Yeah, I actually,

1:39:29.240 --> 1:39:32.200
 I've come to a pretty stable position on that.

1:39:32.200 --> 1:39:33.880
 Like after the first time,

1:39:33.880 --> 1:39:36.840
 I realized that I don't want attention from the masses.

1:39:36.840 --> 1:39:39.160
 I want attention from people who I respect.

1:39:40.280 --> 1:39:41.960
 Who do you respect?

1:39:41.960 --> 1:39:43.960
 I can give a list of people.

1:39:43.960 --> 1:39:47.200
 So are these like Elon Musk type characters?

1:39:47.200 --> 1:39:50.000
 Yeah, well, actually, you know what?

1:39:50.000 --> 1:39:51.240
 I'll make it more broad than that.

1:39:51.240 --> 1:39:54.040
 I won't make it about a person, I respect skill.

1:39:54.040 --> 1:39:56.840
 I respect people who have skills, right?

1:39:56.840 --> 1:40:01.400
 And I would like to like be, I'm not gonna say famous,

1:40:01.400 --> 1:40:05.440
 but be like known among more people who have like real skills.

1:40:06.880 --> 1:40:11.880
 Who in cars do you think have skill, not do you respect?

1:40:15.000 --> 1:40:17.760
 Oh, Kyle Vogt has skill.

1:40:17.760 --> 1:40:20.840
 A lot of people at Waymo have skill and I respect them.

1:40:20.840 --> 1:40:23.760
 I respect them as engineers.

1:40:23.760 --> 1:40:24.920
 Like I can think, I mean,

1:40:24.920 --> 1:40:26.280
 I think about all the times in my life

1:40:26.280 --> 1:40:27.960
 where I've been like dead set on approaches

1:40:27.960 --> 1:40:29.760
 and they turn out to be wrong.

1:40:29.760 --> 1:40:31.720
 So, I mean, this might, I might be wrong.

1:40:31.720 --> 1:40:32.600
 I accept that.

1:40:32.600 --> 1:40:36.600
 I accept that there's a decent chance that I'm wrong.

1:40:36.600 --> 1:40:37.440
 And actually, I mean,

1:40:37.440 --> 1:40:39.480
 having talked to Chris Hermsons, Sterling Anderson,

1:40:39.480 --> 1:40:43.360
 those guys, I mean, I deeply respect Chris.

1:40:43.360 --> 1:40:44.640
 I just admire the guy.

1:40:46.040 --> 1:40:47.400
 He's legit.

1:40:47.400 --> 1:40:48.960
 When you drive a car through the desert

1:40:48.960 --> 1:40:52.440
 when everybody thinks it's impossible, that's legit.

1:40:52.440 --> 1:40:53.840
 And then I also really respect the people

1:40:53.840 --> 1:40:55.680
 who are like writing the infrastructure of the world,

1:40:55.680 --> 1:40:57.760
 like the Linus Torvalds and the Chris Lattiners.

1:40:57.760 --> 1:40:59.080
 They were doing the real work.

1:40:59.080 --> 1:41:00.520
 I know, they're doing the real work.

1:41:00.520 --> 1:41:03.000
 This, having talked to Chris,

1:41:03.000 --> 1:41:04.600
 like Chris Lattiners, you realize,

1:41:04.600 --> 1:41:05.720
 especially when they're humble,

1:41:05.720 --> 1:41:07.720
 it's like you realize, oh, you guys,

1:41:07.720 --> 1:41:09.680
 we're just using your,

1:41:09.680 --> 1:41:10.520
 Oh yeah.

1:41:10.520 --> 1:41:11.560
 All the hard work that you did.

1:41:11.560 --> 1:41:13.160
 Yeah, that's incredible.

1:41:13.160 --> 1:41:17.200
 What do you think, Mr. Anthony Lewandowski,

1:41:18.480 --> 1:41:21.680
 what do you, he's another mad genius.

1:41:21.680 --> 1:41:22.920
 Sharp guy, oh yeah.

1:41:22.920 --> 1:41:27.680
 What, do you think he might long term become a competitor?

1:41:27.680 --> 1:41:28.880
 Oh, to comma?

1:41:28.880 --> 1:41:32.440
 Well, so I think that he has the other right approach.

1:41:32.440 --> 1:41:35.320
 I think that right now there's two right approaches.

1:41:35.320 --> 1:41:37.720
 One is what we're doing, and one is what he's doing.

1:41:37.720 --> 1:41:39.840
 Can you describe, I think it's called Pronto AI.

1:41:39.840 --> 1:41:40.960
 He started a new thing.

1:41:40.960 --> 1:41:42.400
 Do you know what the approach is?

1:41:42.400 --> 1:41:43.240
 I actually don't know.

1:41:43.240 --> 1:41:45.080
 Embark is also doing the same sort of thing.

1:41:45.080 --> 1:41:47.360
 The idea is almost that you want to,

1:41:47.360 --> 1:41:51.840
 so if you're, I can't partner with Honda and Toyota.

1:41:51.840 --> 1:41:56.840
 Honda and Toyota are like 400,000 person companies.

1:41:56.840 --> 1:41:58.640
 It's not even a company at that point.

1:41:58.640 --> 1:42:00.600
 I don't think of it like, I don't personify it.

1:42:00.600 --> 1:42:01.440
 I think of it like an object,

1:42:01.440 --> 1:42:06.280
 but a trucker drives for a fleet,

1:42:06.280 --> 1:42:09.480
 maybe that has like, some truckers are independent.

1:42:09.480 --> 1:42:11.320
 Some truckers drive for fleets with a hundred trucks.

1:42:11.320 --> 1:42:14.160
 There are tons of independent trucking companies out there.

1:42:14.160 --> 1:42:17.400
 Start a trucking company and drive your costs down

1:42:17.400 --> 1:42:22.400
 or figure out how to drive down the cost of trucking.

1:42:23.040 --> 1:42:25.800
 Another company that I really respect is Nato.

1:42:25.800 --> 1:42:27.800
 Actually, I respect their business model.

1:42:27.800 --> 1:42:30.160
 Nato sells a driver monitoring camera

1:42:31.040 --> 1:42:33.360
 and they sell it to fleet owners.

1:42:33.360 --> 1:42:35.840
 If I owned a fleet of cars

1:42:35.840 --> 1:42:40.840
 and I could pay 40 bucks a month to monitor my employees,

1:42:41.840 --> 1:42:45.040
 this is gonna, it like reduces accidents 18%.

1:42:45.040 --> 1:42:48.400
 It's so like that, in the space,

1:42:48.400 --> 1:42:51.480
 that is like the business model that I like most respect.

1:42:52.840 --> 1:42:54.800
 Cause they're creating value today.

1:42:54.800 --> 1:42:57.880
 Yeah, which is a, that's a huge one.

1:42:57.880 --> 1:42:59.680
 How do we create value today with some of this?

1:42:59.680 --> 1:43:01.720
 And the lane keeping thing is huge.

1:43:01.720 --> 1:43:03.840
 And it sounds like you're creeping in

1:43:03.840 --> 1:43:06.720
 or full steam ahead on the driver monitoring too,

1:43:06.720 --> 1:43:09.280
 which I think actually where the short term value,

1:43:09.280 --> 1:43:10.520
 if you can get it right.

1:43:10.520 --> 1:43:12.840
 I still, I'm not a huge fan of the statement

1:43:12.840 --> 1:43:15.160
 that everything has to have driver monitoring.

1:43:15.160 --> 1:43:16.160
 I agree with that completely,

1:43:16.160 --> 1:43:18.720
 but that statement usually misses the point

1:43:18.720 --> 1:43:21.960
 that to get the experience of it right is not trivial.

1:43:21.960 --> 1:43:22.880
 Oh no, not at all.

1:43:22.880 --> 1:43:26.200
 In fact, like, so right now we have,

1:43:26.200 --> 1:43:28.560
 I think the timeout depends on speed of the car,

1:43:29.600 --> 1:43:32.520
 but we want to depend on like the scene state.

1:43:32.520 --> 1:43:35.440
 If you're on like an empty highway,

1:43:35.440 --> 1:43:37.720
 it's very different if you don't pay attention

1:43:37.720 --> 1:43:40.600
 than if like you're like coming up to a traffic light.

1:43:42.080 --> 1:43:45.720
 And longterm, it should probably learn from the driver

1:43:45.720 --> 1:43:48.120
 because that's to do, I watched a lot of video.

1:43:48.120 --> 1:43:49.520
 We've built a smartphone detector

1:43:49.520 --> 1:43:51.600
 just to analyze how people are using smartphones

1:43:51.600 --> 1:43:53.400
 and people are using it very differently.

1:43:53.400 --> 1:43:57.720
 It's a texting styles.

1:43:57.720 --> 1:43:58.560
 There's.

1:43:58.560 --> 1:44:00.280
 We haven't watched nearly enough of the videos.

1:44:00.280 --> 1:44:01.760
 We haven't, I got millions of miles

1:44:01.760 --> 1:44:02.960
 of people driving cars.

1:44:02.960 --> 1:44:05.920
 In this moment, I spent a large fraction of my time

1:44:05.920 --> 1:44:10.840
 just watching videos because it's never fails to learn.

1:44:10.840 --> 1:44:12.280
 Like it never, I've never failed

1:44:12.280 --> 1:44:13.440
 from a video watching session

1:44:13.440 --> 1:44:15.360
 to learn something I didn't know before.

1:44:15.360 --> 1:44:18.440
 In fact, I usually like when I eat lunch,

1:44:18.440 --> 1:44:20.640
 I'll sit, especially when the weather is good

1:44:20.640 --> 1:44:24.560
 and just watch pedestrians with an eye to understand

1:44:24.560 --> 1:44:26.400
 like from a computer vision eye,

1:44:26.400 --> 1:44:29.280
 just to see can this model, can you predict,

1:44:29.280 --> 1:44:30.480
 what are the decisions made?

1:44:30.480 --> 1:44:33.000
 And there's so many things that we don't understand.

1:44:33.000 --> 1:44:34.760
 This is what I mean about the state vector.

1:44:34.760 --> 1:44:37.880
 Yeah, it's, I'm trying to always think like,

1:44:37.880 --> 1:44:40.280
 cause I'm understanding in my human brain,

1:44:40.280 --> 1:44:41.960
 how do we convert that into,

1:44:43.000 --> 1:44:44.960
 how hard is the learning problem here?

1:44:44.960 --> 1:44:46.960
 I guess is the fundamental question.

1:44:46.960 --> 1:44:51.760
 So something that's from a hacking perspective,

1:44:51.760 --> 1:44:54.160
 this is always comes up, especially with folks.

1:44:54.160 --> 1:44:55.520
 Well, first the most popular question

1:44:55.520 --> 1:44:58.400
 is the trolley problem, right?

1:44:58.400 --> 1:45:01.920
 So that's not a sort of a serious problem.

1:45:01.920 --> 1:45:05.000
 There are some ethical questions I think that arise.

1:45:06.080 --> 1:45:09.600
 Maybe you wanna, do you think there's any ethical,

1:45:09.600 --> 1:45:11.280
 serious ethical questions?

1:45:11.280 --> 1:45:14.040
 We have a solution to the trolley problem at Comm.ai.

1:45:14.040 --> 1:45:16.520
 Well, so there is actually an alert in our code,

1:45:16.520 --> 1:45:18.000
 ethical dilemma detected.

1:45:18.000 --> 1:45:18.960
 It's not triggered yet.

1:45:18.960 --> 1:45:21.040
 We don't know how yet to detect the ethical dilemmas,

1:45:21.040 --> 1:45:22.320
 but we're a level two system.

1:45:22.320 --> 1:45:23.480
 So we're going to disengage

1:45:23.480 --> 1:45:25.280
 and leave that decision to the human.

1:45:25.280 --> 1:45:26.640
 You're such a troll.

1:45:26.640 --> 1:45:28.720
 No, but the trolley problem deserves to be trolled.

1:45:28.720 --> 1:45:32.040
 Yeah, that's a beautiful answer actually.

1:45:32.040 --> 1:45:34.400
 I know, I gave it to someone who was like,

1:45:34.400 --> 1:45:35.360
 sometimes people will ask,

1:45:35.360 --> 1:45:36.560
 like you asked about the trolley problem,

1:45:36.560 --> 1:45:38.040
 like you can have a kind of discussion about it.

1:45:38.040 --> 1:45:40.760
 Like you get someone who's like really like earnest about it

1:45:40.760 --> 1:45:43.560
 because it's the kind of thing where,

1:45:43.560 --> 1:45:45.560
 if you ask a bunch of people in an office,

1:45:45.560 --> 1:45:48.280
 whether we should use a SQL stack or a no SQL stack,

1:45:48.280 --> 1:45:50.560
 if they're not that technical, they have no opinion.

1:45:50.560 --> 1:45:52.360
 But if you ask them what color they want to paint the office,

1:45:52.360 --> 1:45:54.040
 everyone has an opinion on that.

1:45:54.040 --> 1:45:56.040
 And that's why the trolley problem is...

1:45:56.040 --> 1:45:57.240
 I mean, that's a beautiful answer.

1:45:57.240 --> 1:45:59.200
 Yeah, we're able to detect the problem

1:45:59.200 --> 1:46:01.960
 and we're able to pass it on to the human.

1:46:01.960 --> 1:46:03.720
 Wow, I've never heard anyone say it.

1:46:03.720 --> 1:46:06.120
 This is your nice escape route.

1:46:06.120 --> 1:46:07.320
 Okay, but...

1:46:07.320 --> 1:46:08.680
 Proud level two.

1:46:08.680 --> 1:46:09.760
 I'm proud level two.

1:46:09.760 --> 1:46:10.600
 I love it.

1:46:10.600 --> 1:46:14.400
 So the other thing that people have some concern about

1:46:14.400 --> 1:46:17.800
 with AI in general is hacking.

1:46:17.800 --> 1:46:20.120
 So how hard is it, do you think,

1:46:20.120 --> 1:46:21.400
 to hack an autonomous vehicle,

1:46:21.400 --> 1:46:23.800
 either through physical access

1:46:23.800 --> 1:46:25.680
 or through the more sort of popular now,

1:46:25.680 --> 1:46:28.200
 these adversarial examples on the sensors?

1:46:28.200 --> 1:46:30.720
 Okay, the adversarial examples one.

1:46:30.720 --> 1:46:32.280
 You want to see some adversarial examples

1:46:32.280 --> 1:46:34.880
 that affect humans, right?

1:46:34.880 --> 1:46:38.000
 Oh, well, there used to be a stop sign here,

1:46:38.000 --> 1:46:40.000
 but I put a black bag over the stop sign

1:46:40.000 --> 1:46:43.520
 and then people ran it, adversarial, right?

1:46:43.520 --> 1:46:47.320
 Like there's tons of human adversarial examples too.

1:46:48.360 --> 1:46:51.480
 The question in general about like security,

1:46:51.480 --> 1:46:53.360
 if you saw something just came out today

1:46:53.360 --> 1:46:55.080
 and like there are always such hypey headlines

1:46:55.080 --> 1:46:57.560
 about like how navigate on autopilot

1:46:57.560 --> 1:47:00.960
 was fooled by a GPS spoof to take an exit.

1:47:00.960 --> 1:47:01.800
 Right.

1:47:01.800 --> 1:47:03.920
 At least that's all they could do was take an exit.

1:47:03.920 --> 1:47:06.360
 If your car is relying on GPS

1:47:06.360 --> 1:47:09.000
 in order to have a safe driving policy,

1:47:09.000 --> 1:47:10.240
 you're doing something wrong.

1:47:10.240 --> 1:47:11.080
 If you're relying,

1:47:11.080 --> 1:47:14.560
 and this is why V2V is such a terrible idea.

1:47:14.560 --> 1:47:19.560
 V2V now relies on both parties getting communication right.

1:47:19.760 --> 1:47:24.760
 This is not even, so I think of safety,

1:47:26.040 --> 1:47:28.440
 security is like a special case of safety, right?

1:47:28.440 --> 1:47:31.840
 Safety is like we put a little, you know,

1:47:31.840 --> 1:47:33.320
 piece of caution tape around the hole

1:47:33.320 --> 1:47:35.520
 so that people won't walk into it by accident.

1:47:35.520 --> 1:47:38.200
 Security is like put a 10 foot fence around the hole

1:47:38.200 --> 1:47:40.100
 so you actually physically cannot climb into it

1:47:40.100 --> 1:47:42.320
 with barbed wire on the top and stuff, right?

1:47:42.320 --> 1:47:45.800
 So like if you're designing systems that are like unreliable,

1:47:45.800 --> 1:47:47.380
 they're definitely not secure.

1:47:48.440 --> 1:47:51.240
 Your car should always do something safe

1:47:51.240 --> 1:47:53.400
 using its local sensors.

1:47:53.400 --> 1:47:55.240
 And then the local sensor should be hardwired.

1:47:55.240 --> 1:47:57.360
 And then could somebody hack into your CAN bus

1:47:57.360 --> 1:47:58.600
 and turn your steering wheel on your brakes?

1:47:58.600 --> 1:48:01.160
 Yes, but they could do it before common AI too, so.

1:48:02.800 --> 1:48:04.640
 Let's think out of the box on some things.

1:48:04.640 --> 1:48:09.360
 So do you think teleoperation has a role in any of this?

1:48:09.360 --> 1:48:13.880
 So remotely stepping in and controlling the cars?

1:48:13.880 --> 1:48:18.880
 No, I think that if the safety operation by design

1:48:22.300 --> 1:48:26.160
 requires a constant link to the cars,

1:48:26.160 --> 1:48:27.600
 I think it doesn't work.

1:48:27.600 --> 1:48:31.120
 So that's the same argument you're using for V2I, V2V?

1:48:31.120 --> 1:48:34.300
 Well, there's a lot of non safety critical stuff

1:48:34.300 --> 1:48:35.140
 you can do with V2I.

1:48:35.140 --> 1:48:37.440
 I like V2I, I like V2I way more than V2V.

1:48:37.440 --> 1:48:39.280
 Because V2I is already like,

1:48:39.280 --> 1:48:40.880
 I already have internet in the car, right?

1:48:40.880 --> 1:48:44.240
 There's a lot of great stuff you can do with V2I.

1:48:44.240 --> 1:48:47.280
 Like for example, you can, well, I already have V2I,

1:48:47.280 --> 1:48:48.880
 Waze is V2I, right?

1:48:48.880 --> 1:48:50.500
 Waze can route me around traffic jams.

1:48:50.500 --> 1:48:52.720
 That's a great example of V2I.

1:48:52.720 --> 1:48:54.420
 And then, okay, the car automatically talks

1:48:54.420 --> 1:48:55.260
 to that same service, like it works.

1:48:55.260 --> 1:48:56.800
 So it's improving the experience,

1:48:56.800 --> 1:48:59.440
 but it's not a fundamental fallback for safety.

1:48:59.440 --> 1:49:04.440
 No, if any of your things that require wireless communication

1:49:04.440 --> 1:49:09.440
 are more than QM, like have an ASL rating, it shouldn't be.

1:49:10.600 --> 1:49:14.160
 You previously said that life is work

1:49:15.400 --> 1:49:17.440
 and that you don't do anything to relax.

1:49:17.440 --> 1:49:20.960
 So how do you think about hard work?

1:49:20.960 --> 1:49:24.680
 What do you think it takes to accomplish great things?

1:49:24.680 --> 1:49:25.820
 And there's a lot of people saying

1:49:25.820 --> 1:49:28.160
 that there needs to be some balance.

1:49:28.160 --> 1:49:31.120
 You need to, in order to accomplish great things,

1:49:31.120 --> 1:49:32.200
 you need to take some time off,

1:49:32.200 --> 1:49:33.920
 you need to reflect and so on.

1:49:33.920 --> 1:49:37.920
 Now, and then some people are just insanely working,

1:49:37.920 --> 1:49:39.680
 burning the candle on both ends.

1:49:39.680 --> 1:49:41.400
 How do you think about that?

1:49:41.400 --> 1:49:43.440
 I think I was trolling in the Siraj interview

1:49:43.440 --> 1:49:44.880
 when I said that.

1:49:44.880 --> 1:49:47.280
 Off camera, right before I smoked a little bit of weed,

1:49:47.280 --> 1:49:49.840
 like, you know, come on, this is a joke, right?

1:49:49.840 --> 1:49:50.880
 Like I do nothing to relax.

1:49:50.880 --> 1:49:52.600
 Look where I am, I'm at a party, right?

1:49:52.600 --> 1:49:55.240
 Yeah, yeah, yeah, that's true.

1:49:55.240 --> 1:49:57.200
 So no, no, of course I don't.

1:49:58.080 --> 1:49:59.840
 When I say that life is work though,

1:49:59.840 --> 1:50:04.200
 I mean that like, I think that what gives my life meaning is work.

1:50:04.200 --> 1:50:05.720
 I don't mean that every minute of the day

1:50:05.720 --> 1:50:06.560
 you should be working.

1:50:06.560 --> 1:50:09.800
 I actually think this is not the best way to maximize results.

1:50:09.800 --> 1:50:12.040
 I think that if you're working 12 hours a day,

1:50:12.040 --> 1:50:14.900
 you should be working smarter and not harder.

1:50:14.900 --> 1:50:17.880
 Well, so work gives you meaning.

1:50:17.880 --> 1:50:20.520
 For some people, other sorts of meaning

1:50:20.520 --> 1:50:24.560
 is personal relationships, like family and so on.

1:50:24.560 --> 1:50:27.200
 You've also, in that interview with Siraj,

1:50:27.200 --> 1:50:30.680
 or the trolling, mentioned that one of the things

1:50:30.680 --> 1:50:34.280
 you look forward to in the future is AI girlfriends.

1:50:34.280 --> 1:50:38.720
 So that's a topic that I'm very much fascinated by,

1:50:38.720 --> 1:50:39.760
 not necessarily girlfriends,

1:50:39.760 --> 1:50:41.960
 but just forming a deep connection with AI.

1:50:42.880 --> 1:50:44.320
 What kind of system do you imagine

1:50:44.320 --> 1:50:46.160
 when you say AI girlfriend,

1:50:46.160 --> 1:50:47.720
 whether you were trolling or not?

1:50:47.720 --> 1:50:49.640
 No, that one I'm very serious about.

1:50:49.640 --> 1:50:52.280
 And I'm serious about that on both a shallow level

1:50:52.280 --> 1:50:53.600
 and a deep level.

1:50:53.600 --> 1:50:55.600
 I think that VR brothels are coming soon

1:50:55.600 --> 1:50:57.760
 and are going to be really cool.

1:50:57.760 --> 1:50:59.680
 It's not cheating if it's a robot.

1:50:59.680 --> 1:51:01.000
 I see the slogan already.

1:51:03.120 --> 1:51:06.160
 But there's, I don't know if you've watched,

1:51:06.160 --> 1:51:08.320
 or just watched the Black Mirror episode.

1:51:08.320 --> 1:51:09.320
 I watched the latest one, yeah.

1:51:09.320 --> 1:51:10.400
 Yeah, yeah.

1:51:11.320 --> 1:51:12.840
 Oh, the Ashley 2 one?

1:51:15.080 --> 1:51:16.920
 No, where there's two friends

1:51:16.920 --> 1:51:20.160
 who are having sex with each other in...

1:51:20.160 --> 1:51:21.000
 Oh, in the VR game.

1:51:21.000 --> 1:51:22.720
 In the VR game.

1:51:22.720 --> 1:51:23.560
 It's just two guys,

1:51:23.560 --> 1:51:27.200
 but one of them was a female, yeah.

1:51:27.200 --> 1:51:29.520
 Which is another mind blowing concept.

1:51:29.520 --> 1:51:33.240
 That in VR, you don't have to be the form.

1:51:33.240 --> 1:51:37.160
 You can be two animals having sex.

1:51:37.160 --> 1:51:38.000
 It's weird.

1:51:38.000 --> 1:51:38.920
 I mean, I'll see how nice that the software

1:51:38.920 --> 1:51:40.240
 maps the nerve endings, right?

1:51:40.240 --> 1:51:41.600
 Yeah, it's huge.

1:51:41.600 --> 1:51:44.440
 I mean, yeah, they sweep a lot of the fascinating,

1:51:44.440 --> 1:51:46.400
 really difficult technical challenges under the rug,

1:51:46.400 --> 1:51:48.320
 like assuming it's possible

1:51:48.320 --> 1:51:51.120
 to do the mapping of the nerve endings, then...

1:51:51.120 --> 1:51:51.960
 I wish, yeah, I saw that,

1:51:51.960 --> 1:51:53.800
 the way they did it with the little like stim unit

1:51:53.800 --> 1:51:55.400
 on the head, that'd be amazing.

1:51:56.800 --> 1:51:58.760
 So, well, no, no, on a shallow level,

1:51:58.760 --> 1:52:01.680
 like you could set up like almost a brothel

1:52:01.680 --> 1:52:05.160
 with like real dolls and Oculus Quests,

1:52:05.160 --> 1:52:06.200
 write some good software.

1:52:06.200 --> 1:52:08.360
 I think it'd be a cool novelty experience.

1:52:09.280 --> 1:52:11.400
 But no, on a deeper, like emotional level,

1:52:12.840 --> 1:52:17.000
 I mean, yeah, I would really like to fall in love

1:52:17.000 --> 1:52:18.120
 with a machine.

1:52:18.120 --> 1:52:23.120
 Do you see yourself having a long term relationship

1:52:25.000 --> 1:52:27.600
 of the kind monogamous relationship that we have now

1:52:28.800 --> 1:52:31.360
 with a robot, with a AI system even,

1:52:31.360 --> 1:52:32.680
 not even just a robot?

1:52:32.680 --> 1:52:37.680
 So I think about maybe my ideal future.

1:52:38.120 --> 1:52:43.120
 When I was 15, I read Eliezer Yudkowsky's early writings

1:52:43.120 --> 1:52:48.120
 on the singularity and like that AI

1:52:49.120 --> 1:52:52.480
 is going to surpass human intelligence massively.

1:52:53.600 --> 1:52:55.440
 He made some Moore's law based predictions

1:52:55.440 --> 1:52:57.360
 that I mostly agree with.

1:52:57.360 --> 1:52:59.320
 And then I really struggled

1:52:59.320 --> 1:53:01.320
 for the next couple of years of my life.

1:53:01.320 --> 1:53:03.320
 Like, why should I even bother to learn anything?

1:53:03.320 --> 1:53:06.080
 It's all gonna be meaningless when the machines show up.

1:53:06.080 --> 1:53:06.920
 Right.

1:53:07.960 --> 1:53:10.480
 Maybe when I was that young,

1:53:10.480 --> 1:53:11.960
 I was still a little bit more pure

1:53:11.960 --> 1:53:13.120
 and really like clung to that.

1:53:13.120 --> 1:53:13.960
 And then I'm like, well,

1:53:13.960 --> 1:53:14.960
 the machines ain't here yet, you know,

1:53:14.960 --> 1:53:16.720
 and I seem to be pretty good at this stuff.

1:53:16.720 --> 1:53:18.440
 Let's try my best, you know,

1:53:18.440 --> 1:53:20.240
 like what's the worst that happens.

1:53:21.320 --> 1:53:24.000
 But the best possible future I see

1:53:24.000 --> 1:53:26.760
 is me sort of merging with the machine.

1:53:26.760 --> 1:53:28.760
 And the way that I personify this

1:53:28.760 --> 1:53:31.560
 is in a long term monogamous relationship with a machine.

1:53:32.880 --> 1:53:34.040
 Oh, you don't think there's a room

1:53:34.040 --> 1:53:35.680
 for another human in your life,

1:53:35.680 --> 1:53:38.080
 if you really truly merge with another machine?

1:53:39.160 --> 1:53:40.840
 I mean, I see merging.

1:53:40.840 --> 1:53:45.000
 I see like the best interface to my brain

1:53:46.280 --> 1:53:48.680
 is like the same relationship interface

1:53:48.680 --> 1:53:49.920
 to merge with an AI, right?

1:53:49.920 --> 1:53:51.520
 What does that merging feel like?

1:53:52.840 --> 1:53:55.920
 I've seen couples who've been together for a long time.

1:53:55.920 --> 1:53:58.400
 And like, I almost think of them as one person,

1:53:58.400 --> 1:54:01.840
 like couples who spend all their time together and...

1:54:01.840 --> 1:54:02.680
 That's fascinating.

1:54:02.680 --> 1:54:03.840
 You're actually putting,

1:54:03.840 --> 1:54:06.040
 what does that merging actually looks like?

1:54:06.040 --> 1:54:08.120
 It's not just a nice channel.

1:54:08.120 --> 1:54:12.160
 Like a lot of people imagine it's just an efficient link,

1:54:12.160 --> 1:54:14.280
 search link to Wikipedia or something.

1:54:14.280 --> 1:54:15.200
 I don't believe in that.

1:54:15.200 --> 1:54:16.040
 But it's more,

1:54:16.040 --> 1:54:18.520
 you're saying that there's the same kind of relationship

1:54:18.520 --> 1:54:19.400
 you have with another human,

1:54:19.400 --> 1:54:20.760
 that's a deep relationship.

1:54:20.760 --> 1:54:22.880
 That's what merging looks like.

1:54:22.880 --> 1:54:24.400
 That's pretty...

1:54:24.400 --> 1:54:26.600
 I don't believe that link is possible.

1:54:26.600 --> 1:54:27.680
 I think that that link,

1:54:27.680 --> 1:54:29.160
 so you're like, oh, I'm gonna download Wikipedia

1:54:29.160 --> 1:54:30.080
 right to my brain.

1:54:30.080 --> 1:54:33.280
 My reading speed is not limited by my eyes.

1:54:33.280 --> 1:54:36.720
 My reading speed is limited by my inner processing loop.

1:54:36.720 --> 1:54:40.680
 And to like bootstrap that sounds kind of unclear

1:54:40.680 --> 1:54:42.360
 how to do it and horrifying.

1:54:42.360 --> 1:54:46.480
 But if I am with somebody and I'll use a somebody

1:54:46.480 --> 1:54:51.280
 who is making a super sophisticated model of me

1:54:51.280 --> 1:54:53.120
 and then running simulations on that model,

1:54:53.120 --> 1:54:54.040
 I'm not gonna get into the question

1:54:54.040 --> 1:54:55.840
 whether the simulations are conscious or not.

1:54:55.840 --> 1:54:58.200
 I don't really wanna know what it's doing.

1:54:58.200 --> 1:55:00.080
 But using those simulations

1:55:00.080 --> 1:55:01.840
 to play out hypothetical futures for me,

1:55:01.840 --> 1:55:04.840
 deciding what things to say to me,

1:55:04.840 --> 1:55:06.240
 to guide me along a path.

1:55:06.240 --> 1:55:08.680
 And that's how I envision it.

1:55:08.680 --> 1:55:13.680
 So on that path to AI of superhuman level intelligence,

1:55:15.080 --> 1:55:16.840
 you've mentioned that you believe in the singularity,

1:55:16.840 --> 1:55:18.600
 that singularity is coming.

1:55:18.600 --> 1:55:20.200
 Again, could be trolling, could be not,

1:55:20.200 --> 1:55:23.000
 could be part, all trolling has truth in it.

1:55:23.000 --> 1:55:24.120
 I don't know what that means anymore.

1:55:24.120 --> 1:55:25.920
 What is the singularity?

1:55:25.920 --> 1:55:28.040
 Yeah, so that's really the question.

1:55:28.040 --> 1:55:30.520
 How many years do you think before the singularity,

1:55:30.520 --> 1:55:32.080
 what form do you think it will take?

1:55:32.080 --> 1:55:35.440
 Does that mean fundamental shifts in capabilities of AI?

1:55:35.440 --> 1:55:38.000
 Or does it mean some other kind of ideas?

1:55:39.400 --> 1:55:41.360
 Maybe that's just my roots, but.

1:55:41.360 --> 1:55:43.880
 So I can buy a human beings worth of compute

1:55:43.880 --> 1:55:46.000
 for like a million bucks today.

1:55:46.000 --> 1:55:47.680
 It's about one TPU pod V3.

1:55:47.680 --> 1:55:50.120
 I want like, I think they claim a hundred pay to flops.

1:55:50.120 --> 1:55:50.960
 That's being generous.

1:55:50.960 --> 1:55:52.240
 I think humans are actually more like 20.

1:55:52.240 --> 1:55:53.080
 So that's like five humans.

1:55:53.080 --> 1:55:53.960
 That's pretty good.

1:55:53.960 --> 1:55:55.560
 Google needs to sell their TPUs.

1:55:56.720 --> 1:55:58.560
 But I could buy, I could buy, I could buy GPUs.

1:55:58.560 --> 1:56:02.200
 I could buy a stack of like, I'd buy 1080 TIs,

1:56:02.200 --> 1:56:03.760
 build data center full of them.

1:56:03.760 --> 1:56:08.040
 And for a million bucks, I can get a human worth of compute.

1:56:08.040 --> 1:56:12.160
 But when you look at the total number of flops in the world,

1:56:12.160 --> 1:56:14.400
 when you look at human flops,

1:56:14.400 --> 1:56:17.040
 which goes up very, very slowly with the population

1:56:17.040 --> 1:56:19.760
 and machine flops, which goes up exponentially,

1:56:19.760 --> 1:56:22.360
 but it's still nowhere near.

1:56:22.360 --> 1:56:24.560
 I think that's the key thing to talk about

1:56:24.560 --> 1:56:25.880
 when the singularity happened.

1:56:25.880 --> 1:56:29.760
 When most flops in the world are Silicon and not biological,

1:56:29.760 --> 1:56:32.280
 that's kind of the crossing point.

1:56:32.280 --> 1:56:35.480
 Like they're now the dominant species on the planet.

1:56:35.480 --> 1:56:38.720
 And just looking at how technology is progressing,

1:56:38.720 --> 1:56:40.360
 when do you think that could possibly happen?

1:56:40.360 --> 1:56:41.680
 You think it would happen in your lifetime?

1:56:41.680 --> 1:56:43.600
 Oh yeah, definitely in my lifetime.

1:56:43.600 --> 1:56:44.440
 I've done the math.

1:56:44.440 --> 1:56:47.520
 I like 2038 because it's the Unix timestamp rollover.

1:56:49.880 --> 1:56:52.640
 Yeah, beautifully put.

1:56:52.640 --> 1:56:57.640
 So you've said that the meaning of life is to win.

1:56:57.960 --> 1:56:59.520
 If you look five years into the future,

1:56:59.520 --> 1:57:02.640
 what does winning look like?

1:57:02.640 --> 1:57:03.680
 So,

1:57:08.560 --> 1:57:10.120
 there's a lot of,

1:57:10.120 --> 1:57:12.680
 I can go into like technical depth

1:57:12.680 --> 1:57:14.640
 to what I mean by that, to win.

1:57:15.760 --> 1:57:18.280
 It may not mean, I was criticized for that in the comments.

1:57:18.280 --> 1:57:20.520
 Like, doesn't this guy wanna like save the penguins

1:57:20.520 --> 1:57:22.520
 in Antarctica or like,

1:57:22.520 --> 1:57:24.920
 oh man, listen to what I'm saying.

1:57:24.920 --> 1:57:27.560
 I'm not talking about like I have a yacht or something.

1:57:27.560 --> 1:57:30.520
 But I am an agent.

1:57:30.520 --> 1:57:31.880
 I am put into this world.

1:57:32.920 --> 1:57:36.320
 And I don't really know what my purpose is.

1:57:37.480 --> 1:57:40.280
 But if you're an intelligent agent

1:57:40.280 --> 1:57:41.400
 and you're put into a world,

1:57:41.400 --> 1:57:43.160
 what is the ideal thing to do?

1:57:43.160 --> 1:57:44.800
 Well, the ideal thing mathematically,

1:57:44.800 --> 1:57:47.080
 you can go back to like Schmidt Hoover theories about this,

1:57:47.080 --> 1:57:50.480
 is to build a compressive model of the world.

1:57:50.480 --> 1:57:51.840
 To build a maximally compressive,

1:57:51.840 --> 1:57:55.600
 to explore the world such that your exploration function

1:57:55.600 --> 1:57:58.880
 maximizes the derivative of compression of the past.

1:57:58.880 --> 1:58:00.720
 Schmidt Hoover has a paper about this.

1:58:00.720 --> 1:58:02.040
 And like, I took that kind of

1:58:02.040 --> 1:58:03.800
 as like a personal goal function.

1:58:05.360 --> 1:58:07.720
 So what I mean to win, I mean like,

1:58:07.720 --> 1:58:09.080
 maybe this is religious,

1:58:09.080 --> 1:58:11.320
 but like I think that in the future,

1:58:11.320 --> 1:58:13.040
 I might be given a real purpose

1:58:13.040 --> 1:58:14.680
 or I may decide this purpose myself.

1:58:14.680 --> 1:58:16.160
 And then at that point,

1:58:16.160 --> 1:58:18.240
 now I know what the game is and I know how to win.

1:58:18.240 --> 1:58:19.080
 I think right now,

1:58:19.080 --> 1:58:20.720
 I'm still just trying to figure out what the game is.

1:58:20.720 --> 1:58:21.800
 But once I know,

1:58:21.800 --> 1:58:26.440
 so you have imperfect information,

1:58:26.440 --> 1:58:28.600
 you have a lot of uncertainty about the reward function

1:58:28.600 --> 1:58:29.720
 and you're discovering it.

1:58:29.720 --> 1:58:30.560
 Exactly.

1:58:30.560 --> 1:58:31.400
 But the purpose is...

1:58:31.400 --> 1:58:33.120
 That's a better way to put it.

1:58:33.120 --> 1:58:34.440
 The purpose is to maximize it

1:58:34.440 --> 1:58:37.960
 while you have a lot of uncertainty around it.

1:58:37.960 --> 1:58:39.400
 And you're both reducing the uncertainty

1:58:39.400 --> 1:58:41.160
 and maximizing at the same time.

1:58:41.160 --> 1:58:42.000
 Yeah.

1:58:42.000 --> 1:58:44.240
 And so that's at the technical level.

1:58:44.240 --> 1:58:47.440
 What is the, if you believe in the universal prior,

1:58:47.440 --> 1:58:49.360
 what is the universal reward function?

1:58:49.360 --> 1:58:51.320
 That's the better way to put it.

1:58:51.320 --> 1:58:53.680
 So that win is interesting.

1:58:53.680 --> 1:58:57.280
 I think I speak for everyone in saying that

1:58:57.280 --> 1:59:01.920
 I wonder what that reward function is for you.

1:59:01.920 --> 1:59:05.920
 And I look forward to seeing that in five years,

1:59:05.920 --> 1:59:07.040
 in 10 years.

1:59:07.040 --> 1:59:08.680
 I think a lot of people, including myself,

1:59:08.680 --> 1:59:09.840
 are cheering you on, man.

1:59:09.840 --> 1:59:14.280
 So I'm happy you exist and I wish you the best of luck.

1:59:14.280 --> 1:59:15.360
 Thanks for talking to me, man.

1:59:15.360 --> 1:59:16.200
 Thank you.

1:59:16.200 --> 1:59:21.200
 Have a good one.

