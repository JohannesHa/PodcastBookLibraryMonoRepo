WEBVTT

00:00.000 --> 00:03.120
 The following is a conversation with Bjarne Stroustrup.

00:03.120 --> 00:09.200
 He is the creator of C++, a programming language that, after 40 years, is still one of the most

00:09.200 --> 00:16.240
 popular and powerful languages in the world. Its focus on fast, stable, robust code underlies many

00:16.240 --> 00:21.360
 of the biggest systems in the world that we have come to rely on as a society. If you're watching

00:21.360 --> 00:27.280
 this on YouTube, for example, many of the critical back end components of YouTube are written in C++.

00:27.280 --> 00:34.320
 The same goes for Google, Facebook, Amazon, Twitter, most Microsoft applications, Adobe applications,

00:34.320 --> 00:41.440
 most database systems, and most physical systems that operate in the real world, like cars, robots,

00:41.440 --> 00:45.680
 rockets that launch us into space and one day will land us on Mars.

00:46.480 --> 00:53.200
 C++ also happens to be the language that I use more than any other in my life. I've written

00:53.200 --> 00:59.520
 several hundred thousand lines of C++ source code. Of course, lines of source code don't mean much,

00:59.520 --> 01:03.600
 but they do give hints of my personal journey through the world of software.

01:04.320 --> 01:08.320
 I've enjoyed watching the development of C++ as a programming language,

01:08.320 --> 01:15.360
 leading up to the big update in the standard in 2011 and those that followed in 14, 17,

01:15.360 --> 01:20.320
 and toward the new C++20 standard hopefully coming out next year.

01:20.320 --> 01:23.920
 TITLE This is the Artificial Intelligence podcast.

01:23.920 --> 01:29.280
 If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon,

01:29.280 --> 01:34.960
 or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N.

01:34.960 --> 01:38.880
 And now, here's my conversation with Björn Stroustrup.

01:40.240 --> 01:44.000
 What was the first program you've ever written? Do you remember?

01:44.000 --> 01:52.640
 BJÖRN It was my second year in university, first year of computer science, and it was an Alco 60.

01:53.520 --> 02:01.760
 I calculated the shape of a super ellipse and then connected points on the perimeter,

02:02.400 --> 02:10.400
 creating star patterns. It was with a wet ink on a paper printer.

02:10.400 --> 02:13.200
 TITLE And that was in college, university?

02:13.200 --> 02:17.120
 BJÖRN Yeah, yeah. I learned to program the second year in university.

02:17.120 --> 02:20.640
 TITLE And what was the first programming language,

02:21.360 --> 02:24.960
 if I may ask it this way, that you fell in love with?

02:24.960 --> 02:32.000
 BJÖRN I think Alco 60. And after that, I remember

02:34.960 --> 02:41.200
 Snowball. I remember Fortran, didn't fall in love with that. I remember Pascal,

02:41.200 --> 02:48.000
 didn't fall in love with that. It all got in the way of me. And then I discovered Assembler,

02:48.000 --> 02:54.000
 and that was much more fun. And from there, I went to Micro Code.

02:54.000 --> 03:00.640
 TITLE So you were drawn to the, you found the low level stuff beautiful.

03:00.640 --> 03:08.080
 BJÖRN I went through a lot of languages, and then I spent significant time in Assembler and

03:08.080 --> 03:14.160
 Micro Code. That was sort of the first really profitable things that paid for my masters,

03:14.160 --> 03:18.480
 actually. And then I discovered Simula, which was absolutely great.

03:18.480 --> 03:20.080
 TITLE Simula?

03:20.080 --> 03:24.720
 BJÖRN Simula was the extension of Alco 60,

03:25.840 --> 03:31.280
 done primarily for simulation. But basically, they invented object oriented programming at

03:31.280 --> 03:40.960
 inheritance and runtime polymorphism while they were doing it. And that was the language that

03:40.960 --> 03:48.320
 taught me that you could have the sort of the problems of a program grow with the size of the

03:48.320 --> 03:55.440
 program rather than with the square of the size of the program. That is, you can actually modularize

03:55.440 --> 04:04.880
 very nicely. And that was a surprise to me. It was also a surprise to me that a stricter type

04:04.880 --> 04:13.440
 system than Pascal's was helpful, whereas Pascal's type system got in my way all the time. So you

04:13.440 --> 04:20.800
 need a strong type system to organize your code well, but it has to be extensible and flexible.

04:20.800 --> 04:25.680
 TITLE Let's get into the details a little bit. If you remember, what kind of type system did

04:25.680 --> 04:30.320
 Pascal have? What type system, typing system did Alco 60 have?

04:30.320 --> 04:37.760
 BJÖRN Basically, Pascal was sort of the simplest language that Niklaus Wirth could

04:37.760 --> 04:47.200
 define that served the needs of Niklaus Wirth at the time. And it has a sort of a highly moral

04:47.200 --> 04:53.600
 tone to it. That is, if you can say it in Pascal, it's good. And if you can't, it's not so good.

04:54.560 --> 05:05.280
 Whereas Simula allowed you basically to build your own type system. So instead of trying to fit

05:05.280 --> 05:13.920
 yourself into Niklaus Wirth's world, Christen Nygaard's language and Johan Dahl's language

05:13.920 --> 05:22.640
 allowed you to build your own. So it's sort of close to the original idea of you build a domain

05:22.640 --> 05:31.200
 specific language. As a matter of fact, what you build is a set of types and relations among types

05:31.200 --> 05:35.440
 that allows you to express something that's suitable for an application.

05:35.440 --> 05:37.200
 TITLE So when you say types,

05:38.160 --> 05:41.600
 stuff you're saying has echoes of object oriented programming.

05:41.600 --> 05:44.800
 BJÖRN Yes, they invented it. Every language

05:44.800 --> 05:55.840
 that uses the word class for type is a descendant of Simula, directly or indirectly. Christen Nygaard

05:55.840 --> 06:04.720
 and Ole Johan Dahl were mathematicians and they didn't think in terms of types, but they understood

06:04.720 --> 06:13.840
 sets and classes of elements. And so they called their types classes. And basically in C++,

06:13.840 --> 06:17.040
 as in Simula, classes are user defined type.

06:17.040 --> 06:21.120
 TITLE So can you try the impossible task and give

06:21.120 --> 06:28.240
 a brief history of programming languages from your perspective? So we started with Algol 60,

06:28.240 --> 06:39.440
 Simula, Pascal, but that's just the 60s and 70s. BJÖRN I can try. The most sort of interesting and

06:39.440 --> 06:47.040
 major improvement of programming languages was Fortran, the first Fortran. Because before that,

06:47.040 --> 06:52.400
 all code was written for a specific machine and each specific machine had a language,

06:52.400 --> 07:02.000
 a simple language or a cross simpler or some extension of that idea. But you're writing for

07:02.000 --> 07:12.880
 a specific machine in the language of that machine. And Bacchus and his team at IBM built a language

07:12.880 --> 07:21.440
 that would allow you to write what you really wanted. That is, you could write it in a language

07:21.440 --> 07:26.880
 that was natural for people. Now, these people happen to be engineers and physicists. So the

07:26.880 --> 07:31.680
 language that came out was somewhat unusual for the rest of the world. But basically they said

07:31.680 --> 07:37.200
 formula translation because they wanted to have the mathematical formulas translated into the

07:37.200 --> 07:47.120
 machine. And as a side effect, they got portability because now they're writing in the terms that the

07:47.120 --> 07:54.000
 humans used and the way humans thought. And then they had a program that translated it into the

07:54.000 --> 08:02.240
 machine's needs. And that was new and that was great. And it's something to remember. We want to

08:02.240 --> 08:07.840
 raise the language to the human level, but we don't want to lose the efficiency.

08:09.200 --> 08:15.200
 And that was the first step towards the human. That was the first step. And of course,

08:15.200 --> 08:20.320
 they were a very particular kind of humans. Business people were different, so they got

08:20.320 --> 08:28.400
 cobalt instead, et cetera, et cetera. And Simula came out. No, let's not go to Simula yet. Let's

08:28.400 --> 08:38.640
 go to Algol. Fortran didn't have, at the time, the notions of not a precise notion of type,

08:38.640 --> 08:48.880
 not a precise notion of scope, not a set of translation phases that was what we have today,

08:49.440 --> 08:55.520
 lexical syntax, semantics. It was sort of a bit of a model in the early days, but

08:56.560 --> 09:01.360
 hey, they've just done the biggest breakthrough in the history of programming, right?

09:01.360 --> 09:06.320
 So you can't criticize them for not having gotten all the technical details right.

09:06.320 --> 09:15.040
 So we got Algol. That was very pretty. And most people in commerce and science considered it

09:15.040 --> 09:20.880
 useless because it was not flexible enough, and it wasn't efficient enough, and et cetera,

09:20.880 --> 09:25.520
 et cetera. But that was a breakthrough from a technical point of view.

09:26.800 --> 09:34.400
 Then Simula came along to make that idea more flexible, and you could define your own types.

09:34.400 --> 09:43.920
 And that's where I got very interested. Christen Nygård was the main idea man behind Simula.

09:43.920 --> 09:45.200
 That was late 60s.

09:45.200 --> 09:52.000
 This was late 60s. Well, I was a visiting professor in Aarhus, and so I learned object

09:52.000 --> 10:04.400
 oriented programming by sitting around and, well, in theory, discussing with Christen Nygård. But

10:04.400 --> 10:09.680
 Christen, once you get started and in full flow, it's very hard to get a word in edgeways.

10:09.680 --> 10:10.560
 Where you just listen.

10:10.560 --> 10:14.160
 So it was great. I learned it from there.

10:14.160 --> 10:18.720
 Not to romanticize the notion, but it seems like a big leap to think about

10:18.720 --> 10:23.600
 object oriented programming. It's really a leap of abstraction.

10:24.960 --> 10:25.760
 Yes.

10:25.760 --> 10:34.720
 And was that as big and beautiful of a leap as it seems from now in retrospect,

10:34.720 --> 10:36.960
 or was it an obvious one at the time?

10:38.080 --> 10:44.480
 It was not obvious, and many people have tried to do something like that,

10:44.480 --> 10:48.880
 and most people didn't come up with something as wonderful as Simula.

10:49.920 --> 10:56.720
 Lots of people got their PhDs and made their careers out of forgetting about Simula or never

10:56.720 --> 11:05.040
 knowing it. For me, the key idea was basically I could get my own types. And that's the idea that

11:05.600 --> 11:12.640
 goes further into C++, where I can get better types and more flexible types and more efficient

11:12.640 --> 11:17.760
 types. But it's still the fundamental idea. When I want to write a program, I want to write it with

11:17.760 --> 11:27.200
 my types that is appropriate to my problem and under the constraints that I'm under with hardware,

11:27.200 --> 11:32.000
 software, environment, et cetera. And that's the key idea.

11:32.720 --> 11:39.120
 People picked up on the class hierarchies and the virtual functions and the inheritance,

11:39.120 --> 11:47.360
 and that was only part of it. It was an interesting and major part and still a major

11:47.360 --> 11:55.440
 part and a lot of graphic stuff, but it was not the most fundamental. It was when you wanted to

11:55.440 --> 12:01.680
 relate one type to another. You don't want them all to be independent. The classical example is

12:01.680 --> 12:11.120
 that you don't actually want to write a city simulation with vehicles where you say, well,

12:11.120 --> 12:17.440
 if it's a bicycle, write the code for turning a bicycle to the left. If it's a normal car,

12:17.440 --> 12:23.440
 turn right the normal car way. If it's a fire engine, turn right the fire engine way. You get

12:23.440 --> 12:32.080
 these big case statements and bunches of if statements and such. Instead, you tell the base

12:32.080 --> 12:41.520
 class that that's the vehicle saying, turn left the way you want to. And this is actually a real

12:41.520 --> 12:53.920
 example. They used it to simulate and optimize the emergency services for somewhere in Norway back in

12:53.920 --> 13:01.680
 the 60s. So this was one of the early examples for why you needed inheritance and you needed

13:01.680 --> 13:12.080
 a runtime polymorphism because you wanted to handle this set of vehicles in a manageable way.

13:13.920 --> 13:18.640
 You can't just rewrite your code each time a new kind of vehicle comes along.

13:19.840 --> 13:24.720
 Yeah, that's a beautiful, powerful idea. And of course it stretches through your work

13:24.720 --> 13:33.120
 with C++ as we'll talk about. But I think you've structured it nicely. What other breakthroughs

13:33.120 --> 13:38.480
 came along in the history of programming languages if we were to tell the history in that way?

13:39.440 --> 13:46.000
 Obviously, I'm better at telling the part of the history that is the path I'm on as opposed to all

13:46.000 --> 13:51.440
 the paths. Yeah, you skipped the hippie John McCarthy and Lisp, one of my favorite languages.

13:51.440 --> 13:53.440
 Functional.

13:53.440 --> 13:59.760
 But Lisp is not one of my favorite languages. It's obviously important. It's obviously interesting.

13:59.760 --> 14:05.680
 Lots of people write code in it and then they rewrite it into C or C++ when they want to go

14:05.680 --> 14:15.600
 to production. It's in the world I'm at, which are constrained by performance, reliability,

14:15.600 --> 14:23.520
 issues, deployability, cost of hardware. I don't like things to be too dynamic.

14:24.560 --> 14:32.560
 It is really hard to write a piece of code that's perfectly flexible that you can also deploy on a

14:32.560 --> 14:40.000
 small computer and that you can also put in, say, a telephone switch in Bogota. What's the chance?

14:40.000 --> 14:45.520
 If you get an error and you find yourself in the debugger that the telephone switch in Bogota on

14:45.520 --> 14:53.600
 late Sunday night has a programmer around, their chance is zero. A lot of the things I think most

14:53.600 --> 15:07.120
 about can't afford that flexibility. I'm quite aware that maybe 70%, 80% of all code are not

15:07.120 --> 15:13.840
 under the kind of constraints I'm interested in. But somebody has to do the job I'm doing

15:14.640 --> 15:20.000
 because you have to get from these high level flexible languages to the hardware.

15:20.560 --> 15:27.120
 The stuff that lasts for 10, 20, 30 years is robust, operates under very constrained conditions.

15:27.120 --> 15:31.920
 Yes, absolutely. That's right. And it's fascinating and beautiful in its own way.

15:31.920 --> 15:40.880
 C++ is one of my favorite languages, and so is Lisp. So I can embody two for different reasons

15:40.880 --> 15:50.480
 as a programmer. I understand why Lisp is popular, and I can see the beauty of the ideas

15:50.480 --> 16:04.400
 and similarly with Smalltalk. It's just not as relevant in my world. And by the way, I distinguish

16:04.400 --> 16:12.560
 between those and the functional languages where I go to things like ML and Haskell. Different kind

16:12.560 --> 16:19.040
 of languages, they have a different kind of beauty and they're very interesting. And I think

16:19.040 --> 16:27.680
 that's interesting. And I actually try to learn from all the languages I encounter to see what is

16:27.680 --> 16:34.880
 there that would make working on the kind of problems I'm interested in with the kind of

16:34.880 --> 16:42.880
 constraints that I'm interested in, what can actually be done better? Because we can surely

16:42.880 --> 16:50.400
 do better than we do today. You've said that it's good for any professional programmer to know at

16:50.400 --> 16:57.920
 least five languages as speaking about a variety of languages that you've taken inspiration from,

16:57.920 --> 17:06.320
 and you've listed yours as being, at least at the time, C++, obviously, Java, Python, Ruby,

17:06.320 --> 17:13.520
 script. Can you first of all, update that list, modify it? You don't have to be constrained

17:15.200 --> 17:20.320
 to just five, but can you describe what you picked up also from each of these languages?

17:21.680 --> 17:25.840
 How do you see them as inspirations for you when you're working with C++?

17:25.840 --> 17:32.880
 This is a very hard question to answer. So about languages, you should know

17:32.880 --> 17:42.000
 languages. I reckon I knew about 25 or thereabouts when I did C++. It was easier in those days

17:42.000 --> 17:48.640
 because the languages were smaller, and you didn't have to learn a whole programming environment and

17:48.640 --> 17:55.280
 such to do it. You could learn the language quite easily. And it's good to learn so many languages.

17:55.280 --> 18:03.120
 I imagine, just like with natural language for communication, there's different

18:03.120 --> 18:08.160
 paradigms that emerge in all of them, that there's commonalities and so on.

18:08.800 --> 18:12.640
 So I picked five out of a hat. You picked five out of a hat.

18:12.640 --> 18:16.640
 Obviously. The important thing that the number is not one.

18:17.680 --> 18:18.160
 That's right.

18:19.120 --> 18:24.240
 It's like, I don't like, I mean, if you're a monoglot, you are likely to think that your

18:24.240 --> 18:30.080
 own culture is the only one superior to everybody else's. A good learning of a foreign language and

18:30.080 --> 18:36.160
 a foreign culture is important. It helps you think and be a better person. With programming

18:36.160 --> 18:41.680
 languages, you become a better programmer, better designer with the second language.

18:41.680 --> 18:48.640
 Now, once you've got two, the weight of five is not that long. It's the second one that's

18:48.640 --> 18:58.880
 most important. And then when I had to pick five, I sort of thinking what kinds of languages are

18:58.880 --> 19:04.080
 there? Well, there's a really low level stuff. It's good. It's actually good to know machine code.

19:04.960 --> 19:05.920
 Even still?

19:05.920 --> 19:13.200
 Even today. The C++ optimizers write better machine code than I do.

19:13.200 --> 19:20.640
 Yes. But I don't think I could appreciate them if I actually didn't understand machine code and

19:20.640 --> 19:28.160
 machine architecture. At least in my position, I have to understand a bit of it because you mess

19:28.160 --> 19:35.280
 up the cache and you're off in performance by a factor of 100. It shouldn't be that if you are

19:35.280 --> 19:42.640
 interested in either performance or the size of the computer you have to deploy. So I would

19:42.640 --> 19:51.280
 go as a simpler. I used to mention C, but these days going low level is not actually what gives

19:51.280 --> 19:57.840
 you the performance. It is to express your ideas so cleanly that you can think about it and the

19:57.840 --> 20:04.240
 optimizer can understand what you're up to. My favorite way of optimizing these days is to throw

20:04.240 --> 20:13.360
 away out the clever bits and see if it still runs fast. And sometimes it runs faster. So I need the

20:13.360 --> 20:20.960
 abstraction mechanisms or something like C++ to write compact high performance code. There was a

20:20.960 --> 20:27.680
 beautiful keynote by Jason Turner at the CppCon a couple of years ago where he decided he was going

20:27.680 --> 20:40.320
 to program Pong on Motorola 6800, I think it was. And he says, well, this is relevant because it

20:40.320 --> 20:46.400
 looks like a microcontroller. It has specialized hardware. It has not very much memory and it's

20:46.400 --> 20:56.000
 relatively slow. And so he shows in real time how he writes Pong starting with fairly straightforward

20:56.000 --> 21:03.920
 low level stuff, improving his abstractions and what he's doing. He's writing C++ and it translates

21:06.560 --> 21:13.440
 into 86 assembler, which you can do with Clang and you can see it in real time. It's

21:14.640 --> 21:19.360
 the compiler explorer, which you can use on the web. And then he wrote a little program

21:19.360 --> 21:27.840
 that translated 86 assembler into Motorola assembler. And so he types and you can see this

21:27.840 --> 21:33.200
 thing in real time. Wow. You can see it in real time. And even if you can't read the assembly code,

21:33.840 --> 21:38.880
 you can just see it. His code gets better. The code, the assembler gets smaller.

21:39.600 --> 21:45.440
 He increases the abstraction level, uses C++ 11 as it were better.

21:45.440 --> 21:53.120
 This code gets cleaner. It gets easier maintainable. The code shrinks and it keeps shrinking. And

21:55.120 --> 22:02.240
 I could not in any reasonable amount of time write that assembler as good as the compiler

22:02.240 --> 22:09.360
 generated from really quite nice modern C++. And I'll go as far as to say the thing that looked

22:09.360 --> 22:20.960
 like C was significantly uglier and smaller and larger when it became machine code.

22:22.160 --> 22:26.640
 So the abstractions that can be optimized are important.

22:27.280 --> 22:30.880
 I would love to see that kind of visualization in larger code bases.

22:30.880 --> 22:31.920
 Yeah. That might be beautiful.

22:31.920 --> 22:38.000
 But you can't show a larger code base in a one hour talk and have it fit on screen.

22:38.000 --> 22:40.240
 Right. So that's C and C++.

22:40.240 --> 22:47.120
 So my two languages would be machine code and C++. And then I think you can learn a

22:47.120 --> 22:54.160
 lot from the functional languages. So PIC has gloy ML. I don't care which. I think actually

22:54.800 --> 23:03.200
 you learn the same lessons of expressing especially mathematical notions really clearly

23:03.200 --> 23:11.520
 and having a type system that's really strict. And then you should probably have a language for sort

23:11.520 --> 23:19.280
 of quickly churning out something. You could pick JavaScript. You could pick Python. You could pick

23:19.280 --> 23:26.800
 Ruby. What do you make of JavaScript in general? So you're talking in the platonic sense about

23:26.800 --> 23:32.880
 languages, about what they're good at, what their philosophy of design is. But there's also a large

23:32.880 --> 23:38.400
 user base behind each of these languages and they use it in the way sometimes maybe it wasn't

23:38.400 --> 23:43.600
 really designed for. That's right. JavaScript is used way beyond probably what it was designed for.

23:44.240 --> 23:48.880
 Let me say it this way. When you build a tool, you do not know how it's going to be used.

23:49.440 --> 23:55.200
 You try to improve the tool by looking at how it's being used and when people cut their fingers

23:55.200 --> 24:01.360
 off and try and stop that from happening. But really you have no control over how something

24:01.360 --> 24:07.840
 is used. So I'm very happy and proud of some of the things C++ is being used at and some of the

24:07.840 --> 24:15.120
 things I wish people wouldn't do. Bitcoin mining being my favorite example uses as much energy as

24:15.120 --> 24:25.440
 Switzerland and mostly serves criminals. But back to the languages, I actually think that having

24:25.440 --> 24:33.440
 JavaScript run in the browser was an enabling thing for a lot of things. Yes, you could have

24:33.440 --> 24:41.520
 done it better, but people were trying to do it better and they were using more principles,

24:41.520 --> 24:49.280
 language designs, but they just couldn't do it right. And the nonprofessional programmers that

24:49.280 --> 24:58.640
 write lots of that code just couldn't understand them. So it did an amazing job for what it was.

24:58.640 --> 25:04.080
 It's not the prettiest language and I don't think it ever will be the prettiest language, but

25:05.200 --> 25:10.400
 let's not be bigots here. So what was the origin story of C++?

25:10.400 --> 25:18.400
 Yeah, you basically gave a few perspectives of your inspiration of object oriented programming.

25:19.280 --> 25:24.400
 That's you had a connection with C and performance efficiency was an important

25:24.400 --> 25:29.920
 thing you were drawn to. Efficiency and reliability. Reliability. You have to get both.

25:30.720 --> 25:38.640
 What's reliability? I really want my telephone calls to get through and I want the quality

25:38.640 --> 25:46.400
 of what I am talking, coming out at the other end. The other end might be in London or wherever.

25:48.400 --> 25:55.760
 And you don't want the system to be crashing. If you're doing a bank, you mustn't crash. It might

25:55.760 --> 26:02.640
 be your bank account that is in trouble. There's different constraints like in games, it doesn't

26:02.640 --> 26:06.560
 matter too much if there's a crash, nobody dies and nobody gets ruined.

26:06.560 --> 26:14.560
 But I am interested in the combination of performance, partly because of sort of speed

26:14.560 --> 26:22.800
 of things being done, part of being able to do things that is necessary to have reliability

26:24.320 --> 26:32.560
 of larger systems. If you spend all your time interpreting a simple function call,

26:32.560 --> 26:39.280
 a simple function call, you are not going to have enough time to do proper signal processing to get

26:39.280 --> 26:46.000
 the telephone calls to sound right. Either that or you have to have ten times as many computers

26:46.000 --> 26:51.760
 and you can't afford your phone anymore. It's a ridiculous idea in the modern world because

26:51.760 --> 26:58.160
 we have solved all of those problems. I mean, they keep popping up in different ways because

26:58.160 --> 27:03.120
 we tackle bigger and bigger problems. So efficiency remains always an important aspect.

27:03.120 --> 27:08.800
 But you have to think about efficiency, not just as speed, but as an enabler to

27:09.680 --> 27:17.280
 important things. And one of the things it enables is reliability, is dependability.

27:18.720 --> 27:24.800
 When I press the pedal, the brake pedal of a car, it is not actually connected directly

27:24.800 --> 27:30.160
 to anything but a computer. That computer better work.

27:31.680 --> 27:39.520
 Let's talk about reliability just a little bit. So modern cars have ECUs, have millions of lines

27:39.520 --> 27:46.560
 of code today. So this is certainly especially true of autonomous vehicles where some of the

27:46.560 --> 27:50.720
 aspects of the control or driver assistance systems that steer the car, that keep it in the

27:50.720 --> 27:56.800
 lane and so on. So how do you think, you know, I talked to regulators, people in government

27:56.800 --> 28:03.360
 who are very nervous about testing the safety of these systems of software. Ultimately software

28:03.360 --> 28:11.920
 that makes decisions that could lead to fatalities. So how do we test software systems like these?

28:11.920 --> 28:21.120
 First of all, safety, like performance and like security is the system's property.

28:21.840 --> 28:27.680
 People tend to look at one part of a system at a time and saying something like, this is secure.

28:28.800 --> 28:34.480
 That's all right. I don't need to do that. Yeah, that piece of code is secure. I'll buy

28:34.480 --> 28:41.600
 your operator. If you want to have reliability, if you want to have performance, if you want to

28:41.600 --> 28:46.640
 have security, you have to look at the whole system. I did not expect you to say that,

28:46.640 --> 28:52.480
 but that's very true. Yes, I'm dealing with one part of the system and I want my part to be really

28:52.480 --> 29:00.320
 good, but I know it's not the whole system. Furthermore, if making an individual part perfect,

29:00.320 --> 29:05.680
 may actually not be the best way of getting the highest degree of reliability and performance and

29:05.680 --> 29:14.080
 such. There's people that say C++ is not type safe. You can break it. Sure. I can break anything

29:14.080 --> 29:20.800
 that runs on a computer. I may not go through your type system. If I wanted to break into your

29:20.800 --> 29:26.400
 computer, I'll probably try SQL injection. And it's very true. If you think about

29:26.400 --> 29:32.640
 safety or even reliability at the system level, especially when a human being is involved,

29:34.080 --> 29:42.480
 it starts becoming hopeless pretty quickly in terms of proving that something is

29:43.840 --> 29:48.800
 safe to a certain level. Yeah. Because there's so many variables. It's so complex. Well, let's get

29:48.800 --> 29:54.000
 back to something we can talk about and actually talk about it. Yeah.

29:54.000 --> 30:01.680
 Talk about and actually make some progress on. Yes. We can look at C++ programs and we can

30:01.680 --> 30:12.160
 try and make sure they crash this often. The way you do that is largely by simplification.

30:14.640 --> 30:21.440
 The first step is to simplify the code, have less code, have code that are less likely to go wrong.

30:21.440 --> 30:28.960
 It's not by runtime testing everything. It is not by big test frameworks that you are using.

30:28.960 --> 30:35.600
 Yes, we do that also. But the first step is actually to make sure that when you want to

30:35.600 --> 30:43.120
 express something, you can express it directly in code rather than going through endless loops

30:43.120 --> 30:51.360
 and convolutions in your head before it gets down the code. The way you are thinking about

30:51.360 --> 30:59.360
 a problem is not in the code. There is a missing piece that's just in your head. And the code,

30:59.360 --> 31:05.920
 you can see what it does, but it cannot see what you thought about it unless you have expressed

31:05.920 --> 31:13.120
 things directly. When you express things directly, you can maintain it. It's easier to find errors.

31:13.120 --> 31:19.280
 It's easier to make modifications. It's actually easier to test it. And lo and behold, it runs

31:19.280 --> 31:26.720
 faster. And therefore, you can use a smaller number of computers, which means there's less

31:26.720 --> 31:33.360
 hardware that could possibly break. So I think the key here is simplification.

31:34.000 --> 31:40.080
 But it has to be, to use the Einstein quote, as simple as possible and no simpler.

31:40.080 --> 31:40.800
 Not simpler.

31:41.600 --> 31:46.880
 There are other areas with under constraints where you can be simpler than you can be in C++.

31:46.880 --> 31:52.160
 But in the domain I'm dealing with, that's the simplification I'm after.

31:53.360 --> 32:02.560
 So how do you inspire or ensure that the Einstein level of simplification is reached?

32:03.280 --> 32:11.840
 So can you do code review? Can you look at code? If I gave you the code for the Ford F150

32:11.840 --> 32:21.440
 and said, here, is this a mess or is this okay? Is it possible to tell? Is it possible to regulate?

32:23.040 --> 32:31.680
 An experienced developer can look at code and see if it smells. Mixed metaphors deliberately.

32:31.680 --> 32:45.360
 Yes. The point is that it is hard to generate something that is really obviously clean and

32:46.880 --> 32:52.160
 can be appreciated. But you can usually recognize when you haven't reached that point.

32:52.160 --> 33:03.360
 And so I've never looked at the F150 code, so I wouldn't know. But I know what I ought to be

33:03.360 --> 33:12.080
 looking for. I'll be looking for some tricks that correlate with bugs and elsewhere. And I have tried

33:12.080 --> 33:22.480
 to formulate rules for what good code looks like. And the current version of that is called the C++

33:22.480 --> 33:32.240
 core guidelines. One thing people should remember is there's what you can do in a language and what

33:32.240 --> 33:39.600
 you should do. In a language, you have lots of things that is necessary in some context,

33:39.600 --> 33:45.680
 but not in others. There's things that exist just because there's 30 year old code out there and

33:45.680 --> 33:51.200
 you can't get rid of it. But you can't have rules that says when you create it, try and follow these

33:51.200 --> 34:02.480
 rules. This does not create good programs by themselves, but it limits the damage from mistakes.

34:02.480 --> 34:08.960
 It limits the possibilities of mistakes. And basically, we are trying to say, what is it that

34:08.960 --> 34:16.240
 a good programmer does? At the fairly simple level of where you use the language and how you use it.

34:16.240 --> 34:24.640
 Now, I can put all the rules for chiseling in marble. It doesn't mean that somebody who follows

34:24.640 --> 34:32.160
 all of those rules can do a masterpiece by Michelangelo. That is, there's something else

34:32.160 --> 34:40.640
 to write a good program. Just is there something else to create an important work of art? That is,

34:40.640 --> 34:53.920
 there's some kind of inspiration, understanding, gift. But we can approach the sort of technical,

34:53.920 --> 35:02.400
 the craftsmanship level of it. The famous painters, the famous sculptures was among other things,

35:03.440 --> 35:14.320
 superb craftsmen. They could express their ideas using their tools very well. And so these days,

35:14.320 --> 35:20.000
 I think what I'm doing, what a lot of people are doing, we are still trying to figure out how it is

35:20.000 --> 35:29.280
 to use our tools very well. For a really good piece of code, you need a spark of inspiration,

35:29.280 --> 35:36.640
 and you can't, I think, regulate that. You cannot say that I'll take a picture only,

35:37.200 --> 35:45.600
 I'll buy your picture only if you're at least Van Gogh. There are other things you can regulate,

35:45.600 --> 35:55.200
 but not the inspiration. I think that's quite beautifully put. It is true that there is as an

35:55.200 --> 36:04.640
 experienced programmer, when you see code that's inspired, that's like Michelangelo, you know it

36:04.640 --> 36:12.240
 when you see it. And the opposite of that is code that is messy, code that smells, you know,

36:12.240 --> 36:17.760
 when you see it. And I'm not sure you can describe it in words, except vaguely through guidelines and

36:17.760 --> 36:27.040
 so on. Yes, it's easier to recognize ugly than to recognize beauty in code. And for the reason is

36:27.040 --> 36:34.000
 that sometimes beauty comes from something that's innovative and unusual. And you have to sometimes

36:34.000 --> 36:41.040
 think reasonably hard to appreciate that. On the other hand, the messes have things that are

36:41.040 --> 36:50.160
 in common. And you can have static checkers and dynamic checkers that find

36:52.080 --> 37:02.400
 a large number of the most common mistakes. You can catch a lot of sloppiness mechanically. I'm

37:02.400 --> 37:09.920
 a great fan of static analysis in particular, because you can check for not just the language

37:09.920 --> 37:16.880
 rules, but for the usage of language rules. And I think we will see much more static analysis

37:16.880 --> 37:24.400
 in the coming decade. Can you describe what static analysis is? You represent a piece of code

37:25.840 --> 37:33.760
 so that you can write a program that goes over that representation and look for things that are

37:33.760 --> 37:43.600
 are right and not right. So, for instance, you can analyze a program to see if

37:46.000 --> 37:54.240
 resources are leaked. That's one of my favorite problems. It's not actually all that hard and

37:54.240 --> 38:00.320
 modern C++, but you can do it. If you are writing in the C level, you have to have a malloc and a

38:00.320 --> 38:08.880
 free. And they have to match. If you have them in a single function, you can usually do it very

38:08.880 --> 38:16.320
 easily. If there's a malloc here, there should be a free there. On the other hand, in between can be

38:16.320 --> 38:22.000
 showing complete code and then it becomes impossible. If you pass that pointer to the

38:22.000 --> 38:31.600
 memory out of a function and then want to make sure that the free is done somewhere else,

38:31.600 --> 38:38.000
 now it gets really difficult. And so for static analysis, you can run through a program and you

38:38.000 --> 38:47.120
 can try and figure out if there's any leaks. And what you will probably find is that you will find

38:47.120 --> 38:54.240
 some leaks and you'll find quite a few places where your analysis can't be complete. It might

38:54.240 --> 39:02.880
 depend on runtime. It might depend on the cleverness of your analyzer and it might take a

39:02.880 --> 39:11.120
 long time. Some of these programs run for a long time. But if you combine such analysis

39:11.120 --> 39:17.120
 with a set of rules that says how people could use it, you can actually see why the rules are

39:17.120 --> 39:25.040
 violated. And that stops you from getting into the impossible complexities. You don't want to

39:25.040 --> 39:31.040
 solve the halting problem. So static analysis is looking at the code without running the code.

39:31.040 --> 39:38.880
 Yes. And thereby it's almost not a production code, but it's almost like an education tool

39:38.880 --> 39:45.440
 of how the language should be used. It guides you like it at its best, right? It would

39:45.440 --> 39:50.320
 guide you in how you write future code as well. And you learn together.

39:50.320 --> 39:56.400
 Yes. So basically you need a set of rules for how you use the language. Then you need a static

39:56.400 --> 40:05.120
 analysis that catches your mistakes when you violate the rules or when your code ends up

40:05.120 --> 40:09.200
 doing things that it shouldn't, despite the rules, because there is the language rules.

40:09.200 --> 40:16.000
 We can go further. And again, it's back to my idea that I'd much rather find errors before

40:16.000 --> 40:23.280
 I start running the code. If nothing else, once the code runs, if it catches an error at run times,

40:23.280 --> 40:30.160
 I have to have an error handler. And one of the hardest things to write in code is error handling

40:30.160 --> 40:35.840
 code, because you know something went wrong. Do you know really exactly what went wrong?

40:36.640 --> 40:42.960
 Usually not. How can you recover when you don't know what the problem was? You can't be 100% sure

40:42.960 --> 40:52.480
 what the problem was in many, many cases. And this is part of it. So yes, we need good languages,

40:52.480 --> 41:02.240
 we need good type systems, we need rules for how to use them, we need static analysis. And the

41:02.240 --> 41:08.320
 ultimate for static analysis is of course program proof, but that still doesn't scale to the kind

41:08.320 --> 41:15.200
 of systems we deploy. Then we start needing testing and the rest of the stuff.

41:15.200 --> 41:22.960
 So C++ is an object oriented programming language that creates, especially with its newer versions,

41:22.960 --> 41:29.120
 as we'll talk about, higher and higher levels of abstraction. So how do you design?

41:30.400 --> 41:35.040
 Let's even go back to the origin of C++. How do you design something with so much abstraction

41:35.040 --> 41:45.200
 that's still efficient and is still something that you can manage, do static analysis on,

41:45.200 --> 41:50.480
 you can have constraints on, they can be reliable, all those things we've talked about.

41:50.480 --> 41:59.440
 To me, there's a slight tension between high level abstraction and efficiency.

41:59.440 --> 42:04.560
 That's a good question. I could probably have a year's course just trying to answer it.

42:06.080 --> 42:13.200
 Yes, there's a tension between efficiency and abstraction, but you also get the interesting

42:13.200 --> 42:20.800
 situation that you get the best efficiency out of the best abstraction. And my main tool

42:21.600 --> 42:28.320
 for efficiency for performance actually is abstraction. So let's go back to how C++ was

42:28.320 --> 42:34.000
 got there. You said it was object oriented programming language. I actually never said that.

42:35.040 --> 42:42.880
 It's always quoted, but I never did. I said C++ supports object oriented programming and other

42:42.880 --> 42:51.520
 techniques. And that's important because I think that the best solution to most complex,

42:51.520 --> 43:00.880
 interesting problems require ideas and techniques from things that has been called object oriented

43:02.880 --> 43:14.960
 data abstraction, functional, traditional C style code, all of the above. And so when I was designing

43:14.960 --> 43:24.560
 C++, I soon realized I couldn't just add features. If you just add what looks pretty or what people

43:24.560 --> 43:32.080
 ask for or what you think is good, one by one, you're not going to get a coherent whole. What

43:32.080 --> 43:40.560
 you need is a set of guidelines that that guides your decisions. Should this feature be in or should

43:40.560 --> 43:47.840
 this feature be out? How should a feature be modified before it can go in and such?

43:48.640 --> 43:56.080
 And in the book I wrote about that, the design evolution of C++, there's a whole bunch of rules

43:56.080 --> 44:04.400
 like that. Most of them are not language technical. They're things like don't violate static type

44:04.400 --> 44:12.480
 system because I like static type system for the obvious reason that I like things to be reliable

44:12.480 --> 44:21.280
 on reasonable amounts of hardware. But one of these rules is the zero overhead principle.

44:21.280 --> 44:22.000
 The what kind of principle?

44:22.000 --> 44:29.600
 The zero overhead principle. It basically says that if you have an abstraction,

44:29.600 --> 44:36.320
 it should not cost anything compared to write the equivalent code at a lower level.

44:38.960 --> 44:50.000
 So if I have, say, a matrix multiply, it should be written in such a way that you could not drop to

44:50.000 --> 44:54.800
 the C level of abstraction and use arrays and pointers and such and run faster.

44:54.800 --> 45:01.920
 And so people have written such matrix multiplications, and they've actually gotten

45:01.920 --> 45:07.520
 code that ran faster than Fortran because once you had the right abstraction, you can eliminate

45:08.640 --> 45:16.560
 temporaries and you can do loop fusion and other good stuff like that. That's quite hard to do by

45:16.560 --> 45:21.600
 hand and in a lower level language. And there's some really nice examples of that.

45:21.600 --> 45:28.320
 And the key here is that that matrix multiplication, the matrix abstraction,

45:29.120 --> 45:34.000
 allows you to write code that's simple and easy. You can do that in any language.

45:34.000 --> 45:39.840
 But with C++, it has the features so that you can also have this thing run faster than if you hand

45:39.840 --> 45:47.680
 coded it. Now, people have given that lecture many times, I and others, and a very common

45:47.680 --> 45:52.800
 question after the talk where you have demonstrated that you can outperform Fortran for

45:52.800 --> 45:57.680
 dense matrix multiplication, people come up and says, yeah, but that was C++.

45:57.680 --> 46:04.800
 If I rewrote your code in C, how much faster would it run? The answer is much slower.

46:06.080 --> 46:11.920
 This happened the first time actually back in the 80s with a friend of mine called Doug McElroy,

46:11.920 --> 46:22.080
 who demonstrated exactly this effect. And so the principle is you should give programmers the tools

46:22.080 --> 46:28.560
 so that the abstractions can follow the zero void principle. Furthermore, when you put in a language

46:28.560 --> 46:35.680
 feature in C++ or a standard library feature, you try to meet this. It doesn't mean it's absolutely

46:35.680 --> 46:45.040
 optimal, but it means if you hand code it with the usual facilities in the language in C++ in C,

46:45.040 --> 46:52.800
 you should not be able to better it. Usually you can do better if you use embedded assembler for

46:53.360 --> 47:00.000
 machine code for some of the details to utilize part of a computer that the compiler doesn't know

47:00.000 --> 47:06.880
 about. But you should get to that point before you beat to the abstraction. So that's a beautiful

47:06.880 --> 47:14.640
 ideal to reach for. And we meet it quite often. Quite often. So where's the magic of that coming

47:14.640 --> 47:20.560
 from? There's some of it is the compilation process. So the implementation of C++, some of it

47:20.560 --> 47:27.280
 is the design of the feature itself, the guidelines. So I think it's important that you

47:27.280 --> 47:34.880
 think about the guidelines. So I've recently and often talked to Chris Latner, so Clang.

47:36.320 --> 47:44.160
 What, just out of curiosity, is your relationship in general with the different implementations of

47:44.160 --> 47:50.480
 C++ as you think about you and committee and other people in C++, think about the design of

47:50.480 --> 47:58.080
 features or design of previous features. In trying to reach the ideal of zero overhead,

47:59.840 --> 48:05.920
 does the magic come from the design, the guidelines, or from the implementations?

48:06.480 --> 48:13.840
 And not all. You go for programming technique,

48:13.840 --> 48:18.000
 programming language features, and implementation techniques. You need all three.

48:18.000 --> 48:21.840
 And how can you think about all three at the same time?

48:22.640 --> 48:28.160
 It takes some experience, takes some practice, and sometimes you get it wrong. But after a while,

48:28.160 --> 48:37.840
 you sort of get it right. I don't write compilers anymore. But Brian Kernighan pointed out that one

48:37.840 --> 48:48.640
 of the reasons C++ succeeded was some of the craftsmanship I put into the early compilers.

48:49.760 --> 48:54.080
 And of course, I did the language assign. Of course, I wrote a fair amount of code using

48:54.080 --> 49:02.720
 this kind of stuff. And I think most of the successes involve progress in all three areas

49:02.720 --> 49:10.400
 together. A small group of people can do that. Two, three people can work together to do something

49:10.400 --> 49:16.160
 like that. It's ideal if it's one person that has all the skills necessary. But nobody has all the

49:16.160 --> 49:23.840
 skills necessary in all the fields where C++ is used. So if you want to approach my ideal in, say,

49:23.840 --> 49:30.240
 concurrent programming, you need to know about algorithms from current programming. You need to

49:30.240 --> 49:36.960
 know the trigger of lock free programming. You need to know something about compiler techniques.

49:36.960 --> 49:46.720
 And then you have to know some of the application areas where this is, like some forms of graphics

49:46.720 --> 49:57.440
 or some forms of what we call web server kind of stuff. And that's very hard to get into a single

49:57.440 --> 50:06.800
 head. But small groups can do it too. So is there differences in your view, not saying which is

50:06.800 --> 50:13.680
 better or so on, but differences in the different implementations of C++? Why are there several

50:13.680 --> 50:23.680
 sort of maybe naive questions for me? GCC, clang, so on? This is a very reasonable question. When

50:23.680 --> 50:35.520
 I designed C++, most languages had multiple implementations. Because if you run on an IBM,

50:35.520 --> 50:41.440
 if you run on a Sun, if you run on a Motorola, there was just many, many companies and they each

50:41.440 --> 50:47.200
 have their own compilation structure and their own compilers. It was just fairly common that

50:47.200 --> 50:54.720
 there was many of them. And I wrote C Front assuming that other people would write compilers

50:54.720 --> 51:04.320
 with C++ if successful. And furthermore, I wanted to utilize all the backend infrastructures that

51:04.320 --> 51:10.240
 were available. I soon realized that my users were using 25 different linkers. I couldn't write my

51:10.240 --> 51:19.200
 own linker. Yes, I could, but I couldn't write 25 linkers and also get any work done on the language.

51:20.080 --> 51:26.480
 And so it came from a world where there was many linkers, many optimizers, many

51:27.120 --> 51:36.080
 compiler front ends, not to start, but many operating systems. The whole world was not an

51:36.080 --> 51:44.000
 86 and a Linux box or something, whatever is the standard today. In the old days, they set a VAX.

51:45.040 --> 51:51.520
 So basically, I assumed there would be lots of compilers. It was not a decision that there should

51:51.520 --> 52:00.400
 be many compilers. It was just a fact. That's the way the world is. And yes, many compilers

52:00.400 --> 52:13.600
 emerged. And today, there's at least four front ends, Clang, GCC, Microsoft, and EDG,

52:13.600 --> 52:21.440
 it is design group. They supply a lot of the independent organizations and the embedded

52:21.440 --> 52:29.040
 systems industry. And there's lots and lots of backends. We have to think about how many dozen

52:29.040 --> 52:35.760
 backends there are. Because different machines have different things, especially in the embedded

52:35.760 --> 52:43.920
 world, the machines are very different, the architectures are very different. And so having

52:43.920 --> 52:52.160
 a single implementation was never an option. Now, I also happen to dislike monocultures.

52:53.120 --> 52:54.320
 Monocultures.

52:54.320 --> 53:01.920
 They are dangerous. Because whoever owns the monoculture can go stale. And there's no

53:01.920 --> 53:09.360
 competition. And there's no incentive to innovate. There's a lot of incentive to put barriers in the

53:09.360 --> 53:15.680
 way of change. Because hey, we own the world. And it's a very comfortable world for us. And who are

53:15.680 --> 53:26.400
 you to mess with that? So I really am very happy that there's four front ends for C++. Clang's

53:26.400 --> 53:36.320
 great. But GCC was great. But then it got somewhat stale. Clang came along. And GCC is much better

53:36.320 --> 53:47.920
 now. Microsoft is much better now. So at least a low number of front ends puts a lot of pressure on

53:51.040 --> 53:57.760
 standards compliance and also on performance and error messages and compile time speed,

53:57.760 --> 53:59.360
 all this good stuff that we want.

53:59.360 --> 54:07.520
 Do you think, crazy question, there might come along, do you hope there might come along

54:08.800 --> 54:15.280
 implementation of C++ written, given all its history, written from scratch?

54:16.400 --> 54:18.960
 So written today from scratch?

54:18.960 --> 54:24.880
 Well, Clang and the LLVM is more or less written from scratch.

54:24.880 --> 54:30.960
 But there's been C++ 11, 14, 17, 20. You know, there's been a lot of

54:30.960 --> 54:36.480
 I think sooner or later somebody's going to try again. There has been attempts to write

54:36.480 --> 54:42.400
 new C++ compilers and some of them has been used and some of them has been absorbed into

54:42.400 --> 54:44.000
 others and such. Yeah, it'll happen.

54:45.200 --> 54:52.960
 So what are the key features of C++? And let's use that as a way to sort of talk about

54:52.960 --> 54:59.360
 the evolution of C++, the new features. So at the highest level, what are the features

54:59.360 --> 55:01.920
 that were there in the beginning? What features got added?

55:03.200 --> 55:13.600
 Let's first get a principle or an aim in place. C++ is for people who want to use hardware

55:13.600 --> 55:18.720
 really well and then manage the complexity of doing that through abstraction.

55:18.720 --> 55:27.120
 And so the first facility you have is a way of manipulating the machines at a fairly low

55:27.120 --> 55:36.560
 level. That looks very much like C. It has loops, it has variables, it has pointers like

55:36.560 --> 55:45.040
 machine addresses, it can access memory directly, it can allocate stuff in the absolute minimum

55:45.040 --> 55:52.560
 of space needed on the machine. There's a machine facing part of C++ which is roughly

55:52.560 --> 55:59.120
 equivalent to C. I said C++ could beat C and it can. It doesn't mean I dislike C. If I

55:59.120 --> 56:07.760
 disliked C, I wouldn't have built on it. Furthermore, after Dennis Ritchie, I'm probably the major

56:07.760 --> 56:18.160
 contributor to modern C. I had lunch with Dennis most days for 16 years and we never

56:18.160 --> 56:26.960
 had a harsh word between us. So these C versus C++ fights are for people who don't quite

56:26.960 --> 56:34.800
 understand what's going on. Then the other part is the abstraction. The key is the class.

56:34.800 --> 56:42.480
 There, the key is the class which is a user defined type. My idea for the class is that

56:42.480 --> 56:48.400
 you should be able to build a type that's just like the building types in the way you

56:48.400 --> 56:54.480
 use them, in the way you declare them, in the way you get the memory and you can do

56:54.480 --> 57:03.680
 just as well. So in C++ there's an int as in C. You should be able to build an abstraction,

57:03.680 --> 57:11.360
 a class which we can call capital int that you can use exactly like an integer and run

57:11.360 --> 57:18.080
 just as fast as an integer. There's the idea right there. And of course you probably don't

57:18.080 --> 57:25.600
 want to use the int itself but it has happened. People have wanted integers that were range

57:25.600 --> 57:29.840
 checked so that you couldn't overflow and such, especially for very safety critical

57:29.840 --> 57:36.320
 applications like the fuel injection for a marine diesel engine for the largest ships.

57:37.040 --> 57:43.360
 This is a real example by the way. This has been done. They built themselves an integer

57:43.360 --> 57:49.200
 that was just like integer except that couldn't overflow. If there was an overflow you went

57:49.200 --> 57:56.880
 into the error handling. And then you built more interesting types. You can build a matrix

57:56.880 --> 58:03.600
 which you need to do graphics or you could build a gnome for a video game.

58:04.400 --> 58:07.760
 And all these are classes and they appear just like the built in types.

58:07.760 --> 58:08.240
 Exactly.

58:08.240 --> 58:11.120
 In terms of efficiency and so on. So what else is there?

58:11.120 --> 58:12.320
 And flexibility.

58:12.320 --> 58:20.400
 So I don't know, for people who are not familiar with object oriented programming there's inheritance.

58:20.400 --> 58:27.040
 There's a hierarchy of classes. You can just like you said create a generic vehicle that can turn

58:27.040 --> 58:27.600
 left.

58:27.600 --> 58:40.320
 So what people found was that you don't actually know. How do I say this? A lot of types are

58:40.320 --> 58:52.960
 related. That is the vehicles, all vehicles are related. Bicycles, cars, fire engines, tanks. They

58:52.960 --> 58:57.600
 have some things in common and some things that differ. And you would like to have the common

58:57.600 --> 59:04.160
 things common and having the differences specific. And when you didn't want to know about

59:04.160 --> 59:12.640
 the differences, just turn left. You don't have to worry about it. That's how you get the traditional

59:12.640 --> 59:19.520
 object oriented programming coming out of Simula adopted by Smalltalk and C++ and all the other

59:19.520 --> 59:25.840
 languages. The other kind of obvious similarity between types comes when you have something like

59:25.840 --> 59:35.760
 a vector. Fortran gave us the vector as called array of doubles. But the minute you have a

59:35.760 --> 59:42.720
 vector of doubles, you want a vector of double precision doubles and for short doubles for

59:42.720 --> 59:50.640
 graphics. And why should you not have a vector of integers while you're added or a vector of

59:50.640 --> 1:00:01.040
 vectors and a vector of vectors of chess pieces? Now you have a board, right? So this is you

1:00:01.040 --> 1:00:09.200
 express the commonality as the idea of a vector and the variations come through parameterization.

1:00:10.080 --> 1:00:17.360
 And so here we get the two fundamental ways of abstracting or of having similarities of

1:00:17.360 --> 1:00:23.120
 types in C++. There's the inheritance and there's a parameterization. There's the object oriented

1:00:23.120 --> 1:00:27.920
 programming and there's the generic programming. With the templates for the generic programming.

1:00:27.920 --> 1:00:37.040
 Yep. So you've presented it very nicely, but now you have to make all that happen and make it

1:00:37.040 --> 1:00:43.280
 efficient. So generic programming with templates, there's all kinds of magic going on, especially

1:00:43.280 --> 1:00:50.160
 recently that you can help catch up on. But it feels to me like you can do way more than what

1:00:50.160 --> 1:00:55.760
 you just said with templates. You can start doing this kind of metaprogramming, this kind of...

1:00:55.760 --> 1:01:02.320
 You can do metaprogramming also. I didn't go there in that explanation. We're trying to be

1:01:02.320 --> 1:01:08.160
 very basic, but go back on to the implementation. If you couldn't implement this efficiently,

1:01:08.160 --> 1:01:14.400
 if you couldn't use it so that it became efficient, it has no place in C++ because

1:01:14.400 --> 1:01:22.560
 it will violate the zero overhead principle. So when I had to get object oriented programming

1:01:22.560 --> 1:01:31.360
 inheritance, I took the idea of virtual functions from Simula. Virtual functions is a Simula term,

1:01:31.360 --> 1:01:38.640
 class is a Simula term. If you ever use those words, say thanks to Christen Nygaard and Olli

1:01:38.640 --> 1:01:46.720
 Høndahl. And I did the simplest implementation I knew of, which was basically a jump table.

1:01:47.520 --> 1:01:54.080
 So you get the virtual function table, the function goes in, does an indirection through

1:01:54.080 --> 1:01:58.000
 a table and get the right function. That's how you pick the right thing there.

1:01:58.000 --> 1:02:06.000
 And I thought that was trivial. It's close to optimal and it was obvious. It turned out the

1:02:06.000 --> 1:02:12.400
 Simula had a more complicated way of doing it and therefore was slower. And it turns out that most

1:02:12.400 --> 1:02:16.880
 languages have something that's a little bit more complicated, sometimes more flexible,

1:02:16.880 --> 1:02:22.880
 but you pay for it. And one of the strengths of C++ was that you could actually do this object

1:02:22.880 --> 1:02:30.800
 oriented stuff and your overhead compared to ordinary functions, there's no indirection. It's

1:02:30.800 --> 1:02:40.400
 sort of in 5, 10, 25% just the call. It's down there. It's not two. And that means you can

1:02:40.400 --> 1:02:46.960
 afford to use it. Furthermore, in C++, you have the distinction between a virtual function and

1:02:46.960 --> 1:02:53.040
 a nonvirtual function. If you don't want any overhead, if you don't need the indirection that

1:02:53.040 --> 1:03:00.640
 gives you the flexibility in object oriented programming, just don't ask for it. So the idea

1:03:00.640 --> 1:03:06.640
 is that you only use virtual functions if you actually need the flexibility. So it's not zero

1:03:06.640 --> 1:03:11.360
 overhead, but it's zero overhead compared to any other way of achieving the flexibility.

1:03:11.360 --> 1:03:25.040
 Now, auto parameterization. Basically, the compiler looks at the template, say the vector,

1:03:25.040 --> 1:03:34.400
 and it looks at the parameter, and then combines the two and generates a piece of code that is

1:03:34.400 --> 1:03:42.400
 exactly as if you've written a vector of that specific type. So that's the minimal overhead.

1:03:42.400 --> 1:03:47.920
 If you have many template parameters, you can actually combine code that the compiler couldn't

1:03:47.920 --> 1:03:56.080
 usually see at the same time and therefore get code that is faster than if you had handwritten

1:03:56.080 --> 1:04:04.800
 the stuff, unless you are very, very clever. So the thing is, parameterized code, the compiler

1:04:04.800 --> 1:04:12.320
 fills stuff in during the compilation process, not during runtime. That's right. And furthermore,

1:04:12.320 --> 1:04:20.160
 it gives all the information it's gotten, which is the template, the parameter, and the context

1:04:20.160 --> 1:04:30.480
 of use. It combines the three and generates good code. But it can generate, now, it's a little

1:04:30.480 --> 1:04:35.360
 outside of what I'm even comfortable thinking about, but it can generate a lot of code. Yes.

1:04:36.560 --> 1:04:45.440
 And how do you, I remember being both amazed at the power of that idea, and

1:04:45.440 --> 1:04:50.960
 how ugly the debugging looked? Yes. Debugging can be truly horrid.

1:04:51.520 --> 1:04:57.040
 Come back to this, because I have a solution. Anyway, the debugging was ugly.

1:04:58.320 --> 1:05:06.880
 The code generated by C++ has always been ugly, because there's these inherent optimizations.

1:05:06.880 --> 1:05:10.720
 A modern C++ compiler has front end, middle end, and back end.

1:05:10.720 --> 1:05:18.640
 Even C Front, back in 83, had front end and back end optimizations. I actually took the code,

1:05:20.320 --> 1:05:27.680
 generated an internal representation, munched that representation to generate good code.

1:05:27.680 --> 1:05:33.200
 So people say, it's not a compiler, it generates C. The reason it generated C was I wanted to use

1:05:33.200 --> 1:05:38.480
 C's code generator, and I wanted to use C's code generator to generate good code.

1:05:38.480 --> 1:05:43.280
 C was I wanted to use C's code generators that was really good at back end optimizations.

1:05:44.080 --> 1:05:50.320
 But I needed front end optimizations, and therefore, the C I generated was optimized C.

1:05:51.280 --> 1:06:00.560
 The way a really good handcrafted optimizer human could generate it, and it was not meant

1:06:00.560 --> 1:06:06.160
 for humans. It was the output of a program, and it's much worse today. And with templates,

1:06:06.160 --> 1:06:16.960
 it gets much worse still. So it's hard to combine simple debugging with the optimal code,

1:06:16.960 --> 1:06:24.080
 because the idea is to drag in information from different parts of the code to generate good code,

1:06:25.680 --> 1:06:34.240
 machine code. And that's not readable. So what people often do for debugging

1:06:34.240 --> 1:06:42.720
 is they turn the optimizer off. And so you get code that when something in your source code

1:06:42.720 --> 1:06:50.480
 looks like a function call, it is a function call. When the optimizer is turned on, it may disappear,

1:06:50.480 --> 1:06:58.400
 the function call, it may inline. And so one of the things you can do is you can actually get code

1:06:58.400 --> 1:07:05.760
 that is smaller than the function call, because you eliminate the function preamble and return.

1:07:06.320 --> 1:07:11.040
 And there's just the operation there. One of the key things when I did

1:07:13.280 --> 1:07:20.080
 templates was I wanted to make sure that if you have, say, a sort algorithm, and you give it a

1:07:20.080 --> 1:07:30.560
 sorting criteria, if that sorting criteria is simply comparing things with less than,

1:07:31.360 --> 1:07:38.880
 the code generated should be the less than, not an indirect function call to a comparison

1:07:40.560 --> 1:07:47.120
 object, which is what it is in the source code. But we really want down to the single instruction.

1:07:47.120 --> 1:07:54.240
 But anyway, turn off the optimizer, and you can debug. The first level of debugging can be done,

1:07:54.240 --> 1:07:59.360
 and I always do without the optimization on, because then I can see what's going on.

1:07:59.360 --> 1:08:07.840
 And then there's this idea of concepts that puts some, now I've never even,

1:08:09.360 --> 1:08:14.640
 I don't know if it was ever available in any form, but it puts some constraints

1:08:14.640 --> 1:08:17.280
 on the stuff you can parameterize, essentially.

1:08:18.240 --> 1:08:27.440
 Let me try and explain this. So yes, it wasn't there 10 years ago. We have had versions of it

1:08:27.440 --> 1:08:37.120
 that actually work for the last four or five years. It was a design by Gabi Dos Reis, Drew

1:08:37.120 --> 1:08:46.720
 Sutton and me. We were professors and postdocs in Texas at the time. And the implementation by

1:08:46.720 --> 1:08:59.040
 Andrew Sutton has been available for that time. And it is part of C++20. And there's a standard

1:08:59.040 --> 1:09:10.640
 library that uses it. So this is becoming really very real. It's available in Clang and GCC. GCC

1:09:10.640 --> 1:09:17.120
 for a couple of years, and I believe Microsoft is soon going to do it. We expect all of C++20

1:09:17.120 --> 1:09:26.720
 to be available in all the major compilers in 20. But this kind of stuff is available now.

1:09:26.720 --> 1:09:30.720
 I'm just saying that because otherwise people might think I was talking about science fiction.

1:09:31.920 --> 1:09:35.440
 And so what I'm going to say is concrete. You can run it today.

1:09:37.040 --> 1:09:46.240
 And there's production uses of it. So the basic idea is that when you have a generic component,

1:09:47.200 --> 1:09:54.560
 like a sort function, the sort function will require at least two parameters. One is the

1:09:54.560 --> 1:10:03.120
 data structure with a given type and a comparison criteria. And these things are related, but

1:10:03.680 --> 1:10:07.840
 obviously you can't compare things if you don't know what the type of things you compare.

1:10:10.160 --> 1:10:16.880
 And so you want to be able to say, I'm going to sort something and it is to be sortable.

1:10:16.880 --> 1:10:20.960
 What does it mean to be sortable? You look it up in the standard. It has to have a

1:10:20.960 --> 1:10:27.200
 it has to be a sequence with a beginning and an end. There has to be random access to that sequence.

1:10:27.200 --> 1:10:34.800
 And there has to be the element types has to be comparable by default.

1:10:34.800 --> 1:10:37.040
 Which means less than operator can operate on.

1:10:37.040 --> 1:10:37.600
 Yes.

1:10:37.600 --> 1:10:39.120
 Less than logical operator can operate.

1:10:39.120 --> 1:10:45.360
 Basically what concepts are, they're compile time predicates. They're predicates you can ask,

1:10:45.360 --> 1:10:52.800
 are you a sequence? Yes, I have a beginning and end. Are you a random access sequence? Yes,

1:10:52.800 --> 1:11:00.560
 I have a subscripting and plus. Is your element type something that has a less than? Yes,

1:11:00.560 --> 1:11:06.960
 I have a less than it's and so basically that's the system. And so instead of saying,

1:11:06.960 --> 1:11:11.440
 I will take a parameter of any type, it'll say, I'll take something that's sortable.

1:11:11.440 --> 1:11:17.920
 And it's well defined. And so we say, okay, you can sort with less than, I don't want less than,

1:11:17.920 --> 1:11:23.920
 I want greater than or something I invent. So you have two parameters, the sortable thing and the

1:11:24.720 --> 1:11:33.920
 comparison criteria. And the comparison criteria will say, well, I can, you can write it saying it

1:11:33.920 --> 1:11:41.200
 should operate on the element type. And then you can say, well, I can sort with less than,

1:11:41.200 --> 1:11:49.200
 and it has the comparison operations. So that's just simply the fundamental thing. It's compile

1:11:49.200 --> 1:11:56.320
 time predicates. Do you have the properties I need? So it specifies the requirements of the code

1:11:56.320 --> 1:12:05.280
 on the parameters that it gets. It's very similar to types actually. But operating in the space of

1:12:05.280 --> 1:12:15.200
 concepts. Concepts. The word concept was used by Alex Stefanov, who is sort of the father of generic

1:12:15.200 --> 1:12:23.520
 programming in the context of C++. There's other places that use that word, but the way we call

1:12:23.520 --> 1:12:29.040
 it generic programming is Alex's. And he called them concepts because he said they are the sort

1:12:29.040 --> 1:12:34.720
 of the fundamental concepts of an area. So they should be called concepts. And we've had

1:12:34.720 --> 1:12:42.480
 concepts all the time. If you look at the KNR book about C, C has arithmetic types and it has

1:12:45.760 --> 1:12:52.480
 integral types. It says so in the book. And then it lists what they are and they have certain

1:12:52.480 --> 1:12:59.200
 properties. The difference today is that we can actually write a concept that will ask a type,

1:12:59.200 --> 1:13:05.200
 are you an integral type? Do you have the properties necessary to be an integral type?

1:13:05.200 --> 1:13:15.200
 Do you have plus, minus, divide and such? So maybe the story of concepts, because I thought

1:13:15.200 --> 1:13:25.680
 it might be part of C++11. C O X or whatever it was at the time. What was the, why didn't it,

1:13:25.680 --> 1:13:30.560
 what, like what we'll, we'll talk a little bit about this fascinating process of standards,

1:13:30.560 --> 1:13:34.000
 because I think it's really interesting for people. It's interesting for me,

1:13:34.000 --> 1:13:40.000
 but why did it take so long? What shapes did the idea of concepts take?

1:13:41.760 --> 1:13:48.320
 What were the challenges? Back in 87 or thereabouts. 1987?

1:13:49.120 --> 1:13:54.960
 Well, 1987 or thereabouts when I was designing templates, obviously I wanted to express the

1:13:54.960 --> 1:14:03.920
 notion of what is required by a template of its arguments. And so I looked at this and basically

1:14:03.920 --> 1:14:14.000
 for templates, I wanted three properties. I wanted to be very flexible. It had to be able to express

1:14:14.000 --> 1:14:20.480
 things I couldn't imagine because I know I can't imagine everything. And I've been suffering from

1:14:20.480 --> 1:14:27.600
 languages that try to constrain you to only do what the designer thought good. Didn't want to

1:14:27.600 --> 1:14:35.920
 do that. Secondly, it had to run faster, as fast or faster than handwritten code. So basically,

1:14:35.920 --> 1:14:43.520
 if I have a vector of T and I take a vector of char, it should run as fast as you built a vector

1:14:43.520 --> 1:14:51.440
 of char yourself without parameterization. And thirdly, I wanted to be able to express

1:14:52.480 --> 1:15:00.480
 the constraints of the arguments, have proper type checking of the interfaces.

1:15:01.680 --> 1:15:09.360
 And neither I nor anybody else at the time knew how to get all three. And I thought for C++,

1:15:09.360 --> 1:15:17.040
 I must have the two first. Otherwise, it's not C++. And it bothered me for another couple of

1:15:17.040 --> 1:15:23.600
 decades that I couldn't solve the third one. I mean, I was the one that put function argument

1:15:23.600 --> 1:15:29.840
 type checking into C. I know the value of good interfaces. I didn't invent that idea. It's very

1:15:29.840 --> 1:15:37.600
 common, but I did it. And I wanted to do the same for templates, of course, and I couldn't.

1:15:37.600 --> 1:15:47.840
 So it bothered me. Then we tried again, 2002, 2003. Gaby DesRays and I started analyzing the

1:15:47.840 --> 1:15:57.280
 problem, explained possible solutions. It was not a complete design. A group in University of Indiana,

1:15:57.280 --> 1:16:10.240
 an old friend of mine, they started a project at Indiana and we thought we could get

1:16:11.360 --> 1:16:22.000
 a good system of concepts in another two or three years that would have made C++ 11 to C++

1:16:22.000 --> 1:16:33.280
 06 or 07. Well, it turns out that I think we got a lot of the fundamental ideas wrong. They were

1:16:33.280 --> 1:16:41.920
 too conventional. They didn't quite fit C++ in my opinion. Didn't serve implicit conversions very

1:16:41.920 --> 1:16:51.120
 well. It didn't serve mixed type arithmetic, mixed type computations very well. A lot of

1:16:51.120 --> 1:17:03.200
 stuff came out of the functional community and that community didn't deal with multiple types

1:17:03.200 --> 1:17:12.480
 in the same way as C++ does, had more constraints on what you could express and didn't have the

1:17:12.480 --> 1:17:19.760
 draconian performance requirements. And basically we tried. We tried very hard. We had some

1:17:19.760 --> 1:17:30.560
 successes, but it just in the end wasn't, didn't compile fast enough, was too hard to use and

1:17:31.440 --> 1:17:40.080
 didn't run fast enough unless you had optimizers that was beyond the state of the art. They still

1:17:40.080 --> 1:17:49.120
 are. So we had to do something else. Basically it was the idea that a set of parameters has

1:17:49.120 --> 1:17:55.760
 defined a set of operations and you go through an interaction table just like for virtual functions

1:17:55.760 --> 1:18:03.360
 and then you try to optimize the interaction away to get performance. And we just couldn't

1:18:03.360 --> 1:18:12.720
 do all of that. But get back to the standardization. We are standardizing C++ under ISO rules,

1:18:12.720 --> 1:18:20.160
 which are very open process. People come in, there's no requirements for education or experience.

1:18:20.160 --> 1:18:28.960
 So you started to develop C++ and there's a whole, when was the first standard established? What is

1:18:28.960 --> 1:18:34.960
 that like? The ISO standard, is there a committee that you're referring to? There's a group of

1:18:34.960 --> 1:18:39.280
 people. What was that like? How often do you meet? What's the discussion?

1:18:39.280 --> 1:18:52.720
 I'll try and explain that. So sometime in early 1989, two people, one from IBM, one from HP,

1:18:52.720 --> 1:19:02.080
 turned up in my office and told me I would like to standardize C++. This was a new idea to me and

1:19:02.080 --> 1:19:09.760
 when I pointed out that it wasn't finished yet and it wasn't ready for formal standardization

1:19:09.760 --> 1:19:14.480
 and such. And they say, no, Bjarne, you haven't gotten it. You really want to do this.

1:19:16.400 --> 1:19:23.760
 Our organizations depend on C++. We cannot depend on something that's owned by another

1:19:23.760 --> 1:19:31.040
 corporation that might be a competitor. Of course we could rely on you, but you might get run over

1:19:31.040 --> 1:19:41.840
 by a boss. We really need to get this out in the open. It has to be standardized under formal rules

1:19:41.840 --> 1:19:51.120
 and we are going to standardize it under ISO rules and you really want to be part of it because

1:19:51.120 --> 1:20:00.800
 basically otherwise we'll do it ourselves. And we know you can do it better. So through a combination

1:20:00.800 --> 1:20:14.400
 of arm twisting and flattery, it got started. So in late 89, there was a meeting in DC at the,

1:20:15.600 --> 1:20:20.640
 actually no, it was not ISO then, it was ANSI, the American National Standard doing.

1:20:23.200 --> 1:20:30.480
 We met there. We were lectured on the rules of how to do an ANSI standard. There was about 25 of us

1:20:30.480 --> 1:20:38.800
 there, which apparently was a new record for that kind of meeting. And some of the old C guys that

1:20:38.800 --> 1:20:45.440
 has been standardized in C was there. So we got some expertise in. So the way this works is that

1:20:45.440 --> 1:20:52.720
 it's an open process. Anybody can sign up if they pay the minimal fee, which is about a thousand

1:20:52.720 --> 1:21:01.040
 dollars, less than a little bit more now. And I think it's $1,280. It's not going to kill you.

1:21:01.680 --> 1:21:10.880
 And we have three meetings a year. This is fairly standard. We tried two meetings a year for a

1:21:10.880 --> 1:21:20.160
 couple of years that didn't work too well. So three one week meetings a year and you meet

1:21:20.160 --> 1:21:28.320
 and you have technical discussions, and then you bring proposals forward for votes. The votes are

1:21:28.320 --> 1:21:39.040
 done one person per, one vote per organization. So you can't have say IBM come in with 10 people

1:21:39.040 --> 1:21:44.160
 and dominate things that's not allowed. And these are organizations that extensively UC

1:21:44.160 --> 1:21:52.640
 plus plus. Yes. Or individuals or individuals. I mean, it's a bunch of people in the room

1:21:53.280 --> 1:22:00.400
 deciding the design of a language based on which a lot of the world's systems run.

1:22:00.400 --> 1:22:05.440
 Right. Well, I think most people would agree it's better than if I decided it

1:22:06.240 --> 1:22:13.200
 or better than if a single organization like AG&T decides it. I don't know if everyone agrees to

1:22:13.200 --> 1:22:22.560
 that, by the way. Bureaucracies have their critics too. Yes. Look, standardization is not pleasant.

1:22:23.360 --> 1:22:31.200
 It's horrifying. It's like democracy. Exactly. As Churchill says, democracy is the worst way,

1:22:31.200 --> 1:22:36.480
 except for the others. Right. And it's, I would say the same with formal standardization.

1:22:36.480 --> 1:22:44.400
 But anyway, so we meet and we have these votes and that determines what the standard is.

1:22:45.040 --> 1:22:53.280
 A couple of years later, we extended this so it became worldwide. We have standard organizations

1:22:53.280 --> 1:23:07.760
 that are active in currently 15 to 20 countries and another 15 to 20 are sort of looking and voting

1:23:08.800 --> 1:23:15.680
 based on the rest of the work on it. And we meet three times a year. Next week I'll be in Cologne,

1:23:15.680 --> 1:23:25.440
 Germany, spending a week doing standardization and we'll vote out the committee draft of C++20,

1:23:25.440 --> 1:23:34.000
 which goes to the national standards committees for comments and requests for changes and

1:23:34.000 --> 1:23:39.600
 improvements. Then we do that and there's a second set of votes where hopefully everybody

1:23:39.600 --> 1:23:47.040
 votes in favor. This has happened several times. The first time we finished, we started in the

1:23:47.040 --> 1:23:55.760
 first technical meeting was in 1990. The last was in 98. We voted it out. That was the standard

1:23:55.760 --> 1:24:04.000
 that people used until 11 or a little bit past 11. And it was an international standard. All the

1:24:04.000 --> 1:24:13.440
 countries voted in favor. It took longer with 11. I'll mention why, but all the nations voted in

1:24:13.440 --> 1:24:23.440
 favor. And we work on the basis of consensus. That is, we do not want something that passes 6040

1:24:24.400 --> 1:24:30.240
 because then we're going to get dialects and opponents and people complain too much. They

1:24:30.240 --> 1:24:37.280
 all complain too much, but basically it has no real effect. The standards has been obeyed. They

1:24:37.280 --> 1:24:44.880
 have been working to make it easier to use many compilers, many computers and all of that kind of

1:24:44.880 --> 1:24:54.080
 stuff. It was traditional with ISO standards to take 10 years. We did the first one in eight,

1:24:54.080 --> 1:25:00.400
 brilliant. And we thought we were going to do the next one in six because now we are good at it.

1:25:00.400 --> 1:25:10.720
 Right. It took 13. Yeah. It was named OX. It was named OX. Hoping that you would at least get it

1:25:10.720 --> 1:25:15.760
 within the single, within the odds, the single digits. I thought we would get, I thought we'd

1:25:15.760 --> 1:25:21.920
 get six, seven or eight. The confidence of youth. That's right. Well, the point is that this was

1:25:21.920 --> 1:25:28.160
 sort of like a second system effect. That is, we now knew how to do it. And so we're going to do

1:25:28.160 --> 1:25:35.680
 it much better. And we've got more ambitious and it took longer. Furthermore, there is this tendency

1:25:35.680 --> 1:25:45.200
 because it's a 10 year cycle or it doesn't matter. Just before you're about to ship,

1:25:45.200 --> 1:25:57.360
 somebody has a bright idea. And so we really, really must get that in. We did that successfully

1:25:57.360 --> 1:26:05.680
 with the STL. We got the standard library that gives us all the STL stuff. That basically,

1:26:05.680 --> 1:26:11.520
 I think it saved C++. It was beautiful. And then people tried it with other things

1:26:11.520 --> 1:26:17.520
 and it didn't work so well. They got things in, but it wasn't as dramatic and it took longer and

1:26:17.520 --> 1:26:26.720
 longer and longer. So after C++ 11, which was a huge improvement and what, basically what most

1:26:26.720 --> 1:26:36.400
 people are using today, we decided never again. And so how do you avoid those slips? And the

1:26:36.400 --> 1:26:46.320
 answer is that you ship more often. So that if you have a slip on a 10 year cycle, by the time

1:26:46.320 --> 1:26:52.960
 you know it's a slip, there's 11 years till you get it. Now with a three year cycle, there is

1:26:52.960 --> 1:27:02.640
 about three or four years till you get it. Like the delay between feature freeze and shipping. So

1:27:02.640 --> 1:27:10.880
 you always get one or two years more. And so we shipped 14 on time, we shipped 17 on time,

1:27:10.880 --> 1:27:21.680
 and we ship, we will ship 20 on time. It'll happen. And furthermore, this gives a predictability

1:27:21.680 --> 1:27:26.320
 that allows the implementers, the compiler implementers, the library implementers,

1:27:26.320 --> 1:27:34.640
 they have a target and they deliver on it. 11 took two years before most compilers were good

1:27:34.640 --> 1:27:44.640
 enough. 14, most compilers were actually getting pretty good in 14. 17, everybody shipped in 17.

1:27:45.360 --> 1:27:53.200
 We are going to have at least almost everybody ship almost everything in 20. And I know this

1:27:53.200 --> 1:28:00.480
 and I know this because they're shipping in 19. Predictability is good. Delivery on time is good.

1:28:01.040 --> 1:28:03.840
 And so yeah. That's great. That's how it works.

1:28:05.920 --> 1:28:12.560
 There's a lot of features that came in in C++ 11. There's a lot of features at the birth of C++

1:28:13.200 --> 1:28:20.240
 that were amazing and ideas with concepts in 2020. What to you is the most,

1:28:20.240 --> 1:28:32.640
 just to you personally, beautiful or just you sit back and think, wow, that's just nice and clean

1:28:32.640 --> 1:28:41.680
 feature of C++? I have written two papers for the History of Programming Languages Conference,

1:28:41.680 --> 1:28:47.520
 which basically asked me such questions. And I'm writing a third one, which I will deliver

1:28:47.520 --> 1:28:53.440
 at the History of Programming Languages Conference in London next year. So I've been thinking about

1:28:53.440 --> 1:29:00.320
 that. And there is one clear answer. Constructors and destructors. The way a constructor can

1:29:00.320 --> 1:29:08.400
 establish the environment for the use of a type for an object and the destructor that cleans up

1:29:08.400 --> 1:29:15.120
 any messes at the end of it. That is key to C++. That's why we don't have to use garbage

1:29:15.120 --> 1:29:22.640
 collection. That's how we can get predictable performance. That's how you can get the minimal

1:29:22.640 --> 1:29:31.520
 overhead in many, many cases, and have really clean types. It's the idea of constructor destructor

1:29:31.520 --> 1:29:40.480
 pairs. Sometimes it comes out under the name RAII. Resource acquisition is initialization,

1:29:40.480 --> 1:29:45.280
 which is the idea that you grab resources in the constructor and release them in destructor.

1:29:46.560 --> 1:29:53.200
 It's also the best example of why I shouldn't be in advertising. I get the best idea and I call it

1:29:53.200 --> 1:29:59.520
 resource acquisition is initialization. Not the greatest naming I've ever heard.

1:29:59.520 --> 1:30:08.880
 Not the greatest naming I've ever heard. So it's types, abstraction of types.

1:30:11.040 --> 1:30:18.000
 You said, I want to create my own types. So types is an essential part of C++ and making them

1:30:18.000 --> 1:30:27.760
 efficient is the key part. And to you, this is almost getting philosophical, but the construction

1:30:27.760 --> 1:30:35.760
 and the destruction, the creation of an instance of a type and the freeing of resources from that

1:30:36.400 --> 1:30:45.200
 instance of a type is what defines the object. It's almost like birth and death is what defines

1:30:45.200 --> 1:30:53.600
 human life. That's right. By the way, philosophy is important. You can't do good language design

1:30:53.600 --> 1:30:58.080
 without philosophy because what you are determining is what people can express and how.

1:30:59.200 --> 1:31:08.160
 This is very important. By the way, constructors destructors came into C++ in 79 in about the

1:31:08.160 --> 1:31:14.080
 second week of my work with what was then called C of the classes. It is a fundamental idea.

1:31:15.120 --> 1:31:21.200
 Next comes the fact that you need to control copying because once you control, as you said,

1:31:21.200 --> 1:31:28.400
 birth and death, you have to control taking copies, which is another way of creating an object.

1:31:29.200 --> 1:31:35.680
 And finally, you have to be able to move things around so you get the move operations. And that's

1:31:35.680 --> 1:31:45.440
 the set of key operations you can define on a C++ type. And so to you, those things are just

1:31:45.440 --> 1:31:54.240
 just a beautiful part of C++ that is at the core of it all. Yes. You mentioned that you hope there

1:31:54.240 --> 1:32:00.000
 will be one unified set of guidelines in the future for how to construct a programming language.

1:32:00.000 --> 1:32:07.280
 So perhaps not one programming language, but a unification of how we build programming languages,

1:32:08.480 --> 1:32:13.840
 if you remember such statements. I have some trouble remembering it, but I know the origin

1:32:13.840 --> 1:32:19.360
 of that idea. So maybe you can talk about sort of C++ has been improving. There's been a lot

1:32:19.360 --> 1:32:25.200
 of programming language. Do you, where does the arc of history taking us? Do you hope that there

1:32:25.200 --> 1:32:30.560
 is a unification about the languages with which we communicate in the digital space?

1:32:32.560 --> 1:32:42.400
 Well, I think that languages should be designed not by clobbering language features together and

1:32:42.400 --> 1:32:51.440
 and doing slightly different versions of somebody else's ideas, but through the creation of a set of

1:32:53.120 --> 1:33:01.360
 principles, rules of thumbs, whatever you call them. I made them for C++. And we're trying to

1:33:02.560 --> 1:33:07.120
 teach people in the standards committee about these rules, because a lot of people come in

1:33:07.120 --> 1:33:12.720
 and says, I've got a great idea. Let's put it in the language. And then you have to ask, why does

1:33:12.720 --> 1:33:18.240
 it fit in the language? Why does it fit in this language? It may fit in another language and not

1:33:18.240 --> 1:33:23.520
 here, or it may fit here and not the other language. So you have to work from a set of

1:33:23.520 --> 1:33:33.920
 principles and you have to develop that set of principles. And one example that I sometimes

1:33:33.920 --> 1:33:42.640
 remember is I was sitting down with some of the designers of Common Lisp and we were talking about

1:33:43.600 --> 1:33:50.880
 languages and language features. And obviously we didn't agree about anything because, well,

1:33:50.880 --> 1:33:58.160
 Lisp is not C++ and vice versa. It's too many parentheses. But suddenly we started making

1:33:58.160 --> 1:34:06.560
 progress. I said, I had this problem and I developed it according to these ideas. And

1:34:06.560 --> 1:34:11.680
 they said, why? We had that problem, different problem, and we developed it with the same kind

1:34:11.680 --> 1:34:21.440
 of principles. And so we worked through large chunks of C++ and large chunks of Common Lisp

1:34:21.440 --> 1:34:29.840
 and figured out we actually had similar sets of principles of how to do it. But the constraints

1:34:29.840 --> 1:34:37.600
 on our designs were very different and the aims for the usage was very different. But there was

1:34:37.600 --> 1:34:45.200
 commonality in the way you reason about language features and the fundamental principles you are

1:34:45.200 --> 1:34:52.240
 trying to do. So do you think that's possible? So there, just like there is perhaps a unified

1:34:52.240 --> 1:35:00.880
 theory of physics, of the fundamental forces of physics, that I'm sure there is commonalities

1:35:00.880 --> 1:35:06.960
 among the languages, but there's also people involved that help drive the development of these

1:35:06.960 --> 1:35:16.880
 languages. Do you have a hope or an optimism that there will be a unification? If you think about

1:35:16.880 --> 1:35:22.640
 physics and Einstein towards a simplified language, do you think that's possible?

1:35:24.560 --> 1:35:32.640
 Let's remember sort of modern physics, I think, started with Galileo in the 1300s. So they've had

1:35:32.640 --> 1:35:43.920
 700 years to get going. Modern computing started in about 49. We've got, what is it, 70 years. They

1:35:43.920 --> 1:35:52.640
 have 10 times. Furthermore, they are not as bothered with people using physics the way

1:35:52.640 --> 1:36:01.680
 we are worried about programming is done by humans. So each have problems and constraints

1:36:01.680 --> 1:36:09.680
 the others have, but we are very immature compared to physics. So I would look at sort of the

1:36:09.680 --> 1:36:18.080
 philosophical level and look for fundamental principles. Like you don't leak resources,

1:36:18.080 --> 1:36:29.280
 you shouldn't. You don't take errors at runtime that you don't need to. You don't violate some

1:36:29.280 --> 1:36:34.160
 kind of type system. There's many kinds of type systems, but when you have one, you don't break it,

1:36:35.760 --> 1:36:43.600
 etc., etc. There will be quite a few, and it will not be the same for all languages. But I think

1:36:44.560 --> 1:36:52.000
 if we step back at some kind of philosophical level, we would be able to agree on sets of

1:36:52.000 --> 1:37:04.320
 principles that applied to sets of problem areas. And within an area of use, like in C++'s case,

1:37:05.280 --> 1:37:12.480
 what used to be called systems programming, the area between the hardware and the fluffier parts

1:37:12.480 --> 1:37:19.200
 of the system, you might very well see a convergence. So these days you see Rust having

1:37:19.200 --> 1:37:27.120
 adopted RAII and sometimes accuse me for having borrowed it 20 years before they discovered it.

1:37:27.120 --> 1:37:38.080
 But we're seeing some kind of convergence here instead of relying on garbage collection all the

1:37:38.080 --> 1:37:46.160
 time. The garbage collection languages are doing things like the dispose patterns and such that

1:37:46.160 --> 1:37:52.480
 imitate some of the construction destruction stuff. And they're trying not to use the garbage

1:37:52.480 --> 1:37:58.320
 collection all the time and things like that. So there's a conversion. But I think we have to step

1:37:58.320 --> 1:38:03.040
 back to the philosophical level, agree on principles, and then we'll see some conversions,

1:38:04.320 --> 1:38:10.720
 convergences. And it will be application domain specific.

1:38:10.720 --> 1:38:16.560
 So a crazy question, but I work a lot with machine learning, with deep learning. I'm not sure if you

1:38:16.560 --> 1:38:23.920
 touch that world that much, but you could think of programming as a thing that takes some input.

1:38:24.480 --> 1:38:29.120
 A programming is the task of creating a program and a program takes some input and produces some

1:38:29.120 --> 1:38:37.600
 output. So machine learning systems train on data in order to be able to take an input and produce

1:38:37.600 --> 1:38:48.640
 output. But they're messy, fuzzy things, much like we as children grow up. We take some input,

1:38:48.640 --> 1:38:53.760
 we make some output, but we're noisy. We mess up a lot. We're definitely not reliable. Biological

1:38:53.760 --> 1:39:01.120
 system are a giant mess. So there's a sense in which machine learning is a kind of way of

1:39:01.120 --> 1:39:11.360
 programming, but just fuzzy. It's very, very, very different than C++. Because C++ is just like you

1:39:11.360 --> 1:39:18.240
 said, it's extremely reliable, it's efficient, you can measure it, you can test it in a bunch of

1:39:18.240 --> 1:39:26.080
 different ways. With biological systems or machine learning systems, you can't say much except sort

1:39:26.080 --> 1:39:34.400
 of empirically saying that 99.8% of the time, it seems to work. What do you think about this fuzzy

1:39:34.400 --> 1:39:41.760
 kind of programming? Do you even see it as programming? Is it totally another kind of world?

1:39:41.760 --> 1:39:48.640
 I think it's a different kind of world. And it is fuzzy. And in my domain, I don't like fuzziness.

1:39:48.640 --> 1:39:56.560
 That is, people say things like they want everybody to be able to program. But I don't

1:39:56.560 --> 1:40:06.400
 want everybody to program my airplane controls or the car controls. I want that to be done by

1:40:06.400 --> 1:40:13.520
 engineers. I want that to be done with people that are specifically educated and trained for doing

1:40:13.520 --> 1:40:20.400
 building things. And it is not for everybody. Similarly, a language like C++ is not for

1:40:20.400 --> 1:40:29.680
 everybody. It is generated to be a sharp and effective tool for professionals, basically,

1:40:30.240 --> 1:40:37.680
 and definitely for people who aim at some kind of precision. You don't have people doing

1:40:37.680 --> 1:40:44.560
 calculations without understanding math. Counting on your fingers is not going to cut it if you want

1:40:44.560 --> 1:40:56.560
 to fly to the moon. And so there are areas where an 84% accuracy rate, 16% false positive rate,

1:40:56.560 --> 1:41:09.360
 is perfectly acceptable and where people will probably get no more than 70. You said 98%. What

1:41:09.360 --> 1:41:16.320
 I have seen is more like 84. And by really a lot of blood, sweat, and tears, you can get up to 92.5.

1:41:16.320 --> 1:41:27.920
 So this is fine if it is, say, prescreening stuff before the human look at it. It is not good enough

1:41:27.920 --> 1:41:36.000
 for life threatening situations. And so there's lots of areas where the fuzziness is perfectly

1:41:36.000 --> 1:41:40.400
 acceptable and good and better than humans, cheaper than humans, cheaper than humans.

1:41:40.400 --> 1:41:47.440
 But it's not the kind of engineering stuff I'm mostly interested in. I worry a bit about

1:41:48.000 --> 1:41:53.200
 machine learning in the context of cars. You know much more about this than I do.

1:41:53.200 --> 1:41:54.160
 I worry too.

1:41:54.160 --> 1:42:02.880
 But I'm sort of an amateur here. I've read some of the papers, but I've not ever done it. And the

1:42:02.880 --> 1:42:12.320
 idea that scares me the most is the one I have heard, and I don't know how common it is, that

1:42:14.640 --> 1:42:24.960
 you have this AI system, machine learning, all of these trained neural nets. And when there's

1:42:24.960 --> 1:42:32.560
 something that's too complicated, they ask the human for help. But the human is reading a book or

1:42:32.560 --> 1:42:41.040
 asleep, and he has 30 seconds or three seconds to figure out what the problem was that the AI

1:42:41.040 --> 1:42:48.400
 system couldn't handle and do the right thing. This is scary. I mean, how do you do the cutting

1:42:48.400 --> 1:42:58.000
 work between the machine and the human? It's very, very difficult. And for the designer of

1:42:58.000 --> 1:43:05.120
 one of the most reliable, efficient, and powerful programming languages, C++, I can understand why

1:43:05.120 --> 1:43:11.920
 that world is actually unappealing. It is for most engineers. To me, it's extremely

1:43:11.920 --> 1:43:18.080
 appealing because we don't know how to get that interaction right. But I think it's possible. But

1:43:18.080 --> 1:43:24.320
 it's very, very hard. It is. And I was stating a problem, not a solution. That is impossible.

1:43:24.320 --> 1:43:29.120
 I mean, I would much rather never rely on the human. If you're driving a nuclear reactor,

1:43:29.120 --> 1:43:35.920
 if you're or an autonomous vehicle, it's much better to design systems written in C++ than

1:43:35.920 --> 1:43:44.800
 never ask human for help. Let's just get one fact in. Yeah. All of this AI stuff is on top of C++.

1:43:47.760 --> 1:43:53.360
 So that's one reason I have to keep a weather eye out on what's going on in that field. But

1:43:53.360 --> 1:43:58.400
 I will never become an expert in that area. But it's a good example of how you separate

1:43:58.400 --> 1:44:05.920
 different areas of applications and you have to have different tools, different principles. And

1:44:05.920 --> 1:44:11.200
 then they interact. No major system today is written in one language. And there are good

1:44:11.200 --> 1:44:20.800
 reasons for that. When you look back at your life work, what is a moment? What is a

1:44:20.800 --> 1:44:27.200
 event creation that you're really proud of? They say, damn, I did pretty good there.

1:44:29.040 --> 1:44:36.880
 Is it as obvious as the creation of C++? It's obvious. I've spent a lot of time with C++. And

1:44:37.920 --> 1:44:43.120
 there's a combination of a few good ideas, a lot of hard work, and a bit of work that I've done.

1:44:43.120 --> 1:44:50.800
 And I've tried to get away from it a few times, but I get dragged in again, partly because I'm

1:44:50.800 --> 1:44:58.400
 most effective in this area and partly because what I do has much more impact if I do it in

1:44:58.400 --> 1:45:05.120
 the context of C++. I have four and a half million people that pick it up tomorrow if I

1:45:05.120 --> 1:45:13.840
 get something right. If I did it in another field, I would have to start learning, then I have to

1:45:13.840 --> 1:45:21.760
 build it and then we'll see if anybody wants to use it. One of the things that has kept me going

1:45:21.760 --> 1:45:29.280
 for all of these years is one, the good things that people do with it and the interesting things

1:45:29.280 --> 1:45:36.160
 they do with it. And also, I get to see a lot of interesting stuff and talk to a lot of interesting

1:45:36.160 --> 1:45:46.400
 people. I mean, if it has just been statements on paper on a screen, I don't think I could have kept

1:45:46.400 --> 1:45:54.400
 going. But I get to see the telescopes up on Mauna Kea and I actually went and see how Ford built

1:45:54.400 --> 1:46:05.440
 cars and I got to JPL and see how they do the Mars rovers. There's so much cool stuff going on. And

1:46:05.440 --> 1:46:10.480
 most of the cool stuff is done by pretty nice people and sometimes in very nice places.

1:46:10.480 --> 1:46:25.360
 Cambridge, Sophia, Silicon Valley. There's more to it than just code. But code is central.

1:46:25.360 --> 1:46:32.480
 On top of the code are the people in very nice places. Well, I think I speak for millions of

1:46:32.480 --> 1:46:40.800
 people, Yaron, in saying thank you for creating this language that so many systems are built on

1:46:40.800 --> 1:46:47.360
 top of that make a better world. So thank you and thank you for talking today. Yeah, thanks.

1:46:47.360 --> 1:47:03.040
 And we'll make it even better. Good.

