WEBVTT

00:00.000 --> 00:02.560
 Let's talk about free speech and censorship.

00:02.560 --> 00:04.040
 You don't build a company like this

00:04.040 --> 00:06.440
 unless you believe that people expressing themselves

00:06.440 --> 00:07.280
 is a good thing.

00:07.280 --> 00:08.640
 Let me ask you as a father,

00:08.640 --> 00:09.760
 there's a weight heavy on you

00:09.760 --> 00:13.000
 that people get bullied on social networks.

00:13.000 --> 00:14.440
 I care a lot about how people feel

00:14.440 --> 00:15.460
 when they use our products

00:15.460 --> 00:19.320
 and I don't want to build products that make people angry.

00:19.320 --> 00:22.000
 Why do you think so many people dislike you?

00:23.440 --> 00:25.580
 Some even hate you.

00:25.580 --> 00:30.160
 And how do you regain their trust and support?

00:30.160 --> 00:32.720
 The following is a conversation with Mark Zuckerberg,

00:32.720 --> 00:35.700
 CEO of Facebook, now called Meta.

00:36.760 --> 00:38.680
 Please allow me to say a few words

00:38.680 --> 00:41.300
 about this conversation with Mark Zuckerberg,

00:41.300 --> 00:42.680
 about social media,

00:42.680 --> 00:45.440
 and about what troubles me in the world today,

00:45.440 --> 00:47.760
 and what gives me hope.

00:47.760 --> 00:49.480
 If this is not interesting to you,

00:49.480 --> 00:51.540
 I understand, please skip.

00:51.540 --> 00:54.620
 I believe that at its best,

00:54.620 --> 00:57.800
 social media puts a mirror to humanity

00:57.800 --> 01:01.060
 and reveals the full complexity of our world,

01:01.060 --> 01:04.080
 shining a light on the dark aspects of human nature

01:04.080 --> 01:06.700
 and giving us hope, a way out,

01:06.700 --> 01:09.780
 through compassionate but tense chaos of conversation

01:09.780 --> 01:12.780
 that eventually can turn into understanding,

01:12.780 --> 01:14.680
 friendship, and even love.

01:15.600 --> 01:17.460
 But this is not simple.

01:17.460 --> 01:19.580
 Our world is not simple.

01:19.580 --> 01:21.460
 It is full of human suffering.

01:22.340 --> 01:24.460
 I think about the hundreds of millions of people

01:24.460 --> 01:28.460
 who are starving and who live in extreme poverty,

01:28.460 --> 01:31.600
 the one million people who take their own life every year,

01:31.600 --> 01:33.940
 the 20 million people that attempt it,

01:33.940 --> 01:37.380
 and the many, many more millions who suffer quietly

01:37.380 --> 01:39.380
 in ways that numbers can never know.

01:40.740 --> 01:44.660
 I'm troubled by the cruelty and pain of war.

01:44.660 --> 01:48.540
 Today, my heart goes out to the people of Ukraine.

01:48.540 --> 01:52.220
 My grandfather spilled his blood on this land,

01:52.220 --> 01:54.020
 held the line as a machine gunner

01:54.020 --> 01:59.020
 against the Nazi invasion, surviving impossible odds.

01:59.180 --> 02:01.380
 I am nothing without him.

02:01.380 --> 02:03.540
 His blood runs in my blood.

02:04.980 --> 02:07.560
 My words are useless here.

02:07.560 --> 02:09.020
 I send my love.

02:09.020 --> 02:10.180
 It's all I have.

02:11.160 --> 02:14.140
 I hope to travel to Russia and Ukraine soon.

02:14.140 --> 02:16.780
 I will speak to citizens and leaders,

02:16.780 --> 02:18.920
 including Vladimir Putin.

02:19.980 --> 02:22.700
 As I've said in the past, I don't care about access,

02:22.700 --> 02:26.760
 fame, money, or power, and I'm afraid of nothing.

02:27.660 --> 02:31.100
 But I am who I am, and my goal in conversation

02:31.100 --> 02:33.460
 is to understand the human being before me,

02:33.460 --> 02:36.540
 no matter who they are, no matter their position.

02:36.540 --> 02:40.060
 And I do believe the line between good and evil

02:40.060 --> 02:42.480
 runs through the heart of every man.

02:43.540 --> 02:45.380
 So this is it.

02:45.380 --> 02:47.420
 This is our world.

02:47.420 --> 02:50.680
 It is full of hate, violence, and destruction.

02:51.720 --> 02:55.300
 But it is also full of love, beauty,

02:55.300 --> 02:57.540
 and the insatiable desire to help each other.

02:59.140 --> 03:01.320
 The people who run the social networks

03:01.320 --> 03:05.380
 that show this world, that show us to ourselves,

03:05.380 --> 03:08.500
 have the greatest of responsibilities.

03:08.500 --> 03:11.740
 In a time of war, pandemic, atrocity,

03:11.740 --> 03:14.460
 we turn to social networks to share real human insights

03:14.460 --> 03:18.620
 and experiences, to organize protests and celebrations,

03:18.620 --> 03:21.940
 to learn and to challenge our understanding of the world,

03:21.940 --> 03:24.300
 of our history and of our future,

03:24.300 --> 03:27.460
 and above all, to be reminded of our common humanity.

03:28.500 --> 03:30.500
 When the social networks fail,

03:30.500 --> 03:33.640
 they have the power to cause immense suffering.

03:33.640 --> 03:35.020
 And when they succeed,

03:35.020 --> 03:37.820
 they have the power to lessen that suffering.

03:37.820 --> 03:39.340
 This is hard.

03:39.340 --> 03:41.080
 It's a responsibility, perhaps,

03:41.080 --> 03:44.080
 almost unlike any other in history.

03:44.080 --> 03:47.260
 This podcast conversation attempts to understand the man

03:47.260 --> 03:50.680
 and the company who take this responsibility on,

03:50.680 --> 03:53.260
 where they fail and where they hope to succeed.

03:54.260 --> 03:57.920
 Mark Zuckerberg's feet are often held to the fire,

03:57.920 --> 04:01.540
 as they should be, and this actually gives me hope.

04:01.540 --> 04:03.900
 The power of innovation and engineering,

04:03.900 --> 04:05.560
 coupled with the freedom of speech

04:05.560 --> 04:07.700
 in the form of its highest ideal,

04:07.700 --> 04:11.140
 I believe can solve any problem in the world.

04:11.140 --> 04:14.780
 But that's just it, both are necessary,

04:14.780 --> 04:16.660
 the engineer and the critic.

04:17.620 --> 04:22.620
 I believe that criticism is essential, but cynicism is not.

04:23.260 --> 04:25.660
 And I worry that in our public discourse,

04:25.660 --> 04:30.380
 cynicism too easily masquerades as wisdom, as truth,

04:30.380 --> 04:32.220
 becomes viral and takes over,

04:32.220 --> 04:35.460
 and worse, suffocates the dreams of young minds

04:35.460 --> 04:39.260
 who want to build solutions to the problems of the world.

04:39.260 --> 04:41.540
 We need to inspire those young minds.

04:41.540 --> 04:43.720
 At least for me, they give me hope.

04:44.580 --> 04:47.160
 And one small way I'm trying to contribute

04:47.160 --> 04:49.520
 is to have honest conversations like these

04:49.520 --> 04:53.260
 that don't just ride the viral wave of cynicism,

04:53.260 --> 04:54.900
 but seek to understand the failures

04:54.900 --> 04:57.940
 and successes of the past, the problems before us,

04:57.940 --> 04:59.540
 and the possible solutions

04:59.540 --> 05:02.560
 in this very complicated world of ours.

05:02.560 --> 05:05.820
 I'm sure I will fail often,

05:05.820 --> 05:10.180
 and I count on the critic to point it out when I do.

05:10.180 --> 05:12.540
 But I ask for one thing,

05:12.540 --> 05:15.180
 and that is to fuel the fire of optimism,

05:15.180 --> 05:18.340
 especially in those who dream to build solutions,

05:18.340 --> 05:21.780
 because without that, we don't have a chance

05:21.780 --> 05:24.600
 on this too fragile, tiny planet of ours.

05:25.820 --> 05:28.020
 This is the Lex Friedman podcast.

05:28.020 --> 05:30.260
 To support it, please check out our sponsors

05:30.260 --> 05:31.620
 in the description.

05:31.620 --> 05:35.680
 And now, dear friends, here's Mark Zuckerberg.

05:40.980 --> 05:43.180
 Can you circle all the traffic lights, please?

05:53.880 --> 05:54.860
 You actually did it.

05:54.860 --> 05:56.820
 That is very impressive performance.

05:56.820 --> 06:00.020
 Okay, now we can initiate the interview procedure.

06:00.020 --> 06:02.980
 Is it possible that this conversation is happening

06:02.980 --> 06:05.380
 inside a metaverse created by you,

06:05.380 --> 06:07.180
 by Meta many years from now,

06:07.180 --> 06:10.180
 and we're doing a memory replay experience?

06:10.180 --> 06:11.260
 I don't know the answer to that.

06:11.260 --> 06:15.220
 Then I'd be some computer construct

06:15.220 --> 06:18.980
 and not the person who created that Meta company.

06:18.980 --> 06:20.500
 But that would truly be Meta.

06:21.380 --> 06:23.360
 Right, so this could be somebody else

06:23.360 --> 06:26.420
 using the Mark Zuckerberg avatar

06:26.420 --> 06:29.200
 who can do the Mark and the Lex conversation replay

06:29.200 --> 06:33.340
 from four decades ago when Meta, it was first sort of.

06:33.340 --> 06:34.780
 I mean, it's not gonna be four decades

06:34.780 --> 06:38.020
 before we have photorealistic avatars like this.

06:38.020 --> 06:40.100
 So I think we're much closer to that.

06:40.100 --> 06:41.380
 Well, that's something you talk about

06:41.380 --> 06:43.500
 is how passionate you are about the idea

06:43.500 --> 06:46.580
 of the avatar representing who you are in the metaverse.

06:46.580 --> 06:49.260
 So I do these podcasts in person.

06:51.100 --> 06:52.260
 You know, I'm a stickler for that,

06:52.260 --> 06:55.780
 because there's a magic to the in person conversation.

06:55.780 --> 06:58.140
 How long do you think it'll be before

06:58.140 --> 07:00.620
 you can have the same kind of magic in the metaverse,

07:00.620 --> 07:02.620
 the same kind of intimacy in the chemistry,

07:02.620 --> 07:06.060
 whatever the heck is there when we're talking in person?

07:06.060 --> 07:07.100
 How difficult is it?

07:07.100 --> 07:09.340
 How long before we have it in the metaverse?

07:10.340 --> 07:12.940
 Well, I think this is like the key question, right?

07:12.940 --> 07:17.500
 Because the thing that's different about virtual

07:17.500 --> 07:19.140
 and hopefully augmented reality

07:19.140 --> 07:22.400
 compared to all other forms of digital platforms before

07:22.400 --> 07:24.420
 is this feeling of presence, right?

07:24.420 --> 07:25.860
 The feeling that you're right,

07:25.860 --> 07:27.000
 that you're in an experience

07:27.000 --> 07:29.700
 and that you're there with other people or in another place.

07:29.700 --> 07:32.300
 And that's just different from all of the other screens

07:32.300 --> 07:33.900
 that we have today, right?

07:33.900 --> 07:36.780
 Phones, TVs, all the stuff.

07:36.780 --> 07:39.500
 They're trying to, in some cases, deliver experiences

07:39.500 --> 07:43.040
 that feel high fidelity,

07:43.040 --> 07:46.380
 but at no point do you actually feel like you're in it, right?

07:46.380 --> 07:49.660
 At some level, your content is trying to sort of convince you

07:49.660 --> 07:51.980
 that this is a realistic thing that's happening,

07:51.980 --> 07:54.860
 but all of the kind of subtle signals are telling you,

07:54.860 --> 07:56.500
 no, you're looking at a screen.

07:56.500 --> 08:00.700
 So the question about how you develop these systems is like,

08:00.700 --> 08:03.860
 what are all of the things that make the physical world

08:03.860 --> 08:04.900
 all the different cues?

08:04.900 --> 08:09.900
 So I think on visual presence and spatial audio,

08:13.080 --> 08:15.440
 we're making reasonable progress.

08:15.440 --> 08:16.940
 Spatial audio makes a huge deal.

08:16.940 --> 08:19.620
 I don't know if you've tried this experience,

08:19.620 --> 08:21.960
 workrooms that we launched where you have meetings.

08:21.960 --> 08:26.380
 And I basically made a rule for all of the top,

08:26.380 --> 08:27.760
 you know, management folks at the company

08:27.760 --> 08:29.520
 that they need to be doing standing meetings

08:29.520 --> 08:31.720
 in workrooms already, right?

08:31.720 --> 08:33.260
 I feel like we got to dog food this,

08:33.260 --> 08:35.760
 you know, this is how people are gonna work in the future.

08:35.760 --> 08:37.840
 So we have to adopt this now.

08:38.800 --> 08:40.780
 And there were already a lot of things

08:40.780 --> 08:42.280
 that I think feel significantly better

08:42.280 --> 08:44.740
 than like typical Zoom meetings,

08:44.740 --> 08:47.440
 even though the avatars are a lot lower fidelity.

08:48.620 --> 08:50.780
 You know, the idea that you have spatial audio,

08:50.780 --> 08:53.940
 you're around a table in VR with people.

08:53.940 --> 08:55.260
 If someone's talking from over there,

08:55.260 --> 08:56.860
 it sounds like it's talking from over there.

08:56.860 --> 08:59.960
 You can see, you know, the arm gestures

08:59.960 --> 09:01.760
 and stuff feel more natural.

09:01.760 --> 09:03.080
 You can have side conversations,

09:03.080 --> 09:04.860
 which is something that you can't really do in Zoom.

09:04.860 --> 09:06.940
 I mean, I guess you can text someone over,

09:06.940 --> 09:08.740
 like out of band,

09:08.740 --> 09:12.000
 but if you're actually sitting around a table with people,

09:12.940 --> 09:14.200
 you know, you can lean over

09:14.200 --> 09:15.580
 and whisper to the person next to you

09:15.580 --> 09:17.760
 and like have a conversation that you can't,

09:17.760 --> 09:19.100
 you know, that you can't really do

09:19.100 --> 09:23.500
 with in just video communication.

09:23.500 --> 09:27.500
 So I think it's interesting in what ways

09:27.500 --> 09:29.820
 some of these things already feel more real

09:29.820 --> 09:32.580
 than a lot of the technology that we have,

09:32.580 --> 09:35.040
 even when the visual fidelity isn't quite there,

09:35.040 --> 09:37.180
 but I think it'll get there over the next few years.

09:37.180 --> 09:38.740
 Now, I mean, you were asking about comparing that

09:38.740 --> 09:40.500
 to the true physical world,

09:40.500 --> 09:42.740
 not Zoom or something like that.

09:42.740 --> 09:45.700
 And there, I mean, I think you have feelings

09:45.700 --> 09:50.700
 of like temperature, you know, olfactory,

09:50.700 --> 09:54.380
 obviously touch, right, we're working on haptic gloves,

09:54.380 --> 09:56.300
 you know, the sense that you wanna be able to,

09:56.300 --> 09:57.220
 you know, put your hands down

09:57.220 --> 09:59.740
 and feel some pressure from the table.

09:59.740 --> 10:00.580
 You know, all of these things

10:00.580 --> 10:01.740
 I think are gonna be really critical

10:01.740 --> 10:04.660
 to be able to keep up this illusion

10:04.660 --> 10:06.820
 that you're in a world

10:06.820 --> 10:08.820
 and that you're fully present in this world.

10:08.820 --> 10:09.740
 But I don't know,

10:09.740 --> 10:11.640
 I think we're gonna have a lot of these building blocks

10:11.640 --> 10:14.220
 within, you know, the next 10 years or so.

10:14.220 --> 10:15.920
 And even before that, I think it's amazing

10:15.920 --> 10:18.140
 how much you're just gonna be able to build with software

10:18.140 --> 10:21.380
 that sort of masks some of these things.

10:21.380 --> 10:22.780
 I realize I'm going long,

10:22.780 --> 10:25.300
 but I was told we have a few hours here.

10:25.300 --> 10:26.140
 So it's a...

10:26.140 --> 10:27.220
 We're here for five to six hours.

10:27.220 --> 10:28.740
 Yeah, so I mean, it's, look,

10:28.740 --> 10:30.460
 I mean, that's on the shorter end

10:30.460 --> 10:32.540
 of the congressional testimonies I've done.

10:32.540 --> 10:36.300
 But it's, but, you know, one of the things

10:36.300 --> 10:39.540
 that we found with hand presence, right?

10:39.540 --> 10:42.000
 So the earliest VR, you just have the headset

10:42.000 --> 10:44.440
 and then, and that was cool, you could look around,

10:44.440 --> 10:45.380
 you feel like you're in a place,

10:45.380 --> 10:47.380
 but you don't feel like you're really able to interact with it

10:47.380 --> 10:48.540
 until you have hands.

10:48.540 --> 10:49.620
 And then there was this big question

10:49.620 --> 10:51.340
 where once you got hands,

10:51.340 --> 10:53.460
 what's the right way to represent them?

10:53.460 --> 10:58.460
 And initially, all of our assumptions was, okay,

10:58.560 --> 11:00.420
 when I look down and see my hands in the physical world,

11:00.420 --> 11:02.780
 I see an arm and it's gonna be super weird

11:02.780 --> 11:04.820
 if you see, you know, just your hand.

11:06.460 --> 11:08.060
 But it turned out to not be the case

11:08.060 --> 11:09.860
 because there's this issue with your arms,

11:09.860 --> 11:11.540
 which is like, what's your elbow angle?

11:11.540 --> 11:14.780
 And if the elbow angle that we're kind of interpolating

11:14.780 --> 11:18.660
 based on where your hand is and where your headset is

11:18.660 --> 11:19.940
 actually isn't accurate,

11:19.940 --> 11:21.900
 it creates this very uncomfortable feeling

11:21.900 --> 11:24.440
 where it's like, oh, like my arm is actually out like this,

11:24.440 --> 11:25.940
 but it's like showing it in here.

11:25.940 --> 11:29.540
 And that actually broke the feeling of presence a lot more.

11:29.540 --> 11:31.900
 Whereas it turns out that if you just show the hands

11:31.900 --> 11:33.740
 and you don't show the arms,

11:34.840 --> 11:36.220
 it actually is fine for people.

11:36.220 --> 11:38.420
 So I think that there's a bunch

11:38.420 --> 11:41.060
 of these interesting psychological cues

11:41.060 --> 11:44.980
 where it'll be more about getting the right details right.

11:44.980 --> 11:46.940
 And I think a lot of that will be possible

11:46.940 --> 11:49.780
 even over a few year period or a five year period.

11:49.780 --> 11:52.100
 And we won't need like every single thing to be solved

11:52.100 --> 11:54.620
 to deliver this like full sense of presence.

11:54.620 --> 11:56.500
 Yeah, it's a fascinating psychology question

11:56.500 --> 11:59.960
 of what is the essence

11:59.960 --> 12:04.260
 that makes in person conversation special?

12:04.260 --> 12:08.020
 It's like emojis are able to convey emotion really well,

12:08.020 --> 12:10.580
 even though they're obviously not photorealistic.

12:10.580 --> 12:12.460
 And so in that same way, Jessica, you're saying,

12:12.460 --> 12:14.260
 just showing the hands is able

12:14.260 --> 12:18.180
 to create a comfortable expression with your hands.

12:18.180 --> 12:19.520
 So I wonder what that is.

12:19.520 --> 12:21.920
 People in the world wars used to write letters

12:21.920 --> 12:24.380
 and you can fall in love with just writing letters.

12:24.380 --> 12:26.640
 You don't need to see each other in person.

12:26.640 --> 12:27.700
 You can convey emotion.

12:27.700 --> 12:32.700
 You can be depth of experience with just words.

12:32.740 --> 12:35.740
 So that's, I think, a fascinating place

12:35.740 --> 12:37.460
 to explore psychology of like,

12:37.460 --> 12:39.220
 how do you find that intimacy?

12:39.220 --> 12:42.700
 Yeah, and the way that I come to all of this stuff is,

12:42.700 --> 12:45.060
 I basically studied psychology and computer science.

12:45.060 --> 12:47.900
 So all of the work that I do

12:47.900 --> 12:49.900
 is sort of at the intersection of those things.

12:49.900 --> 12:52.180
 I think most of the other big tech companies

12:52.180 --> 12:55.060
 are building technology for you to interact with.

12:55.060 --> 12:56.680
 What I care about is building technology

12:56.680 --> 12:58.100
 to help people interact with each other.

12:58.100 --> 12:59.900
 So I think it's a somewhat different approach

12:59.900 --> 13:02.300
 than most of the other tech entrepreneurs

13:02.300 --> 13:04.340
 and big companies come at this from.

13:04.340 --> 13:08.980
 And a lot of the lessons

13:08.980 --> 13:10.980
 in terms of how I think about designing products

13:10.980 --> 13:15.980
 come from some just basic elements of psychology, right?

13:15.980 --> 13:19.060
 In terms of our brains,

13:19.060 --> 13:22.080
 you can compare it to the brains of other animals.

13:22.080 --> 13:25.560
 We're very wired to specific things, facial expressions.

13:25.560 --> 13:28.200
 I mean, we're very visual, right?

13:28.200 --> 13:29.340
 So compared to other animals,

13:29.340 --> 13:31.820
 I mean, that's clearly the main sense

13:31.820 --> 13:32.980
 that most people have.

13:32.980 --> 13:35.260
 But there's a whole part of your brain

13:35.260 --> 13:38.560
 that's just kind of focused on reading facial cues.

13:38.560 --> 13:42.180
 So when we're designing the next version of Quest

13:42.180 --> 13:45.820
 or the VR headset, a big focus for us is face tracking

13:45.820 --> 13:48.860
 and basically eye tracking so you can make eye contact,

13:48.860 --> 13:50.100
 which again, isn't really something

13:50.100 --> 13:51.500
 that you can do over a video conference.

13:51.500 --> 13:55.500
 It's sort of amazing how far video conferencing

13:55.500 --> 13:58.620
 has gotten without the ability to make eye contact, right?

13:58.620 --> 14:00.540
 It's sort of a bizarre thing if you think about it.

14:00.540 --> 14:03.140
 You're looking at someone's face,

14:03.140 --> 14:05.620
 sometimes for an hour when you're in a meeting

14:05.620 --> 14:08.960
 and you looking at their eyes to them

14:08.960 --> 14:11.780
 doesn't look like you're looking at their eyes.

14:11.780 --> 14:15.020
 You're always looking past each other, I guess.

14:15.020 --> 14:15.860
 I guess you're right.

14:15.860 --> 14:16.680
 You're not sending that signal.

14:16.680 --> 14:17.520
 Well, you're trying to.

14:17.520 --> 14:18.360
 Right, you're trying to.

14:18.360 --> 14:19.760
 A lot of times, or at least I find myself,

14:19.760 --> 14:21.420
 I'm trying to look into the other person's eyes.

14:21.420 --> 14:23.060
 But they don't feel like you're looking to their eyes.

14:23.060 --> 14:23.900
 So then the question is,

14:23.900 --> 14:25.220
 all right, am I supposed to look at the camera

14:25.220 --> 14:27.800
 so that way you can have a sensation

14:27.800 --> 14:28.640
 that I'm looking at you?

14:28.640 --> 14:30.140
 I think that that's an interesting question.

14:30.140 --> 14:33.820
 And then with VR today,

14:33.820 --> 14:35.660
 even without eye tracking

14:35.660 --> 14:37.500
 and knowing what your eyes are actually looking at,

14:37.500 --> 14:39.380
 you can fake it reasonably well, right?

14:39.380 --> 14:42.240
 So you can look at where the head pose is.

14:42.240 --> 14:43.720
 And if it looks like I'm kind of looking

14:43.720 --> 14:44.680
 in your general direction,

14:44.680 --> 14:46.500
 then you can sort of assume

14:46.500 --> 14:48.640
 that maybe there's some eye contact intended

14:48.640 --> 14:50.740
 and you can do it in a way where it's like,

14:50.740 --> 14:54.300
 okay, maybe it's not a fixated stare,

14:54.300 --> 14:56.880
 but it's somewhat natural.

14:56.880 --> 14:58.740
 But once you have actual eye tracking,

14:58.740 --> 15:00.180
 you can do it for real.

15:00.180 --> 15:02.140
 And I think that that's really important stuff.

15:02.140 --> 15:05.300
 So when I think about Meta's contribution to this field,

15:05.300 --> 15:06.640
 I have to say it's not clear to me

15:06.640 --> 15:08.700
 that any of the other companies

15:08.700 --> 15:11.180
 that are focused on the Metaverse

15:11.180 --> 15:13.340
 or on virtual and augmented reality

15:13.340 --> 15:15.820
 are gonna prioritize putting these features in the hardware

15:15.820 --> 15:18.260
 because like everything, they're trade offs, right?

15:18.260 --> 15:21.500
 I mean, it adds some weight to the device.

15:21.500 --> 15:22.740
 Maybe it adds some thickness.

15:22.740 --> 15:24.840
 You could totally see another company taking the approach

15:24.840 --> 15:27.600
 of let's just make the lightest and thinnest thing possible.

15:27.600 --> 15:31.380
 But I want us to design the most human thing possible

15:31.380 --> 15:33.340
 that creates the richest sense of presence

15:33.340 --> 15:37.900
 and cause so much of human emotion and expression

15:37.900 --> 15:39.500
 comes from these like micro movements.

15:39.500 --> 15:41.800
 If I like move my eyebrow millimeter,

15:41.800 --> 15:44.640
 you will notice and that like means something.

15:44.640 --> 15:46.840
 So the fact that we're losing these signals

15:46.840 --> 15:49.940
 and a lot of communication I think is a loss.

15:49.940 --> 15:51.700
 So it's not like, okay, there's one feature

15:51.700 --> 15:53.300
 and you add this, then it all of a sudden

15:53.300 --> 15:55.100
 is gonna feel like we have real presence.

15:55.100 --> 15:57.820
 You can sort of look at how the human brain works

15:57.820 --> 16:01.820
 and how we express and kind of read emotions

16:01.820 --> 16:04.700
 and you can just build a roadmap of that,

16:04.700 --> 16:06.460
 of just what are the most important things

16:06.460 --> 16:08.520
 to try to unlock over a five to 10 year period

16:08.520 --> 16:10.040
 and just try to make the experience

16:10.040 --> 16:12.780
 more and more human and social.

16:12.780 --> 16:16.640
 When do you think would be a moment,

16:16.640 --> 16:19.340
 like a singularity moment for the Metaverse

16:19.340 --> 16:22.300
 where there's a lot of ways to ask this question,

16:22.300 --> 16:26.580
 but people will have many or most

16:26.580 --> 16:28.820
 of their meaningful experiences

16:28.820 --> 16:31.340
 in the Metaverse versus the real world.

16:31.340 --> 16:33.060
 And actually it's interesting to think about

16:33.060 --> 16:35.560
 the fact that a lot of people are having

16:35.560 --> 16:37.280
 the most important moments of their life

16:37.280 --> 16:39.100
 happen in the digital sphere,

16:39.100 --> 16:40.540
 especially not during COVID,

16:41.680 --> 16:45.060
 like even falling in love or meeting friends

16:45.060 --> 16:46.420
 or getting excited about stuff

16:46.420 --> 16:49.660
 that is happening on the 2D digital plane.

16:49.660 --> 16:50.860
 When do you think the Metaverse

16:50.860 --> 16:54.100
 will provide those experiences for a large number,

16:54.100 --> 16:54.940
 like a majority of the population?

16:54.940 --> 16:57.240
 Yeah, I think it's a really good question.

16:57.240 --> 17:00.260
 There was someone, I read this piece

17:00.260 --> 17:03.740
 that framed this as a lot of people think

17:03.740 --> 17:06.040
 that the Metaverse is about a place,

17:06.040 --> 17:10.380
 but one definition of this is it's about a time

17:10.380 --> 17:12.900
 when basically immersive digital worlds

17:12.900 --> 17:17.100
 become the primary way that we live our lives

17:17.100 --> 17:18.720
 and spend our time.

17:18.720 --> 17:20.160
 I think that that's a reasonable construct.

17:20.160 --> 17:21.900
 And from that perspective,

17:21.900 --> 17:25.540
 I think you also just wanna look at this as a continuation

17:25.540 --> 17:27.140
 because it's not like, okay,

17:27.140 --> 17:28.940
 we are building digital worlds,

17:28.940 --> 17:29.820
 but we don't have that today.

17:29.820 --> 17:32.340
 I think you and I probably already live

17:32.340 --> 17:34.660
 a very large part of our life in digital worlds.

17:34.660 --> 17:37.260
 They're just not 3D immersive virtual reality,

17:37.260 --> 17:39.820
 but I do a lot of meetings over video

17:39.820 --> 17:42.300
 or I spend a lot of time writing things over email

17:42.300 --> 17:44.540
 or WhatsApp or whatever.

17:44.540 --> 17:46.060
 So what is it gonna take to get there

17:46.060 --> 17:48.700
 for kind of the immersive presence version of this,

17:48.700 --> 17:51.060
 which I think is what you're asking.

17:51.060 --> 17:52.940
 And for that, I think that there's just a bunch

17:52.940 --> 17:54.540
 of different use cases.

17:55.640 --> 18:00.460
 And I think when you're building technology,

18:00.460 --> 18:05.460
 I think a lot of it is just you're managing this duality

18:05.820 --> 18:06.980
 where on the one hand,

18:06.980 --> 18:10.100
 you wanna build these elegant things that can scale

18:10.100 --> 18:12.140
 and have billions of people use them

18:12.140 --> 18:13.340
 and get value from them.

18:13.340 --> 18:14.540
 And then on the other hand,

18:14.540 --> 18:17.020
 you're fighting this kind of ground game

18:17.020 --> 18:19.680
 where there are just a lot of different use cases

18:19.680 --> 18:20.880
 and people do different things

18:20.880 --> 18:22.260
 and you wanna be able to unlock them.

18:22.260 --> 18:25.940
 So the first ones that we basically went after

18:25.940 --> 18:30.340
 were gaming with Quest and social experiences.

18:30.340 --> 18:32.540
 And it goes back to when we started working

18:32.540 --> 18:33.380
 on virtual reality.

18:33.380 --> 18:36.140
 My theory at the time was basically

18:37.400 --> 18:39.440
 people thought about it as gaming,

18:39.440 --> 18:44.160
 but if you look at all computing platforms up to that point,

18:44.160 --> 18:47.440
 gaming is a huge part, it was a huge part of PCs,

18:47.440 --> 18:49.460
 it was a huge part of mobile,

18:49.460 --> 18:51.960
 but it was also very decentralized.

18:51.960 --> 18:54.240
 There wasn't, for the most part,

18:54.240 --> 18:55.660
 one or two gaming companies.

18:55.660 --> 18:57.440
 There were a lot of gaming companies

18:57.440 --> 18:58.700
 and gaming is somewhat hits based.

18:58.700 --> 19:01.440
 I mean, we're getting some games that have more longevity,

19:01.440 --> 19:05.340
 but in general, there were a lot of different games

19:05.340 --> 19:06.560
 out there.

19:06.560 --> 19:10.740
 But on PC and on mobile,

19:10.740 --> 19:13.700
 the companies that focused on communication

19:13.700 --> 19:15.100
 and social interaction,

19:15.100 --> 19:17.260
 there tended to be a smaller number of those

19:17.260 --> 19:19.160
 and that ended up being just as important of a thing

19:19.160 --> 19:21.580
 as all of the games that you did combined.

19:21.580 --> 19:23.140
 I think productivity is another area.

19:23.140 --> 19:23.980
 That's obviously something

19:23.980 --> 19:26.020
 that we've historically been less focused on,

19:26.020 --> 19:27.220
 but I think it's gonna be really important for us.

19:27.220 --> 19:29.580
 With workroom, do you mean productivity

19:29.580 --> 19:30.860
 in the collaborative aspect?

19:30.860 --> 19:34.360
 Yeah, I think that there's a workroom's aspect of this,

19:34.360 --> 19:35.360
 like a meeting aspect,

19:35.360 --> 19:39.500
 and then I think that there's like a Word, Excel,

19:39.500 --> 19:42.940
 productivity, either you're working or coding

19:42.940 --> 19:46.760
 or knowledge work as opposed to just meetings.

19:46.760 --> 19:49.620
 So you can kind of go through all these different use cases.

19:49.620 --> 19:51.280
 Gaming, I think we're well on our way.

19:51.280 --> 19:56.080
 Social, I think we're just the kind of preeminent company

19:56.080 --> 19:57.040
 that focuses on this.

19:57.040 --> 20:00.420
 And I think that that's already on Quest becoming the,

20:00.420 --> 20:03.460
 if you look at the list of what are the top apps,

20:03.460 --> 20:06.460
 social apps are already number one, two, three.

20:06.460 --> 20:10.860
 So that's kind of becoming a critical thing, but I don't know.

20:10.860 --> 20:12.580
 I would imagine for someone like you,

20:12.580 --> 20:17.580
 it'll be until we get a lot of the work things dialed in.

20:17.980 --> 20:20.860
 When this is just like much more adopted

20:20.860 --> 20:24.260
 and clearly better than Zoom for VC,

20:24.260 --> 20:27.100
 when if you're doing your coding or your writing

20:27.100 --> 20:29.420
 or whatever it is in VR,

20:29.420 --> 20:31.260
 which it's not that far off to imagine that

20:31.260 --> 20:32.660
 because pretty soon you're just gonna be able

20:32.660 --> 20:34.220
 to have a screen that's bigger than,

20:34.220 --> 20:36.140
 it'll be your ideal setup and you can bring it with you

20:36.140 --> 20:37.540
 and put it on anywhere

20:37.540 --> 20:39.780
 and have your kind of ideal workstation.

20:39.780 --> 20:42.580
 So I think that there are a few things to work out on that,

20:42.580 --> 20:46.940
 but I don't think that that's more than five years off.

20:46.940 --> 20:48.120
 And then you'll get a bunch of other things

20:48.120 --> 20:50.220
 that like aren't even possible

20:50.220 --> 20:52.040
 or you don't even think about using a phone

20:52.040 --> 20:54.440
 or PC for today, like fitness, right?

20:54.440 --> 20:57.460
 So, I mean, I know you're, we were talking before

20:57.460 --> 20:58.980
 about how you're into running

20:58.980 --> 21:00.780
 and like I'm really into a lot of things

21:00.780 --> 21:02.740
 around fitness as well,

21:02.740 --> 21:04.100
 different things in different places.

21:04.100 --> 21:06.060
 I got really into hydrofoiling recently

21:06.060 --> 21:11.060
 and surfing and I used to fence competitively.

21:12.420 --> 21:13.260
 I like run.

21:13.260 --> 21:14.860
 So, and you were saying that you were thinking

21:14.860 --> 21:16.380
 about trying different martial arts

21:16.380 --> 21:18.180
 and I tried to trick you and convince you

21:18.180 --> 21:19.940
 into doing Brazilian Jiu Jitsu.

21:19.940 --> 21:21.500
 Or you actually mentioned that that was one

21:21.500 --> 21:23.220
 you're curious about and I don't know.

21:23.220 --> 21:24.140
 Is that a trick?

21:24.140 --> 21:25.140
 Yeah, I don't know.

21:26.020 --> 21:27.420
 We're in the metaverse now.

21:27.420 --> 21:29.580
 Yeah, no, I took that seriously.

21:29.580 --> 21:34.260
 I thought that that was a real suggestion.

21:34.260 --> 21:36.380
 That would be an amazing chance

21:36.380 --> 21:37.780
 if we ever step on the mat together

21:37.780 --> 21:39.020
 and just like roll around.

21:39.020 --> 21:40.100
 I'll show you some moves.

21:40.100 --> 21:43.700
 Well, give me a year to train and then we can do it.

21:43.700 --> 21:44.780
 You know, you've seen Rocky IV

21:44.780 --> 21:46.340
 where the Russian faces off the American.

21:46.340 --> 21:47.980
 I'm the Russian in this picture.

21:47.980 --> 21:49.980
 And then you're the Rocky, the underdog

21:49.980 --> 21:51.340
 that gets to win in the end.

21:51.340 --> 21:56.180
 The idea of me as Rocky and like fighting is...

21:56.180 --> 21:58.080
 If he dies, he dies.

21:58.080 --> 22:00.740
 Sorry, I just had to.

22:00.740 --> 22:01.580
 I mean.

22:01.580 --> 22:02.640
 Anyway, yeah.

22:02.640 --> 22:05.900
 But I mean, a lot of aspects of fitness.

22:05.900 --> 22:08.780
 You know, I don't know if you've tried supernatural

22:08.780 --> 22:10.180
 on Quest or...

22:10.180 --> 22:12.060
 So first of all, can I just comment on the fact

22:12.060 --> 22:15.020
 every time I played around with Quest 2,

22:15.020 --> 22:18.780
 I just, I get giddy every time I step into virtual reality.

22:18.780 --> 22:20.860
 So you mentioned productivity and all those kinds of things.

22:20.860 --> 22:23.820
 That's definitely something I'm excited about,

22:23.820 --> 22:26.780
 but really I just love the possibilities

22:26.780 --> 22:28.820
 of stepping into that world.

22:28.820 --> 22:30.460
 Maybe it's the introvert in me,

22:30.460 --> 22:34.060
 but it just feels like the most convenient way

22:34.060 --> 22:37.500
 to travel into worlds,

22:37.500 --> 22:40.340
 into worlds that are similar to the real world

22:40.340 --> 22:41.660
 or totally different.

22:41.660 --> 22:42.860
 It's like Alice in Wonderland.

22:42.860 --> 22:44.660
 Just try out crazy stuff.

22:44.660 --> 22:45.780
 The possibilities are endless.

22:45.780 --> 22:50.780
 And I just, I personally am just love,

22:50.900 --> 22:53.980
 get excited for stepping in those virtual worlds.

22:53.980 --> 22:55.020
 So I'm a huge fan.

22:55.020 --> 22:58.300
 In terms of the productivity as a programmer,

22:58.300 --> 23:00.060
 I spend most of my day programming.

23:00.060 --> 23:01.980
 That's really interesting also,

23:01.980 --> 23:04.340
 but then you have to develop the right IDEs.

23:04.340 --> 23:07.380
 You have to develop, like there has to be a threshold

23:07.380 --> 23:09.340
 where a large amount of the programming community

23:09.340 --> 23:11.860
 moves there, but the collaborative aspects

23:11.860 --> 23:14.260
 that are possible in terms of meetings,

23:14.260 --> 23:18.380
 in terms of when two coders are working together,

23:18.380 --> 23:21.740
 I mean, the possibilities there are super, super exciting.

23:21.740 --> 23:25.840
 I think that in building this, we sort of need to balance.

23:27.100 --> 23:28.160
 There are gonna be some new things

23:28.160 --> 23:29.700
 that you just couldn't do before.

23:29.700 --> 23:31.540
 And those are gonna be the amazing experiences.

23:31.540 --> 23:33.420
 So teleporting to any place, right?

23:33.420 --> 23:37.040
 Whether it's a real place or something that people made.

23:38.620 --> 23:40.340
 And I mean, some of the experiences

23:40.340 --> 23:42.100
 around how we can build stuff in new ways,

23:42.100 --> 23:44.740
 where a lot of the stuff that,

23:44.740 --> 23:46.060
 when I'm coding stuff, it's like, all right,

23:46.060 --> 23:47.180
 you code it and then you build it

23:47.180 --> 23:48.260
 and then you see it afterwards.

23:48.260 --> 23:50.500
 But increasingly it's gonna be possible to,

23:50.500 --> 23:52.780
 you're in a world and you're building the world

23:52.780 --> 23:55.780
 as you are in it and kind of manipulating it.

23:55.780 --> 23:59.900
 One of the things that we showed at our Inside the Lab

23:59.900 --> 24:02.500
 for recent artificial intelligence progress

24:02.500 --> 24:03.940
 is this Builder Bot program,

24:03.940 --> 24:07.180
 where now you can just talk to it and say,

24:07.180 --> 24:08.460
 hey, okay, I'm in this world,

24:08.460 --> 24:10.740
 like put some trees over there and it'll do that.

24:10.740 --> 24:13.220
 And like, all right, put some bottles of water

24:13.220 --> 24:17.060
 on our picnic blanket and it'll do that

24:17.060 --> 24:17.900
 and you're in the world.

24:17.900 --> 24:19.940
 And I think there are gonna be new paradigms for coding.

24:19.940 --> 24:22.100
 So yeah, there are gonna be some things

24:22.100 --> 24:24.620
 that I think are just pretty amazing,

24:24.620 --> 24:26.580
 especially the first few times that you do them,

24:26.580 --> 24:28.300
 but that you're like, whoa,

24:28.300 --> 24:30.620
 like I've never had an experience like this.

24:30.620 --> 24:34.260
 But most of your life, I would imagine,

24:34.260 --> 24:38.180
 is not doing things that are amazing for the first time.

24:38.180 --> 24:39.620
 A lot of this in terms of,

24:39.620 --> 24:42.020
 I mean, just answering your question from before around,

24:42.020 --> 24:42.860
 what is it gonna take

24:42.860 --> 24:45.060
 before you're spending most of your time in this?

24:45.060 --> 24:48.180
 Well, first of all, let me just say it as an aside,

24:48.180 --> 24:50.340
 the goal isn't to have people spend a lot more time

24:50.340 --> 24:51.180
 in computing.

24:51.180 --> 24:52.340
 It's to make it so that. I'm asking for myself.

24:52.340 --> 24:54.460
 Yeah, it's to make it. When will I spend all my time in?

24:54.460 --> 24:57.060
 Yeah, it's to make computing more natural.

24:57.060 --> 25:02.060
 But I think you will spend most of your computing time

25:02.740 --> 25:04.900
 in this when it does the things

25:04.900 --> 25:07.300
 that you use computing for somewhat better.

25:07.300 --> 25:10.540
 So maybe having your perfect workstation

25:10.540 --> 25:15.140
 is a 5% improvement on your coding productivity.

25:15.140 --> 25:18.420
 Maybe it's not like a completely new thing.

25:19.300 --> 25:21.620
 But I mean, look, if I could increase the productivity

25:21.620 --> 25:25.500
 of every engineer at Meta by 5%,

25:25.500 --> 25:27.620
 we'd buy those devices for everyone.

25:27.620 --> 25:30.340
 And I imagine a lot of other companies would too.

25:30.340 --> 25:31.860
 And that's how you start getting to the scale

25:31.860 --> 25:34.500
 that I think makes this rival

25:34.500 --> 25:37.020
 some of the bigger computing platforms that exist today.

25:37.020 --> 25:38.300
 Let me ask you about identity.

25:38.300 --> 25:40.460
 We talked about the avatar.

25:40.460 --> 25:42.740
 How do you see identity in the Metaverse?

25:42.740 --> 25:46.420
 Should the avatar be tied to your identity

25:46.420 --> 25:49.300
 or can I be anything in the Metaverse?

25:49.300 --> 25:52.180
 Like, can I be whatever the heck I want?

25:52.180 --> 25:53.660
 Can I even be a troll?

25:53.660 --> 25:57.420
 So there's exciting freeing possibilities

25:57.420 --> 25:59.420
 and there's the darker possibilities too.

26:00.740 --> 26:03.180
 Yeah, I mean, I think that there's gonna be a range, right?

26:03.180 --> 26:07.660
 So we're working on, for expression and avatars,

26:10.180 --> 26:13.100
 on one end of the spectrum are kind of expressive

26:13.100 --> 26:14.940
 and cartoonish avatars.

26:14.940 --> 26:16.460
 And then on the other end of the spectrum

26:16.460 --> 26:18.500
 are photorealistic avatars.

26:18.500 --> 26:20.660
 And I just think the reality is

26:20.660 --> 26:22.100
 that there are gonna be different use cases

26:22.100 --> 26:23.260
 for different things.

26:23.260 --> 26:25.140
 And I guess there's another axis.

26:25.140 --> 26:28.700
 So if you're going from photorealistic to expressive,

26:28.700 --> 26:31.100
 there's also like representing you directly

26:31.100 --> 26:33.660
 versus like some fantasy identity.

26:33.660 --> 26:35.340
 And I think that there are gonna be things

26:35.340 --> 26:37.860
 on all ends of that spectrum too, right?

26:37.860 --> 26:41.020
 So you'll want photo, like in some experience,

26:41.020 --> 26:44.300
 you might wanna be like a photorealistic dragon, right?

26:44.300 --> 26:46.980
 Or if I'm playing Onward,

26:46.980 --> 26:48.980
 or just this military simulator game,

26:50.940 --> 26:53.620
 I think getting to be more photorealistic as a soldier

26:53.620 --> 26:56.740
 in that could enhance the experience.

26:57.780 --> 26:59.540
 There are times when I'm hanging out with friends

26:59.540 --> 27:02.060
 where I want them to know it's me.

27:02.060 --> 27:06.180
 So a kind of cartoonish or expressive version of me is good.

27:06.180 --> 27:09.580
 But there are also experiences like,

27:09.580 --> 27:11.580
 VRChat does this well today,

27:11.580 --> 27:14.900
 where a lot of the experience is kind of dressing up

27:14.900 --> 27:17.780
 and wearing a fantastical avatar

27:17.780 --> 27:19.580
 that's almost like a meme or is humorous.

27:19.580 --> 27:21.300
 So you come into an experience

27:21.300 --> 27:24.540
 and it's almost like you have like a built in icebreaker

27:24.540 --> 27:27.300
 because like you see people and you're just like,

27:27.300 --> 27:29.940
 all right, I'm cracking up at what you're wearing

27:29.940 --> 27:30.780
 because that's funny.

27:30.780 --> 27:31.900
 And it's just like, where'd you get that?

27:31.900 --> 27:32.740
 Or, oh, you made that?

27:32.740 --> 27:34.340
 That's, it's awesome.

27:35.500 --> 27:38.900
 Whereas, okay, if you're going into a work meeting,

27:38.900 --> 27:41.740
 maybe a photorealistic version of your real self

27:41.740 --> 27:43.540
 is gonna be the most appropriate thing for that.

27:43.540 --> 27:47.340
 So I think the reality is there aren't going to be,

27:47.340 --> 27:48.940
 it's not just gonna be one thing.

27:50.500 --> 27:54.380
 You know, my own sense of kind of how you wanna

27:54.380 --> 27:56.860
 express identity online has sort of evolved over time.

27:56.860 --> 27:58.620
 And that, you know, early days in Facebook,

27:58.620 --> 28:00.260
 I thought, okay, people are gonna have one identity.

28:00.260 --> 28:02.100
 And now I think that's clearly not gonna be the case.

28:02.100 --> 28:04.420
 I think you're gonna have all these different things

28:04.420 --> 28:07.300
 and there's utility in being able to do different things.

28:07.300 --> 28:10.100
 So some of the technical challenges

28:10.100 --> 28:12.140
 that I'm really interested in around it

28:12.140 --> 28:14.180
 are how do you build the software

28:14.180 --> 28:17.100
 to allow people to seamlessly go between them?

28:17.100 --> 28:19.300
 So say, so you could view them

28:19.300 --> 28:24.300
 as just completely discrete points on a spectrum,

28:25.140 --> 28:28.500
 but let's talk about the metaverse economy for a second.

28:28.500 --> 28:31.220
 Let's say I buy a digital shirt

28:31.220 --> 28:34.420
 for my photorealistic avatar, which by the way,

28:34.420 --> 28:36.460
 I think at the time where we're spending a lot of time

28:36.460 --> 28:38.740
 in the metaverse doing a lot of our work meetings

28:38.740 --> 28:40.260
 in the metaverse and et cetera,

28:40.260 --> 28:42.460
 I would imagine that the economy around virtual clothing

28:42.460 --> 28:44.660
 as an example is going to be quite as big.

28:44.660 --> 28:47.100
 Why wouldn't I spend almost as much money

28:47.100 --> 28:49.780
 in investing in my appearance or expression

28:49.780 --> 28:52.420
 for my photorealistic avatar for meetings

28:52.420 --> 28:55.540
 as I would for whatever I'm gonna wear in my video chat.

28:55.540 --> 28:56.700
 But the question is, okay, so you,

28:56.700 --> 28:57.620
 let's say you buy some shirt

28:57.620 --> 28:59.780
 for your photorealistic avatar.

28:59.780 --> 29:02.620
 Wouldn't it be cool if there was a way

29:02.620 --> 29:07.620
 to basically translate that into a more expressive thing

29:07.620 --> 29:11.220
 for your kind of cartoonish or expressive avatar?

29:11.220 --> 29:12.580
 And there are multiple ways to do that.

29:12.580 --> 29:14.940
 You can view them as two discrete points and okay,

29:14.940 --> 29:18.220
 maybe if a designer sells one thing,

29:18.220 --> 29:19.940
 then it actually comes in a pack and there's two

29:19.940 --> 29:22.340
 and you can use either one on that,

29:22.340 --> 29:24.420
 but I actually think this stuff might exist more

29:24.420 --> 29:26.100
 as a spectrum in the future.

29:26.100 --> 29:29.460
 And that's what I do think the direction

29:29.460 --> 29:33.380
 on some of the AI advances that is happening

29:33.380 --> 29:35.980
 to be able to, especially stuff around like style transfer,

29:35.980 --> 29:39.860
 being able to take a piece of art or express something

29:39.860 --> 29:44.860
 and say, okay, paint me this photo in the style of Gauguin

29:44.900 --> 29:48.020
 or whoever it is that you're interested in.

29:49.060 --> 29:51.300
 Take this shirt and put it in the style

29:51.300 --> 29:53.820
 of what I've designed for my expressive avatar.

29:55.220 --> 29:56.940
 I think that's gonna be pretty compelling.

29:56.940 --> 30:00.060
 And so the fashion, you might be buying like a generator,

30:00.060 --> 30:03.260
 like a closet that generates a style.

30:03.260 --> 30:05.540
 And then like with the GANs,

30:05.540 --> 30:08.180
 you'll be able to infinitely generate outfits

30:08.180 --> 30:10.780
 thereby making it, so the reason I wear the same thing

30:10.780 --> 30:12.380
 all the time is I don't like choice.

30:12.380 --> 30:15.140
 You've talked about the same thing,

30:15.140 --> 30:16.700
 but now you don't even have to choose.

30:16.700 --> 30:19.580
 Your closet generates your outfit for you every time.

30:19.580 --> 30:23.460
 So you have to live with the outfit it generates.

30:23.460 --> 30:25.500
 I mean, you could do that, although,

30:25.500 --> 30:27.500
 no, I think that that's, I think some people will,

30:27.500 --> 30:31.300
 but I think like, I think there's going to be a huge aspect

30:31.300 --> 30:35.900
 of just people doing creative commerce here.

30:35.900 --> 30:37.860
 So I think that there is going to be a big market

30:37.860 --> 30:41.060
 around people designing digital clothing.

30:41.060 --> 30:43.020
 But the question is, if you're designing digital clothing,

30:43.020 --> 30:44.860
 do you need to design, if you're the designer,

30:44.860 --> 30:48.140
 do you need to make it for each kind of specific discrete

30:48.140 --> 30:51.500
 point along a spectrum, or are you just designing it

30:51.500 --> 30:54.140
 for kind of a photo realistic case or an expressive case,

30:54.140 --> 30:55.140
 or can you design one

30:55.140 --> 30:57.460
 and have it translate across these things?

30:57.460 --> 31:01.780
 If I buy a style from a designer who I care about,

31:01.780 --> 31:04.220
 and now I'm a dragon, is there a way to morph that

31:04.220 --> 31:07.660
 so it goes on the dragon in a way that makes sense?

31:07.660 --> 31:09.460
 And that I think is an interesting AI problem

31:09.460 --> 31:10.820
 because you're probably not going to make it

31:10.820 --> 31:14.700
 so that designers have to go design for all those things.

31:14.700 --> 31:17.900
 But the more useful the digital content is that you buy

31:17.900 --> 31:21.220
 in a lot of uses, in a lot of use cases,

31:21.220 --> 31:23.420
 the more that economy will just explode.

31:23.420 --> 31:28.100
 And that's a lot of what all of the,

31:28.100 --> 31:29.700
 we were joking about NFTs before,

31:29.700 --> 31:32.580
 but I think a lot of the promise here is that

31:32.580 --> 31:35.020
 if the digital goods that you buy are not just tied

31:35.020 --> 31:37.060
 to one platform or one use case,

31:37.060 --> 31:38.260
 they end up being more valuable,

31:38.260 --> 31:39.820
 which means that people are more willing

31:39.820 --> 31:41.300
 and more likely to invest in them,

31:41.300 --> 31:44.220
 and that just spurs the whole economy.

31:44.220 --> 31:47.260
 But the question is, that's a fascinating positive aspect,

31:47.260 --> 31:50.780
 but the potential negative aspect is that

31:50.780 --> 31:52.660
 you can have people concealing their identity

31:52.660 --> 31:57.060
 in order to troll or even not people, bots.

31:57.060 --> 31:58.780
 So how do you know in the metaverse

31:58.780 --> 32:02.060
 that you're talking to a real human or an AI

32:02.060 --> 32:03.940
 or a well intentioned human?

32:03.940 --> 32:04.980
 Is that something you think about,

32:04.980 --> 32:06.940
 something you're concerned about?

32:06.940 --> 32:10.260
 Well, let's break that down into a few different cases.

32:10.260 --> 32:11.980
 I mean, because knowing that you're talking to someone

32:11.980 --> 32:13.880
 who has good intentions is something that I think

32:13.880 --> 32:17.860
 is not even solved in pretty much anywhere.

32:17.860 --> 32:20.380
 But I mean, if you're talking to someone who's a dragon,

32:20.380 --> 32:22.000
 I think it's pretty clear that they're not representing

32:22.000 --> 32:23.300
 themselves as a person.

32:23.300 --> 32:25.300
 I think probably the most pernicious thing

32:25.300 --> 32:28.580
 that you want to solve for is,

32:30.140 --> 32:32.300
 I think probably one of the scariest ones is

32:32.300 --> 32:35.020
 how do you make sure that someone isn't impersonating you?

32:35.020 --> 32:39.340
 So, okay, you're in a future version of this conversation,

32:39.340 --> 32:41.700
 and we have photorealistic avatars,

32:41.700 --> 32:43.320
 and we're doing this in work rooms

32:43.320 --> 32:44.980
 or whatever the future version of that is,

32:44.980 --> 32:48.860
 and someone walks in who looks like me.

32:48.860 --> 32:50.300
 How do you know that that's me?

32:50.300 --> 32:54.200
 And one of the things that we're thinking about

32:54.200 --> 32:57.500
 is it's still a pretty big AI project

32:57.500 --> 32:59.500
 to be able to generate photorealistic avatars

32:59.500 --> 33:00.880
 that basically can like,

33:00.880 --> 33:03.380
 they work like these codecs of you, right?

33:03.380 --> 33:06.220
 So you kind of have a map from your headset

33:06.220 --> 33:08.020
 and whatever sensors of what your body's actually doing,

33:08.020 --> 33:11.180
 and it takes the model and it kind of displays it in VR.

33:11.180 --> 33:12.660
 But there's a question, which is,

33:12.660 --> 33:15.420
 should there be some sort of biometric security

33:15.420 --> 33:18.220
 so that when I put on my VR headset

33:18.220 --> 33:20.940
 or I'm going to go use that avatar,

33:20.940 --> 33:24.340
 I need to first prove that I am that?

33:24.340 --> 33:26.780
 And I think you probably are gonna want something like that.

33:26.780 --> 33:31.120
 So as we're developing these technologies,

33:31.120 --> 33:34.500
 we're also thinking about the security for things like that

33:34.500 --> 33:37.060
 because people aren't gonna wanna be impersonated.

33:37.060 --> 33:38.860
 That's a huge security issue.

33:41.700 --> 33:42.900
 Then you just get the question

33:42.900 --> 33:46.580
 of people hiding behind fake accounts

33:46.580 --> 33:48.300
 to do malicious things,

33:48.300 --> 33:51.020
 which is not gonna be unique to the metaverse,

33:51.020 --> 33:56.020
 although certainly in a environment

33:56.140 --> 33:57.300
 where it's more immersive

33:57.300 --> 33:58.640
 and you have more of a sense of presence,

33:58.640 --> 34:01.740
 it could be more painful.

34:01.740 --> 34:03.140
 But this is obviously something

34:03.140 --> 34:06.480
 that we've just dealt with for years

34:06.480 --> 34:08.740
 in social media and the internet more broadly.

34:08.740 --> 34:13.140
 And there, I think there have been a bunch of tactics

34:13.140 --> 34:17.900
 that I think we've just evolved to,

34:17.900 --> 34:20.480
 we've built up these different AI systems

34:20.480 --> 34:21.880
 to basically get a sense of,

34:21.880 --> 34:26.340
 is this account behaving in the way that a person would?

34:26.340 --> 34:28.340
 And it turns out,

34:28.340 --> 34:31.940
 so in all of the work that we've done around,

34:31.940 --> 34:33.340
 we call it community integrity

34:33.340 --> 34:36.920
 and it's basically like policing harmful content

34:36.920 --> 34:38.340
 and trying to figure out where to draw the line.

34:38.340 --> 34:39.800
 And there are all these like really hard

34:39.800 --> 34:41.300
 and philosophical questions around like,

34:41.300 --> 34:42.880
 where do you draw the line on some of this stuff?

34:42.880 --> 34:47.820
 And the thing that I've kind of found the most effective

34:47.820 --> 34:51.260
 is as much as possible trying to figure out

34:51.260 --> 34:53.380
 who are the inauthentic accounts

34:53.380 --> 34:55.540
 or where are the accounts that are behaving

34:55.540 --> 34:58.420
 in an overall harmful way at the account level,

34:58.420 --> 35:00.460
 rather than trying to get into like policing

35:00.460 --> 35:01.420
 what they're saying, right?

35:01.420 --> 35:03.700
 Which I think the metaverse is gonna be even harder

35:03.700 --> 35:07.320
 because the metaverse I think will have more properties of,

35:07.320 --> 35:09.220
 it's almost more like a phone call, right?

35:09.220 --> 35:12.380
 Or it's not like I post a piece of content

35:12.380 --> 35:14.700
 and is that piece of content good or bad?

35:14.700 --> 35:16.260
 So I think more of this stuff will have to be done

35:16.260 --> 35:19.420
 at the level of the account.

35:19.420 --> 35:21.740
 But this is the area where,

35:21.740 --> 35:26.740
 between the kind of counter intelligence teams

35:27.140 --> 35:28.480
 that we built up inside the company

35:28.480 --> 35:33.220
 and like years of building just different AI systems

35:33.220 --> 35:36.900
 to basically detect what is a real account and what isn't.

35:36.900 --> 35:37.940
 I'm not saying we're perfect,

35:37.940 --> 35:39.920
 but like this is an area where I just think

35:39.920 --> 35:43.580
 we are like years ahead of basically anyone else

35:43.580 --> 35:48.100
 in the industry in terms of having built those capabilities.

35:48.100 --> 35:50.180
 And I think that that just is gonna be incredibly important

35:50.180 --> 35:51.540
 for this next wave of things.

35:51.540 --> 35:53.460
 And like you said, on a technical level,

35:53.460 --> 35:54.980
 on a philosophical level,

35:54.980 --> 35:57.700
 it's an incredibly difficult problem to solve.

35:59.260 --> 36:03.220
 By the way, I would probably like to open source my avatar

36:03.220 --> 36:05.940
 so there could be like millions of Lexis walking around

36:05.940 --> 36:07.040
 just like an army.

36:07.040 --> 36:08.500
 Like Agent Smith?

36:08.500 --> 36:10.700
 Agent Smith, yeah, exactly.

36:10.700 --> 36:15.700
 So the Unity ML folks built a copy of me

36:16.420 --> 36:18.420
 and they sent it to me.

36:18.420 --> 36:20.220
 So there's a person running around

36:20.220 --> 36:22.500
 and I've just been doing reinforcement learning on it.

36:22.500 --> 36:23.820
 I was gonna release it

36:25.420 --> 36:29.860
 because just to have sort of like thousands of Lexis

36:29.860 --> 36:31.180
 doing reinforcement.

36:31.180 --> 36:32.460
 So they fall over naturally,

36:32.460 --> 36:34.900
 they have to learn how to like walk around and stuff.

36:34.900 --> 36:36.660
 So I love that idea,

36:36.660 --> 36:39.140
 this tension between biometric security,

36:39.140 --> 36:40.340
 you want to have one identity,

36:40.340 --> 36:43.620
 but then certain avatars, you might have to have many.

36:43.620 --> 36:45.400
 I don't know which is better security,

36:45.400 --> 36:48.140
 sort of flooding the world with Lexis

36:48.140 --> 36:49.440
 and thereby achieving security

36:49.440 --> 36:51.780
 or really being protective of your identity.

36:51.780 --> 36:53.860
 I have to ask you a security question actually.

36:53.860 --> 36:56.860
 Well, how does flooding the world with Lexis help me know

36:56.860 --> 36:59.640
 in our conversation that I'm talking to the real Lex?

36:59.640 --> 37:01.580
 I completely destroy the trust

37:01.580 --> 37:03.060
 in all my relationships then, right?

37:03.060 --> 37:04.180
 If I flood,

37:04.180 --> 37:06.700
 cause then it's, yeah, that.

37:07.820 --> 37:09.500
 I think that one's not gonna work that well for you.

37:09.500 --> 37:11.860
 It's not gonna work that well for the original copy.

37:11.860 --> 37:13.380
 It probably fits some things.

37:13.380 --> 37:14.820
 Like if you're a public figure

37:14.820 --> 37:18.500
 and you're trying to have a bunch of,

37:18.500 --> 37:19.480
 if you're trying to show up

37:19.480 --> 37:21.060
 in a bunch of different places in the future,

37:21.060 --> 37:23.500
 you'll be able to do that in the metaverse.

37:23.500 --> 37:26.260
 So that kind of replication I think will be useful.

37:26.260 --> 37:29.260
 But I do think that you're gonna want a notion of like,

37:29.260 --> 37:31.500
 I am talking to the real one.

37:31.500 --> 37:32.700
 Yeah.

37:32.700 --> 37:35.660
 Yeah, especially if the fake ones start outperforming you

37:35.660 --> 37:37.460
 and all your private relationships

37:37.460 --> 37:38.740
 and then you're left behind.

37:38.740 --> 37:41.060
 I mean, that's a serious concern I have with clones.

37:41.060 --> 37:43.340
 Again, the things I think about.

37:43.340 --> 37:48.340
 Okay, so I recently got, I use QNAP NAS storage.

37:48.380 --> 37:50.220
 So just storage for video and stuff.

37:50.220 --> 37:51.460
 And I recently got hacked.

37:51.460 --> 37:53.540
 This is the first time for me with ransomware.

37:53.540 --> 37:56.580
 It's not me personally, it's all QNAP devices.

37:58.700 --> 38:00.780
 So the question that people have

38:00.780 --> 38:03.300
 is about security in general.

38:03.300 --> 38:05.060
 Because I was doing a lot of the right things

38:05.060 --> 38:06.820
 in terms of security and nevertheless,

38:06.820 --> 38:10.940
 ransomware basically disabled my device.

38:10.940 --> 38:12.060
 Is that something you think about?

38:12.060 --> 38:13.780
 What are the different steps you could take

38:13.780 --> 38:16.940
 to protect people's data on the security front?

38:16.940 --> 38:20.440
 I think that there's different solutions for,

38:21.380 --> 38:23.660
 and strategies where it makes sense to have stuff

38:23.660 --> 38:25.460
 kind of put behind a fortress, right?

38:25.460 --> 38:30.220
 So the centralized model versus the decentralizing.

38:30.220 --> 38:32.140
 Then I think both have strengths and weaknesses.

38:32.140 --> 38:33.260
 So I think anyone who says, okay,

38:33.260 --> 38:36.660
 just decentralize everything, that'll make it more secure.

38:36.660 --> 38:38.980
 I think that that's tough because,

38:38.980 --> 38:42.740
 I mean, the advantage of something like encryption

38:42.740 --> 38:46.420
 is that we run the largest encrypted service

38:46.420 --> 38:47.700
 in the world with WhatsApp.

38:47.700 --> 38:49.580
 And we're one of the first to roll out

38:49.580 --> 38:52.660
 a multi platform encryption service.

38:52.660 --> 38:55.980
 And that's something that I think was a big advance

38:55.980 --> 38:57.180
 for the industry.

38:57.180 --> 38:59.300
 And one of the promises that we can basically make

38:59.300 --> 39:02.260
 because of that, our company doesn't see

39:02.260 --> 39:04.500
 when you're sending an encrypted message

39:04.500 --> 39:05.860
 and to an encrypted message,

39:05.860 --> 39:07.860
 what the content is of what you're sharing.

39:07.860 --> 39:10.600
 So that way, if someone hacks Meta servers,

39:11.540 --> 39:14.700
 they're not gonna be able to access the WhatsApp message

39:14.700 --> 39:16.940
 that you're sending to your friend.

39:16.940 --> 39:19.100
 And that I think matters a lot to people

39:19.100 --> 39:21.900
 because obviously if someone is able to compromise

39:21.900 --> 39:23.900
 a company's servers and that company has hundreds

39:23.900 --> 39:25.220
 of millions or billions of people,

39:25.220 --> 39:27.900
 then that ends up being a very big deal.

39:27.900 --> 39:29.380
 The flip side of that is, okay,

39:29.380 --> 39:31.100
 all the content is on your phone.

39:32.900 --> 39:35.860
 Are you following security best practices on your phone?

39:35.860 --> 39:38.060
 If you lose your phone, all your content is gone.

39:38.060 --> 39:39.620
 So that's an issue.

39:39.620 --> 39:42.300
 Maybe you go back up your content from WhatsApp

39:42.300 --> 39:45.740
 or some other service in an iCloud or something,

39:45.740 --> 39:47.940
 but then you're just at Apple's whims about,

39:47.940 --> 39:51.920
 are they gonna go turn over the data to some government

39:51.920 --> 39:53.380
 or are they gonna get hacked?

39:53.380 --> 39:57.340
 So a lot of the time it is useful to have data

39:57.340 --> 40:00.580
 in a centralized place too because then you can train

40:00.580 --> 40:04.740
 systems that can just do much better personalization.

40:04.740 --> 40:08.580
 I think that in a lot of cases, centralized systems

40:08.580 --> 40:13.460
 can offer, especially if you're a serious company,

40:13.460 --> 40:16.020
 you're running the state of the art stuff

40:16.020 --> 40:19.540
 and you have red teams attacking your own stuff

40:19.540 --> 40:24.260
 and you're putting out bounty programs

40:24.260 --> 40:26.260
 and trying to attract some of the best hackers in the world

40:26.260 --> 40:27.820
 to go break into your stuff all the time.

40:27.820 --> 40:30.500
 So any system is gonna have security issues,

40:30.500 --> 40:34.340
 but I think the best way forward is to basically try

40:34.340 --> 40:36.460
 to be as aggressive and open about hardening

40:36.460 --> 40:39.140
 the systems as possible, not trying to kind of hide

40:39.140 --> 40:40.740
 and pretend that there aren't gonna be issues,

40:40.740 --> 40:43.820
 which I think is over time why a lot of open source systems

40:43.820 --> 40:46.540
 have gotten relatively more secure is because they're open

40:46.540 --> 40:48.740
 and it's not, rather than pretending that there aren't

40:48.740 --> 40:50.900
 gonna be issues, just people surface them quicker.

40:50.900 --> 40:53.760
 So I think you want to adopt that approach as a company

40:53.760 --> 40:56.640
 and just constantly be hardening yourself.

40:56.640 --> 41:00.080
 Trying to stay one step ahead of the attackers.

41:01.060 --> 41:03.940
 It's an inherently adversarial space.

41:03.940 --> 41:07.260
 I think it's an interesting security is interesting

41:07.260 --> 41:09.140
 because of the different kind of threats

41:09.140 --> 41:11.820
 that we've managed over the last five years,

41:11.820 --> 41:15.540
 there are ones where basically the adversaries

41:15.540 --> 41:16.820
 keep on getting better and better.

41:16.820 --> 41:21.580
 So trying to kind of interfere with security

41:21.580 --> 41:23.100
 is certainly one area of this.

41:23.100 --> 41:24.860
 If you have nation states that are trying

41:24.860 --> 41:27.300
 to interfere in elections or something,

41:27.300 --> 41:29.460
 they're kind of evolving their tactics.

41:29.460 --> 41:32.780
 Whereas on the other hand, I don't want to be too simplistic

41:32.780 --> 41:36.660
 about it, but if someone is saying something hateful,

41:36.660 --> 41:38.700
 people usually aren't getting smarter and smarter

41:38.700 --> 41:40.460
 about how they say hateful things.

41:40.460 --> 41:42.600
 So maybe there's some element of that,

41:42.600 --> 41:44.820
 but it's a very small dynamic compared

41:44.820 --> 41:48.520
 to how advanced attackers and some of these other places

41:48.520 --> 41:49.980
 get over time.

41:49.980 --> 41:51.360
 I believe most people are good,

41:51.360 --> 41:53.660
 so they actually get better over time

41:53.660 --> 41:55.420
 and not being less hateful

41:55.420 --> 41:59.100
 because they realize it's not fun being hateful.

42:00.060 --> 42:01.980
 That's at least the belief I have.

42:01.980 --> 42:04.940
 But first, bathroom break.

42:04.940 --> 42:05.800
 Sure, okay.

42:06.840 --> 42:08.180
 So we'll come back to AI,

42:08.180 --> 42:11.020
 but let me ask some difficult questions now.

42:11.020 --> 42:13.820
 Social Dilemma is a popular documentary

42:13.820 --> 42:15.500
 that raised concerns about the effects

42:15.500 --> 42:17.540
 of social media on society.

42:17.540 --> 42:20.820
 You responded with a point by point rebuttal titled,

42:20.820 --> 42:23.120
 What the Social Dilemma Gets Wrong.

42:23.120 --> 42:24.980
 People should read that.

42:24.980 --> 42:26.700
 I would say the key point they make

42:26.700 --> 42:29.580
 is because social media is funded by ads,

42:29.580 --> 42:33.280
 algorithms want to maximize attention and engagement

42:33.280 --> 42:38.020
 and an effective way to do so is to get people angry

42:38.020 --> 42:40.940
 at each other, increase division and so on.

42:40.940 --> 42:44.260
 Can you steel man their criticisms and arguments

42:44.260 --> 42:46.260
 that they make in the documentary

42:46.260 --> 42:48.580
 as a way to understand the concern

42:48.580 --> 42:51.580
 and as a way to respond to it?

42:53.060 --> 42:56.860
 Well, yeah, I think that's a good conversation to have.

42:56.860 --> 43:00.420
 I don't happen to agree with the conclusions

43:00.420 --> 43:02.100
 and I think that they make a few assumptions

43:02.100 --> 43:06.300
 that are just very big jumps

43:06.300 --> 43:08.880
 that I don't think are reasonable to make.

43:08.880 --> 43:13.880
 But I understand overall why people would be concerned

43:13.880 --> 43:18.880
 that our business model and ads in general,

43:19.380 --> 43:20.640
 we do make more money

43:20.640 --> 43:23.280
 as people use the service more in general, right?

43:23.280 --> 43:26.680
 So as a kind of basic assumption, okay,

43:26.680 --> 43:29.400
 do we have an incentive for people to build a service

43:29.400 --> 43:31.200
 that people use more?

43:31.200 --> 43:32.840
 Yes, on a lot of levels.

43:32.840 --> 43:34.480
 I mean, we think what we're doing is good.

43:34.480 --> 43:37.140
 So we think that if people are finding it useful,

43:37.140 --> 43:38.560
 they'll use it more.

43:38.560 --> 43:41.320
 Or if you just look at it as this sort of,

43:41.320 --> 43:43.280
 if the only thing we cared about is money,

43:43.280 --> 43:46.200
 which is not for anyone who knows me,

43:46.200 --> 43:47.820
 but okay, we're a company.

43:47.820 --> 43:51.360
 So let's say you just kind of simplified it down to that,

43:51.360 --> 43:53.840
 then would we want people to use the services more?

43:53.840 --> 43:57.240
 Yes, and then you get to the second question,

43:57.240 --> 44:01.840
 which is does kind of getting people agitated

44:02.920 --> 44:07.480
 make them more likely to use the services more?

44:07.480 --> 44:12.480
 And I think from looking at other media in the world,

44:12.480 --> 44:17.280
 especially TV, and there's the old news adage,

44:17.280 --> 44:18.680
 if it bleeds, it leads.

44:18.680 --> 44:20.020
 Like I think that this is,

44:20.020 --> 44:25.020
 there are a bunch of reasons why someone might think

44:25.520 --> 44:30.520
 that that kind of provocative content

44:30.520 --> 44:32.640
 would be the most engaging.

44:32.640 --> 44:35.640
 Now, what I've always found is two things.

44:35.640 --> 44:39.180
 One is that what grabs someone's attention in the near term

44:39.180 --> 44:40.840
 is not necessarily something

44:40.840 --> 44:43.640
 that they're going to appreciate having seen

44:43.640 --> 44:45.320
 or going to be the best over the long term.

44:45.320 --> 44:47.460
 So I think what a lot of people get wrong

44:47.460 --> 44:50.400
 is that I'm not building this company

44:50.400 --> 44:53.300
 to make the most money or get people to spend the most time

44:53.300 --> 44:55.760
 on this in the next quarter or the next year.

44:55.760 --> 44:58.980
 I've been doing this for 17 years at this point,

44:58.980 --> 45:00.380
 and I'm still relatively young,

45:00.380 --> 45:02.040
 and I have a lot more that I wanna do

45:02.040 --> 45:03.380
 over the coming decades.

45:03.380 --> 45:08.380
 So I think that it's too simplistic to say,

45:08.380 --> 45:11.820
 hey, this might increase time in the near term,

45:11.820 --> 45:13.440
 therefore, it's what you're gonna do.

45:13.440 --> 45:15.340
 Because I actually think a deeper look

45:15.340 --> 45:17.240
 at kind of what my incentives are,

45:17.240 --> 45:18.300
 the incentives of a company

45:18.300 --> 45:20.540
 that are focused on the long term,

45:20.540 --> 45:22.720
 is to basically do what people

45:22.720 --> 45:24.160
 are gonna find valuable over time,

45:24.160 --> 45:26.780
 not what is gonna draw people's attention today.

45:26.780 --> 45:28.620
 The other thing that I'd say is that,

45:29.980 --> 45:31.500
 I think a lot of times people look at this

45:31.500 --> 45:33.100
 from the perspective of media

45:34.580 --> 45:37.780
 or kind of information or civic discourse,

45:37.780 --> 45:40.860
 but one other way of looking at this is just that,

45:40.860 --> 45:42.540
 okay, I'm a product designer, right?

45:42.540 --> 45:45.180
 Our company, we build products,

45:45.180 --> 45:47.340
 and a big part of building a product

45:47.340 --> 45:49.020
 is not just the function and utility

45:49.020 --> 45:50.180
 of what you're delivering,

45:50.180 --> 45:52.020
 but the feeling of how it feels, right?

45:52.020 --> 45:55.660
 And we spend a lot of time talking about virtual reality

45:55.660 --> 45:58.820
 and how the kind of key aspect of that experience

45:58.820 --> 46:01.980
 is the feeling of presence, which it's a visceral thing.

46:01.980 --> 46:03.940
 It's not just about the utility that you're delivering,

46:03.940 --> 46:05.940
 it's about like the sensation.

46:05.940 --> 46:10.420
 And similarly, I care a lot about how people feel

46:10.420 --> 46:11.420
 when they use our products,

46:11.420 --> 46:15.300
 and I don't want to build products that make people angry.

46:15.300 --> 46:17.020
 I mean, that's like not, I think,

46:17.020 --> 46:18.460
 what we're here on this earth to do,

46:18.460 --> 46:22.180
 is to build something that people spend a bunch of time doing

46:22.180 --> 46:24.020
 and it just kind of makes them angrier at other people.

46:24.020 --> 46:26.300
 I mean, I think that that's not good.

46:26.300 --> 46:28.740
 That's not what I think would be

46:30.120 --> 46:32.040
 sort of a good use of our time

46:32.040 --> 46:33.660
 or a good contribution to the world.

46:33.660 --> 46:36.500
 So, okay, it's like people, they tell us

46:36.500 --> 46:39.220
 on a per content basis, does this thing,

46:39.220 --> 46:40.060
 do I like it?

46:40.060 --> 46:40.880
 Do I love it?

46:40.880 --> 46:41.720
 Does it make me angry?

46:41.720 --> 46:42.980
 Does it make me sad?

46:42.980 --> 46:47.220
 And based on that, we choose to basically show content

46:47.220 --> 46:49.180
 that makes people angry less,

46:49.180 --> 46:52.720
 because of course, if you're designing a product

46:52.720 --> 46:56.320
 and you want people to be able to connect

46:56.320 --> 46:59.180
 and feel good over a long period of time,

46:59.180 --> 47:02.080
 then that's naturally what you're gonna do.

47:02.080 --> 47:04.380
 So, I don't know, I think overall,

47:06.580 --> 47:10.540
 I understand at a high level,

47:10.540 --> 47:13.680
 if you're not thinking too deeply about it,

47:13.680 --> 47:16.100
 why that argument might be appealing.

47:16.100 --> 47:19.220
 But I just think if you actually look

47:19.220 --> 47:20.940
 at what our real incentives are,

47:20.940 --> 47:25.100
 not just like if we were trying to optimize

47:25.100 --> 47:26.820
 for the next week,

47:26.820 --> 47:28.980
 but like as people working on this,

47:28.980 --> 47:30.480
 like why are we here?

47:30.480 --> 47:32.900
 And I think it's pretty clear

47:32.900 --> 47:34.300
 that that's not actually how you would wanna

47:34.300 --> 47:35.740
 design the system.

47:35.740 --> 47:37.780
 I guess one other thing that I'd say is that,

47:37.780 --> 47:40.820
 while we're focused on the ads business model,

47:40.820 --> 47:43.400
 I do think it's important to note that a lot

47:43.400 --> 47:45.380
 of these issues are not unique to ads.

47:45.380 --> 47:47.900
 I mean, so take like a subscription news business model,

47:47.900 --> 47:50.920
 for example, I think that has just as many

47:50.920 --> 47:52.220
 potential pitfalls.

47:53.180 --> 47:55.240
 Maybe if someone's paying for a subscription,

47:55.240 --> 47:57.940
 you don't get paid per piece of content that they look at,

47:57.940 --> 48:02.640
 but say for example, I think like a bunch

48:02.640 --> 48:06.180
 of the partisanship that we see could potentially

48:06.180 --> 48:10.820
 be made worse by you have these kind of partisan

48:12.620 --> 48:15.740
 news organizations that basically sell subscriptions

48:15.740 --> 48:17.580
 and they're only gonna get people on one side

48:17.580 --> 48:19.900
 to basically subscribe to them.

48:19.900 --> 48:22.780
 So their incentive is not to print content

48:22.780 --> 48:26.100
 or produce content that's kind of centrist

48:26.100 --> 48:27.820
 or down the line either.

48:27.820 --> 48:30.060
 I bet that what a lot of them find is that

48:30.060 --> 48:32.480
 if they produce stuff that's kind of more polarizing

48:32.480 --> 48:35.460
 or more partisan, then that is what gets

48:35.460 --> 48:36.860
 the more subscribers.

48:36.860 --> 48:40.260
 So I think that this stuff is all,

48:40.260 --> 48:41.940
 there's no perfect business model.

48:41.940 --> 48:43.460
 Everything has pitfalls.

48:44.340 --> 48:46.500
 The thing that I think is great about advertising

48:46.500 --> 48:48.740
 is it makes it so the consumer service is free,

48:48.740 --> 48:50.860
 which if you believe that everyone should have a voice

48:50.860 --> 48:52.020
 and everyone should be able to connect,

48:52.020 --> 48:55.000
 then that's a great thing, as opposed to building

48:55.000 --> 48:57.240
 a luxury service that not everyone can afford.

48:57.240 --> 49:00.020
 But look, every business model, you have to be careful

49:00.020 --> 49:02.500
 about how you're implementing what you're doing.

49:02.500 --> 49:04.620
 You responded to a few things there.

49:04.620 --> 49:07.260
 You spoke to the fact that there is a narrative

49:07.260 --> 49:12.260
 of malevolence, like you're leaning into them,

49:12.420 --> 49:15.020
 making people angry just because it makes more money

49:15.020 --> 49:16.300
 in the short term, that kind of thing.

49:16.300 --> 49:17.880
 So you responded to that.

49:17.880 --> 49:22.060
 But there's also kind of reality of human nature.

49:22.060 --> 49:25.380
 Just like you spoke about, there's fights,

49:25.380 --> 49:28.700
 arguments we get in and we don't like ourselves afterwards,

49:28.700 --> 49:30.340
 but we got into them anyway.

49:30.340 --> 49:34.540
 So our longterm growth is, I believe for most of us,

49:34.540 --> 49:38.220
 has to do with learning, challenging yourself,

49:38.220 --> 49:40.960
 improving, being kind to each other,

49:40.960 --> 49:45.960
 finding a community of people that you connect with

49:47.620 --> 49:50.520
 on a real human level, all that kind of stuff.

49:50.520 --> 49:54.660
 But it does seem when you look at social media

49:54.660 --> 49:56.540
 that a lot of fights break out,

49:56.540 --> 49:58.180
 a lot of arguments break out,

49:58.180 --> 50:03.020
 a lot of viral content ends up being sort of outrage

50:03.020 --> 50:04.820
 in one direction or the other.

50:04.820 --> 50:08.020
 And so it's easy from that to infer the narrative

50:08.020 --> 50:11.220
 that social media companies are letting

50:11.220 --> 50:13.940
 this outrage become viral.

50:13.940 --> 50:16.820
 And so they're increasing the division in the world.

50:16.820 --> 50:18.820
 I mean, perhaps you can comment on that

50:18.820 --> 50:21.140
 or further, how can you be,

50:21.140 --> 50:25.780
 how can you push back on this narrative?

50:25.780 --> 50:28.420
 How can you be transparent about this battle?

50:28.420 --> 50:33.420
 Because I think it's not just motivation or financials,

50:33.540 --> 50:36.000
 it's a technical problem too,

50:36.000 --> 50:41.020
 which is how do you improve longterm wellbeing

50:41.020 --> 50:43.020
 of human beings?

50:43.020 --> 50:47.940
 I think that going through some of the design decisions

50:47.940 --> 50:49.660
 would be a good conversation.

50:49.660 --> 50:51.780
 But first, I actually think,

50:51.780 --> 50:54.260
 I think you acknowledged that,

50:54.260 --> 50:56.900
 that narrative is somewhat anecdotal.

50:56.900 --> 50:59.500
 And I think it's worth grounding this conversation

50:59.500 --> 51:02.600
 in the actual research that has been done on this,

51:02.600 --> 51:07.600
 which by and large finds that social media

51:07.980 --> 51:10.780
 is not a large driver of polarization, right?

51:10.780 --> 51:14.820
 And, I mean, there's been a number of economists

51:14.820 --> 51:18.380
 and social scientists and folks who have studied this.

51:18.380 --> 51:21.220
 In a lot of polarization, it varies around the world.

51:21.220 --> 51:23.100
 If social media is basically in every country,

51:23.100 --> 51:24.580
 Facebook's in pretty much every country

51:24.580 --> 51:27.180
 except for China and maybe North Korea.

51:27.180 --> 51:32.180
 And you see different trends in different places

51:32.460 --> 51:37.000
 where in a lot of countries polarization is declining,

51:37.000 --> 51:41.660
 in some it's flat, in the US it's risen sharply.

51:41.660 --> 51:44.660
 So the question is, what are the unique phenomenon

51:44.660 --> 51:45.980
 in the different places?

51:45.980 --> 51:47.580
 And I think for the people who are trying to say,

51:47.580 --> 51:50.220
 hey, social media is the thing that's doing this.

51:50.220 --> 51:52.940
 I think that that clearly doesn't hold up

51:52.940 --> 51:54.480
 because social media is a phenomenon

51:54.480 --> 51:56.020
 that is pretty much equivalent

51:56.020 --> 51:57.740
 in all of these different countries.

51:57.740 --> 52:00.600
 And you have researchers like this economist at Stanford,

52:00.600 --> 52:04.400
 Matthew Genskow, who has just written at length about this.

52:05.300 --> 52:10.300
 And it's a bunch of books by political scientists,

52:10.420 --> 52:13.060
 Ezra Klein and folks, why we're polarized,

52:13.060 --> 52:17.100
 basically goes through this decades long analysis in the US.

52:17.100 --> 52:19.500
 Before I was born, basically talking about

52:19.500 --> 52:22.780
 some of the forces in kind of partisan politics

52:22.780 --> 52:25.160
 and Fox News and different things

52:25.160 --> 52:27.640
 that predate the internet in a lot of ways

52:27.640 --> 52:30.100
 that I think are likely larger contributors.

52:30.100 --> 52:32.220
 So to the contrary on this,

52:32.220 --> 52:35.340
 not only is it pretty clear that social media

52:35.340 --> 52:37.600
 is not a major contributor,

52:37.600 --> 52:40.060
 but most of the academic studies that I've seen

52:40.060 --> 52:42.640
 actually show that social media use

52:42.640 --> 52:45.400
 is correlated with lower polarization.

52:45.400 --> 52:48.640
 And Genskow, the same person who just did the study

52:48.640 --> 52:51.640
 that I cited about longitudinal polarization

52:51.640 --> 52:53.060
 across different countries,

52:54.180 --> 52:57.480
 also did a study that basically showed

52:57.480 --> 53:02.120
 that if you looked after the 2016 election in the US,

53:02.120 --> 53:04.280
 the voters who were the most polarized

53:05.280 --> 53:07.560
 were actually the ones who were not on the internet.

53:07.560 --> 53:10.280
 So, and there have been recent other studies,

53:10.280 --> 53:12.840
 I think in Europe and around the world,

53:12.840 --> 53:16.720
 basically showing that as people stop using social media,

53:16.720 --> 53:19.200
 they tend to get more polarized.

53:19.200 --> 53:21.360
 Then there's a deeper analysis around,

53:21.360 --> 53:24.740
 okay, well, polarization actually isn't even one thing.

53:24.740 --> 53:26.520
 Cause you know, having different opinions on something

53:26.520 --> 53:28.900
 isn't, I don't think that that's by itself bad.

53:28.900 --> 53:33.900
 What people who study this say is most problematic

53:33.920 --> 53:35.920
 is what they call affective polarization,

53:35.920 --> 53:37.920
 which is basically are you,

53:37.920 --> 53:40.040
 do you have negative feelings towards people

53:40.040 --> 53:41.040
 of another group?

53:41.040 --> 53:43.760
 And the way that a lot of scholars study this

53:43.760 --> 53:46.780
 is they basically ask a group,

53:46.780 --> 53:50.600
 would you let your kids marry someone of group X?

53:50.600 --> 53:53.320
 Whatever the groups are that you're worried

53:53.320 --> 53:55.520
 that someone might have negative feelings towards.

53:55.520 --> 53:58.160
 And in general, use of social media

53:58.160 --> 53:59.880
 has corresponded to decreases

53:59.880 --> 54:01.960
 in that kind of affective polarization.

54:01.960 --> 54:04.760
 So I just wanna, I think we should talk

54:04.760 --> 54:07.720
 through the design decisions and how we handle

54:07.720 --> 54:10.720
 the kind of specific pieces of content,

54:10.720 --> 54:13.280
 but overall, I think it's just worth grounding

54:13.280 --> 54:15.600
 that discussion in the research that's existed

54:15.600 --> 54:17.440
 that I think overwhelmingly shows

54:17.440 --> 54:19.560
 that the mainstream narrative around this

54:19.560 --> 54:21.040
 is just not right.

54:21.040 --> 54:23.080
 But the narrative does take hold

54:24.060 --> 54:27.920
 and it's compelling to a lot of people.

54:27.920 --> 54:31.300
 There's another question I'd like to ask you on this.

54:31.300 --> 54:33.800
 I was looking at various polls and saw that you're

54:34.980 --> 54:38.080
 one of the most disliked tech leaders today,

54:38.080 --> 54:41.400
 54% unfavorable rating.

54:41.400 --> 54:43.240
 Elon Musk is 23%.

54:43.240 --> 54:46.260
 It's basically everybody has a very high unfavorable rating

54:46.260 --> 54:48.000
 that are tech leaders.

54:48.000 --> 54:50.640
 Maybe you can help me understand that.

54:50.640 --> 54:53.300
 Why do you think so many people dislike you?

54:54.720 --> 54:56.880
 Some even hate you.

54:56.880 --> 54:59.160
 And how do you regain their trust and support?

54:59.160 --> 55:00.900
 Given everything you just said,

55:02.360 --> 55:05.360
 why are you losing the battle

55:05.360 --> 55:09.440
 in explaining to people what actual impact

55:09.440 --> 55:11.120
 social media has on society?

55:12.440 --> 55:16.760
 Well, I'm curious if that's a US survey or world.

55:16.760 --> 55:17.960
 It is US, yeah.

55:17.960 --> 55:19.360
 So I think that there's a few dynamics.

55:19.360 --> 55:23.360
 One is that our brand

55:24.360 --> 55:27.880
 has been somewhat uniquely challenged in the US

55:27.880 --> 55:29.040
 compared to other places.

55:29.040 --> 55:29.880
 It's not that there are.

55:29.880 --> 55:32.660
 I mean, other countries, we have issues too,

55:32.660 --> 55:36.920
 but I think in the US, there was this dynamic where

55:36.920 --> 55:38.880
 if you look at like the next sentiment

55:38.880 --> 55:42.880
 of kind of coverage or attitude towards us,

55:42.880 --> 55:44.880
 before 2016, I think that there were probably

55:44.880 --> 55:47.480
 very few months, if any, where it was negative.

55:47.480 --> 55:49.440
 And since 2016, I think that there probably

55:49.440 --> 55:51.960
 been very few months, if any, then it's been positive.

55:51.960 --> 55:53.600
 Politics.

55:53.600 --> 55:55.360
 But I think it's a specific thing.

55:55.360 --> 55:56.960
 And this is very different from other places.

55:56.960 --> 55:59.840
 So I think in a lot of other countries in the world,

55:59.840 --> 56:02.440
 the sentiment towards meta and our services

56:02.440 --> 56:04.840
 is extremely positive.

56:04.840 --> 56:06.600
 In the US, we have more challenges.

56:06.600 --> 56:08.800
 And I think compared to other companies,

56:09.800 --> 56:12.520
 you can look at certain industries,

56:12.520 --> 56:16.320
 I think if you look at it from like a partisan perspective,

56:16.320 --> 56:18.060
 not from like a political perspective,

56:18.060 --> 56:19.080
 but just kind of culturally,

56:19.080 --> 56:20.240
 it's like there are people who are probably

56:20.240 --> 56:21.360
 more left of center and there are people

56:21.360 --> 56:22.520
 who are more right of center,

56:22.520 --> 56:25.880
 and there's kind of blue America and red America.

56:25.880 --> 56:27.660
 There are certain industries that I think

56:27.660 --> 56:30.880
 maybe one half of the country has a more positive view

56:30.880 --> 56:32.200
 towards than another.

56:32.200 --> 56:33.680
 And I think we're in a,

56:36.400 --> 56:38.320
 one of the positions that we're in that I think

56:38.320 --> 56:41.720
 is really challenging is that because of a lot

56:41.720 --> 56:44.760
 of the content decisions that we've basically

56:44.760 --> 56:49.560
 had to arbitrate, and because we're not a partisan company,

56:49.560 --> 56:52.640
 we're not a Democrat company or a Republican company,

56:52.640 --> 56:55.080
 we're trying to make the best decisions we can

56:55.080 --> 56:58.480
 to help people connect and help people have as much voice

56:58.480 --> 57:01.120
 as they can while having some rules

57:01.120 --> 57:02.920
 because we're running a community.

57:04.920 --> 57:07.420
 The net effect of that is that we're kind of constantly

57:07.420 --> 57:11.760
 making decisions that piss off people in both camps.

57:12.760 --> 57:17.160
 And the effect that I've sort of seen is that

57:17.160 --> 57:20.260
 when we make a decision that is,

57:21.480 --> 57:24.440
 that's a controversial one that's gonna upset,

57:24.440 --> 57:26.500
 say about half the country,

57:27.880 --> 57:30.340
 those decisions are all negative sum,

57:30.340 --> 57:33.640
 from a brand perspective, because it's not like,

57:33.640 --> 57:35.640
 if we make that decision in one way

57:35.640 --> 57:37.840
 and say half the country is happy

57:37.840 --> 57:40.000
 about that particular decision that we make,

57:40.000 --> 57:43.720
 they tend to not say, oh, sweet, meta got that one right.

57:43.720 --> 57:46.160
 They're just like, ah, you didn't mess that one up.

57:46.160 --> 57:48.960
 But their opinion doesn't tend to go up by that much.

57:48.960 --> 57:51.760
 Whereas the people who kind of are on the other side of it

57:52.840 --> 57:55.080
 are like, God, how could you mess that up?

57:55.080 --> 57:57.760
 How could you possibly think that that piece of content

57:57.760 --> 58:00.120
 is okay and should be up and should not be censored?

58:00.120 --> 58:04.940
 Or, and so I think the, whereas if you leave it up

58:04.940 --> 58:09.220
 and, you know, it's, or if you take it down,

58:09.220 --> 58:11.360
 the people who thought it should be taken down or,

58:11.360 --> 58:12.740
 you know, it's like, all right, fine, great.

58:12.740 --> 58:14.080
 You didn't mess that one up.

58:14.080 --> 58:16.120
 So our internal assessment of,

58:16.120 --> 58:17.920
 and the kind of analytics on our brand

58:17.920 --> 58:20.540
 are basically anytime one of these big controversial things

58:20.540 --> 58:22.000
 comes up in society,

58:23.740 --> 58:26.080
 our brand goes down with half of the country.

58:26.080 --> 58:27.600
 And then like, if you,

58:27.600 --> 58:29.600
 and then if you just kind of extrapolate that out,

58:29.600 --> 58:33.200
 it's just been very challenging for us to try to navigate

58:33.200 --> 58:36.640
 what is a polarizing country in a principled way,

58:36.640 --> 58:38.600
 where we're not trying to kind of hew to one side

58:38.600 --> 58:39.440
 or the other, we're trying to do

58:39.440 --> 58:41.040
 what we think is the right thing.

58:41.040 --> 58:43.220
 But that's what I think is the right thing

58:43.220 --> 58:44.060
 for us to do though.

58:44.060 --> 58:47.360
 So, I mean, that's what we'll try to keep doing.

58:47.360 --> 58:50.160
 Just as a human being, how does it feel though,

58:50.160 --> 58:53.380
 when you're giving so much of your day to day life

58:53.380 --> 58:58.060
 to try to heal division, to try to do good in the world,

58:58.060 --> 59:02.260
 as we've talked about, that so many people in the US,

59:02.260 --> 59:06.480
 the place you call home have a negative view

59:06.480 --> 59:09.120
 of you as a leader, as a human being

59:09.120 --> 59:11.400
 and the company you love?

59:14.040 --> 59:15.880
 Well, I mean, it's not great,

59:15.880 --> 59:20.880
 but I mean, look, if I wanted people to think positively

59:21.040 --> 59:22.800
 about me as a person,

59:25.760 --> 59:27.960
 I don't know, I'm not sure if you go build a company.

59:27.960 --> 59:28.800
 I mean, it's like.

59:28.800 --> 59:30.280
 Or a social media company.

59:30.280 --> 59:32.040
 It seems exceptionally difficult to do

59:32.040 --> 59:32.880
 with a social media company.

59:32.880 --> 59:34.800
 Yeah, so, I mean, I don't know,

59:34.800 --> 59:39.760
 there is a dynamic where a lot of the other people

59:39.760 --> 59:42.160
 running these companies, internet companies,

59:42.160 --> 59:45.320
 have sort of stepped back and they just do things

59:45.320 --> 59:49.480
 that are sort of, I don't know, less controversial.

59:49.480 --> 59:52.720
 And some of it may be that they just get tired over time.

59:52.720 --> 59:55.400
 But, you know, it's, so I don't know.

59:55.400 --> 59:58.120
 I think that, you know, running a company is hard,

59:58.120 --> 59:59.880
 building something at scale is hard.

59:59.880 --> 1:00:01.640
 You only really do it for a long period of time

1:00:01.640 --> 1:00:04.240
 if you really care about what you're doing.

1:00:04.240 --> 1:00:08.000
 And yeah, so, I mean, it's not great, but like,

1:00:08.000 --> 1:00:10.400
 but look, I think that at some level,

1:00:11.560 --> 1:00:14.960
 whether 25% of people dislike you

1:00:14.960 --> 1:00:18.080
 or 75% of people dislike you,

1:00:18.080 --> 1:00:21.040
 your experience as a public figure is gonna be

1:00:21.040 --> 1:00:23.360
 that there's a lot of people who dislike you, right?

1:00:23.360 --> 1:00:28.360
 So, I actually am not sure how different it is.

1:00:28.680 --> 1:00:31.200
 You know, certainly, you know,

1:00:31.200 --> 1:00:32.760
 the country's gotten more polarized

1:00:32.760 --> 1:00:35.040
 and we in particular have gotten, you know,

1:00:35.040 --> 1:00:39.080
 more controversial over the last five or years or so.

1:00:39.080 --> 1:00:44.080
 But, I don't know, I kind of think like as a public figure

1:00:45.240 --> 1:00:48.560
 and leader of one of these enterprises.

1:00:48.560 --> 1:00:49.400
 Comes with the job.

1:00:49.400 --> 1:00:51.440
 Yeah, part of what you do is like,

1:00:51.440 --> 1:00:54.640
 and look, the answer can't just be ignore it, right?

1:00:54.640 --> 1:00:56.680
 Because like a huge part of the job

1:00:56.680 --> 1:00:58.200
 is like you need to be getting feedback

1:00:58.200 --> 1:01:00.760
 and internalizing feedback on how you can do better.

1:01:00.760 --> 1:01:02.520
 But I think increasingly what you need to do

1:01:02.520 --> 1:01:04.560
 is be able to figure out, you know,

1:01:04.560 --> 1:01:08.000
 who are the kind of good faith critics

1:01:08.000 --> 1:01:10.640
 who are criticizing you because

1:01:10.640 --> 1:01:12.520
 they're trying to help you do a better job

1:01:12.520 --> 1:01:13.960
 rather than tear you down.

1:01:13.960 --> 1:01:16.440
 And those are the people I just think you have to cherish

1:01:16.440 --> 1:01:19.120
 and like, and listen very closely

1:01:19.120 --> 1:01:20.280
 to the things that they're saying,

1:01:20.280 --> 1:01:23.040
 because, you know, I think it's just as dangerous

1:01:23.040 --> 1:01:25.920
 to tune out everyone who says anything negative

1:01:26.840 --> 1:01:29.320
 and just listen to the people who are kind of positive

1:01:29.320 --> 1:01:31.240
 and support you, you know,

1:01:31.240 --> 1:01:33.760
 as it would be psychologically to pay attention

1:01:33.760 --> 1:01:36.600
 trying to make people who are never gonna like you like you.

1:01:36.600 --> 1:01:38.880
 So I think that that's just kind of a dance

1:01:38.880 --> 1:01:40.080
 that people have to do.

1:01:40.080 --> 1:01:41.760
 But I mean, I, you know,

1:01:41.760 --> 1:01:44.720
 so you kind of develop more of a feel for like,

1:01:44.720 --> 1:01:46.280
 who actually is trying to accomplish

1:01:46.280 --> 1:01:48.400
 the same types of things in the world

1:01:48.400 --> 1:01:51.440
 and who has different ideas about how to do that

1:01:51.440 --> 1:01:52.880
 and how can I learn from those people?

1:01:52.880 --> 1:01:54.800
 And like, yeah, we get stuff wrong.

1:01:54.800 --> 1:01:57.760
 And when the people whose opinions I respect

1:01:57.760 --> 1:01:59.840
 call me out on getting stuff wrong,

1:01:59.840 --> 1:02:02.120
 that hurts and makes me wanna do better.

1:02:02.120 --> 1:02:04.680
 But I think at this point, I'm pretty tuned to just,

1:02:04.680 --> 1:02:06.360
 all right, if someone, if I know they're,

1:02:06.360 --> 1:02:08.080
 they're kind of like operating in bad faith

1:02:08.080 --> 1:02:10.800
 and they're not really trying to help,

1:02:10.800 --> 1:02:13.000
 then, you know, I don't know, it's not, it's, it doesn't,

1:02:13.000 --> 1:02:13.840
 you know, I think over time,

1:02:13.840 --> 1:02:15.280
 it just doesn't bother you that much.

1:02:15.280 --> 1:02:18.720
 But you are surrounded by people that believe in the mission

1:02:18.720 --> 1:02:19.680
 that love you.

1:02:21.240 --> 1:02:23.600
 Are there friends or colleagues in your inner circle

1:02:23.600 --> 1:02:26.560
 you trust that call you out on your bullshit

1:02:26.560 --> 1:02:28.600
 whenever your thinking may be misguided

1:02:28.600 --> 1:02:30.920
 as it is for leaders at times?

1:02:30.920 --> 1:02:33.480
 I think we have a famously open company culture

1:02:34.840 --> 1:02:39.440
 where we sort of encourage that kind of dissent internally,

1:02:39.440 --> 1:02:41.760
 which is, you know, why there's so much material

1:02:41.760 --> 1:02:43.120
 internally that can leak out

1:02:43.120 --> 1:02:44.520
 with people sort of disagreeing

1:02:44.520 --> 1:02:46.560
 is because that's sort of the culture.

1:02:47.480 --> 1:02:50.200
 You know, our management team, I think it's a lot of people,

1:02:50.200 --> 1:02:52.000
 you know, there are some newer folks who come in,

1:02:52.000 --> 1:02:54.800
 there are some folks who've kind of been there for a while,

1:02:54.800 --> 1:02:56.840
 but there's a very high level of trust.

1:02:56.840 --> 1:02:59.840
 And I would say it is a relatively confrontational

1:02:59.840 --> 1:03:01.080
 group of people.

1:03:01.080 --> 1:03:04.560
 And my friends and family, I think, will push me on this.

1:03:04.560 --> 1:03:06.400
 But look, it's not just,

1:03:06.400 --> 1:03:09.280
 but I think you need some diversity, right?

1:03:09.280 --> 1:03:12.080
 It can't just be, you know,

1:03:12.080 --> 1:03:13.760
 people who are your friends and family.

1:03:13.760 --> 1:03:16.920
 It's also, you know, I mean, there are journalists

1:03:16.920 --> 1:03:19.520
 or analysts or, you know,

1:03:19.520 --> 1:03:23.240
 peer executives at other companies

1:03:23.240 --> 1:03:27.600
 or, you know, other people who sort of are insightful

1:03:27.600 --> 1:03:28.760
 about thinking about the world,

1:03:28.760 --> 1:03:30.800
 you know, certain politicians

1:03:30.800 --> 1:03:32.680
 or people kind of in that sphere

1:03:32.680 --> 1:03:36.160
 who I just think have like very insightful perspectives

1:03:36.160 --> 1:03:39.800
 who even if they would,

1:03:39.800 --> 1:03:41.600
 they come at the world from a different perspective,

1:03:41.600 --> 1:03:44.360
 which is sort of what makes the perspective so valuable.

1:03:44.360 --> 1:03:46.200
 But, you know, I think fundamentally

1:03:46.200 --> 1:03:47.560
 we're trying to get to the same place

1:03:47.560 --> 1:03:50.680
 in terms of, you know, helping people connect more,

1:03:50.680 --> 1:03:53.480
 helping the whole world function better,

1:03:53.480 --> 1:03:55.600
 not just, you know, one place or another.

1:03:57.120 --> 1:03:58.920
 And I don't know, I mean,

1:03:58.920 --> 1:04:02.880
 those are the people whose opinions really matter to me.

1:04:02.880 --> 1:04:04.240
 And I just, it's, you know,

1:04:04.240 --> 1:04:05.640
 that's how I learn on a day to day basis.

1:04:05.640 --> 1:04:07.880
 People are constantly sending me comments on stuff

1:04:07.880 --> 1:04:10.160
 or links to things they found interesting.

1:04:10.160 --> 1:04:13.400
 And I don't know, it's kind of constantly evolving

1:04:13.400 --> 1:04:14.480
 this model of the world

1:04:14.480 --> 1:04:16.840
 and kind of what we should be aspiring to be.

1:04:16.840 --> 1:04:20.000
 You've talked about, you have a famously open culture

1:04:20.880 --> 1:04:25.440
 which comes with the criticism

1:04:25.440 --> 1:04:27.280
 and the painful experiences.

1:04:27.280 --> 1:04:30.960
 So let me ask you another difficult question.

1:04:30.960 --> 1:04:33.440
 Frances Haugen, the Facebook whistleblower,

1:04:33.440 --> 1:04:35.800
 leaked the internal Instagram research

1:04:35.800 --> 1:04:38.040
 into teenagers and wellbeing.

1:04:38.040 --> 1:04:41.240
 Her claim is that Instagram is choosing profit

1:04:41.240 --> 1:04:43.080
 over wellbeing of teenage girls.

1:04:43.080 --> 1:04:46.720
 So Instagram is quote, toxic for them.

1:04:46.720 --> 1:04:48.120
 Your response titled,

1:04:48.120 --> 1:04:52.440
 what our research really says about teen wellbeing

1:04:52.440 --> 1:04:55.520
 and Instagram says, no, Instagram research shows

1:04:55.520 --> 1:04:58.800
 that 11 of 12 wellbeing issues,

1:04:58.800 --> 1:05:02.720
 teenage girls who said they struggle

1:05:02.720 --> 1:05:04.400
 with those difficult issues also said

1:05:04.400 --> 1:05:07.600
 that Instagram made them better rather than worse.

1:05:07.600 --> 1:05:11.000
 Again, can you steal man and defend the point

1:05:11.000 --> 1:05:14.800
 and Frances Haugen's characterization of the study

1:05:14.800 --> 1:05:17.080
 and then help me understand the positive

1:05:17.080 --> 1:05:19.000
 and negative effects of Instagram

1:05:19.000 --> 1:05:20.880
 and Facebook on young people?

1:05:20.880 --> 1:05:25.840
 So there are certainly questions around teen mental health

1:05:25.840 --> 1:05:26.680
 that are really important.

1:05:26.680 --> 1:05:29.480
 It's hard to, as a parent, it's like hard to imagine

1:05:29.480 --> 1:05:32.040
 any set of questions that are sort of more important.

1:05:32.040 --> 1:05:34.080
 I mean, I guess maybe other aspects of physical health

1:05:34.080 --> 1:05:37.240
 or wellbeing are probably come to that level,

1:05:37.240 --> 1:05:40.600
 but like, these are really important questions, right?

1:05:40.600 --> 1:05:43.760
 Which is why we dedicate teams to studying them.

1:05:45.640 --> 1:05:48.880
 I don't think the internet or social media are unique

1:05:48.880 --> 1:05:50.000
 in having these questions.

1:05:50.000 --> 1:05:53.160
 I mean, I think people and there've been sort of magazines

1:05:53.160 --> 1:05:56.320
 with promoting certain body types for women

1:05:56.320 --> 1:05:58.520
 and kids for decades,

1:05:58.520 --> 1:06:01.440
 but we really care about this stuff.

1:06:01.440 --> 1:06:02.760
 So we wanted to study it.

1:06:02.760 --> 1:06:05.000
 And of course, we didn't expect

1:06:05.000 --> 1:06:07.000
 that everything was gonna be positive all the time.

1:06:07.000 --> 1:06:08.520
 So, I mean, the reason why you study this stuff

1:06:08.520 --> 1:06:10.760
 is to try to improve and get better.

1:06:10.760 --> 1:06:13.200
 So, I mean, look, the place where I disagree

1:06:13.200 --> 1:06:15.320
 with the characterization first,

1:06:15.320 --> 1:06:18.720
 I thought some of the reporting and coverage of it

1:06:18.720 --> 1:06:20.840
 just took the whole thing out of proportion

1:06:20.840 --> 1:06:22.640
 and that it focused on, as you said,

1:06:22.640 --> 1:06:24.280
 I think there were like 20 metrics in there

1:06:24.280 --> 1:06:27.600
 and on 18 or 19, the effect of using Instagram

1:06:27.600 --> 1:06:30.920
 was neutral or positive on the teen's wellbeing.

1:06:30.920 --> 1:06:34.560
 And there was one area where I think it showed

1:06:34.560 --> 1:06:35.480
 that we needed to improve

1:06:35.480 --> 1:06:37.720
 and we took some steps to try to do that

1:06:37.720 --> 1:06:38.800
 after doing the research.

1:06:38.800 --> 1:06:41.680
 But I think having the coverage just focus on that one

1:06:41.680 --> 1:06:43.040
 without focusing on the,

1:06:43.040 --> 1:06:45.080
 I mean, I think an accurate characterization

1:06:45.080 --> 1:06:47.920
 would have been that kids using Instagram

1:06:47.920 --> 1:06:52.200
 or not kids, teens is generally positive

1:06:52.200 --> 1:06:53.760
 for their mental health.

1:06:53.760 --> 1:06:55.560
 But of course, that was not the narrative that came out.

1:06:55.560 --> 1:06:56.720
 So I think it's hard to,

1:06:56.720 --> 1:06:59.200
 that's not a kind of logical thing to straw man,

1:06:59.200 --> 1:07:01.440
 but I sort of disagree or steel man,

1:07:01.440 --> 1:07:04.040
 but I sort of disagree with that overall characterization.

1:07:04.040 --> 1:07:08.800
 I think anyone sort of looking at this objectively would,

1:07:09.960 --> 1:07:14.960
 but then, I mean, there is this sort of intent critique

1:07:15.040 --> 1:07:16.360
 that I think you were getting at before,

1:07:16.360 --> 1:07:19.680
 which says, it assumes some sort of malevolence, right?

1:07:19.680 --> 1:07:23.160
 It's like, which it's really hard for me

1:07:23.160 --> 1:07:26.520
 to really wrap my head around this

1:07:26.520 --> 1:07:29.800
 because as far as I know,

1:07:29.800 --> 1:07:31.720
 it's not clear that any of the other tech companies

1:07:31.720 --> 1:07:33.320
 are doing this kind of research.

1:07:33.320 --> 1:07:37.840
 So why the narrative should form that we did research

1:07:37.840 --> 1:07:38.800
 because we were studying an issue

1:07:38.800 --> 1:07:40.760
 because we wanted to understand it to improve

1:07:40.760 --> 1:07:43.560
 and took steps after that to try to improve it,

1:07:43.560 --> 1:07:46.280
 that your interpretation of that would be

1:07:46.280 --> 1:07:47.880
 that we did the research

1:07:47.880 --> 1:07:49.240
 and tried to sweep it under the rug.

1:07:49.240 --> 1:07:53.920
 It just, it sort of is like, I don't know,

1:07:53.920 --> 1:07:55.920
 it's beyond credibility to me

1:07:55.920 --> 1:07:59.000
 that like that's the accurate description of the actions

1:07:59.000 --> 1:08:01.160
 that we've taken compared to the others in the industry.

1:08:01.160 --> 1:08:05.280
 So I don't know, that's kind of, that's my view on it.

1:08:05.280 --> 1:08:06.600
 These are really important issues

1:08:06.600 --> 1:08:07.960
 and there's a lot of stuff

1:08:07.960 --> 1:08:09.120
 that I think we're gonna be working on

1:08:09.120 --> 1:08:11.400
 related to teen mental health for a long time,

1:08:11.400 --> 1:08:14.240
 including trying to understand this better.

1:08:14.240 --> 1:08:15.280
 And I would encourage everyone else

1:08:15.280 --> 1:08:16.840
 in the industry to do this too.

1:08:18.400 --> 1:08:21.880
 Yeah, I would love there to be open conversations

1:08:21.880 --> 1:08:25.680
 and a lot of great research being released internally

1:08:25.680 --> 1:08:27.960
 and then also externally.

1:08:27.960 --> 1:08:31.040
 It doesn't make me feel good

1:08:31.040 --> 1:08:35.000
 to see press obviously get way more clicks

1:08:35.000 --> 1:08:39.280
 when they say negative things about social media.

1:08:39.280 --> 1:08:41.520
 Objectively speaking, I can just tell

1:08:42.400 --> 1:08:44.400
 that there's hunger to say negative things

1:08:44.400 --> 1:08:46.040
 about social media.

1:08:46.040 --> 1:08:50.720
 And I don't understand how that's supposed to lead

1:08:50.720 --> 1:08:53.000
 to an open conversation about the positives

1:08:53.000 --> 1:08:56.000
 and the negatives, the concerns about social media,

1:08:56.000 --> 1:08:59.200
 especially when you're doing that kind of research.

1:08:59.200 --> 1:09:01.720
 I mean, I don't know what to do with that,

1:09:01.720 --> 1:09:03.920
 but let me ask you as a father,

1:09:05.560 --> 1:09:06.720
 there's a weight heavy on you

1:09:06.720 --> 1:09:10.280
 that people get bullied on social networks.

1:09:10.280 --> 1:09:13.520
 So people get bullied in their private life.

1:09:13.520 --> 1:09:17.080
 But now because so much of our life is in the digital world,

1:09:17.080 --> 1:09:19.640
 the bullying moves from the physical world

1:09:19.640 --> 1:09:21.200
 to the digital world.

1:09:21.200 --> 1:09:23.280
 So you're now creating a platform

1:09:24.520 --> 1:09:26.520
 on which bullying happens.

1:09:26.520 --> 1:09:30.440
 And some of that bullying can lead to damage

1:09:30.440 --> 1:09:31.840
 to mental health.

1:09:31.840 --> 1:09:35.120
 And some of that bullying can lead to depression,

1:09:35.120 --> 1:09:36.320
 even suicide.

1:09:37.640 --> 1:09:38.760
 There's a weight heavy on you

1:09:38.760 --> 1:09:43.240
 that people have committed suicide

1:09:43.240 --> 1:09:46.120
 or will commit suicide based on the bullying

1:09:46.120 --> 1:09:48.080
 that happens on social media.

1:09:48.080 --> 1:09:51.560
 Yeah, I mean, there's a set of harms

1:09:51.560 --> 1:09:55.400
 that we basically track and build systems to fight against.

1:09:55.400 --> 1:10:00.400
 And bullying and self harm are,

1:10:01.600 --> 1:10:03.240
 these are some of the biggest things

1:10:03.240 --> 1:10:06.000
 that we are most focused on.

1:10:10.920 --> 1:10:14.400
 For bullying, like you say, it's gonna be,

1:10:16.200 --> 1:10:18.240
 while this predates the internet,

1:10:18.240 --> 1:10:20.880
 then it's probably impossible to get rid of all of it.

1:10:22.000 --> 1:10:24.160
 You wanna give people tools to fight it

1:10:24.160 --> 1:10:27.200
 and you wanna fight it yourself.

1:10:27.200 --> 1:10:28.800
 And you also wanna make sure that people have the tools

1:10:28.800 --> 1:10:30.160
 to get help when they need it.

1:10:30.160 --> 1:10:33.200
 So I think this isn't like a question of,

1:10:33.200 --> 1:10:34.640
 can you get rid of all bullying?

1:10:34.640 --> 1:10:39.080
 I mean, it's like, all right, I mean, I have two daughters

1:10:39.080 --> 1:10:43.840
 and they fight and push each other around and stuff too.

1:10:43.840 --> 1:10:44.680
 And the question is just,

1:10:44.680 --> 1:10:47.080
 how do you handle that situation?

1:10:47.080 --> 1:10:51.480
 And there's a handful of things that I think you can do.

1:10:51.480 --> 1:10:55.000
 We talked a little bit before around some of the AI tools

1:10:55.000 --> 1:10:56.800
 that you can build to identify

1:10:56.800 --> 1:10:59.160
 when something harmful is happening.

1:10:59.160 --> 1:11:00.480
 It's actually, it's very hard in bullying

1:11:00.480 --> 1:11:02.720
 because a lot of bullying is very context specific.

1:11:02.720 --> 1:11:06.320
 It's not like you're trying to fit a formula of like,

1:11:06.320 --> 1:11:09.480
 if like looking at the different harms,

1:11:09.480 --> 1:11:12.280
 someone promoting a terrorist group is like,

1:11:12.280 --> 1:11:14.360
 probably one of the simpler things to generally find

1:11:14.360 --> 1:11:17.000
 because things promoting that group are gonna look

1:11:17.000 --> 1:11:19.240
 at a certain way or feel a certain way.

1:11:19.240 --> 1:11:21.840
 Bullying could just be, you know,

1:11:21.840 --> 1:11:24.880
 someone making some subtle comment about someone's appearance

1:11:24.880 --> 1:11:26.800
 that's idiosyncratic to them.

1:11:26.800 --> 1:11:28.680
 And it could look at just like humor.

1:11:28.680 --> 1:11:31.000
 So humor to one person can be destructive

1:11:31.000 --> 1:11:32.280
 to another human being, yeah.

1:11:32.280 --> 1:11:36.400
 So with bullying, I think there are certain things

1:11:36.400 --> 1:11:39.280
 that you can find through AI systems,

1:11:40.240 --> 1:11:42.640
 but I think it is increasingly important

1:11:42.640 --> 1:11:44.800
 to just give people more agency themselves.

1:11:44.800 --> 1:11:46.480
 So we've done things like making it

1:11:46.480 --> 1:11:47.800
 so people can turn off comments

1:11:47.800 --> 1:11:52.240
 or take a break from hearing from a specific person

1:11:52.240 --> 1:11:54.120
 without having to signal at all

1:11:54.120 --> 1:11:55.600
 that they're gonna stop following them

1:11:55.600 --> 1:11:58.200
 or kind of make some stand that,

1:11:58.200 --> 1:11:59.400
 okay, I'm not friends with you anymore.

1:11:59.400 --> 1:12:00.440
 I'm not following you.

1:12:00.440 --> 1:12:01.880
 I just like, I just don't wanna hear about this,

1:12:01.880 --> 1:12:05.560
 but I also don't wanna signal at all publicly

1:12:05.560 --> 1:12:08.880
 that or to them that there's been an issue.

1:12:10.880 --> 1:12:14.040
 And then you get to some of the more extreme cases

1:12:14.040 --> 1:12:14.880
 like you're talking about

1:12:14.880 --> 1:12:19.160
 where someone is thinking about self harm or suicide.

1:12:19.160 --> 1:12:24.080
 And there we've found that that is a place

1:12:24.080 --> 1:12:26.400
 where AI can identify a lot

1:12:26.400 --> 1:12:28.560
 as well as people flagging things.

1:12:28.560 --> 1:12:31.080
 If people are expressing something

1:12:31.080 --> 1:12:35.000
 that is potentially they're thinking of hurting themselves,

1:12:35.000 --> 1:12:37.520
 those are cues that you can build systems

1:12:37.520 --> 1:12:39.560
 and hundreds of languages around the world

1:12:39.560 --> 1:12:41.080
 to be able to identify that.

1:12:41.080 --> 1:12:45.320
 And one of the things that I'm actually quite proud of

1:12:45.320 --> 1:12:47.400
 is we've built these systems

1:12:47.400 --> 1:12:50.960
 that I think are clearly leading at this point

1:12:50.960 --> 1:12:53.000
 that not only identify that,

1:12:53.000 --> 1:12:57.040
 but then connect with local first responders

1:12:57.040 --> 1:12:59.680
 and have been able to save, I think at this point,

1:12:59.680 --> 1:13:01.960
 it's in thousands of cases,

1:13:01.960 --> 1:13:04.560
 be able to get first responders to people

1:13:04.560 --> 1:13:06.960
 through these systems who really need them

1:13:07.800 --> 1:13:09.600
 because of specific plumbing that we've done

1:13:09.600 --> 1:13:11.680
 between the AI work and being able to communicate

1:13:11.680 --> 1:13:13.800
 with local first responder organizations.

1:13:13.800 --> 1:13:15.800
 We're rolling that out in more places around the world.

1:13:15.800 --> 1:13:18.160
 And I think the team that worked on that

1:13:18.160 --> 1:13:19.360
 just did awesome stuff.

1:13:19.360 --> 1:13:22.760
 So I think that that's a long way of saying,

1:13:22.760 --> 1:13:25.480
 yeah, I mean, this is a heavy topic

1:13:25.480 --> 1:13:28.440
 and you want to attack it in a bunch of different ways

1:13:30.000 --> 1:13:33.240
 and also kind of understand that some of nature

1:13:33.240 --> 1:13:36.360
 is for people to do this to each other,

1:13:36.360 --> 1:13:37.320
 which is unfortunate,

1:13:37.320 --> 1:13:40.600
 but you can give people tools and build things that help.

1:13:40.600 --> 1:13:43.840
 It's still one hell of a burden though.

1:13:43.840 --> 1:13:46.160
 A platform that allows people

1:13:46.160 --> 1:13:47.760
 to fall in love with each other

1:13:48.600 --> 1:13:51.000
 is also by nature going to be a platform

1:13:51.000 --> 1:13:52.880
 that allows people to hurt each other.

1:13:52.880 --> 1:13:57.120
 And when you're managing such a platform, it's difficult.

1:13:57.120 --> 1:13:58.200
 And I think you spoke to it,

1:13:58.200 --> 1:14:01.280
 but the psychology of that, of being a leader in that space,

1:14:01.280 --> 1:14:05.280
 of creating technology that's playing in this space,

1:14:05.280 --> 1:14:08.760
 like you mentioned, psychology is really damn difficult.

1:14:10.280 --> 1:14:13.120
 And I mean, the burden of that is just great.

1:14:13.120 --> 1:14:17.240
 I just wanted to hear you speak to that point.

1:14:18.720 --> 1:14:23.160
 I have to ask about the thing you've brought up a few times,

1:14:23.160 --> 1:14:25.320
 which is making controversial decisions.

1:14:26.520 --> 1:14:29.440
 Let's talk about free speech and censorship.

1:14:29.440 --> 1:14:33.920
 So there are two groups of people pressuring Meta on this.

1:14:33.920 --> 1:14:37.240
 One group is upset that Facebook, the social network,

1:14:37.240 --> 1:14:41.480
 allows misinformation in quotes to be spread on the platform.

1:14:41.480 --> 1:14:44.800
 The other group are concerned that Facebook censors speech

1:14:44.800 --> 1:14:46.560
 by calling it misinformation.

1:14:46.560 --> 1:14:48.840
 So you're getting it from both sides.

1:14:48.840 --> 1:14:53.840
 You, in 2019, October at Georgetown University,

1:14:54.600 --> 1:14:58.240
 eloquently defended the importance of free speech,

1:14:58.240 --> 1:15:04.240
 but then COVID came and the 2020 election came.

1:15:04.360 --> 1:15:06.440
 Do you worry that outside pressures

1:15:06.440 --> 1:15:08.840
 from advertisers, politicians, the public,

1:15:08.840 --> 1:15:11.840
 have forced Meta to damage the ideal of free speech

1:15:11.840 --> 1:15:13.120
 that you spoke highly of?

1:15:14.000 --> 1:15:16.880
 Just to say some obvious things upfront,

1:15:16.880 --> 1:15:18.840
 I don't think pressure from advertisers

1:15:18.840 --> 1:15:21.440
 or politicians directly in any way

1:15:21.440 --> 1:15:22.680
 affects how we think about this.

1:15:22.680 --> 1:15:25.080
 I think these are just hard topics.

1:15:25.080 --> 1:15:26.880
 So let me just take you through our evolution

1:15:26.880 --> 1:15:28.240
 from kind of the beginning of the company

1:15:28.240 --> 1:15:29.360
 to where we are now.

1:15:30.240 --> 1:15:31.720
 You don't build a company like this

1:15:31.720 --> 1:15:34.120
 unless you believe that people expressing themselves

1:15:34.120 --> 1:15:35.720
 is a good thing, right?

1:15:35.720 --> 1:15:38.160
 So that's sort of the foundational thing.

1:15:38.160 --> 1:15:41.880
 You can kind of think about our company as a formula

1:15:41.880 --> 1:15:44.240
 where we think giving people voice

1:15:44.240 --> 1:15:47.440
 and helping people connect creates opportunity, right?

1:15:47.440 --> 1:15:49.640
 So those are the two things that we're always focused on

1:15:49.640 --> 1:15:50.800
 are sort of helping people connect.

1:15:50.800 --> 1:15:52.080
 We talked about that a lot,

1:15:52.080 --> 1:15:53.880
 but also giving people voice

1:15:53.880 --> 1:15:55.800
 and ability to express themselves.

1:15:55.800 --> 1:15:56.960
 Then by the way, most of the time

1:15:56.960 --> 1:15:58.120
 when people express themselves,

1:15:58.120 --> 1:16:00.840
 that's not like politically controversial content.

1:16:00.840 --> 1:16:04.040
 It's like expressing something about their identity

1:16:04.040 --> 1:16:06.520
 that's more related to the avatar conversation

1:16:06.520 --> 1:16:08.600
 we had earlier in terms of expressing some facet,

1:16:08.600 --> 1:16:11.240
 but that's what's important to people on a day to day basis.

1:16:11.240 --> 1:16:13.480
 And sometimes when people feel strongly enough

1:16:13.480 --> 1:16:16.360
 about something, it kind of becomes a political topic.

1:16:16.360 --> 1:16:19.120
 That's sort of always been a thing that we've focused on.

1:16:19.120 --> 1:16:22.320
 There's always been the question of safety in this,

1:16:22.320 --> 1:16:24.360
 which if you're building a community,

1:16:24.360 --> 1:16:26.040
 I think you have to focus on safety.

1:16:26.040 --> 1:16:28.320
 We've had these community standards from early on,

1:16:28.320 --> 1:16:32.640
 and there are about 20 different kinds of harm

1:16:32.640 --> 1:16:34.840
 that we track and try to fight actively.

1:16:34.840 --> 1:16:36.400
 We've talked about some of them already.

1:16:36.400 --> 1:16:40.880
 So it includes things like bullying and harassment.

1:16:40.880 --> 1:16:45.880
 It includes things like terrorism or promoting terrorism,

1:16:46.000 --> 1:16:49.320
 inciting violence, intellectual property theft.

1:16:49.320 --> 1:16:53.760
 And in general, I think call it about 18 out of 20 of those.

1:16:53.760 --> 1:16:57.200
 There's not really a particularly polarized definition

1:16:57.200 --> 1:16:58.040
 of that.

1:16:59.160 --> 1:17:01.440
 I think you're not really gonna find many people

1:17:01.440 --> 1:17:03.760
 in the country or in the world

1:17:03.760 --> 1:17:05.800
 who are trying to say we should be

1:17:07.040 --> 1:17:09.320
 fighting terrorist content less.

1:17:09.320 --> 1:17:12.200
 I think the content where there are a couple of areas

1:17:12.200 --> 1:17:14.000
 where I think that this has gotten more controversial

1:17:14.000 --> 1:17:16.320
 recently, which I'll talk about.

1:17:16.320 --> 1:17:20.000
 And you're right, the misinformation is basically is up there.

1:17:20.000 --> 1:17:21.920
 And I think sometimes the definition of hate speech

1:17:21.920 --> 1:17:22.760
 is up there too.

1:17:22.760 --> 1:17:25.760
 But I think in general, most of the content

1:17:25.760 --> 1:17:28.600
 that I think we're working on for safety

1:17:29.560 --> 1:17:32.560
 is not actually, people don't kind of have these questions.

1:17:32.560 --> 1:17:35.280
 So it's sort of this subset.

1:17:35.280 --> 1:17:37.400
 But if you go back to the beginning of the company,

1:17:37.400 --> 1:17:42.000
 this was sort of pre deep learning days.

1:17:42.000 --> 1:17:47.000
 And therefore, it was me and my roommate Dustin join me.

1:17:47.000 --> 1:17:52.000
 And if someone posted something bad,

1:17:54.040 --> 1:17:57.880
 it was the AI technology did not exist yet

1:17:57.880 --> 1:18:01.240
 to be able to go basically look at all the content.

1:18:02.480 --> 1:18:06.120
 And we were a small enough outfit

1:18:06.120 --> 1:18:08.800
 that no one would expect that we could review it all.

1:18:08.800 --> 1:18:10.400
 Even if someone reported it to us,

1:18:10.400 --> 1:18:11.720
 we basically did our best, right?

1:18:11.720 --> 1:18:12.680
 It's like someone would report it

1:18:12.680 --> 1:18:16.880
 and we try to look at stuff and deal with stuff.

1:18:16.880 --> 1:18:21.880
 And for call it the first seven or eight years

1:18:22.360 --> 1:18:26.600
 of the company, we weren't that big of a company.

1:18:26.600 --> 1:18:28.760
 For a lot of that period, we weren't even really profitable.

1:18:28.760 --> 1:18:30.520
 The AI didn't really exist to be able to do

1:18:30.520 --> 1:18:32.720
 the kind of moderation that we do today.

1:18:32.720 --> 1:18:35.760
 And then at some point in kind of the middle

1:18:35.760 --> 1:18:38.160
 of the last decade, that started to flip.

1:18:38.160 --> 1:18:43.160
 And we got to the point where we were sort of a larger

1:18:44.160 --> 1:18:45.240
 and more profitable company.

1:18:45.240 --> 1:18:48.000
 And the AI was starting to come online

1:18:48.000 --> 1:18:50.480
 to be able to proactively detect

1:18:50.480 --> 1:18:52.840
 some of the simpler forms of this.

1:18:52.840 --> 1:18:54.800
 So things like pornography,

1:18:54.800 --> 1:18:57.600
 you could train an image classifier

1:18:57.600 --> 1:18:59.520
 to identify what a nipple was,

1:18:59.520 --> 1:19:01.320
 or you can fight against terrorist content.

1:19:01.320 --> 1:19:02.160
 You still could.

1:19:02.160 --> 1:19:03.440
 There's actually papers on this, it's great.

1:19:03.440 --> 1:19:04.280
 Oh, of course there are.

1:19:04.280 --> 1:19:05.120
 Technical papers.

1:19:05.120 --> 1:19:06.480
 Of course there are.

1:19:06.480 --> 1:19:09.280
 Those are relatively easier things to train AI to do

1:19:09.280 --> 1:19:12.440
 than for example, understand the nuances

1:19:12.440 --> 1:19:14.000
 of what is inciting violence

1:19:14.000 --> 1:19:15.800
 in a hundred languages around the world

1:19:15.800 --> 1:19:20.200
 and not have the false positives of like,

1:19:20.200 --> 1:19:22.360
 okay, are you posting about this thing

1:19:22.360 --> 1:19:24.040
 that might be inciting violence

1:19:24.040 --> 1:19:26.360
 because you're actually trying to denounce it?

1:19:26.360 --> 1:19:28.280
 In which case we probably shouldn't take that down.

1:19:28.280 --> 1:19:29.520
 Where if you're trying to denounce something

1:19:29.520 --> 1:19:33.920
 that's inciting violence in some kind of dialect

1:19:33.920 --> 1:19:37.200
 in a corner of India, as opposed to,

1:19:37.200 --> 1:19:38.440
 okay, actually you're posting this thing

1:19:38.440 --> 1:19:39.600
 because you're trying to incite violence.

1:19:39.600 --> 1:19:42.360
 Okay, building an AI that can basically get

1:19:42.360 --> 1:19:44.400
 to that level of nuance and all the languages

1:19:44.400 --> 1:19:47.120
 that we serve is something that I think

1:19:47.120 --> 1:19:49.680
 is only really becoming possible now,

1:19:49.680 --> 1:19:51.920
 not towards the middle of the last decade.

1:19:51.920 --> 1:19:54.880
 But there's been this evolution,

1:19:54.880 --> 1:19:56.080
 and I think what happened,

1:19:57.560 --> 1:20:00.120
 people sort of woke up after 2016

1:20:00.120 --> 1:20:02.560
 and a lot of people are like,

1:20:02.560 --> 1:20:05.000
 okay, the country is a lot more polarized

1:20:05.000 --> 1:20:08.080
 and there's a lot more stuff here than we realized.

1:20:08.080 --> 1:20:11.800
 Why weren't these internet companies on top of this?

1:20:11.800 --> 1:20:16.800
 And I think at that point it was reasonable feedback

1:20:18.760 --> 1:20:22.400
 that some of this technology had started becoming possible.

1:20:22.400 --> 1:20:25.320
 And at that point, I really did feel like

1:20:25.320 --> 1:20:27.920
 we needed to make a substantially larger investment.

1:20:27.920 --> 1:20:29.680
 We'd already worked on this stuff a lot,

1:20:29.680 --> 1:20:32.400
 on AI and on these integrity problems,

1:20:32.400 --> 1:20:35.360
 but that we should basically invest,

1:20:35.360 --> 1:20:37.080
 have a thousand or more engineers

1:20:37.080 --> 1:20:39.160
 basically work on building these AI systems

1:20:39.160 --> 1:20:41.600
 to be able to go and proactively identify the stuff

1:20:41.600 --> 1:20:43.680
 across all these different areas.

1:20:43.680 --> 1:20:45.360
 Okay, so we went and did that.

1:20:45.360 --> 1:20:48.000
 Now we've built the tools to be able to do that.

1:20:48.000 --> 1:20:50.560
 And now I think it's actually a much more complicated

1:20:50.560 --> 1:20:53.400
 set of philosophical rather than technical questions,

1:20:53.400 --> 1:20:56.960
 which is the exact policies, which are okay.

1:20:56.960 --> 1:21:01.960
 Now, the way that we basically hold ourselves accountable

1:21:01.960 --> 1:21:04.400
 is we issue these transparency reports every quarter

1:21:04.400 --> 1:21:06.320
 and the metric that we track is for each of these

1:21:06.320 --> 1:21:10.240
 20 types of harmful content.

1:21:10.240 --> 1:21:12.400
 How much of that content are we taking down

1:21:12.400 --> 1:21:14.320
 before someone even has to report it to us?

1:21:14.320 --> 1:21:17.000
 So how effective is our AI at doing this?

1:21:17.000 --> 1:21:19.440
 But that basically creates this big question,

1:21:19.440 --> 1:21:22.960
 which is okay, now we need to really be careful

1:21:22.960 --> 1:21:25.440
 about how proactive we set the AI

1:21:25.440 --> 1:21:28.000
 and where the exact policy lines are

1:21:28.000 --> 1:21:30.200
 around what we're taking down.

1:21:30.200 --> 1:21:35.200
 It's certainly at a point now where I felt like

1:21:35.200 --> 1:21:37.720
 at the beginning of that journey

1:21:37.720 --> 1:21:42.720
 of building those AI systems, there was a lot of push.

1:21:43.160 --> 1:21:44.360
 There's saying, okay, you've got to do more.

1:21:44.360 --> 1:21:46.320
 There's clearly a lot more bad content

1:21:46.320 --> 1:21:49.880
 that people aren't reporting or that you're not getting to

1:21:49.880 --> 1:21:51.200
 and you need to get more effective at that.

1:21:51.200 --> 1:21:52.920
 And I was pretty sympathetic to that.

1:21:52.920 --> 1:21:54.800
 But then I think at some point along the way,

1:21:54.800 --> 1:21:58.960
 there started to be almost equal issues on both sides

1:21:58.960 --> 1:22:00.960
 of, okay, actually you're kind of taking down

1:22:00.960 --> 1:22:02.080
 too much stuff, right?

1:22:02.080 --> 1:22:05.560
 Or some of the stuff is borderline

1:22:05.560 --> 1:22:07.560
 and it wasn't really bothering anyone

1:22:07.560 --> 1:22:09.640
 and they didn't report it.

1:22:09.640 --> 1:22:13.000
 So is that really an issue that you need to take down?

1:22:13.000 --> 1:22:15.440
 Whereas we still have the critique on the other side too

1:22:15.440 --> 1:22:18.560
 where a lot of people think we're not doing enough.

1:22:18.560 --> 1:22:21.840
 So it's become, as we built the technical capacity,

1:22:21.840 --> 1:22:25.960
 I think it becomes more philosophically interesting almost

1:22:25.960 --> 1:22:27.520
 where you wanna be on the line.

1:22:27.520 --> 1:22:31.160
 And I just think you don't want one person

1:22:31.160 --> 1:22:32.440
 making those decisions.

1:22:32.440 --> 1:22:33.760
 So we've also tried to innovate

1:22:33.760 --> 1:22:36.520
 in terms of building out this independent oversight board,

1:22:36.520 --> 1:22:39.520
 which has people who are dedicated to free expression

1:22:39.520 --> 1:22:43.640
 but from around the world who people can appeal cases to.

1:22:43.640 --> 1:22:46.200
 So a lot of the most controversial cases basically go to them

1:22:46.200 --> 1:22:47.640
 and they make the final binding decision

1:22:47.640 --> 1:22:49.080
 on how we should handle that.

1:22:49.080 --> 1:22:50.680
 And then of course, their decisions,

1:22:50.680 --> 1:22:53.000
 we then try to figure out what the principles are

1:22:53.000 --> 1:22:55.760
 behind those and encode them into the algorithms.

1:22:55.760 --> 1:22:58.080
 And how are those people chosen, which, you know,

1:22:58.080 --> 1:23:00.200
 you're outsourcing a difficult decision.

1:23:00.200 --> 1:23:02.560
 Yeah, the initial people,

1:23:02.560 --> 1:23:07.560
 we chose a handful of chairs for the group

1:23:09.040 --> 1:23:12.480
 and we basically chose the people

1:23:12.480 --> 1:23:15.600
 for a commitment to free expression

1:23:16.480 --> 1:23:19.640
 and like a broad understanding of human rights

1:23:19.640 --> 1:23:21.520
 and the trade offs around free expression.

1:23:21.520 --> 1:23:22.720
 So they fundamentally people

1:23:22.720 --> 1:23:24.880
 who are gonna lean towards free expression.

1:23:24.880 --> 1:23:26.040
 Towards freedom of speech.

1:23:26.040 --> 1:23:28.560
 Okay, so there's also this idea of fact checkers.

1:23:28.560 --> 1:23:31.600
 So jumping around to the misinformation questions,

1:23:31.600 --> 1:23:33.120
 especially during COVID,

1:23:33.120 --> 1:23:36.080
 which is an exceptionally speaking of polarization.

1:23:36.080 --> 1:23:38.240
 Can I speak to the COVID thing?

1:23:38.240 --> 1:23:40.240
 I mean, I think one of the hardest set of questions

1:23:40.240 --> 1:23:41.200
 around free expression,

1:23:41.200 --> 1:23:42.240
 because you asked about Georgetown

1:23:42.240 --> 1:23:43.840
 has my stance fundamentally changed?

1:23:43.840 --> 1:23:48.400
 And the answer to that is no, my stance has not changed.

1:23:48.400 --> 1:23:52.040
 It is fundamentally the same as when I was talking

1:23:52.040 --> 1:23:56.480
 at Georgetown from a philosophical perspective.

1:23:56.480 --> 1:24:01.480
 The challenge with free speech is that everyone agrees

1:24:01.840 --> 1:24:05.440
 that there is a line where if you're actually

1:24:05.440 --> 1:24:08.160
 about to do physical harm to people

1:24:08.160 --> 1:24:10.560
 that there should be restrictions.

1:24:10.560 --> 1:24:13.960
 So, I mean, there's the famous Supreme Court

1:24:13.960 --> 1:24:15.120
 historical example of like,

1:24:15.120 --> 1:24:17.200
 you can't yell fire in a crowded theater.

1:24:18.040 --> 1:24:20.360
 The thing that everyone disagrees on

1:24:20.360 --> 1:24:22.680
 is what is the definition of real harm?

1:24:22.680 --> 1:24:24.560
 Where I think some people think,

1:24:24.560 --> 1:24:27.920
 okay, this should only be a very literal,

1:24:27.920 --> 1:24:29.840
 I mean, take it back to the bullying conversation

1:24:29.840 --> 1:24:32.760
 we were just having, where is it just harm

1:24:32.760 --> 1:24:34.800
 if the person is about to hurt themselves

1:24:34.800 --> 1:24:36.640
 because they've been bullied so hard?

1:24:36.640 --> 1:24:39.880
 Or is it actually harm like as they're being bullied?

1:24:39.880 --> 1:24:42.160
 And kind of at what point in the spectrum is that?

1:24:42.160 --> 1:24:44.480
 And that's the part that there's not agreement on.

1:24:44.480 --> 1:24:47.000
 But I think what people agree on pretty broadly

1:24:47.000 --> 1:24:49.440
 is that when there is an acute threat

1:24:49.440 --> 1:24:52.960
 that it does make sense from a societal perspective

1:24:52.960 --> 1:24:57.120
 to tolerate less speech.

1:24:57.120 --> 1:24:59.560
 That could be potentially harmful in that acute situation.

1:24:59.560 --> 1:25:02.840
 So I think where COVID got very difficult is,

1:25:02.840 --> 1:25:06.000
 I don't think anyone expected this to be going on for years.

1:25:06.000 --> 1:25:10.360
 But if you'd kind of asked now a priori,

1:25:10.360 --> 1:25:14.880
 would a global pandemic where a lot of people are dying

1:25:14.880 --> 1:25:19.040
 and catching this, is that an emergency

1:25:19.040 --> 1:25:21.560
 that where you'd kind of consider it

1:25:21.560 --> 1:25:25.600
 that it's problematic to basically yell fire

1:25:25.600 --> 1:25:26.840
 in a crowded theater?

1:25:26.840 --> 1:25:29.000
 I think that that probably passes that test.

1:25:29.000 --> 1:25:32.320
 So I think that it's a very tricky situation,

1:25:32.320 --> 1:25:35.240
 but I think the fundamental commitment

1:25:35.240 --> 1:25:38.200
 to free expression is there.

1:25:38.200 --> 1:25:39.840
 And that's what I believe.

1:25:39.840 --> 1:25:41.440
 And again, I don't think you start this company

1:25:41.440 --> 1:25:42.720
 unless you care about people being able

1:25:42.720 --> 1:25:44.800
 to express themselves as much as possible.

1:25:44.800 --> 1:25:48.880
 But I think that that's the question,

1:25:48.880 --> 1:25:50.480
 is how do you define what the harm is

1:25:50.480 --> 1:25:52.440
 and how acute that is?

1:25:52.440 --> 1:25:55.440
 And what are the institutions that define that harm?

1:25:55.440 --> 1:25:59.720
 A lot of the criticism is that the CDC, the WHO,

1:25:59.720 --> 1:26:03.800
 the institutions we've come to trust as a civilization

1:26:03.800 --> 1:26:07.760
 to give the line of what is and isn't harm

1:26:07.760 --> 1:26:11.640
 in terms of health policy have failed in many ways,

1:26:11.640 --> 1:26:14.320
 in small ways and in big ways, depending on who you ask.

1:26:14.320 --> 1:26:17.120
 And then the perspective of meta and Facebook is like,

1:26:17.120 --> 1:26:20.160
 well, where the hell do I get the information

1:26:20.160 --> 1:26:22.400
 of what is and isn't misinformation?

1:26:22.400 --> 1:26:25.160
 So it's a really difficult place to be in,

1:26:25.160 --> 1:26:26.720
 but it's great to hear that you're leaning

1:26:26.720 --> 1:26:30.140
 towards freedom of speech on this aspect.

1:26:30.140 --> 1:26:33.000
 And again, I think this actually calls to the fact

1:26:33.000 --> 1:26:35.320
 that we need to reform institutions

1:26:35.320 --> 1:26:36.800
 that help keep an open mind

1:26:36.800 --> 1:26:39.000
 of what is and isn't misinformation.

1:26:39.880 --> 1:26:44.600
 And misinformation has been used to bully on the internet.

1:26:44.600 --> 1:26:46.920
 I mean, I just have, I'm friends with Joe Rogan

1:26:46.920 --> 1:26:49.280
 and he is called as a,

1:26:49.280 --> 1:26:51.280
 I remember hanging out with him in Vegas

1:26:51.280 --> 1:26:54.660
 and somebody yelled, stop spreading misinformation.

1:26:54.660 --> 1:26:57.640
 I mean, and there's a lot of people that follow him

1:26:57.640 --> 1:26:59.880
 that believe he's not spreading misinformation.

1:26:59.880 --> 1:27:02.900
 Like you can't just not acknowledge the fact

1:27:02.900 --> 1:27:05.720
 that there's a large number of people

1:27:05.720 --> 1:27:08.840
 that have a different definition of misinformation.

1:27:08.840 --> 1:27:10.760
 And that's such a tough place to be.

1:27:10.760 --> 1:27:11.840
 Like who do you listen to?

1:27:11.840 --> 1:27:15.320
 Do you listen to quote unquote experts who gets,

1:27:15.320 --> 1:27:17.600
 as a person who has a PhD, I gotta say,

1:27:17.600 --> 1:27:20.160
 I mean, I'm not sure I know what defines an expert,

1:27:21.120 --> 1:27:22.720
 especially in a new,

1:27:24.080 --> 1:27:29.080
 in a totally new pandemic or a new catastrophic event,

1:27:29.160 --> 1:27:31.520
 especially when politics is involved

1:27:31.520 --> 1:27:33.320
 and especially when the news are,

1:27:33.320 --> 1:27:37.440
 the media involved that can propagate

1:27:37.440 --> 1:27:39.520
 sort of outrageous narratives

1:27:39.520 --> 1:27:40.720
 and thereby make a lot of money.

1:27:40.720 --> 1:27:41.800
 Like what the hell?

1:27:41.800 --> 1:27:43.200
 Where's the source of truth?

1:27:43.200 --> 1:27:45.480
 And then everybody turns to Facebook.

1:27:45.480 --> 1:27:48.040
 It's like, please tell me what the source of truth is.

1:27:49.040 --> 1:27:50.740
 Well, I mean, well, how would you handle this

1:27:50.740 --> 1:27:52.680
 if you were in my position?

1:27:52.680 --> 1:27:55.160
 Is very, very, very, very difficult.

1:27:55.160 --> 1:27:56.440
 I would say,

1:27:59.400 --> 1:28:02.680
 I would more speak about how difficult the choices are

1:28:02.680 --> 1:28:04.040
 and be transparent about like,

1:28:04.040 --> 1:28:05.360
 what the hell do you do with this?

1:28:05.360 --> 1:28:07.080
 Like here, you got exactly,

1:28:07.080 --> 1:28:08.800
 ask the exact question you just asked me,

1:28:08.800 --> 1:28:10.840
 but to the broader public, like, okay, yeah,

1:28:10.840 --> 1:28:12.400
 you guys tell me what to do.

1:28:12.400 --> 1:28:14.200
 So like crowdsource it.

1:28:14.200 --> 1:28:19.200
 And then the other aspect is when you spoke really eloquently

1:28:19.800 --> 1:28:23.440
 about the fact that there's this going back and forth

1:28:23.440 --> 1:28:25.240
 and now there's a feeling like you're censoring

1:28:25.240 --> 1:28:26.720
 a little bit too much.

1:28:26.720 --> 1:28:30.240
 So I would lean, I would try to be ahead of that feeling.

1:28:30.240 --> 1:28:33.080
 I would now lean towards freedom of speech and say,

1:28:33.080 --> 1:28:36.240
 we're not the ones that are going to define misinformation.

1:28:36.240 --> 1:28:40.040
 Let it be a public debate, let the idea stand.

1:28:40.040 --> 1:28:44.280
 And I actually place, this idea of misinformation,

1:28:44.280 --> 1:28:46.360
 I place the responsibility

1:28:46.360 --> 1:28:50.020
 on the poor communication skills of scientists.

1:28:50.020 --> 1:28:52.560
 They should be in the battlefield of ideas

1:28:52.560 --> 1:28:57.400
 and everybody who is spreading information

1:28:57.400 --> 1:29:00.400
 against the vaccine, they should not be censored.

1:29:00.400 --> 1:29:03.040
 They should be talked with and you should show the data,

1:29:03.040 --> 1:29:04.800
 you should have open discussion

1:29:04.800 --> 1:29:07.080
 as opposed to rolling your eyes and saying,

1:29:07.080 --> 1:29:09.840
 I'm the expert, I know what I'm talking about.

1:29:09.840 --> 1:29:13.240
 No, you need to convince people, it's a battle of ideas.

1:29:13.240 --> 1:29:15.360
 So that's the whole point of freedom of speech.

1:29:15.360 --> 1:29:17.120
 It's the way to defeat bad ideas

1:29:17.120 --> 1:29:20.080
 is with good ideas, with speech.

1:29:20.080 --> 1:29:22.080
 So like the responsibility here falls

1:29:22.080 --> 1:29:26.560
 on the poor communication skills of scientists.

1:29:26.560 --> 1:29:31.560
 Thanks to social media, scientists are not communicators.

1:29:32.180 --> 1:29:34.040
 They have the power to communicate.

1:29:34.040 --> 1:29:36.800
 Some of the best stuff I've seen about COVID

1:29:36.800 --> 1:29:38.840
 from doctors is on social media.

1:29:38.840 --> 1:29:41.520
 It's a way to learn to respond really quickly,

1:29:41.520 --> 1:29:43.800
 to go faster than the peer review process.

1:29:43.800 --> 1:29:45.460
 And so they just need to get way better

1:29:45.460 --> 1:29:46.480
 at that communication.

1:29:46.480 --> 1:29:50.060
 And also by better, I don't mean just convincing,

1:29:50.060 --> 1:29:51.800
 I also mean speak with humility,

1:29:51.800 --> 1:29:54.280
 don't talk down to people, all those kinds of things.

1:29:54.280 --> 1:29:56.000
 And as a platform, I would say,

1:29:56.860 --> 1:29:59.800
 I would step back a little bit.

1:29:59.800 --> 1:30:00.800
 Not all the way, of course,

1:30:00.800 --> 1:30:03.520
 because there's a lot of stuff that can cause real harm

1:30:03.520 --> 1:30:04.440
 as we've talked about,

1:30:04.440 --> 1:30:06.920
 but you lean more towards freedom of speech

1:30:06.920 --> 1:30:09.560
 because then people from a brand perspective

1:30:09.560 --> 1:30:12.740
 wouldn't be blaming you for the other ills of society,

1:30:13.760 --> 1:30:14.600
 which there are many.

1:30:14.600 --> 1:30:19.600
 The institutions have flaws, the political divide,

1:30:19.840 --> 1:30:23.400
 obviously politicians have flaws, that's news.

1:30:23.400 --> 1:30:28.040
 The media has flaws that they're all trying to work with.

1:30:28.040 --> 1:30:31.080
 And because of the central place of Facebook in the world,

1:30:31.080 --> 1:30:34.320
 all of those flaws somehow kind of propagate to Facebook.

1:30:34.320 --> 1:30:38.160
 And you're sitting there as Plato, the philosopher,

1:30:38.160 --> 1:30:40.720
 have to answer to some of the most difficult questions

1:30:40.720 --> 1:30:43.960
 asking, being asked of human civilization.

1:30:43.960 --> 1:30:47.000
 So I don't know, maybe this is an American answer though,

1:30:47.000 --> 1:30:48.420
 to lean towards freedom of speech.

1:30:48.420 --> 1:30:50.320
 I don't know if that applies globally.

1:30:51.300 --> 1:30:52.640
 So yeah, I don't know.

1:30:52.640 --> 1:30:57.400
 But transparency and saying, I think as a technologist,

1:30:57.400 --> 1:30:59.560
 one of the things I sense about Facebook and meta

1:30:59.560 --> 1:31:02.360
 when people talk about this company

1:31:02.360 --> 1:31:04.960
 is they don't necessarily understand

1:31:04.960 --> 1:31:06.880
 fully how difficult the problem is.

1:31:06.880 --> 1:31:08.440
 You talked about AI has to catch

1:31:08.440 --> 1:31:11.720
 a bunch of harmful stuff really quickly.

1:31:11.720 --> 1:31:14.600
 Just the sea of data you have to deal with.

1:31:14.600 --> 1:31:16.700
 It's a really difficult problem.

1:31:16.700 --> 1:31:18.400
 So like any of the critics,

1:31:18.400 --> 1:31:21.520
 if you just hand them the helm for a week,

1:31:22.840 --> 1:31:24.360
 let's see how well you can do.

1:31:25.400 --> 1:31:28.160
 Like that, to me, that's definitely something

1:31:28.160 --> 1:31:31.320
 that would wake people up to how difficult this problem is

1:31:31.320 --> 1:31:32.640
 if there's more transparency

1:31:32.640 --> 1:31:35.580
 of saying how difficult this problem is.

1:31:35.580 --> 1:31:37.800
 Let me ask you about, on the AI front,

1:31:37.800 --> 1:31:41.600
 just because you mentioned language and my ineloquence.

1:31:41.600 --> 1:31:44.120
 Translation is something I wanted to ask you about.

1:31:44.120 --> 1:31:47.760
 And first, just to give a shout out to the supercomputer.

1:31:47.760 --> 1:31:51.960
 You've recently announced the AI research supercluster, RSC.

1:31:51.960 --> 1:31:54.680
 Obviously, I'm somebody who loves the GPUs.

1:31:54.680 --> 1:31:57.120
 It currently has 6,000 GPUs.

1:31:57.120 --> 1:32:02.120
 NVIDIA DGX A100 is the systems that have

1:32:02.160 --> 1:32:04.080
 in total 6,000 GPUs.

1:32:04.080 --> 1:32:06.560
 And it will eventually, maybe this year,

1:32:06.560 --> 1:32:10.000
 maybe soon, will have 16,000 GPUs.

1:32:10.000 --> 1:32:11.680
 So it can do a bunch of different kinds

1:32:11.680 --> 1:32:15.040
 of machine learning applications.

1:32:15.040 --> 1:32:18.560
 There's a cool thing on the distributed storage aspect

1:32:18.560 --> 1:32:19.680
 and all that kind of stuff.

1:32:19.680 --> 1:32:23.040
 So one of the applications that I think is super exciting

1:32:23.040 --> 1:32:26.320
 is translation, real time translation.

1:32:26.320 --> 1:32:29.120
 I mentioned to you that having a conversation,

1:32:29.120 --> 1:32:30.200
 I speak Russian fluently,

1:32:30.200 --> 1:32:32.360
 I speak English somewhat fluently,

1:32:32.360 --> 1:32:34.940
 and having a conversation with Vladimir Putin,

1:32:34.940 --> 1:32:36.040
 say, as a use case.

1:32:36.040 --> 1:32:38.480
 Me, as a user, coming to you as a use case.

1:32:38.480 --> 1:32:42.520
 We both speak each other's language.

1:32:42.520 --> 1:32:45.040
 I speak Russian, he speaks English.

1:32:45.040 --> 1:32:48.000
 How can we have that communication go well

1:32:48.000 --> 1:32:49.400
 with the help of AI?

1:32:49.400 --> 1:32:52.440
 I think it's such a beautiful and a powerful application

1:32:52.440 --> 1:32:54.720
 of AI to connect the world,

1:32:54.720 --> 1:32:57.560
 that bridge the gap, not necessarily between me and Putin,

1:32:57.560 --> 1:33:01.020
 but people that don't have that shared language.

1:33:01.960 --> 1:33:04.120
 Can you just speak about your vision with translation?

1:33:04.120 --> 1:33:06.680
 Because I think that's a really exciting application.

1:33:06.680 --> 1:33:08.000
 If you're trying to help people connect

1:33:08.000 --> 1:33:09.400
 all around the world,

1:33:09.400 --> 1:33:11.600
 a lot of content is produced in one language

1:33:11.600 --> 1:33:14.720
 and people in all these other places are interested in it.

1:33:14.720 --> 1:33:16.640
 So being able to translate that

1:33:17.720 --> 1:33:20.560
 just unlocks a lot of value on a day to day basis.

1:33:20.560 --> 1:33:24.400
 I mean, so the kind of AI around translation is interesting

1:33:24.400 --> 1:33:27.880
 because it's gone through a bunch of iterations.

1:33:27.880 --> 1:33:29.680
 But the basic state of the art

1:33:29.680 --> 1:33:32.560
 is that you don't wanna go through

1:33:33.560 --> 1:33:37.680
 different kind of intermediate symbolic

1:33:38.800 --> 1:33:42.520
 representations of language or something like that.

1:33:42.520 --> 1:33:46.920
 You basically wanna be able to map the concepts

1:33:46.920 --> 1:33:49.300
 and basically go directly from one language to another.

1:33:49.300 --> 1:33:53.040
 And you just can train bigger and bigger models

1:33:53.040 --> 1:33:54.120
 in order to be able to do that.

1:33:54.120 --> 1:33:58.160
 And that's where the research supercluster comes in

1:33:58.160 --> 1:34:01.080
 is basically a lot of the trend in machine learning

1:34:01.080 --> 1:34:03.400
 is just you're building bigger and bigger models

1:34:03.400 --> 1:34:05.700
 and you just need a lot of computation to train them.

1:34:05.700 --> 1:34:08.360
 So it's not that like the translation would run

1:34:08.360 --> 1:34:12.080
 on the supercomputer, the training of the model,

1:34:12.080 --> 1:34:15.800
 which could have billions or trillions of examples

1:34:15.800 --> 1:34:18.200
 of just basically that.

1:34:19.080 --> 1:34:22.360
 You're training models on this supercluster

1:34:22.360 --> 1:34:27.120
 in days or weeks that might take a much longer period of time

1:34:27.120 --> 1:34:28.120
 on a smaller cluster.

1:34:28.120 --> 1:34:30.200
 So it just wouldn't be practical for most teams to do.

1:34:30.200 --> 1:34:32.280
 But the translation work,

1:34:34.560 --> 1:34:38.160
 we're basically getting from being able to go

1:34:38.160 --> 1:34:40.900
 between about a hundred languages seamlessly today

1:34:42.280 --> 1:34:46.740
 to being able to go to about 300 languages in the near term.

1:34:46.740 --> 1:34:48.720
 So from any language to any other language.

1:34:48.720 --> 1:34:49.560
 Yeah.

1:34:49.560 --> 1:34:53.880
 And part of the issue when you get closer to more languages

1:34:53.880 --> 1:34:57.680
 is some of these get to be pretty,

1:34:59.840 --> 1:35:01.920
 not very popular languages, right?

1:35:01.920 --> 1:35:04.280
 Where there isn't that much content in them.

1:35:04.280 --> 1:35:07.280
 So you end up having less data

1:35:07.280 --> 1:35:10.960
 and you need to kind of use a model that you've built up

1:35:10.960 --> 1:35:12.080
 around other examples.

1:35:12.080 --> 1:35:14.040
 And this is one of the big questions around AI

1:35:14.040 --> 1:35:16.680
 is like how generalizable can things be?

1:35:16.680 --> 1:35:18.760
 And that I think is one of the things

1:35:18.760 --> 1:35:19.800
 that's just kind of exciting here

1:35:19.800 --> 1:35:21.300
 from a technical perspective.

1:35:21.300 --> 1:35:23.800
 But capturing, we talked about this with the metaverse,

1:35:23.800 --> 1:35:26.440
 capturing the magic of human to human interaction.

1:35:26.440 --> 1:35:29.180
 So me and Putin, okay.

1:35:29.180 --> 1:35:30.020
 Again, this is therapy session.

1:35:30.020 --> 1:35:31.080
 I mean, it's a tough example

1:35:31.080 --> 1:35:33.360
 because you actually both speak Russian and English.

1:35:33.360 --> 1:35:34.200
 No, but that's.

1:35:34.200 --> 1:35:35.020
 But in the future.

1:35:35.020 --> 1:35:37.740
 I see it as a touring test of a kind

1:35:37.740 --> 1:35:40.440
 because we would both like to have an AI that improves

1:35:40.440 --> 1:35:42.240
 because I don't speak Russian that well.

1:35:42.240 --> 1:35:44.200
 He doesn't speak English that well.

1:35:44.200 --> 1:35:45.040
 Yeah.

1:35:45.040 --> 1:35:48.640
 It would be nice to outperform our abilities

1:35:48.640 --> 1:35:50.640
 and it sets a really nice bar

1:35:50.640 --> 1:35:53.600
 because I think AI can really help in translation

1:35:53.600 --> 1:35:55.720
 for people that don't speak the language at all,

1:35:55.720 --> 1:36:00.120
 but to actually capture the magic of the chemistry,

1:36:00.120 --> 1:36:03.240
 the translation, which would make the metaverse

1:36:03.240 --> 1:36:04.800
 super immersive.

1:36:04.800 --> 1:36:05.840
 I mean, that's exciting.

1:36:05.840 --> 1:36:08.700
 You remove the barrier of language, period.

1:36:08.700 --> 1:36:11.240
 Yeah, so when people think about translation,

1:36:11.240 --> 1:36:14.240
 I think a lot of that is they're thinking about text to text,

1:36:14.240 --> 1:36:17.120
 but speech to speech, I think is a whole nother thing.

1:36:17.120 --> 1:36:19.080
 And I mean, one of the big lessons on that,

1:36:19.080 --> 1:36:22.120
 which I was referring to before is I think early models,

1:36:22.120 --> 1:36:23.800
 it's like, all right, they take speech,

1:36:23.800 --> 1:36:25.080
 they translate it to text,

1:36:25.080 --> 1:36:26.680
 translate the text to another language

1:36:26.680 --> 1:36:29.400
 and then kind of output that as speech in that language.

1:36:29.400 --> 1:36:30.440
 And you don't wanna do that.

1:36:30.440 --> 1:36:32.260
 You just wanna be able to go directly from speech

1:36:32.260 --> 1:36:34.180
 in one language to speech in another language

1:36:34.180 --> 1:36:36.400
 and build up the models to do that.

1:36:36.400 --> 1:36:39.140
 And I mean, I think one of the,

1:36:39.140 --> 1:36:40.760
 there have been,

1:36:40.760 --> 1:36:42.860
 when you look at the progress in machine learning,

1:36:42.860 --> 1:36:47.240
 there have been big advances in the techniques,

1:36:47.240 --> 1:36:51.560
 some of the advances in self supervised learning,

1:36:51.560 --> 1:36:52.920
 which I know you talked to Jan about

1:36:52.920 --> 1:36:55.320
 and he's like one of the leading thinkers in this area.

1:36:55.320 --> 1:36:57.560
 I just think that that stuff is really exciting,

1:36:57.560 --> 1:36:59.840
 but then you couple that with the ability

1:36:59.840 --> 1:37:02.480
 to just throw larger and larger amounts of compute

1:37:02.480 --> 1:37:04.000
 at training these models.

1:37:04.000 --> 1:37:05.600
 And you can just do a lot of things

1:37:05.600 --> 1:37:09.360
 that were harder to do before.

1:37:09.360 --> 1:37:12.960
 But we're asking more of our systems too, right?

1:37:12.960 --> 1:37:14.880
 So if you think about the applications

1:37:14.880 --> 1:37:18.400
 that we're gonna need for the metaverse,

1:37:18.400 --> 1:37:19.400
 or think about it, okay,

1:37:19.400 --> 1:37:21.480
 so let's talk about AR here for a second.

1:37:21.480 --> 1:37:23.140
 You're gonna have these glasses,

1:37:23.140 --> 1:37:24.760
 they're gonna look hopefully

1:37:24.760 --> 1:37:28.140
 like a normal ish looking pair of glasses,

1:37:28.140 --> 1:37:31.240
 but they're gonna be able to put holograms in the world

1:37:31.240 --> 1:37:35.980
 and intermix virtual and physical objects in your scene.

1:37:35.980 --> 1:37:39.080
 And one of the things that's gonna be unique about this

1:37:39.080 --> 1:37:41.240
 compared to every other computing device

1:37:41.240 --> 1:37:42.580
 that you've had before,

1:37:42.580 --> 1:37:45.160
 is that this is gonna be the first computing device

1:37:45.160 --> 1:37:47.560
 that has all the same signals

1:37:47.560 --> 1:37:49.480
 about what's going on around you that you have.

1:37:49.480 --> 1:37:50.480
 Right, so your phone,

1:37:50.480 --> 1:37:54.140
 you can have it take a photo or a video,

1:37:54.140 --> 1:37:56.600
 but I mean, these glasses are gonna,

1:37:56.600 --> 1:37:57.480
 whenever you activate them,

1:37:57.480 --> 1:37:59.000
 they're gonna be able to see what you see

1:37:59.000 --> 1:38:00.240
 from your perspective,

1:38:00.240 --> 1:38:01.540
 they're gonna be able to hear what you hear

1:38:01.540 --> 1:38:03.440
 because the microphones and all that

1:38:03.440 --> 1:38:05.800
 are gonna be right around where your ears are.

1:38:05.800 --> 1:38:08.160
 So you're gonna want an AI assistant,

1:38:08.160 --> 1:38:10.240
 that's a new kind of AI assistant

1:38:10.240 --> 1:38:13.880
 that can basically help you process the world

1:38:13.880 --> 1:38:17.040
 from this first person perspective

1:38:17.040 --> 1:38:18.580
 or from the perspective that you have.

1:38:18.580 --> 1:38:21.800
 And the utility of that is gonna be huge,

1:38:21.800 --> 1:38:25.440
 but the kinds of AI models that we're gonna need

1:38:25.440 --> 1:38:27.400
 are going to be just,

1:38:28.640 --> 1:38:30.040
 I don't know, there's a lot that we're gonna need

1:38:30.040 --> 1:38:31.840
 to basically make advances in.

1:38:31.840 --> 1:38:33.760
 But I mean, but that's why I think these concepts

1:38:33.760 --> 1:38:36.600
 of the metaverse and the advances in AI

1:38:36.600 --> 1:38:38.720
 are so fundamentally interlinked

1:38:40.200 --> 1:38:42.880
 that I mean, they're kind of enabling each other.

1:38:42.880 --> 1:38:45.440
 Yeah, like the world builder is a really cool idea.

1:38:45.440 --> 1:38:47.240
 Like you can be like a Bob Ross,

1:38:47.240 --> 1:38:49.120
 like I'm gonna put a little tree right here.

1:38:49.120 --> 1:38:49.940
 Yeah.

1:38:49.940 --> 1:38:51.200
 I need a little tree, it's missing a little tree.

1:38:51.200 --> 1:38:52.960
 And then, but at scale,

1:38:52.960 --> 1:38:55.680
 like enriching your experience in all kinds of ways.

1:38:55.680 --> 1:38:56.960
 You mentioned the assistant too,

1:38:56.960 --> 1:39:00.020
 that's really interesting how you can have AI assistants

1:39:00.020 --> 1:39:01.640
 helping you out on different levels

1:39:01.640 --> 1:39:04.000
 of sort of intimacy of communication.

1:39:04.000 --> 1:39:05.480
 It could be just like scheduling

1:39:05.480 --> 1:39:08.120
 or it could be like almost like therapy.

1:39:08.120 --> 1:39:09.880
 Clearly I need some.

1:39:09.880 --> 1:39:11.160
 So let me ask you,

1:39:11.160 --> 1:39:14.000
 you're one of the most successful people ever.

1:39:14.000 --> 1:39:16.240
 You've built an incredible company

1:39:16.240 --> 1:39:18.080
 that has a lot of impact.

1:39:18.080 --> 1:39:21.820
 What advice do you have for young people today?

1:39:23.120 --> 1:39:25.480
 How to live a life they can be proud of?

1:39:25.480 --> 1:39:30.420
 How to build something that can have a big positive impact

1:39:30.420 --> 1:39:31.260
 on the world?

1:39:31.260 --> 1:39:36.260
 Well, let's break that down.

1:39:37.460 --> 1:39:41.300
 Cause I think you proud of, have a big positive impact.

1:39:41.300 --> 1:39:42.320
 Well, you're actually listening.

1:39:42.320 --> 1:39:43.880
 And how to live your life

1:39:43.880 --> 1:39:47.580
 are actually three different things that I think,

1:39:47.580 --> 1:39:48.900
 I mean, they could line up,

1:39:48.900 --> 1:39:52.460
 but, and also like what age of people are you talking to?

1:39:52.460 --> 1:39:53.500
 Cause I mean, I can like.

1:39:53.500 --> 1:39:54.700
 High school and college.

1:39:54.700 --> 1:39:56.500
 So you don't really know what you're doing,

1:39:56.500 --> 1:39:58.220
 but your dream big.

1:39:58.220 --> 1:40:02.280
 And you really have a chance to do something unprecedented.

1:40:02.280 --> 1:40:03.120
 Yeah.

1:40:04.180 --> 1:40:05.020
 So I guess just to.

1:40:05.020 --> 1:40:06.300
 Also for people my age.

1:40:06.300 --> 1:40:09.620
 Okay, so let's maybe start with the kind of most

1:40:09.620 --> 1:40:12.060
 philosophical and abstract version of this.

1:40:12.060 --> 1:40:16.220
 Every night when I put my daughters to bed,

1:40:16.220 --> 1:40:18.420
 we go through this thing and like,

1:40:20.380 --> 1:40:21.740
 they call it the good night things.

1:40:21.740 --> 1:40:25.440
 Cause we're basically what we talk about at night.

1:40:25.440 --> 1:40:29.700
 And I just, I go through them.

1:40:29.700 --> 1:40:31.460
 Sounds like a good show.

1:40:31.460 --> 1:40:32.700
 The good night things.

1:40:32.700 --> 1:40:33.540
 Yeah.

1:40:33.540 --> 1:40:34.360
 Priscilla's always asking, she's like,

1:40:34.360 --> 1:40:35.200
 can I get good night things?

1:40:35.200 --> 1:40:36.040
 Like, I don't know.

1:40:36.040 --> 1:40:37.100
 You go to bed too early.

1:40:37.100 --> 1:40:37.940
 But it's,

1:40:41.580 --> 1:40:44.960
 but I basically go through with Max and Augie,

1:40:46.340 --> 1:40:48.940
 what are the things that are most important in life?

1:40:48.940 --> 1:40:49.780
 Right.

1:40:49.780 --> 1:40:51.560
 That I just, it's like, what do I want them to remember

1:40:51.560 --> 1:40:53.940
 and just have like really ingrained in them as they grow up?

1:40:53.940 --> 1:40:56.740
 And it's health, right?

1:40:56.740 --> 1:40:58.800
 Making sure that you take care of yourself

1:40:58.800 --> 1:41:00.700
 and keep yourself in good shape,

1:41:00.700 --> 1:41:02.940
 loving friends and family, right?

1:41:02.940 --> 1:41:05.380
 Because having the relationships,

1:41:05.380 --> 1:41:08.700
 the family and making time for friends,

1:41:08.700 --> 1:41:12.900
 I think is perhaps one of the most important things.

1:41:13.820 --> 1:41:16.040
 And then the third is maybe a little more amorphous,

1:41:16.040 --> 1:41:19.420
 but it is something that you're excited about for the future.

1:41:19.420 --> 1:41:21.300
 And when I'm talking to a four year old,

1:41:21.300 --> 1:41:23.500
 often I'll ask her what she's excited about

1:41:23.500 --> 1:41:25.220
 for tomorrow or the week ahead.

1:41:25.220 --> 1:41:29.580
 But I think for most people, it's really hard.

1:41:29.580 --> 1:41:31.440
 I mean, the world is a heavy place.

1:41:31.440 --> 1:41:34.780
 And I think like the way that we navigate it

1:41:34.780 --> 1:41:37.340
 is that we have things that we're looking forward to.

1:41:37.340 --> 1:41:41.620
 So whether it is building AR glasses for the future

1:41:41.620 --> 1:41:45.520
 or being able to celebrate my 10 year wedding anniversary

1:41:45.520 --> 1:41:47.380
 with my wife that's coming up,

1:41:47.380 --> 1:41:48.620
 it's like, I think people,

1:41:48.620 --> 1:41:51.860
 you know, you have things that you're looking forward to.

1:41:51.860 --> 1:41:53.860
 Or for the girls, it's often I want to see mom

1:41:53.860 --> 1:41:54.700
 in the morning, right?

1:41:54.700 --> 1:41:57.020
 It's just, but it's like that's a really critical thing.

1:41:57.020 --> 1:42:00.340
 And then the last thing is I ask them every day,

1:42:00.340 --> 1:42:02.640
 what did you do today to help someone?

1:42:04.340 --> 1:42:07.140
 Because I just think that that's a really critical thing

1:42:07.140 --> 1:42:10.740
 is like, it's easy to kind of get caught up in yourself

1:42:10.740 --> 1:42:14.300
 and kind of stuff that's really far down the road,

1:42:14.300 --> 1:42:17.520
 but like, did you do something just concrete today

1:42:17.520 --> 1:42:18.360
 to help someone?

1:42:18.360 --> 1:42:21.060
 And, you know, it can just be as simple as, okay, yeah,

1:42:21.060 --> 1:42:23.420
 I helped set the table for lunch, right?

1:42:23.420 --> 1:42:26.440
 Or, you know, this other kid in our school

1:42:26.440 --> 1:42:27.900
 was having a hard time with something

1:42:27.900 --> 1:42:29.260
 and I like helped explain it to him.

1:42:29.260 --> 1:42:32.940
 But in that those are, that's sort of like,

1:42:32.940 --> 1:42:36.080
 if you were to boil down my overall life philosophy

1:42:36.080 --> 1:42:40.140
 into what I try to impart to my kids,

1:42:40.140 --> 1:42:43.000
 those are the things that I think are really important.

1:42:43.000 --> 1:42:44.320
 So, okay, so let's say college.

1:42:44.320 --> 1:42:45.860
 So if you're a graduate in college,

1:42:45.860 --> 1:42:50.860
 probably more practical advice, I'm always very focused

1:42:52.340 --> 1:42:53.180
 on people.

1:42:53.180 --> 1:42:57.140
 And I think the most important decision

1:42:57.140 --> 1:42:59.320
 you're probably gonna make if you're in college

1:42:59.320 --> 1:43:01.620
 is who you surround yourself with,

1:43:01.620 --> 1:43:02.960
 because you become like the people

1:43:02.960 --> 1:43:04.620
 you surround yourself with.

1:43:04.620 --> 1:43:09.620
 And I sort of have this hiring heuristic at Metta,

1:43:09.620 --> 1:43:13.620
 which is that I will only hire someone to work for me

1:43:13.620 --> 1:43:17.220
 if I could see myself working for them.

1:43:17.220 --> 1:43:19.020
 Not necessarily that I want them to run the company

1:43:19.020 --> 1:43:22.420
 because I like my job, but in an alternate universe,

1:43:22.420 --> 1:43:23.980
 if it was their company and I was looking

1:43:23.980 --> 1:43:27.060
 to go work somewhere, would I be happy to work for them?

1:43:27.060 --> 1:43:30.220
 And I think that that's a helpful heuristic

1:43:31.220 --> 1:43:33.060
 to help balance, you know,

1:43:33.060 --> 1:43:33.900
 when you're building something like this,

1:43:33.900 --> 1:43:36.060
 there's a lot of pressure to, you know,

1:43:36.060 --> 1:43:37.380
 you wanna build out your team,

1:43:37.380 --> 1:43:39.620
 because there's a lot of stuff that you need to get done.

1:43:39.620 --> 1:43:41.860
 And everyone always says, don't compromise on quality,

1:43:41.860 --> 1:43:42.940
 but there's this question of, okay,

1:43:42.940 --> 1:43:44.020
 well, how do you know that someone is good enough?

1:43:44.020 --> 1:43:46.860
 And I think my answer is, I would want someone

1:43:46.860 --> 1:43:50.660
 to be on my team if I would work for them.

1:43:50.660 --> 1:43:53.300
 But I think it's actually a pretty similar answer

1:43:53.300 --> 1:43:58.300
 to like, if you were choosing friends or a partner

1:43:58.300 --> 1:43:59.460
 or something like that.

1:43:59.460 --> 1:44:01.900
 So when you're kind of in college,

1:44:01.900 --> 1:44:03.580
 trying to figure out what your circle is gonna be,

1:44:03.580 --> 1:44:04.420
 trying to figure out, you know,

1:44:04.420 --> 1:44:05.260
 you're evaluating data,

1:44:05.260 --> 1:44:07.620
 your circle is gonna be trying to figure out, you know,

1:44:07.620 --> 1:44:09.300
 you're evaluating different job opportunities.

1:44:09.300 --> 1:44:12.980
 Who are the people, even if they're gonna be peers

1:44:12.980 --> 1:44:14.420
 in what you're doing,

1:44:14.420 --> 1:44:17.020
 who are the people who in an alternate university,

1:44:17.020 --> 1:44:18.700
 you would wanna work for them,

1:44:18.700 --> 1:44:20.420
 because you think you're gonna learn a lot from them,

1:44:20.420 --> 1:44:24.180
 because they know, because they are kind of values aligned

1:44:24.180 --> 1:44:25.500
 on the things that you care about,

1:44:25.500 --> 1:44:28.260
 and they're gonna like, and they're gonna push you,

1:44:28.260 --> 1:44:29.500
 but also they know different things

1:44:29.500 --> 1:44:30.660
 and have different experiences

1:44:30.660 --> 1:44:32.940
 that are kind of more of what you wanna become like

1:44:32.940 --> 1:44:33.780
 over time.

1:44:33.780 --> 1:44:37.020
 But I don't know, I think probably people are too,

1:44:37.020 --> 1:44:39.100
 in general, objective focused,

1:44:39.100 --> 1:44:42.700
 and maybe not focused enough on the connections

1:44:42.700 --> 1:44:46.620
 and the people who they're basically building relationships

1:44:46.620 --> 1:44:47.460
 with.

1:44:47.460 --> 1:44:48.300
 I don't know what it says about me,

1:44:48.300 --> 1:44:53.300
 but my place in Austin now has seven legged robots.

1:44:53.540 --> 1:44:55.420
 So I'm surrounded myself by robots,

1:44:55.420 --> 1:44:59.140
 which is probably something I should look into.

1:44:59.140 --> 1:45:02.500
 What kind of world would you like to see your daughters

1:45:02.500 --> 1:45:05.460
 grow up in, even after you're gone?

1:45:09.300 --> 1:45:11.500
 Well, I think one of the promises of all the stuff

1:45:11.500 --> 1:45:15.580
 that is getting built now is that it can be a world

1:45:15.580 --> 1:45:20.580
 where more people can just live out their imagination.

1:45:21.780 --> 1:45:23.420
 One of my favorite quotes,

1:45:23.420 --> 1:45:25.140
 I think it was attributed to Picasso,

1:45:25.140 --> 1:45:26.780
 it's that all children are artists,

1:45:26.780 --> 1:45:28.340
 and the challenge is how do you remain one

1:45:28.340 --> 1:45:29.580
 when you grow up?

1:45:29.580 --> 1:45:33.620
 And if you have kids, this is pretty clear,

1:45:33.620 --> 1:45:36.260
 I mean, they just have wonderful imaginations.

1:45:36.260 --> 1:45:38.980
 And part of what I think is gonna be great

1:45:38.980 --> 1:45:41.380
 about the creator economy and the metaverse

1:45:41.380 --> 1:45:44.740
 and all this stuff is this notion around

1:45:44.740 --> 1:45:46.300
 that a lot more people in the future

1:45:46.300 --> 1:45:49.020
 are gonna get to work doing creative stuff

1:45:49.020 --> 1:45:51.420
 than what I think today we would just consider

1:45:51.420 --> 1:45:53.740
 traditional labor or service.

1:45:53.740 --> 1:45:56.300
 And I think that that's awesome.

1:45:56.300 --> 1:46:00.140
 And that's a lot of what people are here to do

1:46:00.140 --> 1:46:03.140
 is collaborate together, work together,

1:46:03.140 --> 1:46:06.420
 think of things that you wanna build and go do it.

1:46:06.420 --> 1:46:08.540
 And I don't know, one of the things

1:46:08.540 --> 1:46:09.380
 that I just think is striking,

1:46:09.380 --> 1:46:13.660
 so I teach my daughters some basic coding with Scratch.

1:46:13.660 --> 1:46:15.420
 I mean, they're still obviously really young,

1:46:15.420 --> 1:46:18.340
 but I think of coding as building,

1:46:18.340 --> 1:46:19.780
 where it's like when I'm coding,

1:46:19.780 --> 1:46:22.300
 I'm building something that I want to exist.

1:46:22.300 --> 1:46:27.300
 But my youngest daughter, she's very musical

1:46:27.980 --> 1:46:32.820
 and pretty artistic and she thinks about coding as art.

1:46:32.820 --> 1:46:35.540
 She calls it code art, not the code,

1:46:35.540 --> 1:46:37.540
 but the output of what she is making.

1:46:37.540 --> 1:46:39.340
 It's like, she's just very interesting visually

1:46:39.340 --> 1:46:42.580
 in what she can kind of output and how it can move around.

1:46:42.580 --> 1:46:45.020
 And do we need to fix that?

1:46:45.020 --> 1:46:45.860
 Are we good?

1:46:45.860 --> 1:46:47.460
 What happened?

1:46:47.460 --> 1:46:49.460
 Do we have to clap, Alexa?

1:46:49.460 --> 1:46:53.020
 Yeah, so I was just talking about Augie and her code art,

1:46:53.020 --> 1:46:56.540
 but I mean, to me, this is like a beautiful thing, right?

1:46:56.540 --> 1:46:58.700
 The notion that like for me,

1:46:58.700 --> 1:47:01.380
 coding was this functional thing and I enjoyed it.

1:47:01.380 --> 1:47:04.620
 And it like helped build something utilitarian,

1:47:04.620 --> 1:47:06.820
 but that for the next generation of people,

1:47:06.820 --> 1:47:10.460
 it will be even more an expression

1:47:10.460 --> 1:47:14.900
 of their kind of imagination and artistic sense

1:47:14.900 --> 1:47:15.940
 for what they want to exist.

1:47:15.940 --> 1:47:17.620
 So I don't know if that happens,

1:47:17.620 --> 1:47:20.420
 if we can help bring about this world

1:47:20.420 --> 1:47:23.580
 where a lot more people can,

1:47:23.580 --> 1:47:25.900
 that that's like their existence going forward

1:47:25.900 --> 1:47:28.620
 is being able to basically create

1:47:28.620 --> 1:47:32.940
 and live out all these different kinds of art.

1:47:32.940 --> 1:47:34.420
 I just think that that's like a beautiful

1:47:34.420 --> 1:47:37.940
 and wonderful thing and will be very freeing for humanity

1:47:37.940 --> 1:47:40.420
 to spend more of our time on the things that matter to us.

1:47:40.420 --> 1:47:43.140
 Yeah, allow more and more people to express their art

1:47:43.140 --> 1:47:45.140
 in the full meaning of that word.

1:47:45.140 --> 1:47:46.900
 That's a beautiful vision.

1:47:46.900 --> 1:47:49.300
 We mentioned that you are mortal.

1:47:50.260 --> 1:47:51.900
 Are you afraid of death?

1:47:51.900 --> 1:47:53.580
 Do you think about your mortality?

1:47:56.300 --> 1:47:57.820
 And are you afraid of it?

1:48:01.220 --> 1:48:03.100
 You didn't sign up for this on a podcast, did you?

1:48:03.100 --> 1:48:05.100
 No, I mean, it's an interesting question.

1:48:07.060 --> 1:48:08.700
 I mean, I'm definitely aware of it.

1:48:08.700 --> 1:48:13.700
 I do a fair amount of like extreme sport type stuff.

1:48:13.700 --> 1:48:18.700
 So like, so I'm definitely aware of it.

1:48:19.700 --> 1:48:22.220
 And you're flirting with it a bit.

1:48:22.220 --> 1:48:23.700
 I train hard.

1:48:23.700 --> 1:48:25.100
 I mean, so it's like, if I'm gonna go out

1:48:25.100 --> 1:48:27.700
 in like a 15 foot wave.

1:48:27.700 --> 1:48:28.540
 Go out big.

1:48:28.540 --> 1:48:29.700
 Well, then it's like, all right,

1:48:29.700 --> 1:48:31.540
 I'll make sure we have the right safety gear

1:48:31.540 --> 1:48:34.540
 and like make sure that I'm like used to that spot

1:48:34.540 --> 1:48:35.580
 and all that stuff.

1:48:35.580 --> 1:48:37.740
 But like, but you know, I mean, you.

1:48:37.740 --> 1:48:38.940
 The risk is still there.

1:48:38.940 --> 1:48:40.780
 You take some head blows along the way.

1:48:40.780 --> 1:48:44.380
 Yes, but definitely aware of it.

1:48:45.340 --> 1:48:48.020
 Definitely would like to stay safe.

1:48:48.020 --> 1:48:52.020
 I have a lot of stuff that I want to build and want to.

1:48:52.020 --> 1:48:54.180
 Does it freak you out that it's finite though?

1:48:55.460 --> 1:48:57.660
 That there's a deadline when it's all over

1:48:59.180 --> 1:49:01.500
 and that there'll be a time when your daughters are around

1:49:01.500 --> 1:49:03.060
 and you're gone?

1:49:03.060 --> 1:49:03.900
 I don't know.

1:49:03.900 --> 1:49:04.940
 That doesn't freak me out.

1:49:04.940 --> 1:49:09.780
 I think, I don't know.

1:49:09.780 --> 1:49:14.780
 Constraints are helpful.

1:49:16.220 --> 1:49:17.300
 Yeah.

1:49:17.300 --> 1:49:20.260
 Yeah, the finiteness makes ice cream

1:49:20.260 --> 1:49:21.740
 taste more delicious somehow.

1:49:21.740 --> 1:49:23.140
 The fact that it's gonna be over.

1:49:23.140 --> 1:49:25.700
 There's something about that with the metaverse too.

1:49:25.700 --> 1:49:28.500
 You want, we talked about this identity earlier,

1:49:28.500 --> 1:49:30.260
 like having just one, like NFTs.

1:49:30.260 --> 1:49:34.340
 There's something powerful about the constraint

1:49:34.340 --> 1:49:36.900
 of finiteness or uniqueness.

1:49:36.900 --> 1:49:39.740
 That this moment is singular in history.

1:49:39.740 --> 1:49:41.060
 But I mean, a lot of,

1:49:41.060 --> 1:49:42.700
 as you go through different waves of technology,

1:49:42.700 --> 1:49:44.340
 I think a lot of what is interesting is

1:49:44.340 --> 1:49:48.020
 what becomes in practice infinite

1:49:48.020 --> 1:49:51.500
 or kind of there can be many, many of a thing

1:49:51.500 --> 1:49:53.660
 and then what ends up still being constrained.

1:49:53.660 --> 1:49:58.660
 So the metaverse should hopefully allow

1:50:00.340 --> 1:50:04.220
 a very large number or maybe in practice,

1:50:04.220 --> 1:50:06.860
 hopefully close to an infinite amount of expression

1:50:06.860 --> 1:50:09.700
 and worlds, but we'll still only have

1:50:09.700 --> 1:50:11.220
 a finite amount of time.

1:50:11.220 --> 1:50:12.060
 Yes.

1:50:12.060 --> 1:50:17.060
 I think living longer I think is good.

1:50:18.020 --> 1:50:21.700
 And obviously all of my, our philanthropic work is,

1:50:21.700 --> 1:50:23.380
 it's not focused on longevity,

1:50:23.380 --> 1:50:25.940
 but it is focused on trying to achieve

1:50:25.940 --> 1:50:29.620
 what I think is a possible goal in this century,

1:50:29.620 --> 1:50:31.020
 which is to be able to cure, prevent

1:50:31.020 --> 1:50:32.500
 or manage all diseases.

1:50:33.460 --> 1:50:36.140
 So I certainly think people kind of getting sick

1:50:36.140 --> 1:50:37.740
 and dying is a bad thing because,

1:50:37.740 --> 1:50:40.260
 and I'm dedicating almost all of my capital

1:50:40.260 --> 1:50:44.500
 towards advancing research in that area to push on that,

1:50:44.500 --> 1:50:45.460
 which I mean, we could do a whole,

1:50:45.460 --> 1:50:46.940
 another one of these podcasts about that

1:50:46.940 --> 1:50:49.660
 because that's a fascinating topic.

1:50:49.660 --> 1:50:51.740
 I mean, this is with your wife Priscilla Chan,

1:50:51.740 --> 1:50:54.140
 you formed the Chan Zuckerberg Initiative,

1:50:54.140 --> 1:50:57.020
 gave away 99% or pledged to give away 99%

1:50:57.020 --> 1:50:59.260
 of Facebook non meta shares.

1:50:59.260 --> 1:51:01.980
 I mean, like you said, we could talk forever

1:51:01.980 --> 1:51:06.100
 about all the exciting things you're working on there,

1:51:06.100 --> 1:51:11.100
 including the sort of moonshot of eradicating disease

1:51:11.300 --> 1:51:13.260
 by the mid century marker.

1:51:13.260 --> 1:51:15.420
 I don't actually know if you're gonna ever eradicate it,

1:51:15.420 --> 1:51:17.980
 but I think you can get to a point where you

1:51:17.980 --> 1:51:20.900
 can either cure things that happened, right?

1:51:20.900 --> 1:51:22.940
 So people get diseases, but you can cure them.

1:51:22.940 --> 1:51:25.620
 Prevent is probably closest to eradication

1:51:25.620 --> 1:51:28.860
 or just be able to manage as sort of like ongoing things

1:51:28.860 --> 1:51:33.260
 that are not gonna ruin your life.

1:51:33.260 --> 1:51:34.300
 And I think that that's possible.

1:51:34.300 --> 1:51:37.060
 I think saying that there's gonna be no disease at all

1:51:37.060 --> 1:51:41.540
 probably is not possible within the next several decades.

1:51:41.540 --> 1:51:44.300
 Basic thing is increase the quality of life

1:51:44.300 --> 1:51:46.820
 and maybe keep the finiteness

1:51:46.820 --> 1:51:50.180
 because it makes everything taste more delicious.

1:51:50.180 --> 1:51:54.740
 Maybe that's just being a romantic 20th century human.

1:51:54.740 --> 1:51:57.140
 Maybe, but I mean, but it was an intentional decision

1:51:57.140 --> 1:52:01.780
 to not focus on our philanthropy on like explicitly

1:52:01.780 --> 1:52:03.460
 on longevity or living forever.

1:52:03.460 --> 1:52:04.300
 Yes.

1:52:06.980 --> 1:52:09.060
 If at the moment of your death, and by the way,

1:52:09.060 --> 1:52:11.540
 I like that the lights went out

1:52:11.540 --> 1:52:13.380
 when we started talking about death.

1:52:13.380 --> 1:52:14.220
 You get to meet God.

1:52:14.220 --> 1:52:15.660
 It does make it a lot more dramatic.

1:52:15.660 --> 1:52:16.500
 It does.

1:52:17.940 --> 1:52:19.740
 I should get closer to the mic.

1:52:19.740 --> 1:52:22.060
 At the moment of your death, you get to meet God

1:52:23.020 --> 1:52:26.140
 and you get to ask one question.

1:52:26.140 --> 1:52:28.100
 What question would you like to ask?

1:52:29.820 --> 1:52:31.180
 Or maybe a whole conversation.

1:52:31.180 --> 1:52:32.020
 I don't know.

1:52:32.020 --> 1:52:32.860
 It's up to you.

1:52:32.860 --> 1:52:35.060
 It's more dramatic when it's just one question.

1:52:37.100 --> 1:52:40.500
 Well, if it's only one question and I died,

1:52:42.980 --> 1:52:47.980
 I would just wanna know that Priscilla and my family,

1:52:48.020 --> 1:52:49.660
 like if they were gonna be okay.

1:52:50.900 --> 1:52:54.620
 That might depend on the circumstances of my death.

1:52:54.620 --> 1:52:58.060
 But I think that in most circumstances that I can think of,

1:52:58.060 --> 1:53:01.100
 that's probably the main thing that I would care about.

1:53:01.100 --> 1:53:02.820
 Yeah, I think God will hear that question and be like,

1:53:02.820 --> 1:53:04.260
 all right, fine, you get in.

1:53:04.260 --> 1:53:06.700
 That's the right question to ask.

1:53:06.700 --> 1:53:07.540
 Is it?

1:53:07.540 --> 1:53:08.380
 I don't know.

1:53:08.380 --> 1:53:09.580
 The humility and selfishness.

1:53:09.580 --> 1:53:10.820
 All right, you're in.

1:53:10.820 --> 1:53:14.540
 I mean, but well, maybe.

1:53:14.540 --> 1:53:15.380
 They're gonna be fine.

1:53:15.380 --> 1:53:16.220
 Don't worry, you're in.

1:53:16.220 --> 1:53:18.220
 Okay, but I mean, one of the things that I think

1:53:18.220 --> 1:53:22.300
 I struggle with at least is on the one hand,

1:53:22.300 --> 1:53:25.620
 that's probably the thing that's closest to me

1:53:25.620 --> 1:53:29.420
 and maybe the most common human experience.

1:53:29.420 --> 1:53:32.380
 But I don't know, one of the things that I just struggle with

1:53:32.380 --> 1:53:36.140
 in terms of running this large enterprise is like,

1:53:38.100 --> 1:53:41.020
 should the thing that I care more about

1:53:41.020 --> 1:53:44.860
 be that responsibility?

1:53:44.860 --> 1:53:49.300
 And I think it's shifted over time.

1:53:49.300 --> 1:53:52.060
 I mean, like before I really had a family

1:53:52.060 --> 1:53:53.860
 that was like the only thing I cared about.

1:53:53.860 --> 1:53:58.860
 And at this point, I mean, I care deeply about it,

1:53:59.980 --> 1:54:04.980
 but yeah, I think that that's not as obvious of a question.

1:54:06.060 --> 1:54:07.860
 Yeah, we humans are weird.

1:54:07.860 --> 1:54:12.780
 You get this ability to impact millions of lives

1:54:12.780 --> 1:54:15.660
 and it's definitely something, billions of lives,

1:54:15.660 --> 1:54:16.980
 it's something you care about,

1:54:16.980 --> 1:54:21.100
 but the weird humans that are closest to us,

1:54:21.100 --> 1:54:23.700
 those are the ones that mean the most.

1:54:23.700 --> 1:54:26.140
 And I suppose that's the dream of the metaverse

1:54:26.140 --> 1:54:29.300
 is to connect, form small groups like that

1:54:29.300 --> 1:54:31.700
 where you can have those intimate relationships.

1:54:31.700 --> 1:54:33.620
 Let me ask you the big, ridiculous.

1:54:33.620 --> 1:54:35.340
 Well, and to be able to be close,

1:54:36.940 --> 1:54:39.900
 not just based on who you happen to be next to.

1:54:39.900 --> 1:54:41.980
 I think that's what the internet is already doing

1:54:41.980 --> 1:54:44.540
 is allowing you to spend more of your time

1:54:44.540 --> 1:54:46.540
 not physically proximate.

1:54:46.540 --> 1:54:49.940
 I mean, I always think when you think about the metaverse,

1:54:49.940 --> 1:54:52.140
 people ask this question about the real world.

1:54:52.140 --> 1:54:54.860
 It's like the virtual world versus the real world.

1:54:54.860 --> 1:54:58.180
 And it's like, no, the real world is a combination

1:54:58.180 --> 1:55:00.100
 of the virtual world and the physical world.

1:55:00.100 --> 1:55:03.140
 But I think over time, as we get more technology,

1:55:04.060 --> 1:55:06.780
 the physical world is becoming less of a percent

1:55:06.780 --> 1:55:08.180
 of the real world.

1:55:08.180 --> 1:55:10.940
 And I think that that opens up a lot of opportunities

1:55:10.940 --> 1:55:13.460
 for people, because you can work in different places.

1:55:13.460 --> 1:55:17.580
 You can stay more close to, stay closer to people

1:55:17.580 --> 1:55:18.420
 who are in different places.

1:55:18.420 --> 1:55:19.300
 So I think that's good.

1:55:19.300 --> 1:55:21.380
 Removing barriers of geography

1:55:21.380 --> 1:55:23.140
 and then barriers of language.

1:55:23.140 --> 1:55:24.900
 That's a beautiful vision.

1:55:25.860 --> 1:55:27.580
 Big, ridiculous question.

1:55:27.580 --> 1:55:29.620
 What do you think is the meaning of life?

1:55:44.100 --> 1:55:46.560
 I think that, well, there are probably a couple

1:55:46.560 --> 1:55:51.560
 of different ways that I would go at this.

1:55:52.020 --> 1:55:53.900
 But I think it gets back to this last question

1:55:53.900 --> 1:55:55.380
 that we talked about, about the duality

1:55:55.380 --> 1:55:58.660
 between you have the people around you

1:55:58.660 --> 1:56:00.380
 who you care the most about,

1:56:00.380 --> 1:56:03.060
 and then there's like this bigger thing

1:56:03.060 --> 1:56:04.420
 that maybe you're building.

1:56:05.820 --> 1:56:07.340
 And I think that in my own life, I mean,

1:56:07.340 --> 1:56:09.360
 I sort of think about this tension,

1:56:09.360 --> 1:56:11.860
 but I mean, it's like, I started this whole company

1:56:11.860 --> 1:56:15.100
 and my life's work is around human connection.

1:56:15.100 --> 1:56:20.100
 So I think it's intellectually probably the thing

1:56:22.100 --> 1:56:27.100
 that I go to first is just that human connection

1:56:27.720 --> 1:56:28.560
 is the meaning.

1:56:29.560 --> 1:56:31.160
 And I mean, I think that it's a thing

1:56:31.160 --> 1:56:36.160
 that our society probably systematically undervalues.

1:56:36.860 --> 1:56:39.280
 I mean, I just remember when I was growing up

1:56:39.280 --> 1:56:43.140
 and in school, it's like, do your homework

1:56:43.140 --> 1:56:45.200
 and then go play with your friends after.

1:56:45.200 --> 1:56:47.020
 And it's like, no, well, what if playing

1:56:47.020 --> 1:56:48.520
 with your friends is the point?

1:56:50.180 --> 1:56:52.340
 That sounds like an argument your daughter would make.

1:56:52.340 --> 1:56:54.620
 Well, I mean, I don't know, I just think it's interesting.

1:56:54.620 --> 1:56:56.340
 Homework doesn't even matter, man.

1:56:56.340 --> 1:56:58.540
 Well, I think it's interesting because it's,

1:56:58.540 --> 1:57:02.700
 and people, I think people tend to think

1:57:02.700 --> 1:57:05.180
 about that stuff as wasting time,

1:57:05.180 --> 1:57:08.100
 or that's like what you do in the free time that you have.

1:57:08.100 --> 1:57:11.140
 But like, what if that's actually the point?

1:57:11.140 --> 1:57:12.580
 So that's one.

1:57:12.580 --> 1:57:14.760
 But here's maybe a different way of counting out this,

1:57:14.760 --> 1:57:17.880
 which is maybe more like religious in nature.

1:57:17.880 --> 1:57:18.980
 I mean, I always like,

1:57:22.200 --> 1:57:25.400
 there's a rabbi who I've studied with

1:57:25.400 --> 1:57:26.920
 who kind of gave me this,

1:57:27.980 --> 1:57:31.820
 we were talking through Genesis and the Bible and the Torah

1:57:31.820 --> 1:57:36.100
 and they're basically walking through,

1:57:36.100 --> 1:57:40.740
 it's like, okay, you go through the seven days of creation

1:57:40.740 --> 1:57:45.660
 and it's basically, it's like,

1:57:45.660 --> 1:57:48.100
 why does the Bible start there?

1:57:48.100 --> 1:57:49.460
 Right, it's like it could have started anywhere,

1:57:49.460 --> 1:57:52.000
 right, in terms of like how to live.

1:57:52.000 --> 1:57:54.620
 But basically it starts with talking about

1:57:54.620 --> 1:57:58.920
 how God created people in his, her image.

1:58:00.560 --> 1:58:02.720
 But the Bible starts by talking about

1:58:02.720 --> 1:58:04.740
 how God created everything.

1:58:04.740 --> 1:58:11.240
 So I actually think that there's like a compelling argument

1:58:11.240 --> 1:58:12.980
 that I think I've always just found meaningful

1:58:12.980 --> 1:58:16.980
 and inspiring that a lot of the point

1:58:18.400 --> 1:58:22.980
 of what sort of religion has been telling us

1:58:22.980 --> 1:58:27.980
 that we should do is to create and build things.

1:58:30.060 --> 1:58:32.100
 So these things are not necessarily at odds.

1:58:32.100 --> 1:58:34.780
 I mean, I think like, I mean, that's,

1:58:34.780 --> 1:58:36.100
 and I think probably to some degree

1:58:36.100 --> 1:58:37.720
 you'd expect me to say something like this

1:58:37.720 --> 1:58:39.760
 because I've dedicated my life to creating things

1:58:39.760 --> 1:58:40.600
 that help people connect.

1:58:40.600 --> 1:58:42.460
 So, I mean, that's sort of the fusion of,

1:58:43.780 --> 1:58:45.260
 I mean, getting back to what we talked about earlier,

1:58:45.260 --> 1:58:46.500
 it's, I mean, what I studied in school

1:58:46.500 --> 1:58:48.260
 or psychology and computer science, right?

1:58:48.260 --> 1:58:50.580
 So it's, I mean, these are like the two themes

1:58:50.580 --> 1:58:54.460
 that I care about, but I don't know for me,

1:58:54.460 --> 1:58:57.140
 that's kind of what I think about, that's what matters.

1:58:57.140 --> 1:59:02.140
 To create and to love, which is the ultimate form

1:59:02.200 --> 1:59:03.120
 of connection.

1:59:03.980 --> 1:59:07.220
 I think this is one hell of an amazing replay experience

1:59:07.220 --> 1:59:08.060
 in the metaverse.

1:59:08.060 --> 1:59:11.980
 So whoever is using our avatars years from now,

1:59:11.980 --> 1:59:14.780
 I hope you had fun and thank you for talking today.

1:59:14.780 --> 1:59:15.620
 Thank you.

1:59:16.460 --> 1:59:18.180
 Thanks for listening to this conversation

1:59:18.180 --> 1:59:19.500
 with Mark Zuckerberg.

1:59:19.500 --> 1:59:22.060
 To support this podcast, please check out our sponsors

1:59:22.060 --> 1:59:23.660
 in the description.

1:59:23.660 --> 1:59:27.820
 And now, let me leave you with the end of the poem, If,

1:59:27.820 --> 1:59:29.160
 by Roger Kipling.

1:59:30.820 --> 1:59:34.160
 If you can talk with crowds and keep your virtue,

1:59:34.160 --> 1:59:37.820
 or walk with kings, nor lose the common touch,

1:59:37.820 --> 1:59:41.220
 if neither foes nor loving friends can hurt you,

1:59:41.220 --> 1:59:45.740
 if all men count with you, but none too much.

1:59:47.100 --> 1:59:49.260
 If you can fill the unforgiving minute

1:59:49.260 --> 1:59:52.340
 with 60 seconds worth of distance run,

1:59:52.340 --> 1:59:56.340
 yours is the earth and everything that's in it.

1:59:56.340 --> 1:59:59.580
 And which is more, you'll be a man, my son.

1:59:59.580 --> 2:00:21.100
 Thank you for listening and hope to see you next time.

