WEBVTT

00:00.000 --> 00:02.920
 The jury found Pfizer guilty of fraud

00:02.920 --> 00:04.600
 and racketeering violations.

00:04.600 --> 00:06.520
 How does Big Pharma affect your mind?

00:06.520 --> 00:08.800
 Everyone's allowed their own opinion.

00:08.800 --> 00:11.920
 I don't think everyone's allowed their own scientific facts.

00:11.920 --> 00:13.800
 Does Pfizer play by the rules?

00:13.800 --> 00:16.440
 Pfizer isn't battling the FDA.

00:16.440 --> 00:18.780
 Pfizer has joined the FDA.

00:21.440 --> 00:24.320
 The following is a conversation with John Abramson,

00:24.320 --> 00:26.520
 faculty at Harvard Medical School,

00:26.520 --> 00:29.160
 a family physician for over two decades,

00:29.160 --> 00:32.160
 and author of the new book, Sickening,

00:32.160 --> 00:35.000
 about how Big Pharma broke American healthcare

00:35.000 --> 00:37.360
 and how we can fix it.

00:37.360 --> 00:40.200
 This conversation with John Abramson

00:40.200 --> 00:43.680
 is a critical exploration of the pharmaceutical industry.

00:43.680 --> 00:45.400
 I wanted to talk to John

00:45.400 --> 00:48.160
 in order to provide a countervailing perspective

00:48.160 --> 00:50.700
 to the one expressed in my podcast episode

00:50.700 --> 00:55.080
 with the CEO of Pfizer, Albert Borla.

00:55.080 --> 00:58.920
 And here, please allow me to say a few additional words

00:58.920 --> 01:01.880
 about this episode with the Pfizer CEO,

01:01.880 --> 01:04.920
 and in general, about why I do these conversations

01:04.920 --> 01:06.820
 and how I approach them.

01:06.820 --> 01:10.520
 If this is not interesting to you, please skip ahead.

01:10.520 --> 01:13.080
 What do I hope to do with this podcast?

01:13.080 --> 01:15.600
 I want to understand human nature,

01:15.600 --> 01:18.040
 the best and the worst of it.

01:18.040 --> 01:19.840
 I want to understand how power, money,

01:19.840 --> 01:21.840
 and fame changes people.

01:21.840 --> 01:24.620
 I want to understand why atrocities are committed

01:24.620 --> 01:27.240
 by crowds that believe they're doing good.

01:27.240 --> 01:30.720
 All this, ultimately, because I want to understand

01:30.720 --> 01:33.240
 how we can build a better world together,

01:33.240 --> 01:35.400
 to find hope for the future,

01:35.400 --> 01:38.520
 and to rediscover each time,

01:38.520 --> 01:40.880
 through the exploration of ideas,

01:40.880 --> 01:43.340
 just how beautiful this life is.

01:43.340 --> 01:45.360
 This, our human civilization,

01:45.360 --> 01:47.640
 in all of its full complexity,

01:47.640 --> 01:49.280
 the forces of good and evil,

01:49.280 --> 01:52.300
 of war and peace, of hate and love.

01:53.400 --> 01:55.560
 I don't think I can do this with a heart and mind

01:55.560 --> 01:59.040
 that is not open, fragile, and willing to empathize

01:59.040 --> 02:00.920
 with all human beings,

02:00.920 --> 02:03.440
 even those in the darkest corners of our world.

02:04.400 --> 02:06.760
 To attack is easy.

02:06.760 --> 02:09.520
 To understand is hard.

02:09.520 --> 02:11.800
 And I choose the hard path.

02:11.800 --> 02:13.840
 I have learned over the past few months

02:13.840 --> 02:17.360
 that this path involves me getting more and more attacked

02:17.360 --> 02:19.000
 from all sides.

02:19.000 --> 02:21.600
 I will get attacked when I host people

02:21.600 --> 02:24.500
 like Jay Bhattacharya or Francis Collins,

02:24.500 --> 02:28.120
 Jamie Merzl or Vincent Ricanello,

02:28.120 --> 02:31.840
 when I stand for my friend, Joe Rogan,

02:31.840 --> 02:34.720
 when I host tech leaders like Mark Zuckerberg,

02:34.720 --> 02:36.400
 Elon Musk, and others,

02:36.400 --> 02:40.800
 when I eventually talk to Vladimir Putin, Barack Obama,

02:40.800 --> 02:43.840
 and other figures that have turned the tides of history.

02:44.920 --> 02:49.920
 I have and I will get called stupid, naive, weak,

02:50.800 --> 02:52.520
 and I will take these words

02:52.520 --> 02:57.200
 with respect, humility, and love, and I will get better.

02:57.200 --> 03:00.680
 I will listen, think, learn, and improve.

03:00.680 --> 03:04.520
 One thing I can promise is there's no amount of money

03:04.520 --> 03:06.920
 or fame that can buy my opinion

03:06.920 --> 03:09.280
 or make me go against my principles.

03:09.280 --> 03:13.480
 There's no amount of pressure that can break my integrity.

03:13.480 --> 03:16.120
 There's nothing in this world I need

03:16.120 --> 03:18.540
 that I don't already have.

03:18.540 --> 03:21.440
 Life itself is the fundamental gift.

03:21.440 --> 03:23.480
 Everything else is just the bonus.

03:24.520 --> 03:26.640
 That is freedom.

03:26.640 --> 03:28.680
 That is happiness.

03:28.680 --> 03:31.720
 If I die today, I will die a happy man.

03:33.040 --> 03:35.960
 Now, a few comments about my approach

03:35.960 --> 03:39.560
 and lessons learned from the Albert Bourla conversation.

03:39.560 --> 03:41.880
 The goal was to reveal as much as I could

03:41.880 --> 03:43.920
 about the human being before me

03:43.920 --> 03:48.120
 and to give him the opportunity to contemplate in long form

03:48.120 --> 03:49.920
 the complexities of his role,

03:49.920 --> 03:53.200
 including the tension between making money

03:53.200 --> 03:55.320
 and helping people, the corruption

03:55.320 --> 03:58.180
 that so often permeates human institutions,

03:58.180 --> 04:00.800
 the crafting of narratives through advertisements,

04:00.800 --> 04:02.400
 and so on.

04:02.400 --> 04:04.040
 I only had one hour,

04:04.040 --> 04:07.440
 and so this wasn't the time to address these issues deeply

04:07.440 --> 04:10.200
 but to show if Albert struggled with them

04:10.200 --> 04:12.240
 in the privacy of his own mind,

04:12.240 --> 04:16.280
 and if he would let down the veil of political speak

04:16.280 --> 04:19.400
 for a time to let me connect with a man

04:19.400 --> 04:22.560
 who decades ago chose to become a veterinarian,

04:22.560 --> 04:24.840
 who wanted to help lessen the amount of suffering

04:24.840 --> 04:26.300
 in the world.

04:26.300 --> 04:28.400
 I had no pressure placed on me.

04:28.400 --> 04:29.760
 There were no rules.

04:29.760 --> 04:32.120
 The questions I was asking were all mine

04:32.120 --> 04:34.120
 and not seen by Pfizer folks.

04:34.120 --> 04:38.700
 I had no care whether I ever talked to another CEO again.

04:38.700 --> 04:41.820
 None of this was part of the calculation

04:41.820 --> 04:44.140
 in my limited brain computer.

04:44.140 --> 04:45.920
 I didn't want to grill him.

04:45.920 --> 04:48.920
 The way politicians grill CEOs in Congress,

04:48.920 --> 04:51.400
 I thought that this approach is easy,

04:51.400 --> 04:56.240
 self serving, dehumanizing, and it reveals nothing.

04:56.240 --> 04:59.000
 I wanted to reveal the genuine intellectual struggle,

04:59.000 --> 05:01.400
 vision, and motivation of a human being,

05:01.400 --> 05:04.280
 and if that fails, I trusted the listener

05:04.280 --> 05:08.080
 to draw their own conclusion and insights from the result,

05:08.080 --> 05:10.080
 whether it's the words spoken

05:10.080 --> 05:14.480
 or the words left unspoken or simply the silence.

05:14.480 --> 05:15.800
 And that's just it.

05:15.800 --> 05:20.800
 I fundamentally trust the intelligence of the listener, you.

05:21.920 --> 05:24.880
 In fact, if I criticize the person too hard

05:24.880 --> 05:26.840
 or celebrate the person too much,

05:26.840 --> 05:29.320
 I feel I fail to give the listener

05:29.320 --> 05:32.800
 a picture of the human being that is uncontaminated

05:32.800 --> 05:35.440
 by my opinion or the opinion of the crowd.

05:36.480 --> 05:39.320
 I trust that you have the fortitude and the courage

05:39.320 --> 05:43.280
 to use your own mind, to empathize, and to think.

05:43.280 --> 05:46.400
 Two practical lessons I took away.

05:46.400 --> 05:48.520
 First, I will more strongly push

05:48.520 --> 05:52.000
 for longer conversations of three, four, or more hours

05:52.000 --> 05:53.480
 versus just one hour.

05:53.480 --> 05:56.000
 60 minutes is too short for the guest to relax

05:56.000 --> 05:58.280
 and to think slowly and deeply,

05:58.280 --> 06:00.880
 and for me to ask many follow up questions

06:00.880 --> 06:03.000
 or follow interesting tangents.

06:03.000 --> 06:05.920
 Ultimately, I think it's in the interest of everyone,

06:05.920 --> 06:09.640
 including the guest, that we talk in true long form

06:09.640 --> 06:11.600
 for many hours.

06:11.600 --> 06:13.840
 Second, these conversations with leaders

06:13.840 --> 06:16.160
 can be aided by further conversations

06:16.160 --> 06:18.760
 with people who wrote books about those leaders

06:18.760 --> 06:20.440
 or their industries.

06:20.440 --> 06:22.440
 Those that can steel man each perspective

06:22.440 --> 06:25.160
 and attempt to give an objective analysis.

06:25.160 --> 06:26.840
 I think of Teddy Roosevelt's speech

06:26.840 --> 06:28.520
 about the man in the arena.

06:28.520 --> 06:32.400
 I want to talk to both the men and women in the arena

06:32.400 --> 06:36.120
 and the critics and the supporters in the stands.

06:36.120 --> 06:38.880
 For the former, I lean toward wanting to understand

06:38.880 --> 06:43.360
 one human being's struggle with the ideas.

06:43.360 --> 06:45.960
 For the latter, I lean towards understanding

06:45.960 --> 06:48.400
 the ideas themselves.

06:48.400 --> 06:50.320
 That's why I wanted to have this conversation

06:50.320 --> 06:53.640
 with John Abramson, who is an outspoken critic

06:53.640 --> 06:55.600
 of the pharmaceutical industry.

06:55.600 --> 06:58.840
 I hope it helps add context and depth

06:58.840 --> 07:02.320
 to the conversation I had with the Pfizer CEO.

07:02.320 --> 07:06.680
 In the end, I may do worse than I could have or should have.

07:06.680 --> 07:10.080
 Always, I will listen to the criticisms without ego

07:10.080 --> 07:13.640
 and I promise I will work hard to improve.

07:14.640 --> 07:18.960
 But let me say finally that cynicism is easy.

07:20.040 --> 07:23.600
 Optimism, true optimism is hard.

07:24.480 --> 07:28.160
 It is the belief that we can and we will

07:28.160 --> 07:32.720
 build a better world and that we can only do it together.

07:32.720 --> 07:35.000
 This is the fight worth fighting.

07:35.000 --> 07:36.520
 So here we go.

07:36.520 --> 07:39.160
 Once more into the breach, dear friends.

07:39.160 --> 07:40.080
 I love you all.

07:41.680 --> 07:43.880
 This is the Lex Friedman podcast.

07:43.880 --> 07:46.000
 To support it, please check out our sponsors

07:46.000 --> 07:47.280
 in the description.

07:47.280 --> 07:51.320
 And now, here's my conversation with John Abramson.

07:52.320 --> 07:55.200
 Your faculty at Harvard Medical School,

07:55.200 --> 07:57.800
 your family physician for over two decades,

07:57.800 --> 08:01.120
 rated one of the best family physicians in Massachusetts,

08:01.120 --> 08:03.400
 you wrote the book, Overdose to America,

08:03.400 --> 08:07.360
 and the new book coming out now called Sickening

08:07.360 --> 08:10.080
 about how Big Pharma broke American healthcare,

08:10.080 --> 08:14.720
 including science and research, and how we can fix it.

08:14.720 --> 08:18.720
 First question, what is the biggest problem with Big Pharma

08:18.720 --> 08:21.800
 that it fixed would be the most impactful?

08:21.800 --> 08:24.920
 So if you can snap your fingers and fix one thing,

08:24.920 --> 08:26.760
 what would be the most impactful, you think?

08:26.760 --> 08:30.040
 The biggest problem is the way they

08:30.040 --> 08:35.040
 determine the content, the accuracy,

08:35.560 --> 08:39.560
 and the completeness of what doctors believe

08:39.560 --> 08:42.520
 to be the full range of knowledge

08:42.520 --> 08:46.000
 that they need to best take care of their patients.

08:46.000 --> 08:51.000
 So that with the knowledge having been taken over

08:51.440 --> 08:53.840
 by the commercial interests, primarily

08:53.840 --> 08:57.400
 the pharmaceutical industry, the purpose of that knowledge

08:57.400 --> 09:00.720
 is to maximize the profits that get returned

09:00.720 --> 09:04.920
 to investors and shareholders, and not to optimize

09:04.920 --> 09:07.220
 the health of the American people.

09:07.220 --> 09:11.440
 So rebalancing that equation would be the most important

09:11.440 --> 09:15.120
 thing to do to get our healthcare back aimed

09:15.120 --> 09:16.440
 in the right direction.

09:16.440 --> 09:20.680
 Okay, so there's a tension between helping people

09:20.680 --> 09:24.520
 and making money, so if we look at particularly

09:24.520 --> 09:28.600
 the task of helping people in medicine, in healthcare,

09:29.680 --> 09:34.680
 is it possible if money is the primary sort of mechanism

09:35.440 --> 09:38.300
 by which you achieve that as a motivator,

09:38.300 --> 09:39.840
 is it possible to get that right?

09:39.840 --> 09:43.120
 I think it is, Lex, but I think it is not possible

09:43.120 --> 09:46.760
 without guardrails that maintain the integrity

09:46.760 --> 09:48.760
 and the balance of the knowledge.

09:48.760 --> 09:52.000
 Without those guardrails, it's like trying to play

09:52.000 --> 09:54.840
 a professional basketball game without referees

09:54.840 --> 09:57.600
 and having players call their own fouls.

09:57.600 --> 10:01.000
 But the players are paid to win, and you can't count

10:01.000 --> 10:03.760
 on them to call their own fouls, so we have referees

10:03.760 --> 10:05.080
 who are in charge.

10:05.080 --> 10:08.180
 We don't have those referees in American healthcare.

10:08.180 --> 10:13.180
 That's the biggest way that American healthcare

10:13.800 --> 10:17.520
 is distinguished from healthcare in other wealthy nations.

10:17.520 --> 10:19.680
 So okay, you mentioned Milton Friedman,

10:19.680 --> 10:24.280
 and you mentioned his book called Capitalism and Freedom.

10:24.280 --> 10:27.220
 He writes that there are only three legitimate functions

10:27.220 --> 10:30.120
 of government to preserve law and order,

10:30.120 --> 10:33.800
 to enforce private contracts, and to ensure

10:33.800 --> 10:35.820
 that private markets work.

10:36.840 --> 10:40.160
 You said that that was a radical idea at the time,

10:40.160 --> 10:41.840
 but we're failing on all three.

10:41.840 --> 10:43.720
 How are we failing?

10:43.720 --> 10:47.560
 And also maybe the bigger picture is what are the strengths

10:47.560 --> 10:50.880
 and weaknesses of capitalism when it comes to medicine

10:50.880 --> 10:51.840
 and healthcare?

10:51.840 --> 10:53.120
 Can we separate those out?

10:53.120 --> 10:55.200
 Because those are two huge questions.

10:55.200 --> 10:58.080
 So how we're failing on all three,

10:58.080 --> 11:03.080
 and these are the minimal functions that our guru

11:03.320 --> 11:06.740
 of free market capitalism said the government

11:06.740 --> 11:10.100
 should perform, so this is the absolute baseline.

11:11.240 --> 11:14.800
 On preserving law and order, the drug companies

11:14.800 --> 11:19.800
 routinely violate the law in terms of their marketing,

11:20.160 --> 11:25.160
 and in terms of their presentation

11:26.360 --> 11:29.160
 of the results of their trials.

11:29.160 --> 11:32.920
 I know this because I was an expert in litigation

11:32.920 --> 11:34.640
 for about 10 years.

11:35.860 --> 11:40.000
 I presented some of what I learned in civil litigation

11:40.000 --> 11:42.440
 to the FBI and the Department of Justice,

11:42.440 --> 11:46.360
 and that case led to the biggest criminal fine

11:46.360 --> 11:49.040
 in US history as of 2009.

11:49.880 --> 11:54.880
 And I testified in a federal trial in 2010,

11:56.120 --> 12:00.020
 and the jury found Pfizer guilty of fraud

12:00.020 --> 12:02.360
 and racketeering violations.

12:02.360 --> 12:07.360
 In terms of violating the law, it's a routine occurrence.

12:07.480 --> 12:10.800
 The drug companies have paid $38 billion worth of fines

12:10.800 --> 12:14.460
 from I think 1991 to 2017.

12:15.760 --> 12:20.760
 It's never been enough to stop the misrepresentation

12:21.360 --> 12:25.640
 of their data, and rarely are the fines greater

12:25.640 --> 12:27.280
 than the profits that were made.

12:29.520 --> 12:34.160
 Executives have not gone to jail for misrepresenting data

12:34.160 --> 12:38.460
 that have involved even tens of thousands of deaths

12:38.460 --> 12:42.120
 in the case of Vioxx, OxyContin as well.

12:42.120 --> 12:45.520
 And when companies plead guilty to felonies,

12:45.520 --> 12:48.360
 which is not an unusual occurrence,

12:48.360 --> 12:51.240
 the government usually allows the companies,

12:51.240 --> 12:56.000
 the parent companies, to allow subsidiaries to take the plea

12:56.000 --> 12:58.880
 so that they are not one step closer

12:58.880 --> 13:01.260
 to getting disbarred from Medicare,

13:01.260 --> 13:03.360
 not being able to participate in Medicare.

13:03.360 --> 13:08.360
 So in that sense, there is a mechanism

13:11.000 --> 13:15.020
 that is appearing to impose law and order

13:15.020 --> 13:18.140
 on drug company behavior, but it's clearly not enough.

13:18.140 --> 13:19.480
 It's not working.

13:19.480 --> 13:24.480
 Can you actually speak to human nature here?

13:24.580 --> 13:26.320
 Are people corrupt?

13:26.320 --> 13:28.400
 Are people malevolent?

13:28.400 --> 13:32.880
 Are people ignorant that work at the low level

13:32.880 --> 13:36.480
 and at the high level at Pfizer, for example,

13:36.480 --> 13:40.440
 at big pharma companies, how is this possible?

13:40.440 --> 13:43.280
 So I believe, just on a small tangent,

13:43.280 --> 13:45.240
 that most people are good.

13:45.240 --> 13:48.920
 And I actually believe if you join big pharma,

13:48.920 --> 13:52.600
 so a company like Pfizer, your life trajectory

13:52.600 --> 13:56.320
 often involves dreaming and wanting

13:56.320 --> 13:58.920
 and enjoying helping people.

13:58.920 --> 13:59.760
 Yes.

13:59.760 --> 14:03.440
 And so, and then we look at the outcomes

14:03.440 --> 14:07.040
 that you're describing, and it looks,

14:07.040 --> 14:09.400
 and that's why the narrative takes hold

14:09.400 --> 14:14.400
 that Pfizer CEO, Al Bobrola, who I talked to, is malevolent.

14:15.440 --> 14:19.520
 The sense is these companies are evil.

14:19.520 --> 14:24.520
 So if the different parts, the people, are good

14:24.520 --> 14:27.380
 and they want to do good, how are we getting these outcomes?

14:27.380 --> 14:32.380
 Yeah, I think it has to do with the cultural milieu

14:33.140 --> 14:35.320
 that this is unfolding in.

14:35.320 --> 14:40.320
 And we need to look at sociology to understand this,

14:41.440 --> 14:46.440
 that when the cultural milieu is set up

14:49.340 --> 14:52.560
 to maximize the returns on investment

14:52.560 --> 14:55.440
 for shareholders and other venture capitalists

14:55.440 --> 14:57.520
 and hedge funds and so forth,

14:57.520 --> 15:00.640
 when that defines the culture

15:00.640 --> 15:04.240
 and the higher up you are in the corporation,

15:04.240 --> 15:09.240
 the more you're in on the game of getting rewarded

15:10.080 --> 15:13.040
 for maximizing the profits of the investors,

15:13.040 --> 15:14.860
 that's the culture they live in.

15:15.760 --> 15:19.700
 And it becomes normative behavior

15:19.700 --> 15:25.640
 to do things with science that look normal

15:25.640 --> 15:28.520
 in that environment and are shared values

15:28.520 --> 15:31.240
 within that environment by good people

15:31.240 --> 15:34.920
 whose self evaluation becomes modified

15:34.920 --> 15:37.680
 by the goals that are shared by the people around them.

15:39.080 --> 15:44.080
 And within that milieu, you have one set of standards,

15:44.760 --> 15:48.680
 and then the rest of good American people

15:48.680 --> 15:50.720
 have the expectation that the drug companies

15:50.720 --> 15:53.480
 are trying to make money, but that they're playing

15:53.480 --> 15:58.480
 by rules that aren't part of the insider milieu.

15:59.560 --> 16:02.920
 That's fascinating, the game they're playing

16:02.920 --> 16:07.480
 modifies the culture of inside the meetings,

16:07.480 --> 16:09.460
 inside the rooms, day to day,

16:10.620 --> 16:12.440
 that there's a bubble that forms.

16:12.440 --> 16:15.660
 Like we're all in bubbles of different sizes.

16:15.660 --> 16:18.840
 And that bubble allows you to drift in terms

16:18.840 --> 16:23.080
 of what you see as ethical and unethical.

16:24.200 --> 16:28.520
 Because you see the game as just part of the game.

16:28.520 --> 16:30.500
 So marketing is just part of the game.

16:32.040 --> 16:35.280
 Paying the fines is just part of the game of science.

16:36.520 --> 16:40.880
 And without guardrails, it becomes

16:40.880 --> 16:42.200
 even more part of the game.

16:42.200 --> 16:44.660
 You keep moving in that direction.

16:44.660 --> 16:48.160
 If you're not bumping up against guardrails.

16:48.160 --> 16:49.900
 And I think that's how we've gotten

16:49.900 --> 16:52.220
 to the extreme situation we're in now.

16:53.400 --> 16:57.200
 So, like I mentioned, I spoke with Pfizer CEO,

16:57.200 --> 17:00.960
 Albert Berla, and I'd like to raise with you

17:00.960 --> 17:02.920
 some of the concerns I raised with him.

17:03.840 --> 17:07.120
 So one, you already mentioned, I raised the concern

17:07.120 --> 17:11.220
 that Pfizer's engaged in aggressive advertising campaigns.

17:11.220 --> 17:14.240
 As you can imagine, he said no.

17:15.520 --> 17:16.540
 What do you think?

17:18.440 --> 17:20.320
 I think you're both right.

17:21.360 --> 17:23.720
 I think that the, I agree with you,

17:23.720 --> 17:26.280
 that the aggressive advertising campaigns

17:27.780 --> 17:30.540
 do not add value to society.

17:30.540 --> 17:34.980
 And I agree with him that they're, for the most part, legal.

17:34.980 --> 17:37.000
 And it's the way the game is played.

17:37.000 --> 17:38.640
 Right, so, sorry to interrupt,

17:38.640 --> 17:42.320
 but oftentimes his responses are,

17:44.880 --> 17:47.640
 especially now, he's been CEO for only like two years,

17:47.640 --> 17:50.560
 three years, he says Pfizer was a different company,

17:50.560 --> 17:53.880
 we've made mistakes, right, in the past.

17:53.880 --> 17:56.380
 We don't make mistakes anymore.

17:56.380 --> 18:00.380
 That there's rules, and we play by the rules.

18:00.380 --> 18:02.800
 So like, with every concern raised,

18:02.800 --> 18:06.060
 there's very, very strict rules, as he says.

18:06.060 --> 18:08.520
 In fact, he says sometimes way too strict.

18:08.520 --> 18:10.200
 And we play by them.

18:10.200 --> 18:12.180
 And so in that sense, advertisement,

18:12.180 --> 18:14.320
 it doesn't seem like it's too aggressive,

18:14.320 --> 18:16.020
 because it's playing by the rules.

18:17.600 --> 18:19.800
 And relative to the other, again, it's the game.

18:19.800 --> 18:22.160
 Relative to the other companies,

18:22.160 --> 18:23.880
 it's actually not that aggressive.

18:24.920 --> 18:26.480
 Relative to the other big pharma companies.

18:26.480 --> 18:29.560
 Yes, yes, I hope we can quickly get back

18:29.560 --> 18:31.280
 to whether or not they're playing by the rules,

18:31.280 --> 18:32.760
 but in general.

18:32.760 --> 18:34.360
 But let's just look at the question

18:34.360 --> 18:36.640
 of advertising specifically.

18:36.640 --> 18:39.620
 I think that's a good example of what it looks like

18:39.620 --> 18:43.120
 from within that culture, and from outside that culture.

18:44.880 --> 18:49.800
 He's saying that we follow the law on our advertising.

18:49.800 --> 18:51.520
 We state the side effects,

18:51.520 --> 18:53.960
 and we state the FDA approved indications,

18:53.960 --> 18:57.720
 and we do what the law says we have to do for advertising.

18:57.720 --> 19:01.780
 And I have not, I've not been an expert in litigation

19:01.780 --> 19:04.960
 for a few years, and I don't know what's going on currently,

19:04.960 --> 19:07.080
 but let's take him at his word.

19:07.080 --> 19:09.920
 It could be true, it might not be, but it could be.

19:09.920 --> 19:14.920
 But if that's true, in his world, in his culture,

19:15.480 --> 19:17.280
 that's ethical business behavior.

19:18.160 --> 19:22.560
 From a common sense person's point of view,

19:22.560 --> 19:27.200
 a drug company paying highly skilled media folks

19:27.200 --> 19:30.440
 to take the information about the drug

19:30.440 --> 19:34.400
 and create the illusion, the emotional impact,

19:34.400 --> 19:38.000
 and the takeaway message for viewers of advertisements

19:38.000 --> 19:41.200
 that grossly exaggerate the benefit of the drug

19:41.200 --> 19:45.400
 and minimize the harms, it's sociopathic behavior

19:45.400 --> 19:49.960
 to have viewers of ads leave the ad

19:49.960 --> 19:52.960
 with an unrealistic impression

19:52.960 --> 19:56.200
 of the benefits and harms of the drug.

19:56.200 --> 19:58.880
 And yet he's playing by the rules,

19:58.880 --> 20:01.320
 he's doing his job as CEO

20:01.320 --> 20:04.560
 to maximize the effect of his advertising,

20:04.560 --> 20:07.640
 and if he doesn't do it, this is a key point,

20:07.640 --> 20:11.940
 if he doesn't do it, he'll get fired and the next guy will.

20:11.940 --> 20:13.620
 So the people that survive in the company,

20:13.620 --> 20:16.720
 the people that get raises in the company,

20:16.720 --> 20:19.200
 move up in the company are the ones that play by the rules,

20:19.200 --> 20:21.560
 and that's how the game solidifies itself.

20:21.560 --> 20:24.360
 But the game is within the bounds of the law.

20:24.360 --> 20:26.960
 Sometimes, most of the time, not always.

20:26.960 --> 20:29.240
 We'll return to that question.

20:29.240 --> 20:31.680
 I'm actually more concerned

20:31.680 --> 20:34.360
 about the effect of advertisement

20:34.360 --> 20:39.360
 in a kind of much larger scale

20:39.520 --> 20:43.040
 on the people that are getting funded

20:43.040 --> 20:46.320
 by the advertisement in self censorship,

20:46.320 --> 20:50.920
 just like more subtle, more passive pressure

20:50.920 --> 20:52.980
 to not say anything negative.

20:52.980 --> 20:57.980
 Because I've seen this, and I've been saddened by it,

20:57.980 --> 21:02.980
 that people sacrifice integrity in small ways

21:03.160 --> 21:05.740
 when they're being funded by a particular company.

21:06.600 --> 21:09.440
 They don't see themselves as doing so,

21:09.440 --> 21:12.880
 but you can just clearly see that the space of opinions

21:12.880 --> 21:15.240
 that they're willing to engage in,

21:15.240 --> 21:18.480
 or a space of ideas they're willing to play with,

21:18.480 --> 21:22.460
 is one that doesn't include negative,

21:22.460 --> 21:25.560
 anything that could possibly be negative about the company.

21:25.560 --> 21:27.160
 They just choose not to.

21:27.160 --> 21:28.880
 Because, you know, why?

21:28.880 --> 21:30.620
 And that's really sad to me,

21:30.620 --> 21:33.640
 that if you give me a hundred bucks,

21:33.640 --> 21:36.360
 I'm less likely to say something negative about you.

21:38.520 --> 21:39.920
 That makes me sad.

21:39.920 --> 21:42.600
 Because the reason I wouldn't say something negative

21:42.600 --> 21:45.600
 about you, I prefer, is the pressure of friendship

21:45.600 --> 21:48.360
 and human connection, those kinds of things.

21:48.360 --> 21:50.700
 So I understand that.

21:50.700 --> 21:52.160
 That's also a problem, by the way,

21:52.160 --> 21:54.340
 sort of having dinners and shaking hands,

21:54.340 --> 21:56.260
 and oh, aren't we friends?

21:56.260 --> 21:58.520
 But the fact that money has that effect

21:58.520 --> 22:00.220
 is really sad to me.

22:00.220 --> 22:04.120
 On the news media, on the journalists, on scientists,

22:05.320 --> 22:06.920
 that's scary to me.

22:06.920 --> 22:09.240
 But of course, the direct advertisement to consumers,

22:09.240 --> 22:11.320
 like you said, is a potentially very negative effect.

22:11.320 --> 22:14.480
 I wanted to ask if what you think

22:14.480 --> 22:17.100
 is the most negative impact of advertisement,

22:17.100 --> 22:20.320
 is it that direct to consumer on television?

22:20.320 --> 22:22.300
 Is it advertisement of the doctors?

22:22.300 --> 22:24.780
 Which I'm surprised to learn,

22:24.780 --> 22:26.320
 I was vaguely looking at,

22:26.320 --> 22:31.320
 is more spent on advertising to doctors than to consumers.

22:32.680 --> 22:34.040
 That's really confusing to me.

22:34.040 --> 22:35.640
 It's fascinating, actually.

22:35.640 --> 22:38.960
 And then also, obviously, the law side of things

22:38.960 --> 22:40.960
 is the lobbying dollars,

22:40.960 --> 22:42.660
 which I think is less than all of those.

22:42.660 --> 22:44.680
 But anyway, it's in the ballpark.

22:44.680 --> 22:46.540
 What concerns you most?

22:46.540 --> 22:49.760
 Well, it's the whole nexus of influence.

22:49.760 --> 22:53.960
 There's not one thing, and they don't invest all their,

22:53.960 --> 22:55.560
 they don't put all their eggs in one basket.

22:55.560 --> 23:00.560
 It's a whole surround sound program here.

23:01.160 --> 23:04.480
 But in terms of advertisements,

23:04.480 --> 23:06.120
 let's take the advertisement.

23:06.120 --> 23:09.640
 Trulicity is a diabetes drug,

23:09.640 --> 23:12.560
 for type two diabetes, an injectable drug.

23:12.560 --> 23:15.680
 And it lowers blood sugar just about as well

23:15.680 --> 23:18.520
 as Metformin does.

23:18.520 --> 23:21.060
 Metformin costs about $4 a month.

23:21.060 --> 23:25.760
 Trulicity costs, I think, $6,200 a year.

23:25.760 --> 23:29.480
 So $48 a year versus $6,200.

23:29.480 --> 23:31.600
 Trulicity has distinguished itself

23:31.600 --> 23:35.080
 because the manufacturer did a study

23:35.080 --> 23:37.340
 that showed that it significantly reduces

23:37.340 --> 23:41.080
 the risk of cardiovascular disease in diabetics.

23:41.080 --> 23:44.380
 And they got approval on the basis of that study,

23:44.380 --> 23:47.560
 that very large study being statistically significant.

23:47.560 --> 23:52.560
 So the ads obviously extol the virtues of Trulicity

23:53.360 --> 23:56.840
 because it reduces the risk of heart disease and stroke,

23:56.840 --> 23:59.360
 and that's one of the major morbidities,

23:59.360 --> 24:01.600
 risks of type two diabetes.

24:01.600 --> 24:03.680
 What the ad doesn't say is that you have to treat

24:03.680 --> 24:08.120
 323 people to prevent one nonfatal event

24:08.120 --> 24:10.240
 at a cost of $2.7 million.

24:11.600 --> 24:13.840
 And even more importantly than that,

24:13.840 --> 24:17.720
 what the ad doesn't say is that the evidence shows

24:17.720 --> 24:22.040
 that engaging in an active, healthy lifestyle program

24:22.040 --> 24:24.600
 reduces the risk of heart disease and strokes

24:24.600 --> 24:27.460
 far more than Trulicity does.

24:28.640 --> 24:32.160
 Now, to be fair to the company, the sponsor,

24:32.160 --> 24:37.160
 there's never been a study that compared Trulicity

24:37.440 --> 24:39.760
 to lifestyle changes.

24:39.760 --> 24:42.680
 But that's part of the problem of our advertising.

24:42.680 --> 24:45.360
 You would think in a rational society

24:45.360 --> 24:50.320
 that was way out on a limb as a lone country

24:50.320 --> 24:52.320
 besides New Zealand that allows

24:52.320 --> 24:54.360
 direct to consumer advertising,

24:54.360 --> 24:59.120
 that part of allowing direct to consumer advertising

24:59.120 --> 25:03.080
 would be to mandate that the companies establish

25:03.080 --> 25:05.520
 whether their drug is better than,

25:05.520 --> 25:07.960
 say, healthy lifestyle adoption

25:07.960 --> 25:11.820
 to prevent the problems that they claim to be preventing.

25:11.820 --> 25:13.800
 But we don't require that.

25:13.800 --> 25:17.560
 So the companies can afford to do very large studies

25:17.560 --> 25:19.560
 so that very small differences

25:19.560 --> 25:21.840
 become statistically significant.

25:21.840 --> 25:23.880
 And their studies are asking the question,

25:23.880 --> 25:25.640
 how can we sell more drug?

25:25.640 --> 25:27.320
 They're not asking the question,

25:27.320 --> 25:30.620
 how can we prevent cardiovascular disease

25:30.620 --> 25:32.720
 in people with type 2 diabetes?

25:32.720 --> 25:34.240
 And that's how we get off in this,

25:34.240 --> 25:38.560
 we're now in the extreme arm of this distortion

25:38.560 --> 25:41.400
 of our medical knowledge of studying

25:41.400 --> 25:45.480
 how to sell more drugs than how to make people more healthy.

25:45.480 --> 25:48.920
 That's a really great thing to compare to,

25:48.920 --> 25:51.400
 is lifestyle changes.

25:51.400 --> 25:53.240
 Because that should be the bar.

25:53.240 --> 25:56.680
 If you do some basic diet, exercise,

25:56.680 --> 25:58.420
 all those kinds of things,

25:58.420 --> 26:00.240
 how does this drug compare to that?

26:00.240 --> 26:01.420
 Right, right.

26:01.420 --> 26:04.080
 And that study was done, actually, in the 90s.

26:04.080 --> 26:06.080
 It's called the Diabetes Prevention Program.

26:06.080 --> 26:09.160
 It was federally funded by the NIH

26:09.160 --> 26:13.240
 so that there wasn't this drug company imperative

26:13.240 --> 26:15.840
 to just try to prove your drug was better than nothing.

26:16.800 --> 26:19.660
 And it was a very well designed study,

26:19.660 --> 26:22.440
 randomized controlled trial

26:22.440 --> 26:25.000
 in people who were at high risk of diabetes,

26:25.000 --> 26:26.840
 so called pre diabetics.

26:26.840 --> 26:30.040
 And they were randomized to three different groups,

26:30.040 --> 26:33.760
 a placebo group, a group that got treated with metformin,

26:34.760 --> 26:36.200
 and a group that got treated

26:36.200 --> 26:38.860
 with intensive lifestyle counseling.

26:38.860 --> 26:42.200
 So this study really tested

26:42.200 --> 26:46.000
 whether you can get people in a randomized controlled trial

26:46.000 --> 26:49.280
 assigned to intensive lifestyle changes,

26:49.280 --> 26:50.680
 whether that works.

26:50.680 --> 26:54.640
 Now the common wisdom amongst physicians,

26:54.640 --> 26:56.080
 and I think in general,

26:56.080 --> 26:57.960
 is that you can't get people to change.

26:57.960 --> 26:59.240
 You know, you can do whatever you want,

26:59.240 --> 27:00.320
 you can stand on your head,

27:00.320 --> 27:02.640
 you can beg and plead, people won't change.

27:02.640 --> 27:05.040
 So give it up and let's just move on with the drugs

27:05.040 --> 27:06.440
 and not waste any time.

27:06.440 --> 27:08.280
 Except this study that was published

27:08.280 --> 27:11.080
 in the New England Journal, I think in 2002,

27:11.080 --> 27:12.900
 shows that's wrong.

27:12.900 --> 27:16.200
 That the people who were in the intensive lifestyle group

27:16.200 --> 27:18.080
 ended up losing 10 pounds,

27:18.080 --> 27:21.240
 exercising five times a week, maintaining it,

27:21.240 --> 27:26.240
 and reduced their risk of getting diabetes by 58%,

27:26.320 --> 27:27.920
 compared to the metformin group,

27:27.920 --> 27:32.000
 which reduced its risk of getting diabetes by 31%.

27:32.000 --> 27:34.920
 So that exact study was done

27:34.920 --> 27:38.520
 and it showed that lifestyle intervention is the winner.

27:38.520 --> 27:43.520
 Who, as a small tangent, is the leader,

27:44.840 --> 27:49.140
 who is supposed to fight for the side of lifestyle changes?

27:49.140 --> 27:54.140
 Where's the big pharma version of lifestyle changes?

27:54.600 --> 27:57.240
 Who's supposed to have the big bully pulpit,

27:57.240 --> 28:00.040
 the big money behind lifestyle changes?

28:00.040 --> 28:03.400
 In your sense, because that seems to be missing

28:03.400 --> 28:06.280
 in a lot of our discussions about health policy.

28:06.280 --> 28:08.080
 Right, that's exactly right.

28:08.080 --> 28:12.800
 And the answer is that we assume

28:12.800 --> 28:15.760
 that the market has to solve all of these problems.

28:15.760 --> 28:18.320
 And the market can't solve all of these problems.

28:18.320 --> 28:23.240
 There needs to be some way of protecting the public interest

28:23.240 --> 28:26.520
 for things that aren't financially driven.

28:26.520 --> 28:28.760
 So that the overriding question has to be

28:28.760 --> 28:31.420
 how best to improve Americans health,

28:31.420 --> 28:36.200
 not companies funding studies to try and prove

28:36.200 --> 28:39.240
 that their new inexpensive drug is better

28:39.240 --> 28:40.880
 and should be used.

28:40.880 --> 28:45.460
 Well, some of that is also people sort of like yourself.

28:45.460 --> 28:48.800
 I mean, it's funny, you spoke with Joe Rogan.

28:48.800 --> 28:50.960
 He constantly espouses lifestyle changes.

28:50.960 --> 28:55.960
 So some of it is almost like understanding the problems

28:55.960 --> 28:58.160
 that big pharma is creating in society

28:58.160 --> 29:02.440
 and then sort of these influential voices

29:02.440 --> 29:03.560
 speaking up against it.

29:03.560 --> 29:08.600
 So whether they're scientists or just regular communicators.

29:08.600 --> 29:11.320
 Yeah, I think you gotta tip your hat to Joe

29:11.320 --> 29:13.120
 for getting that message out.

29:13.120 --> 29:17.360
 And he clearly believes it and does his best.

29:17.360 --> 29:21.040
 But it's not coming out in the legitimate avenues,

29:21.040 --> 29:26.040
 in the legitimate channels that are evidence based medicine

29:26.040 --> 29:31.040
 and from the sources that the docs are trained to listen to

29:32.040 --> 29:34.320
 and modify their patient care on.

29:34.320 --> 29:36.480
 Now, it's not 100%.

29:36.480 --> 29:40.160
 I mean, there are articles in the big journals

29:40.160 --> 29:42.160
 about the benefits of lifestyle,

29:42.160 --> 29:45.800
 but they don't carry the same gravitas

29:45.800 --> 29:48.240
 as the randomized controlled trials

29:48.240 --> 29:50.320
 that test this drug against placebo

29:50.320 --> 29:52.360
 or this drug against another drug.

29:52.360 --> 29:55.680
 So the Joe Rogans of the world keep going.

29:55.680 --> 29:57.040
 I tip my hat.

29:57.040 --> 30:00.920
 But it's not gonna carry the day for most of the people

30:00.920 --> 30:04.240
 until it has the legitimacy of the medical establishment.

30:04.240 --> 30:05.960
 Yeah, like something that the doctors

30:05.960 --> 30:07.160
 really pay attention to.

30:07.160 --> 30:09.700
 Well, there's an entire mechanism established

30:09.700 --> 30:11.320
 for testing drugs.

30:11.320 --> 30:14.400
 There's not an entire mechanism established

30:14.400 --> 30:17.600
 in terms of scientific rigor of testing lifestyle changes.

30:17.600 --> 30:20.520
 I mean, it's more difficult.

30:20.520 --> 30:23.440
 I mean, everything's difficult in science.

30:23.440 --> 30:27.120
 That science that involves humans, especially.

30:27.120 --> 30:30.640
 But it's just, these studies are very expensive.

30:30.640 --> 30:31.960
 They're difficult.

30:31.960 --> 30:33.400
 It's difficult to find conclusions

30:33.400 --> 30:35.480
 and to control all the variables.

30:35.480 --> 30:37.360
 And so it's very easy to dismiss them

30:37.360 --> 30:40.960
 unless you really do a huge study that's very well funded.

30:40.960 --> 30:42.840
 And so maybe the doctors just lean

30:42.840 --> 30:45.740
 towards the simpler studies over and over,

30:45.740 --> 30:48.040
 which is what the drug companies fund.

30:48.040 --> 30:50.400
 They can control more variables.

30:50.400 --> 30:53.680
 See, but the control there is sometimes

30:56.960 --> 31:00.920
 by hiding things too, right?

31:00.920 --> 31:03.480
 So sometimes you can just say

31:03.480 --> 31:06.420
 that this is a well controlled study

31:06.420 --> 31:09.240
 by pretending there's a bunch of other stuff.

31:09.240 --> 31:13.280
 It's just ignoring the stuff that could be correlated.

31:13.280 --> 31:15.560
 It could be the real cause of the effects you're seeing,

31:15.560 --> 31:17.360
 all that kind of stuff.

31:17.360 --> 31:21.720
 So money can buy ignorance, I suppose, in science.

31:21.720 --> 31:24.720
 It buys the kind of blinders that are on

31:24.720 --> 31:28.040
 that don't look outside the reductionist model.

31:28.040 --> 31:31.480
 And that's another issue is that we kind of,

31:31.480 --> 31:34.320
 nobody says to doctors in training,

31:34.320 --> 31:39.320
 only listen to reductionist studies and conclusions

31:39.360 --> 31:42.080
 and methods of promoting health.

31:42.080 --> 31:43.980
 Nobody says that explicitly.

31:43.980 --> 31:47.640
 But the respectable science

31:47.640 --> 31:49.760
 has to do with controlling the factors.

31:49.760 --> 31:54.200
 And I mean, it just doesn't make sense to me.

31:54.200 --> 31:55.440
 I'm gonna pick on trulicity

31:55.440 --> 31:57.240
 because it's such an obvious example,

31:57.240 --> 32:01.320
 but it's not more egregious than many others.

32:01.320 --> 32:03.720
 It doesn't make sense to me to allow a drug

32:03.720 --> 32:06.960
 to be advertised as preventing cardiovascular disease

32:06.960 --> 32:09.960
 when you haven't included lifestyle changes

32:09.960 --> 32:11.660
 as an arm in the study.

32:11.660 --> 32:15.980
 It's just so crystal clear that the purpose of that study

32:15.980 --> 32:17.420
 is to sell trulicity.

32:17.420 --> 32:20.400
 It's not to prevent cardiovascular disease.

32:21.280 --> 32:24.720
 If we were in charge, I would try to convince you

32:24.720 --> 32:27.640
 that anywhere that study, the results of that study

32:27.640 --> 32:31.040
 were presented to physicians,

32:31.040 --> 32:33.560
 it would be stamped in big red letters,

32:33.560 --> 32:37.680
 this study did not compare trulicity to lifestyle changes.

32:37.680 --> 32:38.960
 They need to know that.

32:38.960 --> 32:40.640
 And the docs are kind of trained,

32:40.640 --> 32:42.680
 these blinders get put on,

32:42.680 --> 32:46.320
 and they're trained to kind of forget that that's not there.

32:46.320 --> 32:48.240
 Do you think, so first of all,

32:48.240 --> 32:51.320
 that's a small or big change to advertisement

32:51.320 --> 32:53.100
 that seems obvious to say,

32:54.080 --> 32:56.500
 like in force that it should be compared

32:56.500 --> 32:57.700
 to lifestyle changes.

32:59.040 --> 33:01.240
 Do you think advertisements, period,

33:01.240 --> 33:04.200
 in the United States for pharmaceutical drugs

33:04.200 --> 33:05.920
 should be banned?

33:05.920 --> 33:07.520
 I think they can't be banned.

33:07.520 --> 33:09.200
 So it doesn't matter what I think.

33:09.200 --> 33:13.200
 Okay, let's say you were a dictator,

33:13.200 --> 33:15.200
 and two, why can't they be banned?

33:15.200 --> 33:16.720
 Okay.

33:16.720 --> 33:17.700
 Answer either one.

33:18.700 --> 33:22.800
 I believe, I've been told by lawyers who I trust,

33:22.800 --> 33:27.280
 that the freedom of speech in the U.S. Constitution

33:27.280 --> 33:29.360
 is such that you can't ban them,

33:29.360 --> 33:33.300
 that you could ban cigarettes and alcohol,

33:33.300 --> 33:35.640
 which have no therapeutic use,

33:35.640 --> 33:37.680
 but drugs have a therapeutic use,

33:37.680 --> 33:41.600
 and advertisements about them can't be banned.

33:41.600 --> 33:43.680
 Let's assume that they can't be,

33:43.680 --> 33:45.860
 because we know they won't be anyway,

33:46.860 --> 33:49.120
 but let's assume they can't be,

33:49.120 --> 33:51.840
 and especially our Supreme Court now

33:51.840 --> 33:55.900
 would be unlikely to take that seriously.

33:55.900 --> 33:57.360
 But that's not the issue.

33:57.360 --> 34:00.260
 The issue is that if the drug companies

34:00.260 --> 34:02.640
 want to spend their money advertising,

34:02.640 --> 34:06.880
 they should have to have independent analysis

34:06.880 --> 34:10.440
 of the message that the viewers are left with

34:10.440 --> 34:13.400
 about the drug, so that it's realistic.

34:13.400 --> 34:15.520
 What's the chance the drug will help them?

34:15.520 --> 34:19.000
 Well, in true city, it's one out of 323.

34:19.000 --> 34:21.120
 322 people aren't gonna benefit

34:21.120 --> 34:23.700
 from the cardiovascular reduction, risk reduction.

34:25.080 --> 34:26.880
 What's the true cost?

34:26.880 --> 34:30.640
 When drugs advertise that you may be able to get this

34:30.640 --> 34:33.900
 for a $25 copay or something,

34:33.900 --> 34:35.960
 tens of thousands of dollars a year drug,

34:35.960 --> 34:40.120
 for a $25 copay, what an enormous disservice that is

34:40.120 --> 34:42.600
 to misrepresent the cost to society.

34:42.600 --> 34:44.040
 That should not be allowed.

34:44.040 --> 34:48.680
 So you should have to make it clear to the viewers

34:48.680 --> 34:49.960
 how many people are gonna benefit,

34:49.960 --> 34:51.680
 what's your chance of benefiting?

34:51.680 --> 34:53.560
 How does it compare to lifestyle changes

34:53.560 --> 34:55.860
 or less expensive therapies?

34:55.860 --> 34:58.440
 What do you give up if you use a less expensive therapy

34:58.440 --> 34:59.960
 or gain, perhaps?

34:59.960 --> 35:01.160
 And how much it costs.

35:01.160 --> 35:02.280
 How much it costs.

35:02.280 --> 35:03.560
 Now, that can go either way,

35:03.560 --> 35:06.760
 because if you say Humira costs $72,000

35:06.760 --> 35:08.960
 and it's no more effective as a first line drug

35:08.960 --> 35:12.320
 than methotrexate, which costs $480,

35:12.320 --> 35:15.040
 people might say, I want the expensive drug

35:15.040 --> 35:17.740
 because I can get it for a $25 copay.

35:17.740 --> 35:21.640
 So you'd have to temper that a little bit.

35:21.640 --> 35:25.560
 Oh, you mean people are so, they don't care.

35:25.560 --> 35:26.400
 They don't care.

35:26.400 --> 35:29.440
 Their insurance is gonna cover it and it's a $25 copay,

35:29.440 --> 35:31.840
 but we could figure out how to deal with that.

35:31.840 --> 35:35.240
 The main point is that if we assume

35:35.240 --> 35:38.760
 that advertisements are gonna keep going, and they are,

35:38.760 --> 35:43.760
 we could require that there be outside evaluation

35:45.480 --> 35:48.900
 of the message that reasonable, unbiased viewers

35:48.900 --> 35:50.980
 take away from the ads,

35:50.980 --> 35:54.220
 and the ads would have to tell the truth about the drug.

35:55.720 --> 36:00.720
 And the truth should have sub truth guardrails,

36:00.720 --> 36:03.700
 meaning like the cost that we talked about,

36:03.700 --> 36:07.060
 the effects compared to things that actually,

36:07.060 --> 36:11.820
 lifestyle changes, just these details,

36:11.820 --> 36:16.500
 very strict guardrails of what actually has to be specified.

36:16.500 --> 36:19.380
 And I would make it against the law

36:19.380 --> 36:23.340
 to have family picnics or dogs catching Frisbees in the ads.

36:23.340 --> 36:28.340
 So, you mean 95% of the ads, yes.

36:28.340 --> 36:32.620
 I mean, there's something dark and inauthentic

36:32.620 --> 36:34.500
 about those advertisements, but they seem,

36:34.500 --> 36:36.240
 I mean, I'm sure they're being done

36:36.240 --> 36:38.640
 because they work for the target audience.

36:43.500 --> 36:45.120
 And then the doctors too.

36:46.060 --> 36:48.740
 Can you really buy a doctor's opinion?

36:48.740 --> 36:51.300
 Why does it have such an effect on doctors?

36:52.260 --> 36:55.460
 Advertisement to doctors, like you as a physician,

36:55.460 --> 36:58.460
 again, like from everything I've seen, people love you.

36:58.460 --> 37:03.460
 And I've just, people should definitely look you up from,

37:04.880 --> 37:09.300
 there's a bunch of videos of you giving talks on YouTube,

37:09.300 --> 37:14.300
 and it's just, it's so refreshing to hear

37:14.700 --> 37:17.460
 just the clarity of thought about health policy,

37:17.460 --> 37:19.660
 about healthcare, just the way you think

37:19.660 --> 37:20.660
 throughout the years.

37:20.660 --> 37:21.500
 Thank you.

37:21.500 --> 37:23.700
 So like, it's easy to think about like,

37:23.700 --> 37:25.360
 maybe you're criticizing Big Pharma,

37:25.360 --> 37:28.820
 that's one part of the message that you're talking about,

37:28.820 --> 37:33.020
 but that's not like, your brilliance actually shines

37:33.020 --> 37:35.440
 in the positive, in the solutions and how to do it.

37:35.440 --> 37:40.440
 So as a doctor, what affects your mind?

37:40.900 --> 37:43.120
 And how does Big Pharma affect your mind?

37:43.120 --> 37:46.500
 Number one, the information that comes through

37:46.500 --> 37:50.300
 legitimate sources that doctors have been taught

37:50.300 --> 37:52.560
 to rely on, evidence based medicine,

37:52.560 --> 37:55.420
 the articles in peer reviewed journals,

37:55.420 --> 37:57.020
 the guidelines that are issued.

37:57.020 --> 37:59.220
 Now, those are problematic,

37:59.220 --> 38:03.240
 because when an article is peer reviewed

38:03.240 --> 38:05.100
 and published in a respected journal,

38:06.340 --> 38:10.340
 people and doctors obviously assume

38:10.340 --> 38:15.340
 that the peer reviewers have had access to the data

38:15.820 --> 38:18.420
 and they've independently analyzed the data,

38:18.420 --> 38:21.900
 and they corroborate the findings in the manuscript

38:21.900 --> 38:25.740
 that was submitted, or they give feedback to the authors

38:25.740 --> 38:28.220
 and say, we disagree with you on this point,

38:28.220 --> 38:30.740
 and would you please check our analysis

38:30.740 --> 38:32.420
 and if you agree with us, make it.

38:32.420 --> 38:35.580
 That's what they assume the peer review process is,

38:35.580 --> 38:36.900
 but it's not.

38:36.900 --> 38:39.220
 The peer reviewers don't have the data.

38:39.220 --> 38:41.800
 The peer reviewers have the manuscript

38:41.800 --> 38:44.340
 that's been submitted by the,

38:44.340 --> 38:49.340
 usually in conjunction with or by the drug company

38:49.340 --> 38:51.500
 that manufactures the drug.

38:51.500 --> 38:56.500
 So peer reviewers are unable to perform the job

38:57.320 --> 38:59.700
 that doctors think they're performing

38:59.700 --> 39:03.260
 to vet the data to assure that it's accurate

39:03.260 --> 39:05.060
 and reasonably complete.

39:05.060 --> 39:06.300
 They can't do it.

39:07.300 --> 39:09.460
 And then we have the clinical practice guidelines,

39:09.460 --> 39:11.280
 which are increasingly more important

39:11.280 --> 39:15.840
 as the information, the flow of information

39:15.840 --> 39:18.660
 keeps getting brisker and brisker,

39:18.660 --> 39:22.020
 and docs need to get to the bottom line quickly.

39:22.020 --> 39:25.680
 Clinical practice guidelines become much more important.

39:25.680 --> 39:28.780
 And we assume that the authors

39:28.780 --> 39:30.380
 of those clinical practice guidelines

39:30.380 --> 39:32.380
 have independently analyzed the data

39:32.380 --> 39:35.880
 from the clinical trials and make their recommendations

39:35.880 --> 39:39.140
 that set the standards of care based on their analysis.

39:39.140 --> 39:40.860
 That's not what happens.

39:40.860 --> 39:44.180
 The experts who write the clinical trials

39:44.180 --> 39:49.180
 rely almost entirely on the publications

39:49.460 --> 39:51.940
 presenting the results of the clinical trials,

39:51.940 --> 39:52.980
 which are peer reviewed,

39:52.980 --> 39:56.340
 but the peer reviewers haven't had access to the data.

39:56.340 --> 40:01.140
 So we've got a system of the highest level of evidence

40:01.140 --> 40:03.780
 that doctors have been trained over and over again

40:03.780 --> 40:06.420
 to rely on to practice evidence based medicine

40:06.420 --> 40:10.860
 to be good doctors that has not been verified.

40:10.860 --> 40:14.300
 Do you think that data that's coming

40:14.300 --> 40:17.100
 from the pharma companies,

40:17.100 --> 40:18.160
 do you think there,

40:19.420 --> 40:22.520
 what level of manipulation is going on with that data?

40:22.520 --> 40:25.940
 Is it at the study design level?

40:25.940 --> 40:28.140
 Is it at literally there's some data

40:28.140 --> 40:33.140
 that you just keep off, keep out of the charts,

40:33.860 --> 40:38.580
 keep out of the aggregate analysis that you then publish?

40:38.580 --> 40:41.380
 Or is it the worst case,

40:41.380 --> 40:44.640
 which is just change some of the numbers?

40:44.640 --> 40:45.480
 It happened.

40:45.480 --> 40:46.300
 All three happened.

40:46.300 --> 40:48.540
 I can't, I don't know what the denominator is,

40:48.540 --> 40:51.660
 but I spent about 10 years in litigation.

40:51.660 --> 40:54.900
 And for example, in Vioxx,

40:54.900 --> 40:57.380
 which was withdrawn from the market in 2004

40:57.380 --> 41:01.220
 in the biggest drug recall in American history,

41:02.280 --> 41:06.080
 the problem was that it got recalled

41:06.080 --> 41:08.580
 when a study that Merck sponsored

41:08.580 --> 41:10.580
 showed that Vioxx doubled the risk,

41:10.580 --> 41:12.740
 more than doubled the risk of heart attacks,

41:12.740 --> 41:16.760
 strokes, and blood clots, serious blood clots.

41:16.760 --> 41:18.100
 It got pulled then.

41:18.100 --> 41:20.660
 But there was a study, a bigger study

41:20.660 --> 41:22.740
 that had been published in 2000

41:22.740 --> 41:24.660
 in the New England Journal of Medicine

41:24.660 --> 41:28.580
 that showed that Vioxx was a better drug

41:28.580 --> 41:32.820
 for arthritis and pain,

41:32.820 --> 41:34.240
 not because it was more effective.

41:34.240 --> 41:36.440
 It's no more effective than Aleve or Advil,

41:37.460 --> 41:40.220
 but because it was less likely

41:40.220 --> 41:43.220
 to cause serious GI complications,

41:43.220 --> 41:45.100
 bleeds and perforations in the gut.

41:46.180 --> 41:48.140
 Now, in that study that was published

41:48.140 --> 41:51.620
 in the New England Journal that was never corrected,

41:51.620 --> 41:55.960
 it was a little bit modified 15 months

41:55.960 --> 41:57.540
 after the drug was taken off the market,

41:57.540 --> 42:01.540
 but never corrected, Merck left out three heart attacks.

42:01.540 --> 42:05.600
 And the FDA knew that Merck left out three heart attacks,

42:05.600 --> 42:10.400
 and the FDA's analysis of the data from that study

42:10.400 --> 42:14.680
 said that the FDA wasn't gonna do the analysis

42:14.680 --> 42:16.920
 without the three heart attacks in it.

42:16.920 --> 42:19.640
 And the important part of this story

42:19.640 --> 42:23.080
 is that there were 12 authors listed on that study

42:23.080 --> 42:24.320
 in the New England Journal.

42:24.320 --> 42:26.240
 Two were Merck employees.

42:26.240 --> 42:27.760
 They knew about the three heart attacks

42:27.760 --> 42:29.600
 that had been omitted.

42:29.600 --> 42:34.440
 The other 10 authors, the academic authors,

42:34.440 --> 42:35.420
 didn't know about it.

42:35.420 --> 42:37.080
 They hadn't seen that data.

42:38.000 --> 42:41.940
 So Merck just, they had an excuse.

42:41.940 --> 42:44.240
 It's complicated, and the FDA didn't accept it,

42:44.240 --> 42:46.800
 so there's no reason to go into it.

42:46.800 --> 42:48.800
 But Merck just left out the three heart attacks.

42:48.800 --> 42:50.000
 And the three heart attacks,

42:50.000 --> 42:52.720
 it may seem three heart attacks in a 10,000 person study

42:52.720 --> 42:54.160
 may seem like nothing,

42:54.160 --> 42:57.540
 except they completely changed the statistics

42:57.540 --> 43:00.020
 so that had the three heart attacks been included,

43:00.020 --> 43:02.600
 the only conclusion that Merck could have made

43:02.600 --> 43:04.700
 was that Vioxx significantly increased

43:04.700 --> 43:06.360
 the risk of heart attack.

43:06.360 --> 43:09.600
 And they abbreviated their endpoint

43:09.600 --> 43:12.380
 from heart attack, strokes, and blood clots

43:12.380 --> 43:13.800
 to just heart attacks.

43:13.800 --> 43:14.720
 Yeah.

43:14.720 --> 43:17.120
 So those are, maybe in their mind,

43:17.120 --> 43:18.300
 they're also playing by the rules

43:18.300 --> 43:20.400
 because of some technical excuse that you mentioned

43:20.400 --> 43:21.400
 that was rejected.

43:22.240 --> 43:24.040
 How can this, because this is crossing the line.

43:24.040 --> 43:25.080
 No, no, let me interrupt.

43:25.080 --> 43:28.080
 No, that's not true.

43:28.080 --> 43:30.440
 The study was completed.

43:30.440 --> 43:33.480
 The blind was broken, meaning they looked at the data.

43:34.460 --> 43:37.400
 In March of 2000, the article was published

43:37.400 --> 43:40.120
 in the New England Journal in November of 2000.

43:40.120 --> 43:45.120
 In March of 2000, there was an email by the head scientist

43:45.960 --> 43:48.200
 that was published in the Wall Street Journal

43:49.680 --> 43:53.840
 that said the day that the data were unblinded,

43:53.840 --> 43:57.700
 that it's a shame that the cardiovascular events are there,

43:58.660 --> 44:03.660
 but the drug will do well and we will do well.

44:08.680 --> 44:10.840
 But removing the three heart attacks,

44:10.840 --> 44:12.360
 how does that happen?

44:12.360 --> 44:16.840
 Like who has to convince themselves?

44:16.840 --> 44:18.560
 Is this pure malevolence?

44:19.520 --> 44:21.440
 You have to be the judge of that,

44:21.440 --> 44:24.560
 but the person who was in charge of the Data Safety

44:24.560 --> 44:28.440
 Monitoring Board issued a letter that said

44:28.440 --> 44:32.400
 they'll stop counting cardiovascular events

44:32.400 --> 44:35.120
 a month before the trial is over

44:35.120 --> 44:38.420
 and they'll continue counting GI events.

44:38.420 --> 44:43.360
 And that person got a contract to consult with Merck

44:43.360 --> 44:47.580
 for $5,000 a day, I think for 12 days a year,

44:47.580 --> 44:52.400
 for one or two years that was signed, that contract

44:53.880 --> 44:58.220
 was signed within two weeks of the decision

44:58.220 --> 45:00.480
 to stop counting heart attacks.

45:00.480 --> 45:03.140
 I wanna understand that man or woman.

45:04.440 --> 45:08.040
 I wanna, I want, it's the, I've been reading a lot

45:08.040 --> 45:10.960
 about Nazi Germany and thinking a lot

45:10.960 --> 45:15.960
 about the good Germans because I want to understand

45:15.960 --> 45:20.000
 so that we can each encourage each other

45:20.000 --> 45:23.800
 to take the small heroic actions that prevents that.

45:23.800 --> 45:27.140
 Because it feels to me, removing malevolence

45:27.140 --> 45:31.240
 from the table where it's just a pure psychopathic person,

45:31.240 --> 45:34.120
 that there's just a momentum created

45:34.120 --> 45:35.680
 by the game like you mentioned.

45:35.680 --> 45:40.680
 And so it takes reversing the momentum within the company,

45:40.680 --> 45:45.680
 I think requires many small acts of heroism.

45:46.880 --> 45:50.640
 Not gigantic, I'm going to leave and become a whistleblower

45:50.640 --> 45:52.480
 and publish a book about it.

45:52.480 --> 45:57.060
 But small, quiet acts of pressuring against this.

45:57.060 --> 45:59.200
 Like, what are we doing here?

45:59.200 --> 46:00.480
 We're trying to help people.

46:00.480 --> 46:01.680
 Is this the right thing to do?

46:01.680 --> 46:03.380
 Looking in the mirror constantly asking,

46:03.380 --> 46:05.240
 is this the right thing to do?

46:05.240 --> 46:07.620
 I mean, that's how, that's what integrity is.

46:07.620 --> 46:11.220
 Acknowledging the pressures you're under

46:11.220 --> 46:13.100
 and then still be able to zoom out

46:13.100 --> 46:15.300
 and think what is the right thing to do here.

46:16.620 --> 46:21.180
 But the data, hiding the data makes it too easy

46:21.180 --> 46:22.660
 to live in ignorance.

46:22.660 --> 46:25.420
 So like within those, inside those companies.

46:29.540 --> 46:34.540
 So your idea is that the reviewers should see the data.

46:34.760 --> 46:36.380
 That's one step.

46:36.380 --> 46:39.740
 So to even push back on that idea is,

46:40.980 --> 46:43.340
 I assume you mean the data remains private

46:43.340 --> 46:47.040
 except to the peer reviews, reviewers.

46:47.040 --> 46:49.620
 The problem with, of course, as you probably know

46:49.620 --> 46:52.040
 is the peer review process is not perfect.

46:53.060 --> 46:55.460
 You know, it's individuals.

46:55.460 --> 46:58.740
 It feels like there should be a lot more eyes on the data

46:58.740 --> 47:00.440
 than just the peer reviewers.

47:00.440 --> 47:03.500
 Yes, this is not a hard problem to solve.

47:03.500 --> 47:06.660
 When a study is completed,

47:06.660 --> 47:09.020
 a clinical study report is made.

47:10.220 --> 47:12.300
 And it's usually several thousand pages.

47:12.300 --> 47:15.940
 And what it does is it takes the raw patient data

47:15.940 --> 47:20.940
 and it tabulates it in the ways it's supposedly and usually

47:22.060 --> 47:25.620
 in the ways that the company has pre specified.

47:25.620 --> 47:28.420
 So that you then end up with a searchable,

47:28.420 --> 47:30.740
 let's say 3000 page document.

47:30.740 --> 47:35.740
 As I became more experienced as an expert in litigation,

47:36.160 --> 47:39.680
 I could go through those documents pretty quickly.

47:39.680 --> 47:42.040
 Quickly may mean 20 hours or 40 hours,

47:42.040 --> 47:44.360
 but it doesn't mean three months of my work.

47:45.280 --> 47:49.120
 And see if the companies,

47:49.120 --> 47:51.640
 if the way the company has analyzed the data

47:51.640 --> 47:53.640
 is consistent with the way,

47:53.640 --> 47:55.800
 with their statistical analysis plan

47:55.800 --> 48:00.080
 and their pre specified outcome measures.

48:00.080 --> 48:01.280
 It's not hard.

48:01.280 --> 48:02.800
 And I think you're right.

48:02.800 --> 48:06.200
 Peer reviewers, I don't peer review clinical trials,

48:06.200 --> 48:09.320
 but I peer review other kinds of articles.

48:09.320 --> 48:11.520
 I have to do one on the airplane on the way home.

48:11.520 --> 48:12.360
 And it's hard.

48:12.360 --> 48:15.640
 I mean, we're just ordinary mortal people volunteering to.

48:15.640 --> 48:19.160
 Unpaid, the motivation is not clear.

48:19.160 --> 48:22.080
 The motivation is to keep,

48:23.520 --> 48:27.920
 to be a good citizen in the medical community

48:27.920 --> 48:31.120
 and to be on friendly terms with the journals

48:31.120 --> 48:33.280
 so that if you wanna get published,

48:33.280 --> 48:37.320
 there's sort of an unspoken incentive.

48:37.320 --> 48:39.840
 As somebody who enjoys game theory,

48:39.840 --> 48:42.200
 I feel like that motivation is good,

48:42.200 --> 48:43.700
 but it could be a lot better.

48:44.560 --> 48:46.540
 Yes, you should get more recognition

48:46.540 --> 48:50.280
 or in some way academic credit for it.

48:50.280 --> 48:53.000
 It should go to your career advancement.

48:53.000 --> 48:54.400
 If it's an important paper

48:54.400 --> 48:56.600
 and you recognize it's an important paper

48:56.600 --> 48:58.440
 as a great peer reviewer,

48:58.440 --> 49:01.240
 that this is not in that area

49:01.240 --> 49:05.920
 where it's like clearly a piece of crap paper

49:05.920 --> 49:08.320
 or clearly an awesome paper

49:08.320 --> 49:10.880
 that doesn't have controversial aspects to it

49:10.880 --> 49:13.120
 and it's just a beautiful piece of work.

49:13.120 --> 49:14.640
 Okay, those are easy.

49:14.640 --> 49:17.720
 And then there is like the very difficult gray area,

49:17.720 --> 49:20.240
 which may require many, many days of work

49:20.240 --> 49:21.920
 on your part as a peer reviewer.

49:21.920 --> 49:24.400
 So it's not just a couple hours,

49:24.400 --> 49:27.280
 but really seriously reading.

49:27.280 --> 49:30.720
 Like some papers can take months to really understand.

49:30.720 --> 49:33.600
 So if you really wanna struggle,

49:33.600 --> 49:35.920
 there has to be an incentive for that struggle.

49:35.920 --> 49:40.920
 Yes, and billions of dollars ride on some of these studies.

49:41.280 --> 49:44.680
 And lives, right, not to mention.

49:44.680 --> 49:49.680
 Right, but it would be easy to have full time statisticians

49:49.680 --> 49:53.840
 hired by the journals or shared by the journals

49:55.280 --> 50:00.280
 who were independent of any other financial incentive

50:00.280 --> 50:04.000
 to go over these kind of methodological issues

50:04.000 --> 50:08.880
 and take responsibility for certifying the analyses

50:08.880 --> 50:11.200
 that are done and then pass it on

50:11.200 --> 50:14.080
 to the volunteer peer reviewers.

50:14.080 --> 50:15.920
 See, I believe even in this,

50:15.920 --> 50:19.400
 in the sort of capitalism or even social capital,

50:19.400 --> 50:23.560
 after watching Twitter in the time of COVID

50:23.560 --> 50:27.440
 and just looking at people that investigate themselves,

50:27.440 --> 50:30.040
 I believe in the citizenry.

50:30.040 --> 50:32.440
 People, if you give them access to the data,

50:32.440 --> 50:35.880
 like these like citizen scientists arise.

50:35.880 --> 50:38.360
 A lot of them on the, it's kind of funny,

50:39.320 --> 50:40.960
 a lot of people that are just really used

50:40.960 --> 50:41.960
 to working with data,

50:43.160 --> 50:44.600
 they don't know anything about medicine

50:44.600 --> 50:46.800
 and they don't have actually the biases

50:46.800 --> 50:48.880
 that a lot of doctors and medical

50:48.880 --> 50:51.040
 and a lot of the people that read these papers,

50:51.040 --> 50:53.240
 they'll just go raw into the data

50:53.240 --> 50:56.120
 and look at it with like they're bored almost

50:56.120 --> 50:58.320
 and they do incredible analysis.

50:58.320 --> 51:01.080
 So I, you know, there's some argument to be made

51:01.080 --> 51:04.080
 for a lot of this data to become public,

51:04.080 --> 51:07.120
 like deanonymized, no, sorry, anonymized,

51:08.360 --> 51:11.120
 all that kind of stuff, but for a lot of it to be public,

51:11.120 --> 51:13.360
 especially when you're talking about things

51:14.520 --> 51:16.960
 as impactful as some of these drugs.

51:16.960 --> 51:19.960
 I agree 100%, so let's turn the micro,

51:19.960 --> 51:22.160
 let's get a little bit more granular.

51:22.160 --> 51:24.200
 On the peer review issue,

51:24.200 --> 51:27.800
 we're talking about pre publication transparencies

51:27.800 --> 51:29.600
 and that is critically important.

51:29.600 --> 51:33.600
 Once a paper is published, the horses are out of the barn

51:33.600 --> 51:34.840
 and docs are gonna read it,

51:34.840 --> 51:36.800
 take it as evidence based medicine.

51:36.800 --> 51:41.040
 The economists call what then happens as stickiness

51:41.040 --> 51:43.360
 that the docs hold on to their beliefs

51:43.360 --> 51:47.280
 and my own voice inside says,

51:47.280 --> 51:52.000
 once doctors start doing things to their patients bodies,

51:52.000 --> 51:53.640
 they're really not too enthusiastic

51:53.640 --> 51:55.440
 about hearing it was wrong.

51:55.440 --> 51:57.880
 Yeah, that's the stickiness of human nature.

51:57.880 --> 52:00.840
 Wow, so that bar, once it's published,

52:01.880 --> 52:05.120
 the doctors, that's when the stickiness emerges, wow.

52:05.120 --> 52:08.200
 Yeah, it's hard to put that toothpaste back in the tube.

52:08.200 --> 52:11.520
 Now, that's pre publication transparency,

52:11.520 --> 52:14.520
 which is essential and you could have,

52:14.520 --> 52:17.440
 whoever saw that data pre publication

52:17.440 --> 52:19.960
 could sign confidentiality agreements

52:19.960 --> 52:22.480
 so that the drug companies couldn't argue

52:22.480 --> 52:24.680
 that we're just opening the spigots of our data

52:24.680 --> 52:28.880
 and people can copy it and blah, all the excuses they make.

52:28.880 --> 52:30.520
 You could argue that you didn't have to

52:30.520 --> 52:32.400
 but let's just let them do it.

52:32.400 --> 52:35.160
 Let the peer reviewers sign confidentiality agreements

52:35.160 --> 52:36.760
 and they won't leak the data

52:36.760 --> 52:39.840
 but then you have to go to post publication transparency,

52:39.840 --> 52:41.720
 which is what you were just getting at

52:41.720 --> 52:46.720
 to let the data free and let citizens

52:47.000 --> 52:50.520
 and citizen scientists and other doctors

52:50.520 --> 52:52.640
 who are interested have at it.

52:53.640 --> 52:56.600
 Kind of like Wiki, Wikipedia, have at it.

52:57.680 --> 53:00.080
 Let it out and let people criticize each other.

53:01.280 --> 53:03.120
 Okay, so speaking of the data,

53:03.120 --> 53:08.120
 the FDA asked 55 years to release Pfizer vaccine data.

53:08.120 --> 53:11.600
 This is also something I raised with Albert Bourla.

53:11.600 --> 53:13.200
 What did he say?

53:13.200 --> 53:16.200
 There's several things I didn't like about what he said.

53:16.200 --> 53:17.760
 So some things are expected

53:17.760 --> 53:20.520
 and some of it is just revealing the human being,

53:20.520 --> 53:23.160
 which is what I'm interested in doing.

53:23.160 --> 53:27.520
 But he said he wasn't aware of the 75 and the 55.

53:27.520 --> 53:29.240
 I'm sorry, wait a minute.

53:29.240 --> 53:30.520
 He wasn't aware of?

53:30.520 --> 53:33.120
 The how long, so here I'll explain what he.

53:33.120 --> 53:36.800
 Do you know that since you spoke to him,

53:36.800 --> 53:41.800
 Pfizer has petitioned the judge to join the suit

53:42.120 --> 53:45.000
 in behalf of the FDA's request

53:45.000 --> 53:50.040
 to release that data over 55 or 75 years?

53:50.040 --> 53:52.200
 Pfizer's fully aware of what's going on.

53:52.200 --> 53:53.280
 He's aware.

53:53.280 --> 53:56.280
 I'm sure he's aware in some formulation.

53:56.280 --> 53:59.080
 The exact years he might have not been aware.

53:59.080 --> 54:01.200
 But the point is that there is,

54:02.520 --> 54:06.600
 that is the FDA, the relationship of Pfizer and the FDA

54:06.600 --> 54:11.000
 in terms of me being able to read human beings

54:11.000 --> 54:14.320
 was the thing he was most uncomfortable with,

54:14.320 --> 54:17.440
 that he didn't wanna talk about the FDA.

54:17.440 --> 54:20.080
 And that really, it was clear

54:20.080 --> 54:22.280
 that there was a relationship there

54:22.280 --> 54:26.440
 that if the words you use may do a lot of harm,

54:26.440 --> 54:28.520
 potentially because like you're saying,

54:28.520 --> 54:31.360
 there might be lawsuits going on, there's litigation,

54:31.360 --> 54:33.480
 there's legal stuff, all that kind of stuff.

54:33.480 --> 54:36.600
 And then there's a lot of games being played in this space.

54:36.600 --> 54:40.040
 So I don't know how to interpret it

54:40.040 --> 54:41.560
 if he's actually aware or not,

54:41.560 --> 54:46.560
 but the deeper truth is that he's deeply uncomfortable

54:49.600 --> 54:53.080
 bringing light to this part of the game.

54:53.080 --> 54:56.000
 Yes, and I'm gonna read between the lines

54:56.000 --> 54:59.960
 and Albert Borla certainly didn't ask me to speak for him.

54:59.960 --> 55:02.480
 But I think, but when did you speak to him?

55:02.480 --> 55:03.440
 How long ago?

55:03.440 --> 55:05.800
 Wow, time flies when you're having fun.

55:05.800 --> 55:06.640
 Two months ago.

55:06.640 --> 55:07.480
 Two months ago.

55:07.480 --> 55:12.040
 So that was just recently it's come out,

55:12.040 --> 55:14.480
 just in the past week it's come out

55:14.480 --> 55:18.920
 that Pfizer isn't battling the FDA.

55:18.920 --> 55:23.920
 Pfizer has joined the FDA in the opposition to the request

55:24.880 --> 55:29.880
 to release these documents in the same amount of time

55:29.880 --> 55:33.200
 that the FDA took to evaluate them.

55:33.200 --> 55:34.080
 Yeah.

55:34.080 --> 55:39.080
 So Pfizer is offering to help the FDA

55:43.740 --> 55:48.740
 to petition the judge to not enforce the timeline

55:51.560 --> 55:54.120
 that he seems to be moving towards.

55:54.120 --> 55:55.600
 So for people who are not familiar,

55:55.600 --> 55:59.120
 we're talking about the Freedom of Information Act request

55:59.120 --> 56:04.120
 to release the Pfizer vaccine data, study data

56:05.200 --> 56:07.240
 to release as much of the data as possible,

56:07.240 --> 56:08.920
 like the raw data, the details,

56:08.920 --> 56:10.560
 or actually not even the raw data,

56:10.560 --> 56:14.620
 it's data, doesn't matter, there's details to it.

56:14.620 --> 56:19.620
 And I think the response from the FDA is that of course,

56:20.200 --> 56:25.200
 yes, of course, but we can only publish

56:25.200 --> 56:29.720
 we can only publish like some X number of pages a day.

56:29.720 --> 56:31.000
 500 pages.

56:31.000 --> 56:32.720
 500 pages of data.

56:32.720 --> 56:36.440
 It's not a day though, it's a week I think.

56:36.440 --> 56:39.400
 The point is whatever they're able to publish is ridiculous.

56:39.400 --> 56:44.400
 It's like my printer can only print three pages a day

56:45.520 --> 56:48.000
 and we cannot afford a second printer.

56:48.000 --> 56:52.320
 So it's some kind of bureaucratic language for,

56:52.320 --> 56:56.160
 there's a process to this, and now you're saying

56:56.160 --> 57:00.320
 that Pfizer is obviously more engaged

57:00.320 --> 57:04.160
 in helping this kind of bureaucratic process prosper

57:04.160 --> 57:08.880
 in its full absurdity, Kafkaesque absurdity.

57:08.880 --> 57:11.860
 So what is this?

57:11.860 --> 57:13.800
 This really bothered people.

57:13.800 --> 57:14.640
 This really.

57:14.640 --> 57:15.680
 This is really troublesome.

57:15.680 --> 57:19.660
 And just to put it in just plain English terms,

57:19.660 --> 57:23.540
 Pfizer's making the case that it can't,

57:24.860 --> 57:27.460
 the FDA and Pfizer together are making the case

57:27.460 --> 57:29.820
 that they can't go through the documents.

57:29.820 --> 57:33.700
 It's gonna take them some number of hundredfold,

57:33.700 --> 57:37.140
 hundreds of folds more time to go through the documents

57:37.140 --> 57:39.860
 than the FDA required to go through the documents

57:39.860 --> 57:42.300
 to approve the vaccines,

57:42.300 --> 57:44.940
 to give the vaccines full FDA approval.

57:44.940 --> 57:48.940
 And the FDA's argument, talk about Kafkaesque,

57:48.940 --> 57:51.340
 is that to do it more rapidly

57:51.340 --> 57:52.980
 would cost them $3 million.

57:54.820 --> 57:59.820
 $3 million equals one hour of vaccine sales over two years.

58:01.980 --> 58:04.340
 One hour of sales.

58:04.340 --> 58:05.900
 And they can't come up with the money.

58:05.900 --> 58:08.020
 And now Pfizer has joined the suit

58:08.020 --> 58:11.140
 to help the FDA fight off this judge, this mean judge,

58:11.140 --> 58:12.900
 who thinks they ought to release the data.

58:12.900 --> 58:15.020
 But evidently Pfizer isn't offering

58:15.020 --> 58:17.300
 to come up with the $3 million either.

58:17.300 --> 58:19.820
 So, but for $3 million, I mean, maybe,

58:21.740 --> 58:25.500
 maybe the FDA should do a GoFundMe campaign.

58:25.500 --> 58:28.420
 Well, obviously the money thing,

58:28.420 --> 58:31.380
 I mean, I'm sure if Elon Musk comes along and says,

58:31.380 --> 58:35.500
 I'll give you $100 million, publish it now,

58:35.500 --> 58:37.900
 I think they'll come up with another.

58:37.900 --> 58:41.900
 So, I mean, it's clear that there's cautiousness.

58:43.660 --> 58:47.140
 I don't know the source of it from the FDA.

58:47.140 --> 58:49.660
 There's only one explanation that I can think of,

58:50.580 --> 58:53.020
 which is that the FDA and Pfizer

58:53.020 --> 58:54.540
 don't wanna release the data.

58:55.420 --> 58:57.940
 They don't wanna release the three

58:57.940 --> 59:02.020
 or 500,000 pages of documents.

59:03.180 --> 59:05.380
 And I don't know what's in there.

59:05.380 --> 59:08.140
 I wanna say one thing very clearly.

59:08.140 --> 59:10.140
 I am not an anti faxer.

59:10.140 --> 59:11.940
 I believe the vaccines work.

59:11.940 --> 59:15.220
 I believe everybody should get vaccinated.

59:15.220 --> 59:17.620
 The evidence is clear that if you're vaccinated,

59:17.620 --> 59:20.900
 you reduce your risk of dying of COVID by 20 fold.

59:20.900 --> 59:23.460
 And we've got new sub variants coming along.

59:23.460 --> 59:26.620
 And I just wanna be very clear about this.

59:26.620 --> 59:31.620
 That said, there's something I would give you 10 to one odds

59:32.420 --> 59:35.100
 on a bet that there's something in that data

59:35.100 --> 59:40.100
 that is gonna be embarrassing to either FDA or Pfizer

59:40.460 --> 59:41.300
 or both.

59:41.300 --> 59:42.140
 So there's two options.

59:42.140 --> 59:43.740
 I agree with you 100%.

59:43.740 --> 59:46.700
 One is they know of embarrassing things.

59:46.700 --> 59:48.180
 That's option one.

59:48.180 --> 59:51.740
 And option two, they haven't invested enough

59:51.740 --> 59:54.180
 to truly understand the data.

59:54.180 --> 59:56.420
 Like, I mean, it's a lot of data

59:56.420 --> 59:58.140
 that they have a sense

59:58.140 --> 1:00:00.020
 that might be something embarrassing in there.

1:00:00.020 --> 1:00:02.100
 And if we release it,

1:00:02.100 --> 1:00:04.380
 surely the world will discover the embarrassing

1:00:04.380 --> 1:00:08.860
 and to do a sort of the steel man their argument.

1:00:08.860 --> 1:00:11.660
 They'll take the small, the press,

1:00:11.660 --> 1:00:14.420
 the people will take the small embarrassing things

1:00:14.420 --> 1:00:16.380
 and blow them up into big things.

1:00:16.380 --> 1:00:20.260
 Yes, and support the anti vax campaign.

1:00:20.260 --> 1:00:22.660
 I think that's all possible.

1:00:22.660 --> 1:00:27.660
 Nonetheless, the data are about the original clinical trial.

1:00:27.860 --> 1:00:32.860
 And the emergency use authorization was based

1:00:33.340 --> 1:00:36.140
 on the first few months of the data from that trial.

1:00:36.140 --> 1:00:37.780
 And it was a two year trial.

1:00:37.780 --> 1:00:40.140
 The rest of that data has not been opened up

1:00:40.140 --> 1:00:43.460
 and there was not an advisory committee meeting

1:00:43.460 --> 1:00:44.940
 to look at that data

1:00:44.940 --> 1:00:47.340
 when the FDA granted full authorization.

1:00:47.340 --> 1:00:49.220
 Again, I am pro vaccine.

1:00:49.220 --> 1:00:52.540
 I am not making an anti vax argument here.

1:00:52.540 --> 1:00:56.060
 But I suspect that there's something pretty serious

1:00:56.060 --> 1:00:57.380
 in that data.

1:00:57.380 --> 1:01:00.020
 And the reason why I'm not an anti vaxxer,

1:01:00.980 --> 1:01:03.380
 having not been able to see the data

1:01:03.380 --> 1:01:06.020
 that the FDA and Pfizer seem to willing

1:01:06.020 --> 1:01:09.940
 not just to put effort into preventing the release of,

1:01:09.940 --> 1:01:12.100
 but seem to have quite a bit of energy

1:01:12.100 --> 1:01:15.140
 into preventing, invest quite a bit of energy

1:01:15.140 --> 1:01:16.460
 in not releasing that data.

1:01:16.460 --> 1:01:18.380
 The reason why that doesn't tip me over

1:01:18.380 --> 1:01:20.180
 into the anti vaxxer side

1:01:20.180 --> 1:01:22.380
 is because that's clinical trial data,

1:01:22.380 --> 1:01:23.660
 early clinical trial data

1:01:23.660 --> 1:01:25.780
 that involved several thousand people.

1:01:25.780 --> 1:01:28.900
 We now have millions of data points

1:01:28.900 --> 1:01:31.060
 from people who have had the vaccine.

1:01:31.060 --> 1:01:32.900
 This is real world data,

1:01:32.900 --> 1:01:35.700
 showing the efficacy of the vaccines.

1:01:35.700 --> 1:01:38.100
 And so far, knock on wood,

1:01:38.100 --> 1:01:41.220
 there aren't side effects

1:01:41.220 --> 1:01:45.100
 that overcome the benefits of vaccine.

1:01:45.100 --> 1:01:46.500
 So I'm with you.

1:01:46.500 --> 1:01:51.360
 I'm now, I guess, three shots of the vaccine.

1:01:53.180 --> 1:01:55.740
 But there's a lot of people that are kind of saying,

1:01:55.740 --> 1:02:00.260
 well, even the data on the real world use large scale data

1:02:03.980 --> 1:02:05.660
 is messy.

1:02:05.660 --> 1:02:06.820
 The way it's being reported,

1:02:06.820 --> 1:02:08.780
 the way it's being interpreted.

1:02:08.780 --> 1:02:11.500
 Well, one thing is clear to me

1:02:11.500 --> 1:02:13.820
 that it is being politicized.

1:02:13.820 --> 1:02:16.120
 I mean, if you just look objectively,

1:02:17.120 --> 1:02:21.740
 don't have to go to at the shallow surface level.

1:02:21.740 --> 1:02:24.140
 It seems like there's two groups

1:02:25.180 --> 1:02:29.020
 that I can't even put a term to it

1:02:29.020 --> 1:02:32.140
 because it's not really pro vaccine versus anti vaccine

1:02:32.140 --> 1:02:37.140
 because it's pro vaccine, triple mask, Democrat, liberal,

1:02:41.140 --> 1:02:44.700
 and then anti mandate, whatever those groups are.

1:02:44.700 --> 1:02:46.540
 I can't quite, cause they're changing.

1:02:46.540 --> 1:02:50.380
 Anti mask, but not really, but kind of.

1:02:50.380 --> 1:02:53.260
 So those two groups that feel political in nature,

1:02:53.260 --> 1:02:56.700
 not scientific in nature, they're bickering.

1:02:56.700 --> 1:03:01.200
 And then it's clear that this data is being interpreted

1:03:01.200 --> 1:03:03.140
 by the different groups differently.

1:03:04.020 --> 1:03:07.460
 And it's very difficult for me as a human being

1:03:07.460 --> 1:03:11.180
 to understand where the truth lies,

1:03:11.180 --> 1:03:14.060
 especially given how much money is flying around

1:03:14.060 --> 1:03:15.380
 on all sides.

1:03:15.380 --> 1:03:19.380
 So the anti vaxxers can make a lot of money too.

1:03:19.380 --> 1:03:20.220
 Let's not forget this.

1:03:20.220 --> 1:03:22.500
 From the individual perspective,

1:03:22.500 --> 1:03:25.260
 you can become famous being an anti vaxxer.

1:03:25.260 --> 1:03:28.060
 And so there's a lot of incentives on all sides here.

1:03:28.060 --> 1:03:33.060
 And there's real human emotion and fear

1:03:33.300 --> 1:03:35.300
 and also credibility.

1:03:37.620 --> 1:03:41.100
 Scientists don't wanna ruin their reputation

1:03:41.100 --> 1:03:45.340
 if they speak out in whatever, like speak their opinion

1:03:45.340 --> 1:03:49.540
 or they look at some slice of the data

1:03:49.540 --> 1:03:51.300
 and begin to interpret it in some kind of way.

1:03:51.300 --> 1:03:53.740
 They're very, it's clear that fear is dominating

1:03:53.740 --> 1:03:57.020
 the discourse here, especially in the scientific community.

1:03:57.020 --> 1:03:59.320
 So I don't know what to make of that.

1:04:01.860 --> 1:04:05.660
 And the only happy people here is Pfizer.

1:04:06.780 --> 1:04:08.660
 It's just plowing all ahead.

1:04:08.660 --> 1:04:13.240
 I mean, with every single variant,

1:04:13.240 --> 1:04:18.240
 there's very, I would say, outside of arguably

1:04:20.300 --> 1:04:23.260
 a very flawed system, there's a lot of incredible

1:04:23.260 --> 1:04:25.760
 scientific and engineering work being done

1:04:25.760 --> 1:04:29.820
 in constantly developing new, like antiviral drugs,

1:04:29.820 --> 1:04:33.380
 new vaccines to deal with the variants.

1:04:33.380 --> 1:04:37.540
 So they're happily being a capitalist machine.

1:04:37.540 --> 1:04:42.540
 And it's very difficult to know what to do with that.

1:04:43.620 --> 1:04:46.580
 And let's just put this in perspective for folks.

1:04:46.580 --> 1:04:49.660
 The best selling drug in the world has been Humira

1:04:49.660 --> 1:04:51.420
 for a number of years.

1:04:51.420 --> 1:04:55.500
 It's approved for the treatment of rheumatoid arthritis

1:04:55.500 --> 1:04:57.740
 and eight other indications.

1:04:57.740 --> 1:05:02.140
 And it's sold about $20 billion globally

1:05:02.140 --> 1:05:03.820
 over the past few years.

1:05:03.820 --> 1:05:07.140
 It peaked at that level.

1:05:07.140 --> 1:05:12.140
 Pfizer expects to sell $65 billion of vaccine

1:05:12.940 --> 1:05:16.280
 in the first two years of the pandemic.

1:05:16.280 --> 1:05:19.960
 So this is by far the biggest selling

1:05:19.960 --> 1:05:22.700
 and most profitable drug that's ever come along.

1:05:22.700 --> 1:05:27.020
 I can ask you a difficult question here.

1:05:28.480 --> 1:05:31.520
 In the fog that we're operating in here,

1:05:34.320 --> 1:05:38.680
 on the Pfizer BioNTech vaccine,

1:05:40.340 --> 1:05:43.460
 what was done well and what was done badly

1:05:43.460 --> 1:05:47.740
 that you can see now, it seems like we'll know

1:05:47.740 --> 1:05:50.080
 more decades from now.

1:05:50.080 --> 1:05:51.380
 Yes.

1:05:51.380 --> 1:05:56.380
 But now in the fog of today with the $65 billion

1:05:57.860 --> 1:06:02.220
 flying around, where do you land?

1:06:03.060 --> 1:06:08.060
 So we're gonna get to what I think is one of the key problems

1:06:08.500 --> 1:06:12.220
 with the pharmaceutical industry model in the United States

1:06:12.220 --> 1:06:15.040
 about being profit driven.

1:06:15.040 --> 1:06:20.040
 So in 2016, the NIH did the key infrastructure work

1:06:22.440 --> 1:06:25.240
 to make mRNA vaccines.

1:06:26.920 --> 1:06:29.320
 That gets left out of the discussion a lot.

1:06:29.320 --> 1:06:33.520
 And Pfizer BioNTech actually paid royalties voluntarily

1:06:35.160 --> 1:06:36.000
 to the NIH.

1:06:36.000 --> 1:06:36.920
 I don't know how much it was.

1:06:36.920 --> 1:06:38.540
 I don't think it was a whole lot of money,

1:06:38.540 --> 1:06:41.200
 but I think they wanted to avoid the litigation

1:06:41.200 --> 1:06:45.880
 that Moderna got itself into by just taking that 2016

1:06:45.880 --> 1:06:48.780
 knowledge and having that be the foundation

1:06:48.780 --> 1:06:50.120
 of their product.

1:06:50.120 --> 1:06:54.640
 So Pfizer took that and they did their R&D,

1:06:54.640 --> 1:06:59.160
 they paid for their R&D having received that technology.

1:06:59.160 --> 1:07:03.800
 And when they got the genetic code from China

1:07:03.800 --> 1:07:08.800
 about the virus, they very quickly made a vaccine

1:07:09.480 --> 1:07:10.920
 and the vaccine works.

1:07:10.920 --> 1:07:14.520
 And President Trump to his credit launched

1:07:14.520 --> 1:07:18.120
 Operation Warp Speed and just threw money at the problem.

1:07:18.120 --> 1:07:22.400
 They just said, we spent five times more per person

1:07:22.400 --> 1:07:26.840
 than the EU early on, just pay them whatever they want.

1:07:26.840 --> 1:07:28.360
 Let's just get this going.

1:07:28.360 --> 1:07:32.360
 And Americans were vaccinated more quickly.

1:07:32.360 --> 1:07:34.160
 We paid a lot of money.

1:07:34.160 --> 1:07:37.120
 The one mistake that I think the federal government made

1:07:37.120 --> 1:07:41.000
 was they were paying these guaranteed fortunes

1:07:41.000 --> 1:07:45.320
 and they didn't require that the companies participate

1:07:45.320 --> 1:07:49.040
 in a program to do global vaccinations.

1:07:50.080 --> 1:07:53.480
 So the companies doing their business model

1:07:53.480 --> 1:07:56.240
 distributed the vaccines where they would make

1:07:56.240 --> 1:07:57.240
 the most money.

1:07:57.240 --> 1:07:59.080
 And obviously they would make the most money

1:07:59.080 --> 1:08:00.000
 in the first world.

1:08:00.000 --> 1:08:04.240
 And almost I think 85% of the vaccines early on

1:08:04.240 --> 1:08:08.760
 went to the first world and very, very few vaccinations

1:08:08.760 --> 1:08:10.520
 went to the third world.

1:08:10.520 --> 1:08:15.520
 So what happened is there was such a low vaccination rate

1:08:16.440 --> 1:08:21.440
 in May of 2021, there was all hands on deck cry for help

1:08:23.040 --> 1:08:25.120
 from the World Trade Organization,

1:08:26.520 --> 1:08:31.480
 the World Health Organization, the IMF and the World Bank

1:08:31.480 --> 1:08:36.480
 made a plea for $50 billion so that we could get

1:08:36.720 --> 1:08:40.520
 to 40% vaccination rate in the third world

1:08:40.520 --> 1:08:42.280
 by the end of 2021.

1:08:44.360 --> 1:08:47.480
 And it was unrequited, nobody answered.

1:08:48.840 --> 1:08:53.840
 And now Africa has about a 8.9% vaccination rate.

1:08:54.440 --> 1:08:57.080
 India is coming up, but it's been very low.

1:08:57.080 --> 1:09:02.080
 The problem with all this is I believe those mRNA vaccines

1:09:02.200 --> 1:09:03.800
 are excellent vaccines.

1:09:04.680 --> 1:09:07.920
 But if we leave the third world unvaccinated,

1:09:07.920 --> 1:09:12.720
 we're gonna have a constant supply of variants of COVID

1:09:12.720 --> 1:09:15.760
 that are gonna come back into the United States

1:09:15.760 --> 1:09:20.720
 and harm Americans exactly like Delta and Omicron have.

1:09:20.720 --> 1:09:25.720
 So we've made a great drug, it reduces the risk of mortality

1:09:25.720 --> 1:09:28.400
 in Americans who get it by a lot.

1:09:28.400 --> 1:09:31.080
 But we're not doing what we need to do

1:09:31.080 --> 1:09:33.320
 to protect Americans from Omicron.

1:09:33.320 --> 1:09:34.760
 You don't have to be an idealist

1:09:34.760 --> 1:09:36.960
 and worry about global vaccine equity.

1:09:36.960 --> 1:09:41.280
 If you're just ordinary selfish people like most of us are,

1:09:41.280 --> 1:09:43.600
 and you're worried about the health of Americans,

1:09:43.600 --> 1:09:47.080
 you would ensure global vaccine distribution.

1:09:47.080 --> 1:09:49.120
 Let me just make one more point.

1:09:49.120 --> 1:09:51.760
 That $50 billion that was requested

1:09:51.760 --> 1:09:55.240
 by the four organizations back in May of 2021,

1:09:55.240 --> 1:09:59.320
 32 billionaires made $50 billion

1:09:59.320 --> 1:10:01.440
 from the vaccines at that point,

1:10:01.440 --> 1:10:03.960
 took it into their private wealth.

1:10:03.960 --> 1:10:05.040
 So what had been taken,

1:10:05.040 --> 1:10:06.920
 this enormous amounts of money that had been taken

1:10:06.920 --> 1:10:10.200
 into private wealth was enough to do

1:10:10.200 --> 1:10:12.840
 what those organizations said needed to be done

1:10:12.840 --> 1:10:15.600
 to prevent the sub variants from coming back

1:10:15.600 --> 1:10:16.640
 and doing what they're doing.

1:10:16.640 --> 1:10:19.080
 So the money was there, but how does the motivation,

1:10:19.080 --> 1:10:22.600
 the money driven motivation of Big Pharma lead to that,

1:10:22.600 --> 1:10:27.600
 that kind of allocation of vaccines?

1:10:28.480 --> 1:10:31.480
 Because they can make more money in the United States.

1:10:31.480 --> 1:10:33.080
 They're gonna distribute their vaccines

1:10:33.080 --> 1:10:34.560
 where they can make the most money.

1:10:34.560 --> 1:10:39.560
 Right, is there a malevolent aspect to this

1:10:40.120 --> 1:10:44.520
 where, boy, I don't like saying this,

1:10:44.520 --> 1:10:49.520
 but that they don't see it as a huge problem

1:10:49.520 --> 1:10:53.200
 that variants will come back to the United States.

1:10:53.200 --> 1:10:56.760
 I think it's the issue we were talking about earlier on

1:10:56.760 --> 1:10:58.560
 where they're in a different culture

1:10:58.560 --> 1:11:02.500
 and their culture is that their moral obligation,

1:11:02.500 --> 1:11:04.600
 as Milton Friedman would say,

1:11:04.600 --> 1:11:06.280
 is to maximize the profits

1:11:06.280 --> 1:11:07.760
 that they return to shareholders.

1:11:07.760 --> 1:11:10.600
 And don't think about the bigger picture.

1:11:10.600 --> 1:11:12.720
 The collateral damage, don't think about the collateral.

1:11:12.720 --> 1:11:16.780
 And also kind of believe, convince yourself

1:11:16.780 --> 1:11:20.160
 that if we give into this capitalist machine

1:11:20.160 --> 1:11:23.160
 in this very narrow sense of capitalism,

1:11:23.160 --> 1:11:25.920
 that in the end, they'll do the most good.

1:11:25.920 --> 1:11:28.560
 This kind of belief that like,

1:11:28.560 --> 1:11:32.640
 if we just maximize profits, we'll do the most good.

1:11:32.640 --> 1:11:36.800
 Yeah, that's an orthodoxy of several decades ago.

1:11:36.800 --> 1:11:40.200
 And I don't think people can really say that in good faith.

1:11:40.200 --> 1:11:43.720
 When you're talking about vaccinating the third world

1:11:43.720 --> 1:11:44.920
 so we don't get hurt,

1:11:44.920 --> 1:11:47.280
 it's a little bit hard to make the argument

1:11:47.280 --> 1:11:48.500
 that the world's a better place

1:11:48.500 --> 1:11:51.080
 because the profits of the investors went up.

1:11:51.080 --> 1:11:52.480
 Yeah, but at the same time,

1:11:54.800 --> 1:11:58.040
 I think that's a belief you can hold.

1:11:58.040 --> 1:12:01.240
 I mean, I've interacted with a bunch of folks that kinda,

1:12:01.240 --> 1:12:05.460
 it's the, I don't wanna mischaracterize Ayn Rand, okay?

1:12:05.460 --> 1:12:07.340
 I respect a lot of people,

1:12:07.340 --> 1:12:10.080
 but there's a belief that can take hold.

1:12:10.080 --> 1:12:13.880
 If I just focus on this particular maximization,

1:12:13.880 --> 1:12:16.000
 it will do the most good for the world.

1:12:16.000 --> 1:12:19.160
 The problem is when you choose what to maximize

1:12:19.160 --> 1:12:20.680
 and you put blinders on,

1:12:20.680 --> 1:12:24.680
 it's too easy to start making gigantic mistakes

1:12:24.680 --> 1:12:28.120
 that have a big negative impact on society.

1:12:28.120 --> 1:12:30.680
 So it's really matters what you're maximizing.

1:12:30.680 --> 1:12:33.680
 Right, and if we had a true democracy

1:12:33.680 --> 1:12:35.260
 and everybody had one vote,

1:12:36.500 --> 1:12:39.560
 everybody got decent information and had one vote,

1:12:39.560 --> 1:12:44.040
 Ayn Rand's position would get some votes, but not many,

1:12:44.040 --> 1:12:47.820
 and it would be way outvoted by the common people.

1:12:48.840 --> 1:12:53.840
 Let me ask you about this very difficult topic.

1:12:53.840 --> 1:12:58.840
 I'm talking to Mark Zuckerberg of Metta,

1:13:00.640 --> 1:13:03.020
 the topic of censorship.

1:13:03.020 --> 1:13:04.760
 I don't know if you've heard,

1:13:04.760 --> 1:13:08.960
 but there's a guy named Robert Malone and Peter McCullough

1:13:08.960 --> 1:13:10.880
 that were removed from many platforms

1:13:10.880 --> 1:13:14.200
 for speaking about the COVID vaccine as being risky.

1:13:14.200 --> 1:13:16.800
 They were both on Joe Rogan's program.

1:13:17.680 --> 1:13:22.460
 What do you think about censorship in this space?

1:13:23.600 --> 1:13:28.600
 In this difficult space where so much is controlled by,

1:13:29.240 --> 1:13:31.580
 not controlled, but influenced by advertisements

1:13:31.580 --> 1:13:32.560
 from Big Pharma,

1:13:32.560 --> 1:13:37.560
 and science can even be influenced by Big Pharma.

1:13:39.300 --> 1:13:41.280
 Where do you lean on this?

1:13:41.280 --> 1:13:46.280
 Should we lean towards freedom

1:13:46.700 --> 1:13:50.140
 and just allow all the voices,

1:13:50.140 --> 1:13:54.540
 even those that go against the scientific consensus?

1:13:54.540 --> 1:13:59.540
 Is that one way to fight the science

1:13:59.540 --> 1:14:02.600
 that is funded by Big Pharma,

1:14:02.600 --> 1:14:05.360
 or is that do more harm than good,

1:14:05.360 --> 1:14:08.440
 having too many voices that are contending here?

1:14:08.440 --> 1:14:10.640
 Should the ultimate battle be fought

1:14:10.640 --> 1:14:15.120
 in the space of scientific publications?

1:14:15.120 --> 1:14:19.360
 And particularly in the era of COVID,

1:14:19.360 --> 1:14:22.600
 where there are large public health ramifications

1:14:22.600 --> 1:14:27.440
 to this public discourse, the ante is way up.

1:14:27.440 --> 1:14:30.000
 So I don't have a simple answer to that.

1:14:31.160 --> 1:14:34.800
 I think everyone's allowed their own opinion.

1:14:34.800 --> 1:14:38.680
 I don't think everyone's allowed their own scientific facts.

1:14:38.680 --> 1:14:42.240
 And how we develop a mechanism

1:14:43.100 --> 1:14:45.360
 that's other than an open internet

1:14:45.360 --> 1:14:49.560
 where whoever is shouting the loudest gets the most clicks

1:14:49.560 --> 1:14:54.240
 and rage creates value on the internet,

1:14:54.240 --> 1:14:58.200
 I think that's not a good mechanism for working this out.

1:14:58.200 --> 1:14:59.800
 And I don't think we have one.

1:14:59.800 --> 1:15:01.800
 I don't have a solution to this.

1:15:01.800 --> 1:15:05.300
 I mean, ideally, if we had a philosopher king,

1:15:05.300 --> 1:15:08.720
 we could have a panel of people

1:15:08.720 --> 1:15:12.760
 who were not conflicted by rigid opinions

1:15:13.880 --> 1:15:18.800
 decide on what the boundaries of public discourse might be.

1:15:19.640 --> 1:15:21.760
 I don't think it should be fully open.

1:15:21.760 --> 1:15:24.380
 I don't think people who are making,

1:15:25.360 --> 1:15:28.300
 who are committed to an anti vaccine position

1:15:28.300 --> 1:15:31.000
 and will tailor their interpretation

1:15:31.000 --> 1:15:34.920
 of complex scientific data to support their opinion,

1:15:34.920 --> 1:15:36.780
 I think that can be harmful.

1:15:36.780 --> 1:15:39.240
 Constraining their speech can be harmful as well.

1:15:39.240 --> 1:15:41.160
 So I don't have an answer here.

1:15:41.160 --> 1:15:42.160
 But yeah.

1:15:42.160 --> 1:15:45.760
 I tend to believe that it's more dangerous

1:15:45.760 --> 1:15:49.320
 to censor anti vax messages.

1:15:49.320 --> 1:15:53.360
 The way to defeat anti vax messages

1:15:53.360 --> 1:15:56.420
 is by being great communicators,

1:15:56.420 --> 1:15:58.320
 by being great scientific communicators.

1:15:58.320 --> 1:16:01.020
 So it's not that we need to censor

1:16:02.060 --> 1:16:04.120
 the things we don't like.

1:16:04.120 --> 1:16:06.720
 We need to be better at communicating

1:16:06.720 --> 1:16:08.240
 the things we do like,

1:16:08.240 --> 1:16:10.760
 or the things that we do believe represent

1:16:10.760 --> 1:16:13.920
 the deep scientific truth.

1:16:13.920 --> 1:16:18.400
 Because I think if you censor,

1:16:18.400 --> 1:16:20.600
 you get worse at doing science

1:16:22.160 --> 1:16:24.860
 and you give the wrong people power.

1:16:27.200 --> 1:16:30.980
 So I tend to believe that you should give power

1:16:30.980 --> 1:16:33.400
 to the individual scientists

1:16:33.400 --> 1:16:35.720
 and also give them the responsibility

1:16:35.720 --> 1:16:38.880
 of being better educators, communicators,

1:16:38.880 --> 1:16:41.680
 expressers of scientific ideas,

1:16:41.680 --> 1:16:43.480
 put pressure on them to release data,

1:16:43.480 --> 1:16:46.800
 to release that data in a way that's easily consumable,

1:16:46.800 --> 1:16:49.220
 not just like very difficult to understand,

1:16:49.220 --> 1:16:50.760
 but in a way that can be understood

1:16:50.760 --> 1:16:52.520
 by a large number of people.

1:16:52.520 --> 1:16:54.740
 So the battle should be fought

1:16:54.740 --> 1:16:57.160
 in the open space of ideas

1:16:57.160 --> 1:17:02.160
 versus in the quiet space of journals.

1:17:02.640 --> 1:17:05.960
 I think we no longer have that comfort,

1:17:05.960 --> 1:17:08.280
 especially at the highest of stakes.

1:17:08.280 --> 1:17:11.600
 So this kind of idea that a couple of peer reviewers

1:17:11.600 --> 1:17:14.280
 decide the fate of billions

1:17:14.280 --> 1:17:18.960
 doesn't seem to be sustainable,

1:17:18.960 --> 1:17:23.960
 especially given a very real observation now

1:17:24.180 --> 1:17:29.180
 that the reason Robert Malone has a large following

1:17:30.840 --> 1:17:33.020
 is there's a deep distrust of institutions,

1:17:33.020 --> 1:17:34.940
 deep distrust of scientists,

1:17:34.940 --> 1:17:37.760
 of science as an institution,

1:17:37.760 --> 1:17:41.400
 of power centers, of companies, of everything,

1:17:41.400 --> 1:17:43.960
 and perhaps rightfully so.

1:17:43.960 --> 1:17:45.520
 But the way to defend against that

1:17:45.520 --> 1:17:49.760
 is not for the powerful to build a bigger wall.

1:17:49.760 --> 1:17:51.720
 It's for the powerful to be authentic

1:17:53.380 --> 1:17:55.760
 and maybe a lot of them to get fired,

1:17:55.760 --> 1:17:58.900
 and for new minds, for new fresh scientists,

1:17:59.840 --> 1:18:01.800
 ones who are more authentic, more real,

1:18:01.800 --> 1:18:03.980
 better communicators to step up.

1:18:03.980 --> 1:18:06.480
 So I fear censorship

1:18:06.480 --> 1:18:09.980
 because it feels like censorship

1:18:09.980 --> 1:18:13.720
 is an even harder job to do it well

1:18:13.720 --> 1:18:16.660
 than being good communicators.

1:18:16.660 --> 1:18:19.160
 And it seems like it's always the C students

1:18:19.160 --> 1:18:21.320
 that end up doing the censorship.

1:18:21.320 --> 1:18:24.960
 It's always the incompetent people,

1:18:24.960 --> 1:18:28.760
 and not just the incompetent, but the biggest whiners.

1:18:28.760 --> 1:18:32.960
 So what happens is the people

1:18:32.960 --> 1:18:36.560
 that get the most emotional and the most outraged

1:18:36.560 --> 1:18:38.220
 will drive the censorship.

1:18:39.520 --> 1:18:42.560
 And it doesn't seem like reason drives the censorship.

1:18:42.560 --> 1:18:44.840
 That's just objectively observing

1:18:44.840 --> 1:18:47.960
 how censorship seems to work in this current.

1:18:47.960 --> 1:18:50.760
 So there's so many forms of censorship.

1:18:50.760 --> 1:18:51.960
 You look at the Soviet Union

1:18:51.960 --> 1:18:54.040
 or the propaganda or Nazi Germany,

1:18:54.040 --> 1:18:56.520
 it's a very different level of censorship.

1:18:56.520 --> 1:18:59.360
 People tend to conflate all of these things together.

1:18:59.360 --> 1:19:03.720
 Social media trying desperately to have trillions

1:19:03.720 --> 1:19:07.280
 or hundreds of billions of exchanges a day,

1:19:07.280 --> 1:19:10.640
 and try to make sure that their platform

1:19:10.640 --> 1:19:15.640
 has some semblance of, quote, healthy conversations.

1:19:16.980 --> 1:19:18.560
 People just don't go insane.

1:19:18.560 --> 1:19:20.840
 They actually like using the platform,

1:19:20.840 --> 1:19:23.420
 and they censor based on that.

1:19:23.420 --> 1:19:24.920
 That's a different level of censorship.

1:19:24.920 --> 1:19:28.040
 But even there, you can really run afoul

1:19:28.040 --> 1:19:32.440
 of the people that get the whiny C students

1:19:32.440 --> 1:19:34.880
 controlling too much of the censorship.

1:19:34.880 --> 1:19:39.480
 I believe you should actually put the responsibility

1:19:39.480 --> 1:19:42.520
 on the self proclaimed holders of truth,

1:19:42.520 --> 1:19:45.640
 AKA scientists, at being better communicators.

1:19:46.760 --> 1:19:47.600
 I agree with that.

1:19:47.600 --> 1:19:51.440
 I'm not advocating for any kind of censorship.

1:19:51.440 --> 1:19:55.600
 But Marshall McLuhan was very influential

1:19:55.600 --> 1:19:57.200
 when I was in college.

1:19:57.200 --> 1:20:02.200
 And his, that meme, the medium is the message.

1:20:03.280 --> 1:20:04.840
 It's a little bit hard to understand

1:20:04.840 --> 1:20:06.800
 when you're comparing radio to TV

1:20:06.800 --> 1:20:09.880
 and saying radio's hotter or TV's hotter or something.

1:20:09.880 --> 1:20:12.480
 But we now have the medium as the message

1:20:12.480 --> 1:20:14.200
 in a way that we've never seen,

1:20:14.200 --> 1:20:16.200
 we've never imagined before,

1:20:16.200 --> 1:20:20.880
 where rage and anger and polarization

1:20:22.800 --> 1:20:27.800
 are what drives the traffic on the internet.

1:20:28.160 --> 1:20:33.160
 And we don't, it's a question of building the commons.

1:20:34.120 --> 1:20:36.000
 Ideally, I don't know how to get there,

1:20:36.000 --> 1:20:38.400
 so I'm not pretending to have a solution.

1:20:38.400 --> 1:20:42.240
 But the commons of discourse about this particular issue,

1:20:42.240 --> 1:20:47.160
 about vaccines, has been largely destroyed by the edges,

1:20:47.160 --> 1:20:50.040
 by the drug companies and the advocates on the one side

1:20:50.040 --> 1:20:54.680
 and the people who just criticize and think

1:20:54.680 --> 1:20:57.720
 that even though the data are flawed

1:20:57.720 --> 1:21:00.960
 that there's no way vaccines can be beneficial.

1:21:00.960 --> 1:21:04.080
 And to have those people screaming at each other

1:21:04.080 --> 1:21:07.200
 does nothing to improve the health

1:21:07.200 --> 1:21:10.680
 of the 95% of the people in the middle

1:21:10.680 --> 1:21:15.680
 who want to know what the rational way to go forward is

1:21:16.480 --> 1:21:18.560
 and protect their families from COVID

1:21:18.560 --> 1:21:20.320
 and live a good life

1:21:20.320 --> 1:21:22.560
 and be able to participate in the economy.

1:21:22.560 --> 1:21:25.200
 And that's the problem.

1:21:25.200 --> 1:21:26.440
 I don't have a solution.

1:21:26.440 --> 1:21:29.520
 Well, there's a difficult problem for Spotify and YouTube.

1:21:29.520 --> 1:21:30.360
 I don't know if you heard,

1:21:30.360 --> 1:21:33.360
 this is a thing that Joe Rogan is currently going through.

1:21:33.360 --> 1:21:36.680
 As a platform, whether to censor the conversation

1:21:36.680 --> 1:21:38.240
 that, for example, Joe's having.

1:21:39.120 --> 1:21:40.080
 So I don't know if you heard,

1:21:40.080 --> 1:21:43.920
 but Neil Young and other musicians have kind of spoke out

1:21:43.920 --> 1:21:45.760
 and saying they're going to leave the platform

1:21:45.760 --> 1:21:49.720
 because Joe Rogan is allowed to be on this platform

1:21:49.720 --> 1:21:51.320
 having these kinds of conversations

1:21:51.320 --> 1:21:52.960
 with the likes of Robert Malone.

1:21:54.680 --> 1:21:57.760
 And it's clear to me that Spotify and YouTube

1:21:57.760 --> 1:21:59.800
 are being significantly influenced

1:21:59.800 --> 1:22:03.400
 by these extreme voices, like you mentioned, on each side.

1:22:03.400 --> 1:22:05.800
 And it's also clear to me that Facebook is the same

1:22:05.800 --> 1:22:07.680
 and it was going back and forth.

1:22:07.680 --> 1:22:10.280
 In fact, that's why Facebook has been oscillating

1:22:10.280 --> 1:22:12.600
 on the censorship is like one group gets louder

1:22:12.600 --> 1:22:16.200
 than the other, depending on whether it's an election year.

1:22:19.880 --> 1:22:21.200
 There's several things to say here.

1:22:21.200 --> 1:22:24.560
 So one, it does seem, I think you put it really well,

1:22:24.560 --> 1:22:26.480
 it would be amazing if these platforms

1:22:26.480 --> 1:22:29.360
 could find mechanisms to listen to the center,

1:22:29.360 --> 1:22:34.360
 to the big center that's actually going to be affected

1:22:34.440 --> 1:22:38.560
 by the results of our pursuit of scientific truth.

1:22:40.520 --> 1:22:42.120
 And listen to those voices.

1:22:42.120 --> 1:22:45.800
 I also believe that most people are intelligent enough

1:22:45.800 --> 1:22:49.360
 to process information and to make up their own minds.

1:22:49.360 --> 1:22:51.680
 Like they're not, in terms of,

1:22:54.120 --> 1:22:55.240
 it's complicated, of course,

1:22:55.240 --> 1:22:57.120
 because we've just been talking about advertisement

1:22:57.120 --> 1:22:58.880
 and how people can be influenced.

1:22:58.880 --> 1:23:03.880
 But I feel like if you have raw, long form podcasts

1:23:05.080 --> 1:23:08.440
 or programs where people express their mind

1:23:08.440 --> 1:23:12.400
 and express their argument in full,

1:23:12.400 --> 1:23:15.400
 I think people can hear it to make up their own mind.

1:23:15.400 --> 1:23:18.080
 And if those arguments have a platform on which

1:23:18.080 --> 1:23:21.160
 they can live, then other people could provide

1:23:21.160 --> 1:23:23.680
 better arguments if they disagree with it.

1:23:23.680 --> 1:23:26.720
 And now we as human beings, as rational,

1:23:26.720 --> 1:23:29.120
 as intelligent human beings, can look at both

1:23:29.120 --> 1:23:30.560
 and make up our own minds.

1:23:30.560 --> 1:23:33.080
 And that's where social media can be very good

1:23:33.080 --> 1:23:35.920
 at this collective intelligence.

1:23:35.920 --> 1:23:39.160
 We together listen to all of these voices

1:23:39.160 --> 1:23:40.640
 and make up our own mind.

1:23:40.640 --> 1:23:42.840
 Humble ourselves, actually, often.

1:23:42.840 --> 1:23:46.680
 You think, you know, like you're an expert,

1:23:46.680 --> 1:23:48.600
 say you have a PhD in a certain thing,

1:23:48.600 --> 1:23:50.920
 so there's this confidence that comes with that.

1:23:50.920 --> 1:23:54.320
 And the collective intelligence, uncensored,

1:23:54.320 --> 1:23:56.880
 allows you to humble yourself eventually.

1:23:56.880 --> 1:24:01.160
 Like as you discover, all it takes is a few times,

1:24:01.160 --> 1:24:05.040
 you know, looking back five years later,

1:24:05.040 --> 1:24:07.240
 realizing I was wrong.

1:24:07.240 --> 1:24:09.040
 And that's really healthy for a scientist.

1:24:09.040 --> 1:24:11.000
 That's really healthy for anybody to go through.

1:24:11.000 --> 1:24:13.880
 And only through having that open discourse

1:24:13.880 --> 1:24:15.920
 can you really have that.

1:24:15.920 --> 1:24:20.920
 That said, Spotify also, just like Pfizer is a company,

1:24:20.920 --> 1:24:25.920
 which is why this podcast,

1:24:26.760 --> 1:24:29.240
 I don't know if you know what RSS feeds are,

1:24:29.240 --> 1:24:31.560
 but podcasts can't be censored.

1:24:31.560 --> 1:24:33.320
 So Joe's in the unfortunate position

1:24:33.320 --> 1:24:35.360
 he only lives on Spotify.

1:24:35.360 --> 1:24:37.920
 So Spotify has been actually very good

1:24:37.920 --> 1:24:40.720
 at saying we're staying out of it for now.

1:24:41.920 --> 1:24:44.840
 But RSS, this is pirate radio.

1:24:44.840 --> 1:24:47.080
 Nobody can censor it, it's the internet.

1:24:47.080 --> 1:24:51.840
 So financially, in terms of platforms,

1:24:51.840 --> 1:24:53.640
 this cannot be censored,

1:24:53.640 --> 1:24:56.760
 which is why podcasts are really beautiful.

1:24:56.760 --> 1:25:01.680
 And so if Spotify or YouTube wants to be

1:25:01.680 --> 1:25:04.240
 the host of podcasts,

1:25:04.240 --> 1:25:09.240
 I think where they flourish is free expression,

1:25:10.880 --> 1:25:12.880
 no matter how crazy.

1:25:12.880 --> 1:25:18.160
 Yes, but I do wanna push back a little bit on what you're saying.

1:25:18.160 --> 1:25:23.080
 I have anti fax friends who I love.

1:25:23.080 --> 1:25:26.120
 They're dear, cherished friends.

1:25:26.120 --> 1:25:28.680
 And they'll send me stuff.

1:25:28.680 --> 1:25:34.200
 And it'll take me an hour to go through what they sent

1:25:34.200 --> 1:25:37.720
 to see if it is credible.

1:25:37.720 --> 1:25:40.520
 And usually it's not.

1:25:40.520 --> 1:25:42.800
 It's not a random sample of the anti fax argument.

1:25:42.800 --> 1:25:46.760
 I'm not saying I can disprove the anti fax argument.

1:25:46.760 --> 1:25:50.960
 But I am saying that it's almost like we were talking about

1:25:50.960 --> 1:25:54.120
 how medical science clinical trials,

1:25:54.120 --> 1:25:56.720
 the presentation of clinical trials to physicians

1:25:56.720 --> 1:25:57.920
 could be improved.

1:25:57.920 --> 1:26:00.520
 And the first thing we came up with

1:26:00.520 --> 1:26:04.360
 is to have pre publication transparency

1:26:04.360 --> 1:26:06.160
 in the peer review process.

1:26:06.160 --> 1:26:10.040
 So bad information, biased information doesn't get out

1:26:10.040 --> 1:26:13.320
 as if it's legitimate, and you can't put it back,

1:26:13.320 --> 1:26:16.120
 recapture it once it gets out.

1:26:16.120 --> 1:26:18.360
 I think there's an element of that

1:26:18.360 --> 1:26:21.920
 in the arguments that are going on about vaccines.

1:26:21.920 --> 1:26:23.160
 And they're on both sides.

1:26:23.160 --> 1:26:28.360
 But I think the anti fax side puts out more units

1:26:28.360 --> 1:26:33.480
 of information claiming to show that the vaccines don't work.

1:26:33.480 --> 1:26:36.480
 And I guess in an ideal situation,

1:26:36.480 --> 1:26:41.120
 there would be real time fact checking by independent people,

1:26:41.120 --> 1:26:45.120
 not to censor it, but to just say that study was set up

1:26:45.120 --> 1:26:47.960
 to do this, and this is what the conclusions were.

1:26:47.960 --> 1:26:52.440
 So the way it was stated is on one side of this argument.

1:26:52.440 --> 1:26:53.800
 But that's what I'm arguing.

1:26:53.800 --> 1:26:55.040
 I agree with you.

1:26:55.040 --> 1:26:58.480
 What I'm arguing is that this big network of humans

1:26:58.480 --> 1:27:00.920
 that we have, that is the collective intelligence,

1:27:00.920 --> 1:27:04.000
 can't do that real time if you allow it to,

1:27:04.000 --> 1:27:05.920
 if you encourage people to do it.

1:27:05.920 --> 1:27:08.200
 And the scientists, as opposed to, listen,

1:27:08.200 --> 1:27:10.400
 I interact with a lot of colleagues,

1:27:10.400 --> 1:27:12.520
 a lot of friends that are scientists,

1:27:12.520 --> 1:27:14.040
 they roll their eyes.

1:27:14.040 --> 1:27:16.480
 Their response is like, ugh.

1:27:16.480 --> 1:27:18.800
 Like they don't want to interact with this.

1:27:18.800 --> 1:27:22.880
 But that's just not the right response.

1:27:22.880 --> 1:27:26.440
 When a huge number of people believe this,

1:27:26.440 --> 1:27:30.040
 it is your job as communicators to defend your ideas.

1:27:30.040 --> 1:27:33.160
 It is no longer the case that you go to a conference

1:27:33.160 --> 1:27:36.440
 and defend your ideas to two other nerds

1:27:36.440 --> 1:27:38.560
 that have been working on the same problem forever.

1:27:38.560 --> 1:27:40.320
 I mean, sure, you can do that,

1:27:40.320 --> 1:27:44.040
 but then you're rejecting the responsibility

1:27:44.040 --> 1:27:48.040
 you have explicitly or implicitly accepted

1:27:48.040 --> 1:27:49.800
 when you go into this field,

1:27:49.800 --> 1:27:52.600
 that you will defend the ideas of truth.

1:27:52.600 --> 1:27:55.840
 And the way to defend them is in the open battlefield

1:27:55.840 --> 1:27:58.920
 of ideas, and become a better communicator.

1:27:58.920 --> 1:28:00.960
 And I believe that when you have a lot,

1:28:00.960 --> 1:28:02.600
 you said you invested one or two hours

1:28:02.600 --> 1:28:06.680
 in this particular, but that's little ants interacting

1:28:06.680 --> 1:28:11.680
 at scale, I think that allows us to progress towards truth.

1:28:12.040 --> 1:28:14.560
 At least, you know, at least I hope so.

1:28:14.560 --> 1:28:15.880
 I think you're an optimist.

1:28:15.880 --> 1:28:17.920
 I want to work with you a little bit on this.

1:28:17.920 --> 1:28:22.480
 Let's say a person like Joe Rogan,

1:28:22.480 --> 1:28:26.040
 who, by the way, had me on his podcast and let me.

1:28:26.040 --> 1:28:28.040
 It's an amazing conversation, I really enjoyed it.

1:28:28.040 --> 1:28:29.040
 Well, thank you.

1:28:29.040 --> 1:28:29.960
 I did too.

1:28:29.960 --> 1:28:31.480
 And I didn't know Joe.

1:28:31.480 --> 1:28:32.840
 I didn't know much about his podcast.

1:28:32.840 --> 1:28:35.440
 He pushed back on Joe a bunch, which is great.

1:28:35.440 --> 1:28:38.440
 And he was a gentleman, and we had it out.

1:28:38.440 --> 1:28:41.240
 In fact, he put one clip, at one point,

1:28:41.240 --> 1:28:43.080
 he said something that was a little bit wrong,

1:28:43.080 --> 1:28:44.240
 and I corrected him.

1:28:44.240 --> 1:28:46.440
 And he had the guy who.

1:28:46.440 --> 1:28:47.280
 Jamie.

1:28:47.280 --> 1:28:48.920
 Jamie, he had Jamie check it,

1:28:48.920 --> 1:28:51.200
 and was very forthright in saying,

1:28:51.200 --> 1:28:53.520
 yeah, you know, John's got a right here.

1:28:53.520 --> 1:28:54.840
 We gotta modify this.

1:28:54.840 --> 1:28:56.560
 In any event, in any event.

1:28:56.560 --> 1:28:58.160
 You got him.

1:28:58.160 --> 1:28:59.960
 Well, I wasn't trying to get him,

1:28:59.960 --> 1:29:01.640
 I was just trying to. No, no, no, no.

1:29:01.640 --> 1:29:03.320
 Totally, it was a beautiful exchange.

1:29:03.320 --> 1:29:04.840
 There was so much respect in the room,

1:29:04.840 --> 1:29:06.360
 pushing back and forth, it was great.

1:29:06.360 --> 1:29:08.960
 Yeah, so I respect him.

1:29:08.960 --> 1:29:13.120
 And I think when he has somebody on

1:29:13.120 --> 1:29:16.680
 who's a dyed in the wool anti faxer,

1:29:16.680 --> 1:29:21.640
 the question is, how can you balance,

1:29:21.640 --> 1:29:24.440
 if it needs balance, in real time?

1:29:24.440 --> 1:29:26.280
 I'm not talking about afterwards.

1:29:26.280 --> 1:29:27.680
 I'm talking in real time.

1:29:27.680 --> 1:29:30.800
 Maybe you record, well, he does record it, obviously.

1:29:30.800 --> 1:29:33.720
 But maybe when there's a statement made

1:29:33.720 --> 1:29:38.000
 that is made as if it's fact based,

1:29:38.000 --> 1:29:41.880
 maybe that statement should be checked by

1:29:41.880 --> 1:29:44.520
 some folks who,

1:29:45.760 --> 1:29:48.080
 imaginary folks who are trustworthy.

1:29:48.080 --> 1:29:51.640
 And in real time, as that discussion

1:29:51.640 --> 1:29:54.200
 is being played on the podcast,

1:29:54.200 --> 1:29:59.080
 to show what independent experts say about that claim.

1:29:59.080 --> 1:30:00.200
 That's a really interesting idea.

1:30:00.200 --> 1:30:01.600
 By the way, for some reason,

1:30:01.600 --> 1:30:03.960
 this idea popped into my head now.

1:30:03.960 --> 1:30:05.560
 I think real time is very difficult,

1:30:05.560 --> 1:30:07.280
 and it's not difficult,

1:30:07.280 --> 1:30:09.320
 but it kind of ruins the conversation

1:30:09.320 --> 1:30:11.800
 because you want the idea to breathe.

1:30:11.800 --> 1:30:15.160
 I think what's very possible is before it's published,

1:30:15.160 --> 1:30:18.400
 it's the pre publication, before it's published,

1:30:18.400 --> 1:30:20.360
 you let a bunch of people review it,

1:30:20.360 --> 1:30:23.680
 and they can add their voices in post.

1:30:23.680 --> 1:30:27.120
 Before it's published, they can add arguments,

1:30:29.680 --> 1:30:31.480
 arguments against certain parts.

1:30:31.480 --> 1:30:32.880
 That's very interesting to sort of,

1:30:32.880 --> 1:30:37.240
 as one podcast, publish addendums.

1:30:37.240 --> 1:30:40.440
 Publish the peer review together with the publication.

1:30:40.440 --> 1:30:41.720
 That's very interesting.

1:30:43.240 --> 1:30:44.120
 I might actually do that.

1:30:44.120 --> 1:30:45.280
 That's really interesting.

1:30:45.280 --> 1:30:47.120
 Because I've been doing more debates

1:30:47.120 --> 1:30:51.720
 where at the same time have multiple people,

1:30:51.720 --> 1:30:53.480
 which has a different dynamic

1:30:53.480 --> 1:30:56.120
 because both people, I mean,

1:30:56.120 --> 1:30:58.800
 it's really nice to have the time to pause

1:30:58.800 --> 1:31:02.040
 just by yourself to fact check,

1:31:02.040 --> 1:31:04.120
 to look at the study that was mentioned,

1:31:04.120 --> 1:31:05.600
 to understand what's going on.

1:31:05.600 --> 1:31:09.480
 So the peer review process, to have a little bit of time.

1:31:09.480 --> 1:31:10.600
 That's really interesting.

1:31:10.600 --> 1:31:14.360
 I actually would, I'd like to try that.

1:31:14.360 --> 1:31:17.720
 To agree with you on some point in terms of anti vax,

1:31:17.720 --> 1:31:20.640
 I've been fascinated by listening to arguments

1:31:20.640 --> 1:31:23.800
 from this community of folks that's been quite large

1:31:23.800 --> 1:31:25.520
 called the flat earthers,

1:31:25.520 --> 1:31:28.080
 the people that believe the earth is flat.

1:31:28.080 --> 1:31:30.920
 And I don't know if you've ever listened to them

1:31:30.920 --> 1:31:33.760
 or read their arguments,

1:31:33.760 --> 1:31:36.160
 but it's fascinating how consistent

1:31:36.160 --> 1:31:37.800
 and convincing it all sounds

1:31:37.800 --> 1:31:39.600
 when you just kind of take it in.

1:31:39.600 --> 1:31:43.720
 Just like, just take it in like listening normally.

1:31:43.720 --> 1:31:45.360
 It's all very logical.

1:31:46.560 --> 1:31:49.120
 Like if you don't think very,

1:31:49.120 --> 1:31:53.200
 well, no, so the thing is,

1:31:53.200 --> 1:31:57.280
 the reality is at the very basic human level

1:31:57.280 --> 1:32:00.600
 with our limited cognitive capabilities,

1:32:00.600 --> 1:32:03.680
 the earth is pretty flat when you go outside

1:32:03.680 --> 1:32:04.880
 and you look at flat.

1:32:04.880 --> 1:32:08.040
 So like when you use common sense reasoning,

1:32:08.040 --> 1:32:09.960
 it's very easy to play to that,

1:32:09.960 --> 1:32:12.080
 to convince you that the earth is flat.

1:32:12.080 --> 1:32:13.640
 Plus there's powerful organizations

1:32:13.640 --> 1:32:16.280
 that want to manipulate you and so on.

1:32:16.280 --> 1:32:20.920
 But then there's the whole progress of science

1:32:20.920 --> 1:32:22.600
 and physics of the past,

1:32:22.600 --> 1:32:26.120
 but that's difficult to integrate into your thought process.

1:32:26.120 --> 1:32:29.200
 So it's very true that the people

1:32:29.200 --> 1:32:30.720
 should listen to flat earthers

1:32:30.720 --> 1:32:33.400
 because it was very revealing to me

1:32:33.400 --> 1:32:37.920
 how easy it is to be convinced of basically anything

1:32:39.240 --> 1:32:42.440
 by charismatic arguments.

1:32:42.440 --> 1:32:46.920
 And if we're arguing about whether the earth is flat or not,

1:32:46.920 --> 1:32:48.760
 as long as we're not navigating airplanes

1:32:48.760 --> 1:32:49.920
 and doing other kinds of things,

1:32:49.920 --> 1:32:53.800
 trying to get satellites to do transmission,

1:32:53.800 --> 1:32:56.200
 it's not that important what I believe.

1:32:56.200 --> 1:32:59.480
 But if we're arguing about how we approach

1:32:59.480 --> 1:33:02.400
 the worst public health crisis in,

1:33:02.400 --> 1:33:03.320
 I don't know how long,

1:33:03.320 --> 1:33:06.400
 I think we're getting worse than the Spanish flu now.

1:33:06.400 --> 1:33:07.800
 I don't know what the total global deaths

1:33:07.800 --> 1:33:10.120
 with Spanish flu were, but in the United States,

1:33:10.120 --> 1:33:12.440
 we certainly have more deaths than we had from Spanish flu.

1:33:12.440 --> 1:33:14.720
 Plus the economic pain and suffering.

1:33:14.720 --> 1:33:19.640
 Yes, yes, and the damage to the kids in school and so forth.

1:33:19.640 --> 1:33:23.040
 We got a problem and it's not going away, unfortunately.

1:33:23.040 --> 1:33:25.000
 So when we get a problem like that,

1:33:25.000 --> 1:33:28.520
 it's not just an interesting bar room conversation

1:33:28.520 --> 1:33:30.720
 about whether the earth is flat.

1:33:30.720 --> 1:33:32.560
 There are millions of lives involved.

1:33:34.320 --> 1:33:36.480
 Let me ask you yet another question,

1:33:36.480 --> 1:33:40.280
 an issue I raised with Pfizer CO, Albert Burla.

1:33:42.160 --> 1:33:45.400
 It's the question of revolving doors.

1:33:45.400 --> 1:33:47.440
 That there seems to be a revolving door

1:33:47.440 --> 1:33:51.120
 between Pfizer, FDA, and CDC.

1:33:51.120 --> 1:33:53.280
 People that have worked at the FDA,

1:33:53.280 --> 1:33:56.480
 now work at Pfizer, and vice versa,

1:33:56.480 --> 1:33:58.660
 including the CDC and so on.

1:34:00.760 --> 1:34:01.760
 What do you think about that?

1:34:01.760 --> 1:34:03.920
 So first of all, his response, once again,

1:34:03.920 --> 1:34:06.400
 is there's rules, there's very strict rules,

1:34:06.400 --> 1:34:07.480
 and we follow them.

1:34:08.680 --> 1:34:10.280
 Do you think that's a problem?

1:34:11.140 --> 1:34:11.980
 Hoo ha.

1:34:12.960 --> 1:34:16.200
 And also, maybe this is a good time to talk about

1:34:16.200 --> 1:34:18.220
 this Pfizer play by the rules.

1:34:19.480 --> 1:34:20.320
 One at a time?

1:34:20.320 --> 1:34:21.160
 One at a time.

1:34:21.160 --> 1:34:22.720
 Okay, and this isn't even about Pfizer,

1:34:22.720 --> 1:34:24.280
 but it's an answer to the question.

1:34:24.280 --> 1:34:25.120
 Yes.

1:34:25.120 --> 1:34:27.480
 So there's this drug, Ajihelm,

1:34:27.480 --> 1:34:31.320
 that was approved by the FDA maybe six months ago.

1:34:31.320 --> 1:34:34.920
 It's a drug to prevent the progression

1:34:34.920 --> 1:34:37.120
 of low grade Alzheimer's disease.

1:34:38.320 --> 1:34:43.320
 The target for drug development for Alzheimer's disease

1:34:43.600 --> 1:34:47.960
 has been reducing the amyloid plaques in the brain,

1:34:47.960 --> 1:34:52.100
 which correlate with the progression of Alzheimer's.

1:34:52.100 --> 1:34:57.100
 And Biogen showed that its drug, Ajihelm,

1:34:57.760 --> 1:35:00.980
 reduces amyloid plaques in the brain.

1:35:00.980 --> 1:35:03.020
 They did two clinical trials

1:35:03.020 --> 1:35:05.600
 to determine the clinical efficacy,

1:35:05.600 --> 1:35:09.960
 and they found that neither trial showed a meaningful benefit.

1:35:09.960 --> 1:35:12.180
 And in those two trials,

1:35:12.180 --> 1:35:15.960
 33% more people in the Ajihelm group

1:35:15.960 --> 1:35:19.060
 developed symptomatic brain swelling and bleeding

1:35:19.060 --> 1:35:20.820
 than people in the placebo group.

1:35:22.080 --> 1:35:25.940
 There was an advisory committee convened

1:35:27.080 --> 1:35:30.400
 to debate and determine how they felt

1:35:30.400 --> 1:35:34.200
 about the approvability of Ajihelm, given those facts.

1:35:35.080 --> 1:35:37.120
 And those facts aren't in dispute.

1:35:37.120 --> 1:35:41.540
 They're in Biogen slides, as well as FDA documents.

1:35:41.540 --> 1:35:46.540
 The advisory committee voted 10 against approval

1:35:47.600 --> 1:35:49.920
 and one abstain.

1:35:49.920 --> 1:35:52.600
 So that's essentially universal,

1:35:52.600 --> 1:35:56.240
 unanimous vote against approving Ajihelm.

1:35:56.240 --> 1:36:00.680
 Now, the advisory committees have been pretty much cleansed

1:36:00.680 --> 1:36:03.240
 of financial conflicts of interest.

1:36:03.240 --> 1:36:08.240
 So this advisory committee votes 10 no, one abstention,

1:36:09.240 --> 1:36:13.160
 and the FDA overrules the unanimous opinion

1:36:13.160 --> 1:36:16.140
 of its advisory committee and approves the drug.

1:36:17.400 --> 1:36:21.320
 Three of the members of the advisory committee resign.

1:36:21.320 --> 1:36:22.320
 They say, we're not gonna be part,

1:36:22.320 --> 1:36:24.760
 if the FDA is not gonna listen to a unanimous vote

1:36:24.760 --> 1:36:26.720
 against approving this drug,

1:36:26.720 --> 1:36:30.540
 which shows more harm than benefit, undisputed,

1:36:31.560 --> 1:36:33.840
 we're not gonna participate in this.

1:36:33.840 --> 1:36:36.680
 And the argument against approval

1:36:36.680 --> 1:36:38.960
 is that the surrogate endpoint,

1:36:38.960 --> 1:36:43.360
 the reduction of amyloid, the progression of amyloid plaques

1:36:43.360 --> 1:36:48.020
 is known by the FDA not to be a valid clinical indicator.

1:36:48.020 --> 1:36:50.920
 It doesn't correlate, 27 studies have shown,

1:36:50.920 --> 1:36:53.340
 it doesn't correlate with clinical progression,

1:36:53.340 --> 1:36:54.840
 interrupting the amyloid plaques

1:36:54.840 --> 1:36:59.840
 doesn't mean that your Alzheimer's doesn't get worse.

1:37:02.000 --> 1:37:05.200
 So it seems like it's a slam dunk

1:37:05.200 --> 1:37:09.000
 and the FDA made a mistake and they should do whatever

1:37:09.000 --> 1:37:12.080
 they do to protect their bureaucratic reputation.

1:37:12.080 --> 1:37:15.280
 So the head of the Bureau of the FDA,

1:37:15.280 --> 1:37:17.320
 the Center for Drug Evaluation and Research

1:37:17.320 --> 1:37:21.880
 that approves new drugs, who had spent 16 years

1:37:21.880 --> 1:37:25.300
 as an executive in the pharmaceutical industry,

1:37:25.300 --> 1:37:28.000
 issued a statement and said,

1:37:28.000 --> 1:37:30.920
 "'What we should do in this situation

1:37:30.920 --> 1:37:35.920
 "'is to loosen the prohibition of financial ties of interest

1:37:36.820 --> 1:37:38.540
 "'with the drug companies,

1:37:38.540 --> 1:37:41.400
 "'so we get less emotional responses.'"

1:37:43.400 --> 1:37:46.160
 Said this, it's in print.

1:37:49.400 --> 1:37:51.520
 People are just too emotional about this.

1:37:51.520 --> 1:37:52.960
 People were just too emotional.

1:37:52.960 --> 1:37:55.060
 The 10 people who voted against it

1:37:55.060 --> 1:37:56.720
 and the no people who voted for it,

1:37:56.720 --> 1:37:58.480
 it's all too emotional.

1:37:58.480 --> 1:38:00.000
 So this gets back,

1:38:00.000 --> 1:38:02.560
 this is a long answer to your short question.

1:38:02.560 --> 1:38:04.880
 I think this is a wonderful window

1:38:04.880 --> 1:38:07.120
 into the thinking of the FDA

1:38:08.000 --> 1:38:11.160
 that financial conflicts of interest don't matter

1:38:11.160 --> 1:38:13.280
 in a situation when I think it's obvious

1:38:13.280 --> 1:38:15.000
 that they would matter.

1:38:15.000 --> 1:38:18.040
 But there's not a direct financial conflict of interest.

1:38:18.040 --> 1:38:23.040
 It's kinda, like it's not, like Albert said, there's rules.

1:38:26.120 --> 1:38:27.200
 I mean, you're not allowed

1:38:27.200 --> 1:38:29.760
 to have direct financial conflicts of interest.

1:38:29.760 --> 1:38:32.280
 It's indirect.

1:38:32.280 --> 1:38:34.560
 Right, but what I'm saying is,

1:38:34.560 --> 1:38:36.560
 I'm not denying what he said is true,

1:38:37.880 --> 1:38:42.020
 but the FDA, a high official in the FDA,

1:38:42.020 --> 1:38:45.480
 is saying that we need to allow conflicts of interest

1:38:45.480 --> 1:38:48.320
 in our advisory committee meetings.

1:38:48.320 --> 1:38:49.280
 Wow.

1:38:49.280 --> 1:38:53.320
 And that, she wants to change the rules.

1:38:53.320 --> 1:38:54.160
 Right.

1:38:54.160 --> 1:38:58.040
 So Albert Borla would still be playing by the rules,

1:38:58.040 --> 1:39:03.040
 but it just shows how one side of the thinking here is.

1:39:03.380 --> 1:39:05.280
 But you think that's influenced by the fact

1:39:05.280 --> 1:39:07.360
 that there were pharmaceutical executives

1:39:07.360 --> 1:39:09.920
 working at the FDA and vice versa?

1:39:09.920 --> 1:39:11.720
 And they think that's a great idea.

1:39:13.120 --> 1:39:14.520
 Who gets to fix this?

1:39:14.520 --> 1:39:16.480
 Do you think it should be just banned?

1:39:16.480 --> 1:39:17.320
 Like if you worked.

1:39:17.320 --> 1:39:19.040
 I don't know, two separate questions.

1:39:19.040 --> 1:39:23.640
 One is should the officials at the FDA come from pharma

1:39:23.640 --> 1:39:24.800
 and vice versa?

1:39:24.800 --> 1:39:25.640
 Yes.

1:39:25.640 --> 1:39:26.460
 That's one question.

1:39:26.460 --> 1:39:28.960
 And the other question is should advisory committee members

1:39:28.960 --> 1:39:31.680
 be allowed to have financial conflicts of interest?

1:39:31.680 --> 1:39:33.120
 Yes.

1:39:33.120 --> 1:39:38.120
 I think, in my opinion, and people might say I'm biased,

1:39:38.240 --> 1:39:40.320
 I think advisory committee people

1:39:40.320 --> 1:39:42.080
 should not have conflicts of interest.

1:39:42.080 --> 1:39:44.880
 I think their only interest ought to be the public interest.

1:39:44.880 --> 1:39:49.240
 And that was true from my understanding of the situation.

1:39:49.240 --> 1:39:51.280
 It's the afterword in my book.

1:39:51.280 --> 1:39:54.200
 I spent some time studying it about Ajihelm.

1:39:54.200 --> 1:39:56.520
 I think it's a slam dunk that there ought to be

1:39:56.520 --> 1:39:57.660
 no conflicts of interest.

1:39:57.660 --> 1:40:01.400
 Now the head of CDER, Center for Drug Evaluation Research,

1:40:01.400 --> 1:40:04.660
 thinks that that's gonna give you a biased result

1:40:04.660 --> 1:40:07.380
 because we don't have company influence.

1:40:07.380 --> 1:40:12.380
 And that, I think, shows how biased their thinking is.

1:40:14.360 --> 1:40:17.340
 That not having company influence is a bias.

1:40:19.200 --> 1:40:21.200
 Let me try to load that in.

1:40:21.200 --> 1:40:23.320
 I'm trying to empathize with the belief

1:40:23.320 --> 1:40:26.760
 that companies should have a voice at the table.

1:40:28.680 --> 1:40:30.440
 I mean, yeah, it's part of the game.

1:40:30.440 --> 1:40:31.400
 They've convinced themselves

1:40:31.400 --> 1:40:33.240
 that this is how it should be played.

1:40:34.520 --> 1:40:36.320
 But they have a voice at the table.

1:40:36.320 --> 1:40:37.720
 They've designed the studies.

1:40:37.720 --> 1:40:38.560
 Right.

1:40:38.560 --> 1:40:39.400
 That's their voice.

1:40:39.400 --> 1:40:40.220
 That's the whole point.

1:40:40.220 --> 1:40:41.060
 They analyze the data.

1:40:41.060 --> 1:40:43.080
 I mean, what bigger voice do you deserve?

1:40:43.080 --> 1:40:47.040
 But I do also think, on the more challenging question,

1:40:47.040 --> 1:40:50.180
 I do think that there should be a ban.

1:40:50.180 --> 1:40:53.600
 If you work at a pharmaceutical company,

1:40:53.600 --> 1:40:55.400
 you should not be allowed to work

1:40:55.400 --> 1:41:00.400
 at any regulatory agency.

1:41:00.680 --> 1:41:01.520
 Yes.

1:41:01.520 --> 1:41:02.340
 You should not.

1:41:02.340 --> 1:41:03.960
 I mean, that, going back and forth,

1:41:03.960 --> 1:41:06.680
 it just, even if it's 30 years later.

1:41:06.680 --> 1:41:07.520
 Yeah, I agree.

1:41:07.520 --> 1:41:11.000
 And I have another nomination for a ban.

1:41:11.000 --> 1:41:12.960
 We're in this crazy situation

1:41:12.960 --> 1:41:15.120
 where Medicare is not allowed to negotiate

1:41:15.120 --> 1:41:17.800
 the price of drugs with the drug companies.

1:41:17.800 --> 1:41:20.840
 So the drug companies get a patent on a new drug.

1:41:20.840 --> 1:41:22.440
 Unlike every other developed country,

1:41:22.440 --> 1:41:24.020
 they can charge whatever they want

1:41:24.020 --> 1:41:27.800
 so they have a monopoly on a utility

1:41:27.800 --> 1:41:29.560
 because no one else can make the drug.

1:41:29.560 --> 1:41:31.960
 Charge whatever they want and Medicare has to pay for it.

1:41:31.960 --> 1:41:35.640
 And you say, how did we get in this crazy situation?

1:41:36.760 --> 1:41:39.600
 So how we got here is that in 2003,

1:41:39.600 --> 1:41:42.020
 when Medicare Part D was passed,

1:41:42.020 --> 1:41:45.680
 Billy Towson was head of the Ways and Means Committee

1:41:45.680 --> 1:41:48.960
 in the House, played a key role in ushering this through

1:41:48.960 --> 1:41:52.440
 with the nonnegotiation clause of it.

1:41:52.440 --> 1:41:53.960
 And after it was passed,

1:41:53.960 --> 1:41:57.480
 Billy Towson did not finish out his term in Congress.

1:41:57.480 --> 1:42:02.160
 He went to pharma for a $2 million a year job.

1:42:02.160 --> 1:42:05.160
 This is incredible.

1:42:05.160 --> 1:42:08.000
 You might think that a ban on that would be a good idea.

1:42:09.480 --> 1:42:12.080
 I spoke with Francis Collins, head of the NIH,

1:42:12.080 --> 1:42:13.680
 on this podcast.

1:42:13.680 --> 1:42:18.680
 He and NIH have a lot of power over funding in science.

1:42:22.120 --> 1:42:24.840
 What are they doing right, what are they doing wrong

1:42:24.840 --> 1:42:28.760
 in this interplay with big pharma?

1:42:28.760 --> 1:42:30.440
 How connected are they?

1:42:32.160 --> 1:42:33.720
 Again, returning to the question,

1:42:33.720 --> 1:42:35.500
 what are they doing right,

1:42:35.500 --> 1:42:37.680
 what are they doing wrong in your view?

1:42:37.680 --> 1:42:41.160
 So my knowledge of the NIH is not as granular

1:42:41.160 --> 1:42:43.260
 as my knowledge of pharma.

1:42:44.480 --> 1:42:47.520
 That said, in broad brushstrokes,

1:42:47.520 --> 1:42:51.180
 the NIH is doing the infrastructure work

1:42:51.180 --> 1:42:53.400
 for all drug development.

1:42:53.400 --> 1:42:56.700
 I think they've participated in 100% of the drugs

1:42:56.700 --> 1:42:58.920
 that have been approved by the FDA

1:42:58.920 --> 1:43:00.600
 over the past 10 years or so.

1:43:01.480 --> 1:43:03.080
 They've done infrastructure work.

1:43:03.080 --> 1:43:08.080
 And what they do is not work on particular drugs,

1:43:08.160 --> 1:43:12.360
 but they develop work on drug targets,

1:43:12.360 --> 1:43:16.920
 on targets in the human body that can be affected by drugs

1:43:16.920 --> 1:43:21.560
 and might be beneficial to turn on or off.

1:43:21.560 --> 1:43:24.560
 And then the drug companies, when they find a target

1:43:24.560 --> 1:43:29.360
 that is mutable and potentially beneficial,

1:43:29.360 --> 1:43:32.020
 then the drug companies can take the research

1:43:32.020 --> 1:43:34.640
 and choose to invest in the development of the drugs,

1:43:34.640 --> 1:43:35.640
 specific drug.

1:43:36.740 --> 1:43:38.360
 That's our model.

1:43:38.360 --> 1:43:43.360
 Now, 96% of the research that's done in clinical trials

1:43:44.160 --> 1:43:47.280
 in the United States is about drugs and devices.

1:43:47.280 --> 1:43:49.960
 And only a fraction of the 4% that's left over

1:43:49.960 --> 1:43:51.780
 is about preventive medicine

1:43:51.780 --> 1:43:54.480
 and how to make Americans healthier.

1:43:54.480 --> 1:43:58.520
 I think, again, from the satellite view,

1:43:58.520 --> 1:44:03.520
 the NIH is investing more in science

1:44:04.260 --> 1:44:07.280
 that can lead to commercial development

1:44:07.280 --> 1:44:10.160
 rather than, as you said at the beginning of the podcast,

1:44:10.160 --> 1:44:13.480
 there's no big fitness and lifestyle industry

1:44:13.480 --> 1:44:15.980
 that can counter pharma.

1:44:15.980 --> 1:44:19.700
 So I think at the NIH level, that countering can be done.

1:44:19.700 --> 1:44:22.560
 And the diabetes prevention program study

1:44:22.560 --> 1:44:24.920
 that we talked about before where lifestyle

1:44:24.920 --> 1:44:26.500
 was part of a randomized trial

1:44:26.500 --> 1:44:28.940
 and was shown to be more effective than metformin

1:44:28.940 --> 1:44:31.000
 at preventing the development of diabetes,

1:44:31.000 --> 1:44:34.460
 that is absolute proof positive

1:44:34.460 --> 1:44:36.140
 that investing in that kind of science

1:44:36.140 --> 1:44:37.900
 can produce good results.

1:44:37.900 --> 1:44:42.900
 So I think that we're aimed at drug development

1:44:43.100 --> 1:44:44.880
 and what we ought to be aimed at

1:44:44.880 --> 1:44:47.700
 is an epidemiological approach

1:44:47.700 --> 1:44:49.900
 to improving the health of all Americans.

1:44:49.900 --> 1:44:54.040
 We rank 68th in the world in healthy life expectancy

1:44:55.060 --> 1:44:58.100
 despite spending an extra trillion and a half dollars a year.

1:44:59.000 --> 1:45:02.560
 And I believe strongly

1:45:02.560 --> 1:45:05.920
 that the reason why we've gotten in this crazy position

1:45:06.880 --> 1:45:10.280
 is because the knowledge that we're producing

1:45:10.280 --> 1:45:12.480
 is about new drugs and devices

1:45:12.480 --> 1:45:15.780
 and it's not about improving population health.

1:45:15.780 --> 1:45:19.680
 In this problem, the NIH is the perfect institution

1:45:19.680 --> 1:45:23.160
 to play a role in rebalancing our research agenda.

1:45:23.160 --> 1:45:24.940
 And some of that is on the leadership side

1:45:24.940 --> 1:45:27.920
 with Francis Collins and Anthony Fauci,

1:45:27.920 --> 1:45:32.460
 not just speaking about basically everything

1:45:32.460 --> 1:45:34.760
 that just leads to drug development, vaccine development,

1:45:34.760 --> 1:45:36.760
 but also speaking about healthy lifestyles

1:45:36.760 --> 1:45:40.800
 and speaking about health, not just sickness.

1:45:40.800 --> 1:45:43.200
 Yes, and investing, investing in health.

1:45:43.200 --> 1:45:48.200
 I mean, it's like one feeds the other.

1:45:49.000 --> 1:45:51.200
 One, you have to communicate to the public

1:45:51.200 --> 1:45:53.880
 the importance of investing in health

1:45:53.880 --> 1:45:57.840
 and that leads to you getting props for investing in health

1:45:57.840 --> 1:45:59.520
 and then you can invest in health more and more

1:45:59.520 --> 1:46:01.680
 and that communicates, I mean,

1:46:01.680 --> 1:46:05.120
 everything that Anthony Fauci says or Francis Collins says

1:46:05.120 --> 1:46:07.240
 has an impact on scientists.

1:46:07.240 --> 1:46:12.120
 I mean, it sets the priorities.

1:46:12.120 --> 1:46:15.940
 I don't think they, it's the sad thing about leaders,

1:46:18.680 --> 1:46:22.080
 forgive me for saying the word, but mediocre leaders

1:46:22.080 --> 1:46:26.800
 is they don't see themselves as part of a game.

1:46:26.800 --> 1:46:29.920
 They don't see the momentum.

1:46:29.920 --> 1:46:31.160
 It's like a fish in the water.

1:46:31.160 --> 1:46:32.920
 They don't see the water.

1:46:32.920 --> 1:46:36.080
 Great leaders stand up and reverse the direction

1:46:36.080 --> 1:46:37.120
 of how things are going.

1:46:37.120 --> 1:46:39.920
 And I actually put a lot of responsibility,

1:46:39.920 --> 1:46:43.520
 some people say too much, but whatever.

1:46:43.520 --> 1:46:46.440
 I think leaders carry the responsibility.

1:46:46.440 --> 1:46:48.800
 I put a lot of responsibility on Anthony Fauci

1:46:48.800 --> 1:46:51.360
 and Francis Collins for not actually speaking

1:46:51.360 --> 1:46:55.920
 a lot more about health, not, and bigger,

1:46:55.920 --> 1:47:00.920
 inspiring people in the power

1:47:01.200 --> 1:47:05.560
 and the trustworthiness of science.

1:47:05.560 --> 1:47:10.560
 You know, that's on the shoulders of Anthony Fauci.

1:47:12.240 --> 1:47:13.760
 I'm gonna abstain from that

1:47:13.760 --> 1:47:15.800
 because I'm not expert enough, but.

1:47:15.800 --> 1:47:18.040
 Neither am I, but I'm opinionated.

1:47:18.040 --> 1:47:21.080
 I am too, but not on camera.

1:47:21.080 --> 1:47:22.520
 Yes.

1:47:22.520 --> 1:47:27.200
 No, but seriously, the problem is pretty simple,

1:47:27.200 --> 1:47:31.400
 that we're investing 96% of our funding

1:47:31.400 --> 1:47:33.520
 of clinical research in drugs and devices

1:47:33.520 --> 1:47:36.800
 and 80% of our health is determined

1:47:36.800 --> 1:47:38.120
 by how we live our lives.

1:47:38.120 --> 1:47:39.160
 Yes.

1:47:39.160 --> 1:47:41.720
 And this is ridiculous.

1:47:42.600 --> 1:47:45.600
 The United States is going further and further

1:47:45.600 --> 1:47:49.760
 behind the other wealthy countries in terms of our health.

1:47:49.760 --> 1:47:53.560
 We ranked 38th in healthy life expectancy in 2000

1:47:53.560 --> 1:47:56.960
 and now we're spending a trillion and a half dollars extra

1:47:56.960 --> 1:47:58.360
 and we rank 68th.

1:47:58.360 --> 1:47:59.520
 We've gone down.

1:47:59.520 --> 1:48:02.400
 You have this excellent, there's a few charts

1:48:02.400 --> 1:48:06.440
 that I'll overlay that tell this story

1:48:06.440 --> 1:48:09.720
 in really powerful ways.

1:48:09.720 --> 1:48:13.600
 So one is the healthcare spending is percentage of GDP

1:48:13.600 --> 1:48:17.680
 that on the X axis is years and the Y axis is percentage

1:48:17.680 --> 1:48:20.800
 and the United States as compared to other countries

1:48:20.800 --> 1:48:25.800
 on average has been much larger and growing.

1:48:26.440 --> 1:48:30.520
 Right, we are now spending 7% more of our GDP,

1:48:30.520 --> 1:48:35.200
 17.7% versus 10.7% on healthcare.

1:48:35.200 --> 1:48:38.840
 7% and I think GDP is the fairest way

1:48:38.840 --> 1:48:40.080
 to compare healthcare spending.

1:48:40.080 --> 1:48:43.480
 Where per person in dollars we're spending even,

1:48:43.480 --> 1:48:45.560
 the difference is even greater

1:48:45.560 --> 1:48:48.200
 but other costs vary with GDP.

1:48:48.200 --> 1:48:50.800
 So let's stick with the conservative way to do it.

1:48:50.800 --> 1:49:00.760
 17.7 or 18% of GDP, 18% of GDP spent on healthcare,

1:49:00.760 --> 1:49:04.800
 7% higher than the comparable country average.

1:49:04.800 --> 1:49:05.640
 Right.

1:49:05.640 --> 1:49:09.960
 17.7% versus 10.7, 7% higher.

1:49:09.960 --> 1:49:14.960
 Right and 7% of $23 trillion GDP

1:49:15.160 --> 1:49:19.040
 is more than $1.5 trillion a year in excess.

1:49:19.040 --> 1:49:21.000
 And then you have another chart that shows

1:49:21.000 --> 1:49:24.840
 healthcare system performance compared to spending.

1:49:25.840 --> 1:49:29.800
 And there's a cloud, a point cloud of different countries.

1:49:29.800 --> 1:49:33.160
 The X axis being healthcare spending

1:49:33.160 --> 1:49:36.360
 is a percentage of GDP which we just talked about.

1:49:36.360 --> 1:49:40.880
 That US is 7% higher than everyone, the average.

1:49:40.880 --> 1:49:44.520
 And then on the Y axis is performance.

1:49:44.520 --> 1:49:48.280
 So X axis spending, Y axis performance.

1:49:48.280 --> 1:49:50.600
 And there's a point cloud, we'll overlay this

1:49:50.600 --> 1:49:52.400
 if you're watching on YouTube,

1:49:52.400 --> 1:49:57.000
 of a bunch of countries that have high performance

1:49:58.600 --> 1:50:01.320
 for what they're spending and then US

1:50:02.640 --> 1:50:07.480
 is all alone on the right bottom side of the chart

1:50:07.480 --> 1:50:10.760
 where it's low performance and high spending.

1:50:10.760 --> 1:50:11.600
 Correct.

1:50:12.880 --> 1:50:17.960
 So this is a system that is abiding by spending

1:50:17.960 --> 1:50:21.160
 that is directed by the most profitable ways

1:50:21.160 --> 1:50:22.480
 to deliver healthcare.

1:50:22.480 --> 1:50:25.040
 So you put that in the hands of big pharma.

1:50:25.040 --> 1:50:28.400
 As you maximize for profit, you're going to decrease

1:50:28.400 --> 1:50:31.600
 performance and increase spending.

1:50:31.600 --> 1:50:34.800
 Yes, but I wanna qualify that and say

1:50:34.800 --> 1:50:36.360
 it's not all big pharma's fault.

1:50:37.440 --> 1:50:39.320
 They're not responsible for all the problems

1:50:39.320 --> 1:50:41.200
 in our healthcare system.

1:50:41.200 --> 1:50:43.160
 They're not responsible for the administrative costs

1:50:43.160 --> 1:50:44.520
 for example.

1:50:44.520 --> 1:50:49.400
 But they are the largest component of the rising,

1:50:49.400 --> 1:50:51.320
 our rising healthcare costs.

1:50:51.320 --> 1:50:54.160
 And it has to do with this knowledge issue.

1:50:54.160 --> 1:50:56.760
 Controlling the knowledge that doctors have

1:50:57.640 --> 1:51:01.240
 makes it so that doctors can live with this situation

1:51:01.240 --> 1:51:04.880
 believing that it's optimal when it's a wreck.

1:51:04.880 --> 1:51:06.160
 Yeah.

1:51:06.160 --> 1:51:08.680
 Let me ask you the big, so as a physician,

1:51:10.160 --> 1:51:13.680
 so everything you've seen, we've talked about 80%

1:51:13.680 --> 1:51:15.960
 of the impact on health is lifestyle.

1:51:18.480 --> 1:51:20.200
 How do we live longer?

1:51:20.200 --> 1:51:22.120
 What advice would you give to general people?

1:51:22.120 --> 1:51:27.120
 What space of ideas result in living longer

1:51:29.080 --> 1:51:30.720
 and higher quality lives?

1:51:30.720 --> 1:51:33.560
 Right, this is a very simple question to answer.

1:51:34.480 --> 1:51:37.800
 Exercise for at least a half hour

1:51:37.800 --> 1:51:39.360
 at least five times a week.

1:51:41.040 --> 1:51:42.360
 Number one.

1:51:42.360 --> 1:51:44.160
 Number two, don't smoke.

1:51:45.560 --> 1:51:49.320
 Number three, maintain a reasonably healthy body weight.

1:51:49.320 --> 1:51:53.720
 Some people argue that being lower than a BMI of 25

1:51:53.720 --> 1:51:54.800
 is healthy.

1:51:54.800 --> 1:51:56.480
 I think that may be true,

1:51:56.480 --> 1:52:00.440
 but I think getting above 30 is unhealthy

1:52:00.440 --> 1:52:01.920
 and that ought to be.

1:52:01.920 --> 1:52:06.920
 Now that's largely impacted by socioeconomic status

1:52:07.600 --> 1:52:09.920
 and we don't wanna blame the victims here.

1:52:09.920 --> 1:52:12.600
 So we gotta understand that when we talk about

1:52:12.600 --> 1:52:14.920
 all of these things, not cigarettes,

1:52:14.920 --> 1:52:18.360
 but exercise and a good diet

1:52:18.360 --> 1:52:21.320
 and maintaining a healthy body weight,

1:52:23.000 --> 1:52:26.120
 we have to include in doing those things

1:52:27.000 --> 1:52:32.000
 the impediments to people of lower socioeconomic status

1:52:32.480 --> 1:52:34.360
 being able to make those changes.

1:52:34.360 --> 1:52:38.120
 We've got to understand that personal responsibility

1:52:38.120 --> 1:52:39.880
 accounts for some of this,

1:52:39.880 --> 1:52:44.000
 but also social circumstances accounts for some of it.

1:52:44.000 --> 1:52:47.000
 And back to your fish bowl analogy,

1:52:47.000 --> 1:52:50.040
 if you're swimming in a fish bowl,

1:52:50.040 --> 1:52:51.240
 if you live in a fish tank

1:52:51.240 --> 1:52:53.960
 that's not being properly maintained,

1:52:53.960 --> 1:52:58.080
 the approach wouldn't be to treat individual sick fish,

1:52:58.080 --> 1:53:01.560
 it would be to fix your fish tank

1:53:01.560 --> 1:53:03.040
 to get the bacteria out of it

1:53:03.040 --> 1:53:05.720
 and whatever bad stuff is in there

1:53:05.720 --> 1:53:08.440
 and make your fish tank healthier.

1:53:08.440 --> 1:53:12.840
 Well, we invest far less than the other wealthy countries do.

1:53:12.840 --> 1:53:15.120
 We're flipped, we have the mirror image

1:53:15.120 --> 1:53:19.040
 in the spending on social determinants of health

1:53:19.040 --> 1:53:20.840
 and medical determinants of health.

1:53:20.840 --> 1:53:23.120
 We have exactly the wrong order.

1:53:23.120 --> 1:53:25.800
 And not only does that choke off

1:53:25.800 --> 1:53:28.320
 social determinants of health, which are very important,

1:53:28.320 --> 1:53:30.720
 but actually just the ratio,

1:53:30.720 --> 1:53:32.920
 even if you were spending,

1:53:32.920 --> 1:53:35.760
 if we raise the social spending

1:53:35.760 --> 1:53:38.360
 and raise our medical spending in proportion,

1:53:38.360 --> 1:53:41.280
 it's the ratio of social spending to medical spending

1:53:41.280 --> 1:53:42.920
 that's the problem.

1:53:42.920 --> 1:53:44.560
 So, and why do we do that?

1:53:44.560 --> 1:53:46.440
 Well, the answer is perfectly obvious

1:53:46.440 --> 1:53:48.680
 that the way to transfer money

1:53:48.680 --> 1:53:51.840
 from working Americans to investors

1:53:51.840 --> 1:53:53.680
 is through the biomedical model,

1:53:54.560 --> 1:53:57.720
 not through the social health model.

1:53:57.720 --> 1:53:59.920
 And that's the problem for,

1:53:59.920 --> 1:54:02.840
 and I'd like to discuss this

1:54:02.840 --> 1:54:06.360
 because the market isn't gonna get us

1:54:06.360 --> 1:54:08.040
 to a reasonable allocation.

1:54:08.040 --> 1:54:09.680
 All the other wealthy countries

1:54:09.680 --> 1:54:11.560
 that are so much healthier than we are

1:54:11.560 --> 1:54:14.040
 and spending so much less than we are

1:54:14.040 --> 1:54:17.120
 have some form of government intervention

1:54:17.120 --> 1:54:20.480
 in the quality of the health data that's available,

1:54:20.480 --> 1:54:25.480
 in the budgeting of health and social factors.

1:54:25.920 --> 1:54:28.040
 And we don't, we're kind of the Wild West

1:54:28.040 --> 1:54:31.080
 and we let the market determine those allocations.

1:54:31.080 --> 1:54:34.360
 And it's an awful failure.

1:54:34.360 --> 1:54:36.720
 It's a horrendous failure.

1:54:36.720 --> 1:54:39.800
 So one argument against government,

1:54:39.800 --> 1:54:43.760
 or sorry, an alternative to the government intervention

1:54:44.720 --> 1:54:48.320
 is the market can work better

1:54:48.320 --> 1:54:51.720
 if the citizenry has better information.

1:54:51.720 --> 1:54:53.160
 So one argument is that

1:54:53.160 --> 1:54:58.160
 communicators like podcasts and so on,

1:54:58.680 --> 1:55:01.080
 but other channels of communication

1:55:01.080 --> 1:55:03.840
 will be the way to fight big pharma.

1:55:03.840 --> 1:55:05.640
 Your book is the way to,

1:55:05.640 --> 1:55:07.560
 by providing information.

1:55:07.560 --> 1:55:10.360
 The alternative to the government intervention

1:55:10.360 --> 1:55:11.760
 on every aspect of this,

1:55:11.760 --> 1:55:13.440
 including communication with the doctors

1:55:13.440 --> 1:55:15.400
 is to provide them other information

1:55:15.400 --> 1:55:18.600
 and not allow the market to provide that information

1:55:18.600 --> 1:55:22.440
 by basically making it exciting

1:55:22.440 --> 1:55:27.000
 to buy books, to make better and better communicators

1:55:27.000 --> 1:55:30.840
 on Twitter, through books, through op eds,

1:55:30.840 --> 1:55:32.960
 through podcasts, through so on.

1:55:32.960 --> 1:55:35.840
 So basically, cause there's a lot of incentive

1:55:35.840 --> 1:55:40.440
 to communicate against the messages of big pharma.

1:55:40.440 --> 1:55:43.640
 There's incentive because people want to understand

1:55:43.640 --> 1:55:44.760
 what's good for their lives

1:55:44.760 --> 1:55:46.880
 and they're willing to listen to charismatic people

1:55:46.880 --> 1:55:50.920
 that are able to clearly explain what is good for them.

1:55:50.920 --> 1:55:54.000
 And they do, and more than 80% of people

1:55:54.000 --> 1:55:55.480
 think that drugs cost too much

1:55:55.480 --> 1:55:58.780
 and the drug industry is too interested in profits.

1:56:00.400 --> 1:56:02.320
 But they still get influenced.

1:56:02.320 --> 1:56:05.520
 They can't, you can't get the vote through Congress.

1:56:05.520 --> 1:56:08.720
 You know, Democrats and Republicans alike

1:56:08.720 --> 1:56:10.280
 are taking money from Congress

1:56:10.280 --> 1:56:13.920
 and somehow it just doesn't work out

1:56:13.920 --> 1:56:17.200
 that these even small changes.

1:56:17.200 --> 1:56:21.800
 I mean, the pared down part of Medicare,

1:56:21.800 --> 1:56:26.800
 the plan for increasing Medicare negotiation drug costs

1:56:27.640 --> 1:56:29.360
 in Build Back Better,

1:56:29.360 --> 1:56:32.840
 it's literally gonna reduce the number of new drugs

1:56:32.840 --> 1:56:37.720
 that are beneficial, uniquely beneficial

1:56:37.720 --> 1:56:42.120
 by about one new drug or two new drugs over 30 years.

1:56:42.120 --> 1:56:47.120
 It will have virtually an indecipherable impact.

1:56:48.440 --> 1:56:53.440
 And yet pharma is talking about the impact on innovation.

1:56:53.760 --> 1:56:55.920
 And if you vote for this,

1:56:55.920 --> 1:56:58.280
 if you let your Congressman vote for this,

1:56:58.280 --> 1:57:03.280
 you're gonna severely slow down drug innovation

1:57:04.340 --> 1:57:07.040
 and that's gonna affect the quality of your life.

1:57:07.040 --> 1:57:12.040
 Let me ask you about over medication

1:57:17.000 --> 1:57:19.680
 that we've been talking about from different angles.

1:57:19.680 --> 1:57:22.640
 But one difficult question for me,

1:57:22.640 --> 1:57:25.520
 I'll just, I'll pick one of the difficult topics,

1:57:25.520 --> 1:57:26.960
 depression.

1:57:26.960 --> 1:57:31.960
 So depression is a serious, painful condition

1:57:31.960 --> 1:57:36.320
 that leads to a lot of people suffering in the world.

1:57:37.240 --> 1:57:40.560
 And yet it is likely they were over prescribing

1:57:40.560 --> 1:57:42.380
 antidepressants.

1:57:42.380 --> 1:57:47.040
 So as a doctor, as a patient, as a healthcare system,

1:57:47.040 --> 1:57:50.340
 as a society, what do we do with that fact

1:57:50.340 --> 1:57:53.040
 that people suffer?

1:57:53.040 --> 1:57:56.560
 There's a lot of people suffering from depression

1:57:57.560 --> 1:57:59.160
 and there's also people suffering

1:57:59.160 --> 1:58:01.920
 from over prescribing of antidepressants.

1:58:01.920 --> 1:58:02.840
 Right.

1:58:02.840 --> 1:58:06.840
 So a paper in the New England Journal by Eric Turner

1:58:06.840 --> 1:58:09.200
 showed that the data,

1:58:09.200 --> 1:58:12.320
 if you put all the data together from antidepressants,

1:58:12.320 --> 1:58:17.320
 you find out that antidepressants are not effective

1:58:17.940 --> 1:58:19.360
 for people who are depressed

1:58:19.360 --> 1:58:21.060
 but don't have a major depression.

1:58:22.240 --> 1:58:25.280
 Major depression is a serious problem.

1:58:25.280 --> 1:58:27.260
 People can't function normally.

1:58:27.260 --> 1:58:31.020
 They have a hard time getting out,

1:58:31.020 --> 1:58:34.220
 performing their normal social roles.

1:58:35.780 --> 1:58:39.460
 But what's happened is that the publicity,

1:58:39.460 --> 1:58:43.020
 I mean, Prozac Nation was a good example

1:58:43.020 --> 1:58:45.980
 of making the argument that why should people

1:58:45.980 --> 1:58:47.580
 settle for normal happiness

1:58:47.580 --> 1:58:49.740
 when they can have better than normal happiness?

1:58:49.740 --> 1:58:52.460
 And if you're not having normal happiness,

1:58:52.460 --> 1:58:53.540
 you should take a drug.

1:58:53.540 --> 1:58:58.540
 Well, that concept that serotonin metabolism

1:59:00.340 --> 1:59:03.520
 is the root cause of depression

1:59:03.520 --> 1:59:05.500
 is really a destructive one.

1:59:05.500 --> 1:59:08.740
 We have drugs that change serotonin metabolism

1:59:08.740 --> 1:59:12.140
 but we don't know if that's why antidepressants

1:59:12.140 --> 1:59:14.440
 work on major depression.

1:59:14.440 --> 1:59:16.020
 And they certainly don't work on everybody

1:59:16.020 --> 1:59:16.860
 with major depression.

1:59:16.860 --> 1:59:18.500
 I forget what the number needed a treat is.

1:59:18.500 --> 1:59:20.820
 I think it's around four,

1:59:20.820 --> 1:59:23.580
 one out of four people have significant improvement.

1:59:23.580 --> 1:59:28.160
 But the people without major depression don't get better.

1:59:28.160 --> 1:59:30.420
 And the vast majority of these drugs

1:59:30.420 --> 1:59:33.700
 are used for people without major depression.

1:59:33.700 --> 1:59:37.260
 So what's happened is that the feelings

1:59:37.260 --> 1:59:42.020
 of life satisfaction of happiness and not sadness

1:59:42.020 --> 1:59:43.940
 have been medicalized.

1:59:43.940 --> 1:59:47.860
 The normal range of feelings have been medicalized.

1:59:47.860 --> 1:59:51.020
 And that's not to say that they shouldn't be attended to.

1:59:51.020 --> 1:59:54.340
 But the evidence shows that attending to them

1:59:54.340 --> 1:59:57.020
 by giving somebody a medicine doesn't help

1:59:57.020 --> 1:59:59.660
 except that they feel like somebody cares about them

1:59:59.660 --> 2:00:01.420
 and believes that they're suffering.

2:00:01.420 --> 2:00:04.060
 But there are problems in living

2:00:04.060 --> 2:00:07.740
 that give rise to much of this symptomatology

2:00:07.740 --> 2:00:10.100
 of less than major depression.

2:00:10.100 --> 2:00:12.380
 And let's call it what it is

2:00:12.380 --> 2:00:14.780
 and figure out a way to help people

2:00:14.780 --> 2:00:17.980
 in visual therapy, group therapy.

2:00:17.980 --> 2:00:19.880
 Maybe lifestyle modification would work.

2:00:19.880 --> 2:00:20.880
 We gotta try that.

2:00:21.920 --> 2:00:24.760
 But let's call it what it is instead of saying,

2:00:24.760 --> 2:00:29.760
 oh, you're in this vast basket of people who are depressed

2:00:29.860 --> 2:00:31.540
 so we'll give you an antidepressant

2:00:31.540 --> 2:00:33.340
 even though the evidence shows

2:00:33.340 --> 2:00:36.620
 that people who are suffering from your level of depression

2:00:36.620 --> 2:00:38.220
 don't get better.

2:00:38.220 --> 2:00:42.540
 And that's a consequence of not focusing

2:00:42.540 --> 2:00:46.060
 on preventative medicine, the lifestyle changes,

2:00:46.060 --> 2:00:47.140
 all that kind of stuff.

2:00:47.140 --> 2:00:49.660
 Well, yes, but it's really a consequence

2:00:49.660 --> 2:00:53.060
 of the drug companies creating the impression

2:00:53.060 --> 2:00:54.720
 that if you're sad, take a pill.

2:00:56.620 --> 2:01:01.140
 If you're nonmajor depression,

2:01:01.140 --> 2:01:03.460
 how do you overcome depression?

2:01:03.460 --> 2:01:06.700
 Well, you have to talk about what the problem is.

2:01:06.700 --> 2:01:09.900
 So talk therapy, lifestyle changes.

2:01:09.900 --> 2:01:12.260
 Well, no, I'm not jumping to that.

2:01:12.260 --> 2:01:15.100
 I'm saying that you ought to,

2:01:15.100 --> 2:01:19.420
 A, the way you feel must be respected.

2:01:19.420 --> 2:01:21.140
 Yeah, acknowledge that you're suffering.

2:01:21.140 --> 2:01:22.660
 Acknowledge that you're suffering

2:01:22.660 --> 2:01:24.700
 and deal with healthcare providers

2:01:24.700 --> 2:01:27.220
 who acknowledge that you're suffering.

2:01:27.220 --> 2:01:30.180
 So let's take that first step.

2:01:30.180 --> 2:01:32.260
 And then. Big first step also.

2:01:32.260 --> 2:01:33.540
 Big first step, yeah.

2:01:33.540 --> 2:01:36.220
 Family docs are pretty good at that.

2:01:36.220 --> 2:01:38.980
 That's kind of the arena

2:01:38.980 --> 2:01:41.880
 that caused me to go into family medicine.

2:01:41.880 --> 2:01:44.260
 The subjective experience of the patient.

2:01:44.260 --> 2:01:46.700
 Okay, so you're a person

2:01:46.700 --> 2:01:49.620
 who is not getting the enjoyment out of their life

2:01:49.620 --> 2:01:52.040
 that they feel they ought to be getting.

2:01:52.040 --> 2:01:54.620
 Now let's figure out why

2:01:54.620 --> 2:01:57.300
 and whether that means some time with a social worker,

2:01:57.300 --> 2:01:59.020
 some time with a psychiatrist,

2:01:59.020 --> 2:02:01.320
 some time with a psychiatric nurse.

2:02:02.220 --> 2:02:04.100
 I'm not sure how you'd best do that

2:02:04.100 --> 2:02:05.760
 most effectively and efficiently,

2:02:05.760 --> 2:02:07.500
 but that's what you need to do.

2:02:07.500 --> 2:02:11.680
 And it may be that there's a marital problem

2:02:11.680 --> 2:02:13.620
 and there's something going on

2:02:13.620 --> 2:02:18.580
 and one of the spouses can't find satisfaction

2:02:18.580 --> 2:02:21.500
 in the life they have to live within their relationship.

2:02:21.500 --> 2:02:24.640
 Maybe there's a past history of trauma or abuse

2:02:24.640 --> 2:02:28.820
 that somebody is projecting onto their current situation.

2:02:28.820 --> 2:02:31.100
 Maybe there's socioeconomic circumstances

2:02:31.100 --> 2:02:33.100
 where they can't find a job

2:02:33.100 --> 2:02:36.540
 that gives them self respect and enough money to live.

2:02:36.540 --> 2:02:39.700
 All, you know, an infinite range of things.

2:02:39.700 --> 2:02:42.080
 But let's figure out, make a diagnosis first.

2:02:42.080 --> 2:02:45.460
 The diagnosis isn't that the person feels sadder

2:02:45.460 --> 2:02:48.620
 than they feel, than they want to feel.

2:02:48.620 --> 2:02:51.980
 The diagnosis is why does the person feel sadder

2:02:51.980 --> 2:02:53.140
 than they want to feel?

2:02:54.500 --> 2:02:56.340
 You mentioned this is what made you want

2:02:56.340 --> 2:02:59.260
 to get into family medicine.

2:03:00.980 --> 2:03:03.100
 As a doctor, what do you think about the saying,

2:03:03.100 --> 2:03:05.380
 save one life, save the world?

2:03:05.380 --> 2:03:10.380
 This was always moving to me about doctors

2:03:13.780 --> 2:03:16.740
 because you have like this human in front of you

2:03:17.700 --> 2:03:20.920
 and your time is worth money.

2:03:22.340 --> 2:03:26.220
 Your, what you prescribe and your efforts

2:03:26.220 --> 2:03:28.820
 after the visit are worth money.

2:03:28.820 --> 2:03:31.860
 And it seems like the task of the doctor

2:03:31.860 --> 2:03:34.760
 is to not think about any of that.

2:03:34.760 --> 2:03:39.760
 Or not the task, but it seems like a great doctor,

2:03:42.480 --> 2:03:45.080
 despite all that, just forgets it all

2:03:45.080 --> 2:03:47.020
 and just cares about the one human.

2:03:47.020 --> 2:03:51.260
 And somehow that feels like the love and effort

2:03:51.260 --> 2:03:53.220
 you put into helping one person

2:03:53.220 --> 2:03:55.460
 is the thing that will save the world.

2:03:55.460 --> 2:03:58.420
 It's not like some economic argument

2:03:58.420 --> 2:04:03.420
 or some political argument or financial argument.

2:04:03.420 --> 2:04:08.420
 It's a very human drive that ultimately

2:04:09.580 --> 2:04:13.020
 is behind all of this that will do good for the world.

2:04:13.020 --> 2:04:15.600
 Yes, I think that's true.

2:04:15.600 --> 2:04:19.660
 And at the same time, I think it's equally true

2:04:19.660 --> 2:04:23.660
 that all physicians need to have a sense of responsibility

2:04:23.660 --> 2:04:28.660
 about how the common resources are allocated

2:04:28.660 --> 2:04:33.660
 to serve the whole population's interest best.

2:04:34.180 --> 2:04:36.420
 That's a tension that you have as a physician.

2:04:36.420 --> 2:04:38.500
 Let's take the extreme example.

2:04:38.500 --> 2:04:41.460
 Let's say you had a patient in front of you

2:04:41.460 --> 2:04:46.380
 who if you gave one $10 billion pill to,

2:04:46.380 --> 2:04:47.740
 you would save their life.

2:04:49.180 --> 2:04:52.420
 I would just be tortured by that as a physician

2:04:52.420 --> 2:04:56.140
 because I know that $10 billion spent properly

2:04:56.140 --> 2:05:00.260
 in an epidemiologically guided way

2:05:00.260 --> 2:05:03.580
 is gonna save a whole lot more lives than one life.

2:05:03.580 --> 2:05:06.380
 So it's also your responsibility as a physician

2:05:06.380 --> 2:05:08.700
 to walk away from that patient.

2:05:08.700 --> 2:05:10.540
 I wouldn't say that.

2:05:10.540 --> 2:05:12.060
 I think it's your responsibility

2:05:12.060 --> 2:05:14.020
 to be tortured by it.

2:05:14.020 --> 2:05:15.180
 That's exactly right.

2:05:17.100 --> 2:05:18.460
 The human condition.

2:05:21.460 --> 2:05:24.700
 That's a tough job, but yeah, yeah.

2:05:24.700 --> 2:05:27.220
 To maintain your humanity through it all.

2:05:27.220 --> 2:05:30.260
 Yeah, but you've been asking at different points

2:05:30.260 --> 2:05:35.260
 in this conversation, why are doctors so complacent

2:05:35.980 --> 2:05:38.860
 about the tremendous amount of money we're spending?

2:05:38.860 --> 2:05:41.460
 Why do they accept knowledge from different sources

2:05:41.460 --> 2:05:44.340
 that may not pan out when they really know the truth?

2:05:45.300 --> 2:05:48.380
 And the answer is that they're trying to do their best

2:05:48.380 --> 2:05:49.500
 for their patients.

2:05:49.500 --> 2:05:54.500
 And there's this, it's the same kind of torture

2:05:56.340 --> 2:05:59.860
 to figure out what the hell is going on with the data.

2:06:00.740 --> 2:06:03.420
 And that's a sort of future project.

2:06:03.420 --> 2:06:06.140
 And maybe people will read my book

2:06:06.140 --> 2:06:08.100
 and maybe they'll get a little more excited about it,

2:06:08.100 --> 2:06:10.140
 become more legitimate in practice.

2:06:10.140 --> 2:06:13.620
 I would feel like my life was worthwhile if that happened.

2:06:13.620 --> 2:06:17.140
 But at the same time, they've got to do something

2:06:17.140 --> 2:06:18.740
 with the patient in front of them.

2:06:18.740 --> 2:06:21.100
 They've got to make a decision.

2:06:21.100 --> 2:06:24.820
 And they probably, there are not many weirdos like me

2:06:24.820 --> 2:06:27.300
 who invest their life in figuring out

2:06:27.300 --> 2:06:28.300
 what's behind the data.

2:06:28.300 --> 2:06:29.780
 They're trying to get through the day

2:06:29.780 --> 2:06:31.620
 and do the right thing for their patient.

2:06:31.620 --> 2:06:34.980
 So they're tortured by that decision too.

2:06:34.980 --> 2:06:38.460
 And so if you're not careful,

2:06:38.460 --> 2:06:43.460
 big pharma can manipulate that drive

2:06:43.460 --> 2:06:44.940
 to try to help the patient,

2:06:44.940 --> 2:06:49.700
 that humanity of dealing with the uncertainty of it all.

2:06:49.700 --> 2:06:51.940
 Like what is the best thing to do?

2:06:51.940 --> 2:06:53.780
 Big pharma can step in and use money

2:06:53.780 --> 2:06:55.500
 to manipulate that humanity.

2:06:55.500 --> 2:06:57.500
 Yeah, I would state it quite differently.

2:06:57.500 --> 2:07:00.940
 It's sort of an opt out rather than an opt in.

2:07:00.940 --> 2:07:02.820
 Big pharma will do that.

2:07:02.820 --> 2:07:04.420
 And you need to opt out of it.

2:07:07.980 --> 2:07:11.300
 What advice would you give to a young person today

2:07:11.300 --> 2:07:13.100
 in high school or college

2:07:13.100 --> 2:07:17.020
 stepping into this complicated world

2:07:17.020 --> 2:07:22.020
 full of advertisements, of big powerful institutions,

2:07:22.540 --> 2:07:24.900
 of big rich companies,

2:07:24.900 --> 2:07:27.100
 how to have a positive impact in the world,

2:07:27.100 --> 2:07:29.460
 how to live a life they can be proud of?

2:07:30.860 --> 2:07:33.340
 I would say should that person

2:07:34.580 --> 2:07:38.140
 who has only good motives go into medicine.

2:07:38.140 --> 2:07:39.740
 They have an inclination to go into medicine

2:07:39.740 --> 2:07:42.060
 and they've asked me what I think about that

2:07:42.060 --> 2:07:45.420
 given what I know about the undermining

2:07:45.420 --> 2:07:47.660
 of American healthcare at this point.

2:07:47.660 --> 2:07:50.660
 And my answer is if you've got the calling,

2:07:50.660 --> 2:07:51.500
 you should do it.

2:07:52.420 --> 2:07:54.340
 You should do it because nobody's gonna do it

2:07:54.340 --> 2:07:55.180
 better than you.

2:07:56.220 --> 2:07:57.860
 And if you don't have the calling

2:07:58.780 --> 2:08:01.020
 and you're in it for the money,

2:08:01.020 --> 2:08:03.260
 you're not gonna be proud of yourself.

2:08:03.260 --> 2:08:07.700
 How do you prevent yourself from doing,

2:08:07.700 --> 2:08:12.700
 from letting the system change you over years and years,

2:08:12.940 --> 2:08:17.940
 like letting the game of pharmaceutical influence affect you?

2:08:20.820 --> 2:08:22.620
 It's a very hard question

2:08:22.620 --> 2:08:27.620
 because the sociologic norms are to be affected

2:08:28.060 --> 2:08:32.980
 and to trust the sources of information

2:08:32.980 --> 2:08:36.340
 that are largely controlled by the drug industry.

2:08:36.340 --> 2:08:38.220
 And that's why I wrote Sickening,

2:08:38.220 --> 2:08:43.220
 is to try and help those people in the medical profession

2:08:46.020 --> 2:08:50.620
 to understand that what's going on right now looks normal

2:08:50.620 --> 2:08:52.380
 but it's not.

2:08:52.380 --> 2:08:55.460
 The health of Americans is going downhill.

2:08:55.460 --> 2:08:57.580
 Our society's getting ruined by the money

2:08:57.580 --> 2:09:02.580
 that's getting pulled out of other socially beneficial uses

2:09:02.580 --> 2:09:06.420
 to pay for health care that is not helping us.

2:09:08.060 --> 2:09:12.580
 So fundamentally, the thing that is normal,

2:09:12.580 --> 2:09:16.940
 now question the normal, don't.

2:09:17.820 --> 2:09:21.820
 If you conform, conform hesitantly.

2:09:21.820 --> 2:09:23.700
 Well, you have to conform.

2:09:23.700 --> 2:09:26.620
 You can't become a doctor without conforming.

2:09:26.620 --> 2:09:30.100
 I just made it through.

2:09:30.100 --> 2:09:35.100
 But there aren't many and it's hard work.

2:09:35.300 --> 2:09:38.060
 But you have to conform.

2:09:38.060 --> 2:09:40.580
 And even with my colleagues in my own practice,

2:09:40.580 --> 2:09:44.300
 I couldn't convince them that some of the beliefs they had

2:09:44.300 --> 2:09:47.220
 about how best to practice weren't accurate.

2:09:47.220 --> 2:09:51.100
 There's one scene, a younger physician

2:09:51.100 --> 2:09:53.580
 had prescribed hormone replacement therapy.

2:09:53.580 --> 2:09:56.220
 This is back in 2000, 2001.

2:09:56.220 --> 2:10:00.380
 Had prescribed hormone replacement therapy for one of my patients

2:10:00.380 --> 2:10:03.220
 who happened to be a really good personal friend.

2:10:03.220 --> 2:10:08.780
 And I saw that patient covering for my colleague at one point

2:10:08.780 --> 2:10:13.340
 and I saw that her hormone replacement therapy had been renewed.

2:10:13.340 --> 2:10:15.580
 And I said, are you having hot flashes or any problem?

2:10:15.580 --> 2:10:16.660
 No, no, no, no.

2:10:16.660 --> 2:10:21.220
 But Dr. So and So said it's better for my health.

2:10:21.220 --> 2:10:23.060
 And I said, no, it's not.

2:10:23.060 --> 2:10:26.180
 The research is showing that it's not, it's harmful for your health

2:10:26.180 --> 2:10:27.980
 and I think you should stop it.

2:10:27.980 --> 2:10:32.780
 So my colleague approached me when she saw the chart and said,

2:10:32.780 --> 2:10:34.780
 wait a minute, that's my patient.

2:10:34.780 --> 2:10:37.180
 Maybe your friend, but it's my patient.

2:10:37.180 --> 2:10:43.900
 And I went to a conference from my alma mater, medical school,

2:10:43.900 --> 2:10:47.940
 and they said that healthy people should be given hormone replacement.

2:10:47.940 --> 2:10:51.500
 And I said, there's got to be a way to get rid of it.

2:10:51.500 --> 2:10:55.300
 And I said, there's got to be drug companies involved in this.

2:10:55.300 --> 2:10:57.700
 And she said, no, no, no, it was at my university.

2:10:57.700 --> 2:10:59.900
 It was not a drug company thing.

2:10:59.900 --> 2:11:02.380
 We didn't go to a Caribbean island.

2:11:02.380 --> 2:11:03.860
 I said, do you have the syllabus?

2:11:03.860 --> 2:11:05.140
 She said, yeah.

2:11:05.140 --> 2:11:07.660
 And she went and got the syllabus and sure enough,

2:11:07.660 --> 2:11:10.380
 it was sponsored by a drug company.

2:11:10.380 --> 2:11:11.340
 They're everywhere.

2:11:11.340 --> 2:11:12.220
 They're everywhere.

2:11:12.220 --> 2:11:16.340
 And it's back to Kuhn that groups of experts

2:11:16.340 --> 2:11:21.740
 share unspoken assumptions, and in order to be included

2:11:21.740 --> 2:11:23.140
 in that group of experts, you have

2:11:23.140 --> 2:11:25.260
 to share those unspoken assumptions.

2:11:25.260 --> 2:11:27.900
 And what I'm hoping to do with my book, Sickening,

2:11:27.900 --> 2:11:31.900
 and being here having this wonderful conversation with you

2:11:31.900 --> 2:11:36.220
 is to create an alternative to this normal

2:11:36.220 --> 2:11:45.060
 that people can pursue and practice better medicine

2:11:45.060 --> 2:11:47.220
 and also prevent burnout.

2:11:47.220 --> 2:11:49.900
 I mean, about half the doctors complain that they're burned

2:11:49.900 --> 2:11:51.260
 out and they've had it.

2:11:51.260 --> 2:11:54.180
 And I think that this is subjective.

2:11:54.180 --> 2:11:55.300
 I don't have data on this.

2:11:55.300 --> 2:11:57.540
 This is just my opinion.

2:11:57.540 --> 2:11:59.900
 But I think that a lot of that burnout

2:11:59.900 --> 2:12:04.380
 is so called moral injury from practicing in a way

2:12:04.380 --> 2:12:08.420
 that the docs know isn't working.

2:12:08.420 --> 2:12:12.020
 It's not actually providing an alternative to the normals,

2:12:12.020 --> 2:12:13.860
 expanding the normals, shifting the normal,

2:12:13.860 --> 2:12:15.220
 just like with Kuhn.

2:12:15.220 --> 2:12:19.420
 You're basically looking to shift

2:12:19.420 --> 2:12:24.340
 the way medicine is done to the original,

2:12:24.340 --> 2:12:29.860
 to the intent that it represents the ideal of medicine,

2:12:29.860 --> 2:12:30.580
 of health care.

2:12:30.580 --> 2:12:33.620
 Yeah, in Kuhnian terms, to have a revolution.

2:12:33.620 --> 2:12:36.860
 And that revolution would be to practice medicine

2:12:36.860 --> 2:12:40.620
 in a way that will be epidemiologically most

2:12:40.620 --> 2:12:43.660
 effective, not most profitable for the people

2:12:43.660 --> 2:12:47.420
 who are providing you with what's called knowledge.

2:12:47.420 --> 2:12:53.220
 You helped a lot of people, as a doctor, as an educator,

2:12:53.220 --> 2:12:56.540
 live better lives, live longer.

2:12:56.540 --> 2:12:59.180
 But you yourself are a mortal being.

2:12:59.180 --> 2:13:02.260
 Do you think about your own mortality?

2:13:02.260 --> 2:13:03.660
 Do you think about your death?

2:13:03.660 --> 2:13:06.020
 Are you afraid of death?

2:13:06.020 --> 2:13:06.540
 I'm not.

2:13:06.540 --> 2:13:12.100
 I've faced it, been close.

2:13:12.100 --> 2:13:12.780
 Yourself?

2:13:12.780 --> 2:13:14.980
 Yeah, yeah.

2:13:14.980 --> 2:13:16.220
 How do you think about it?

2:13:16.220 --> 2:13:19.780
 What wisdom do you gain from having come close to death,

2:13:19.780 --> 2:13:23.060
 the fact that the whole thing ends?

2:13:23.060 --> 2:13:25.780
 It's liberating.

2:13:25.780 --> 2:13:26.740
 It's very liberating.

2:13:26.740 --> 2:13:27.460
 I'm serious.

2:13:27.460 --> 2:13:30.700
 I was close, and not too long ago.

2:13:34.060 --> 2:13:41.820
 And it was a sense of, this may be the way it ends.

2:13:41.820 --> 2:13:45.780
 And I've done my best.

2:13:45.780 --> 2:13:48.220
 It's not been perfect.

2:13:48.220 --> 2:13:51.180
 And if it ends here, it ends here.

2:13:51.180 --> 2:13:54.460
 The people around me are trying to do their best.

2:13:54.460 --> 2:13:57.860
 And in fact, I got pulled out of it.

2:13:57.860 --> 2:14:01.540
 But it didn't look like I was going to get pulled out of it.

2:14:01.540 --> 2:14:07.420
 Are you ultimately grateful for the ride, even though it ends?

2:14:07.420 --> 2:14:11.940
 Well, it's a little odd.

2:14:11.940 --> 2:14:13.140
 I think so.

2:14:13.140 --> 2:14:18.820
 If I know you can't take the ride if you know it's going to end well.

2:14:18.820 --> 2:14:19.940
 It's not the real ride.

2:14:19.940 --> 2:14:22.140
 It's just a ride.

2:14:22.140 --> 2:14:25.220
 But having gone through the whole thing,

2:14:25.220 --> 2:14:31.260
 I definitely freed me of a sense of anxiety about death.

2:14:31.260 --> 2:14:35.540
 And it said to me, do your best every day,

2:14:35.540 --> 2:14:38.460
 because it's going to end sometime.

2:14:38.460 --> 2:14:40.820
 I apologize for the ridiculously big question.

2:14:40.820 --> 2:14:45.780
 But what do you think is the meaning of life,

2:14:45.780 --> 2:14:47.420
 of our human existence?

2:14:52.140 --> 2:14:56.900
 I think it's to care about something and do your best with it.

2:14:56.900 --> 2:14:59.620
 Whether it's being a doctor and trying

2:14:59.620 --> 2:15:03.180
 to make sure that the greatest number of people

2:15:03.180 --> 2:15:06.460
 get the best health care.

2:15:06.460 --> 2:15:09.380
 Or it's a gardener who wants to have the most beautiful plants.

2:15:09.380 --> 2:15:12.780
 Or it's a grandparent who wants to have a good relationship

2:15:12.780 --> 2:15:13.820
 with their grandchildren.

2:15:13.820 --> 2:15:19.260
 But whatever it is that gives you a sense of meaning,

2:15:19.260 --> 2:15:21.900
 as long as it doesn't hurt other people,

2:15:21.900 --> 2:15:24.980
 to really commit yourself to it.

2:15:24.980 --> 2:15:27.940
 That commitment, being in that commitment for me

2:15:27.940 --> 2:15:29.860
 is the meaning of life.

2:15:29.860 --> 2:15:34.540
 Put your whole heart and soul into the thing.

2:15:34.540 --> 2:15:38.860
 What is it, the Bukowski poem, go all the way.

2:15:38.860 --> 2:15:42.500
 John, you're an incredible human being, incredible educator.

2:15:42.500 --> 2:15:45.060
 Like I said, I recommend people listen to your lectures.

2:15:45.060 --> 2:15:47.980
 It's so refreshing to see that clarity

2:15:47.980 --> 2:15:49.380
 of thought and brilliance.

2:15:49.380 --> 2:15:51.900
 And obviously, your criticism of Big Pharma

2:15:51.900 --> 2:15:56.420
 or your illumination of the mechanisms of Big Pharma

2:15:56.420 --> 2:15:58.500
 is really important at this time.

2:15:58.500 --> 2:16:02.820
 So I really hope people read your book, Sickening,

2:16:02.820 --> 2:16:07.820
 that's out today, or depending on when this comes out.

2:16:07.820 --> 2:16:11.140
 Thank you so much for spending your extremely valuable time

2:16:11.140 --> 2:16:12.260
 with me today.

2:16:12.260 --> 2:16:13.100
 It was amazing.

2:16:13.100 --> 2:16:15.460
 Well, Lex, I wanted back to you.

2:16:15.460 --> 2:16:18.700
 Thanks for engaging in this conversation,

2:16:18.700 --> 2:16:21.420
 for creating the space to have it,

2:16:21.420 --> 2:16:24.260
 and creating a listenership that is

2:16:24.260 --> 2:16:27.380
 interested in understanding serious ideas.

2:16:27.380 --> 2:16:29.460
 And I really appreciate the conversation.

2:16:29.460 --> 2:16:30.940
 And I should mention that offline,

2:16:30.940 --> 2:16:34.060
 you told me you listened to the Gilbert Strang episode.

2:16:34.060 --> 2:16:35.980
 So for anyone who don't know Gilbert Strang,

2:16:35.980 --> 2:16:39.020
 another epic human being that you should check out.

2:16:39.020 --> 2:16:41.260
 If you don't know anything about mathematics

2:16:41.260 --> 2:16:43.260
 or linear algebra, go look him up.

2:16:43.260 --> 2:16:46.700
 He's one of the great mathematics educators of all time.

2:16:46.700 --> 2:16:49.060
 So of all the people you mentioned to me,

2:16:49.060 --> 2:16:50.780
 I appreciate that you mentioned him,

2:16:50.780 --> 2:16:54.100
 because he is a rockstar of mathematics.

2:16:54.100 --> 2:16:56.220
 John, thank you so much for talking to us, it was awesome.

2:16:56.220 --> 2:16:57.900
 Great, thank you.

2:16:57.900 --> 2:17:00.740
 Thanks for listening to this conversation with John Abramson.

2:17:00.740 --> 2:17:02.140
 To support this podcast,

2:17:02.140 --> 2:17:04.980
 please check out our sponsors in the description.

2:17:04.980 --> 2:17:08.820
 And now, let me leave you some words from Marcus Aurelius.

2:17:09.900 --> 2:17:14.740
 "'Waste no time arguing about what a good man should be.

2:17:14.740 --> 2:17:15.740
 Be one."

2:17:15.740 --> 2:17:28.740
 Thank you for listening and hope to see you next time.

