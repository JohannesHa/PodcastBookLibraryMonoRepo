WEBVTT

00:00.000 --> 00:05.920
 The following is a conversation with Rob Reed, entrepreneur, author, and host of the After

00:05.920 --> 00:07.520
 On Podcast.

00:07.520 --> 00:12.620
 Sam Harris recommended that I absolutely must talk to Rob about his recent work on the

00:12.620 --> 00:15.120
 future of engineer pandemics.

00:15.120 --> 00:21.580
 I then listened to the 4 hours special episode of Sam's Making Sense podcast with Rob titled

00:21.580 --> 00:27.260
 Engineering the Apocalypse, and I was floored, and knew I had to talk to him.

00:27.260 --> 00:33.560
 Quick mention of our sponsors, Athletic Greens, Belcampo, Fundrise, and NetSuite.

00:33.560 --> 00:36.960
 Check them out in the description to support this podcast.

00:36.960 --> 00:41.880
 As a side note, let me say a few words about the lab leak hypothesis, which proposes that

00:41.880 --> 00:47.560
 COVID 19 is a product of gain of function research on coronaviruses conducted at the

00:47.560 --> 00:53.120
 Wuhan Institute of Virology that was then accidentally leaked due to human error.

00:53.120 --> 00:59.080
 For context, this lab is biosafety level 4, BSL 4, and it investigates coronaviruses.

00:59.080 --> 01:04.040
 BSL 4 is the highest level of safety, but if you look at all the human in the loop pieces

01:04.040 --> 01:09.060
 required to achieve this level of safety, it becomes clear that even BSL 4 labs are

01:09.060 --> 01:11.560
 highly susceptible to human error.

01:11.560 --> 01:15.800
 To me, whether the virus leaked from the lab or not, getting to the bottom of what happened

01:15.800 --> 01:18.800
 is about much more than this particular catastrophic case.

01:18.800 --> 01:25.000
 It is a test for our scientific, political, journalistic, and social institutions of how

01:25.000 --> 01:31.440
 well we can prepare and respond to threats that can cripple or destroy human civilization.

01:31.440 --> 01:37.000
 If we continue gain of function research on viruses, eventually these viruses will leak,

01:37.000 --> 01:40.220
 and they will be more deadly and more contagious.

01:40.220 --> 01:45.880
 We can pretend that won't happen, or we can openly and honestly talk about the risks involved.

01:45.880 --> 01:49.880
 This research can both save and destroy human life on earth as we know it.

01:49.880 --> 01:52.640
 It's a powerful double edged sword.

01:52.640 --> 01:59.000
 If YouTube and other platforms censor conversations about this, if scientists self censor conversations

01:59.000 --> 02:05.940
 about this, we'll become merely victims of our brief homo sapiens story, not its heroes.

02:05.940 --> 02:11.540
 As I said before, too carelessly labeling ideas as misinformation and dismissing them

02:11.540 --> 02:16.840
 because of that will eventually destroy our ability to discover the truth, and without

02:16.840 --> 02:22.880
 truth we don't have a fighting chance against the great filter before us.

02:22.880 --> 02:28.960
 This is the Lex Friedman Podcast, and here is my conversation with Rob Reid.

02:28.960 --> 02:33.920
 I have seen evidence on the internet that you have a sense of humor, allegedly, but

02:33.920 --> 02:38.280
 you also talk and think about the destruction of human civilization.

02:38.280 --> 02:42.880
 What do you think of the Elon Musk hypothesis that the most entertaining outcome is the

02:42.880 --> 02:44.560
 most likely?

02:44.560 --> 02:49.280
 And he, I think, followed on to say a scene from an external observer, like if somebody

02:49.280 --> 02:56.600
 was watching us, it seems we come up with creative ways of progressing our civilization

02:56.600 --> 02:57.600
 that's fun to watch.

02:57.600 --> 03:03.380
 Yeah, so he, exactly, he said from the standpoint of the observer, not the participant, I think.

03:03.380 --> 03:07.600
 And so what's interesting about that, those were, I think, just a couple of freestanding

03:07.600 --> 03:12.520
 tweets and delivered without a whole lot of wrapper of context, so it's left to the mind

03:12.520 --> 03:16.920
 of the reader of the tweets to infer what he was talking about.

03:16.920 --> 03:20.400
 So that's kind of like, it provokes some interesting thoughts.

03:20.400 --> 03:26.480
 Like first of all, it presupposes the existence of an observer, and it also presupposes that

03:26.480 --> 03:32.040
 the observer wishes to be entertained and has some mechanism of enforcing their desire

03:32.040 --> 03:33.080
 to be entertained.

03:33.080 --> 03:35.540
 So there's like a lot underpinning that.

03:35.540 --> 03:40.280
 And to me, that suggests, particularly coming from Elon, that it's a reference to simulation

03:40.280 --> 03:46.400
 theory, that somebody is out there and has far greater insights and a far greater ability

03:46.400 --> 03:52.000
 to, let's say, peer into a single individual life and find that entertaining and full of

03:52.000 --> 03:58.440
 plot twists and surprises and either a happy or tragic ending, or they have an incredible

03:58.440 --> 04:04.320
 meta view and they can watch the arc of civilization unfolding in a way that is entertaining and

04:04.320 --> 04:08.160
 full of plot twists and surprises and a happy or unhappy ending.

04:08.160 --> 04:11.960
 So okay, so we're presupposing an observer.

04:11.960 --> 04:17.520
 Then on top of that, when you think about it, you're also presupposing a producer,

04:17.520 --> 04:23.440
 because the act of observation is mostly fun if there are plot twists and surprises and

04:23.440 --> 04:25.840
 other developments that you weren't foreseeing.

04:25.840 --> 04:30.760
 I have reread my own novels, and that's fun because it's something that I worked hard

04:30.760 --> 04:34.960
 on and I slaved over and I love, but there aren't a lot of surprises in there.

04:34.960 --> 04:39.960
 So now I'm thinking we need a producer and an observer for that to be true.

04:39.960 --> 04:45.260
 And on top of that, it's got to be a very competent producer because Elon said the most

04:45.260 --> 04:48.440
 entertaining outcome is the most likely one.

04:48.440 --> 04:51.600
 So there's lots of layers for thinking about that.

04:51.600 --> 04:55.280
 And when you've got a producer who's trying to make it entertaining, it makes me think

04:55.280 --> 05:00.760
 of there was a South Park episode in which Earth turned out to be a reality show.

05:00.760 --> 05:05.920
 And somehow we had failed to entertain the audience as much as we used to, so the Earth

05:05.920 --> 05:09.120
 show was going to get canceled, et cetera.

05:09.120 --> 05:13.200
 So taking all that together, and I'm obviously being a little bit playful in laying this

05:13.200 --> 05:20.220
 out, what is the evidence that we have that we are in a reality that is intended to be

05:20.220 --> 05:21.720
 most entertaining?

05:21.720 --> 05:26.300
 Now you could look at that reality on the level of individual lives or the whole arc

05:26.300 --> 05:30.040
 of civilization, other lives, levels as well, I'm sure.

05:30.040 --> 05:34.240
 But just looking from my own life, I think I'd make a pretty lousy show.

05:34.240 --> 05:38.880
 I spend an inordinate amount of time just looking at a computer.

05:38.880 --> 05:40.640
 I don't think that's very entertaining.

05:40.640 --> 05:46.360
 And there's just a completely inadequate level of shootouts and car chases in my life.

05:46.360 --> 05:50.120
 I mean, I'll go weeks, even months without a single shootout or car chase.

05:50.120 --> 05:53.000
 That just means that you're one of the non player characters in this game.

05:53.000 --> 05:54.000
 You're just waiting.

05:54.000 --> 05:55.200
 I'm an extra.

05:55.200 --> 05:59.120
 You're an extra that waiting for your one opportunity for a brief moment to actually

05:59.120 --> 06:03.120
 interact with one of the main characters in the play.

06:03.120 --> 06:04.600
 Okay, that's good.

06:04.600 --> 06:08.520
 So okay, so we rule out me being the star of the show, which I probably could have guessed

06:08.520 --> 06:09.520
 at.

06:09.520 --> 06:13.260
 Anyway, but then even the arc of civilization, I mean, there have been a lot of really intriguing

06:13.260 --> 06:16.560
 things that have happened and a lot of astounding things that have happened.

06:16.560 --> 06:23.280
 But I would have some werewolves, I'd have some zombies, I would have some really improbable

06:23.280 --> 06:28.660
 developments like maybe Canada absorbing the United States.

06:28.660 --> 06:33.240
 So I don't know, I'm not sure if we're necessarily designed for maximum entertainment.

06:33.240 --> 06:40.280
 But if we are, that will mean that 2020 is just a prequel for even more bizarre years

06:40.280 --> 06:41.320
 ahead.

06:41.320 --> 06:45.120
 So I kind of hope that we're not designed for maximum entertainment.

06:45.120 --> 06:47.840
 Well, the night is still young in terms of Canada.

06:47.840 --> 06:52.520
 But do you think it's possible for the observer and the producer to be kind of emergent?

06:52.520 --> 06:59.380
 So meaning, it does seem when you kind of watch memes on the internet, the funny ones,

06:59.380 --> 07:01.640
 the entertaining ones spread more efficiently.

07:01.640 --> 07:02.640
 They do.

07:02.640 --> 07:11.560
 I mean, I don't know what it is about the human mind that soaks up on mass funny things

07:11.560 --> 07:12.920
 much more sort of aggressively.

07:12.920 --> 07:16.760
 It's more viral in the full sense of that word.

07:16.760 --> 07:23.560
 Is there some sense that whatever the evolutionary process that created our cognitive capabilities

07:23.560 --> 07:28.440
 is the same process that's going to, in an emergent way, create the most entertaining

07:28.440 --> 07:36.120
 outcome, the most memeifiable outcome, the most viral outcome if we were to share it

07:36.120 --> 07:37.120
 on Twitter?

07:37.120 --> 07:38.680
 Yeah, that's interesting.

07:38.680 --> 07:41.680
 Yeah, we do have an incredible ability.

07:41.680 --> 07:45.040
 Like I mean, how many memes are created in a given day and the ones that go viral are

07:45.040 --> 07:48.800
 almost uniformly funny, at least to somebody with a particular sense of humor.

07:48.800 --> 07:53.560
 Yeah, I'd have to think about that.

07:53.560 --> 07:59.120
 We are definitely great at creating atomized units of funny.

07:59.120 --> 08:05.040
 Like in the example that you used, there are going to be X million brains parsing and judging

08:05.040 --> 08:07.520
 whether this meme is retweetable or not.

08:07.520 --> 08:14.860
 And so that sort of atomic element of funniness, of entertainingness, et cetera, we definitely

08:14.860 --> 08:20.160
 have an environment that's good at selecting for that and selective pressure and everything

08:20.160 --> 08:21.920
 else that's going on.

08:21.920 --> 08:31.180
 But in terms of the entire ecosystem of conscious systems here on the Earth driving for a level

08:31.180 --> 08:38.720
 of entertainment, that is on such a much higher level that I don't know if that would necessarily

08:38.720 --> 08:44.860
 follow directly from the fact that atomic units of entertainment are very, very aptly

08:44.860 --> 08:45.960
 selected for us.

08:45.960 --> 08:46.960
 I don't know.

08:46.960 --> 08:54.400
 Do you find it compelling or useful to think about human civilization from the perspective

08:54.400 --> 08:59.760
 of the ideas versus the perspective of the individual human brains?

08:59.760 --> 09:02.560
 Just almost thinking about the ideas or the memes.

09:02.560 --> 09:09.520
 This is the Dawkins thing as the organisms and then the humans as just like vehicles

09:09.520 --> 09:13.960
 for briefly carrying those organisms as they jump around and spread.

09:13.960 --> 09:19.360
 Yeah, for propagating them, mutating them, putting selective pressure on them, et cetera.

09:19.360 --> 09:27.400
 I mean, I found Dawkins interpret or his launching of the idea of memes is just kind of an afterthought

09:27.400 --> 09:32.120
 to his unbelievably brilliant book about the selfish gene.

09:32.120 --> 09:37.440
 What a PS to put at the end of a long chunk of writing, profoundly interesting.

09:37.440 --> 09:43.640
 I view the relationship though between humans and memes as probably an oversimplification,

09:43.640 --> 09:47.740
 but maybe a little bit like the relationship between flowers and bees, right?

09:47.740 --> 09:52.000
 Do flowers have bees or do bees in a sense have flowers?

09:52.000 --> 09:58.640
 And the answer is it is a very, very symbiotic relationship in which both have semi independent

09:58.640 --> 10:03.320
 roles that they play and both are highly dependent upon the other.

10:03.320 --> 10:07.780
 And so in the case of bees, obviously, you could see the flower is being this monolithic

10:07.780 --> 10:14.320
 structure physically in relation to any given bee and it's the source of food and sustenance.

10:14.320 --> 10:17.140
 So you could kind of say, well, flowers have bees.

10:17.140 --> 10:20.800
 But on the other hand, the flowers would obviously be doomed.

10:20.800 --> 10:22.920
 They weren't being pollinated by the bees.

10:22.920 --> 10:26.480
 So you could kind of say, well, you know, bees are, you know, flowers are really expression

10:26.480 --> 10:28.600
 of what the bees need.

10:28.600 --> 10:30.600
 And the truth is a symbiosis.

10:30.600 --> 10:39.160
 So with, with memes and human minds, our brains are clearly the Petri dishes in which memes

10:39.160 --> 10:45.420
 are either propagated or not propagated, get mutated or don't get mutated if they are the

10:45.420 --> 10:51.420
 venue in which competition, selective competition plays out between different memes.

10:51.420 --> 10:53.080
 So all of that is very true.

10:53.080 --> 10:58.880
 And you could look at that and say, really, the human mind is a production of memes and

10:58.880 --> 11:01.880
 ideas have us rather than us having ideas.

11:01.880 --> 11:07.160
 But at the same time, let's take a catchy tune as an example of a meme.

11:07.160 --> 11:11.320
 That catchy tune did originate in a human mind.

11:11.320 --> 11:13.000
 Somebody had to structure that thing.

11:13.000 --> 11:18.720
 And as much as I like Elizabeth Gilbert's TED talk about how the universe, I'm simplifying,

11:18.720 --> 11:22.960
 but you know, kind of the ideas find their way in this beautiful TED talk.

11:22.960 --> 11:23.960
 It's very lyrical.

11:23.960 --> 11:30.160
 She talked about, you know, ideas and prose kind of beaming into our minds.

11:30.160 --> 11:33.240
 And you know, she talked about needing to pull over to the side of the road when she

11:33.240 --> 11:38.260
 got inspiration for a particular paragraph or a particular idea and a burning need to

11:38.260 --> 11:40.160
 write that down.

11:40.160 --> 11:41.160
 I love that.

11:41.160 --> 11:47.520
 It's that beautiful as a writer, as a novelist myself, I've never had that experience.

11:47.520 --> 11:54.160
 And I think that really most things that do become memes are the product of a great deal

11:54.160 --> 11:59.520
 of deliberate and willful exertion of a conscious mind.

11:59.520 --> 12:04.440
 And so like the bees and the flowers, I think there's a great symbiosis and they both kind

12:04.440 --> 12:05.740
 of have one another.

12:05.740 --> 12:08.000
 Ideas have us, but we have ideas for real.

12:08.000 --> 12:14.400
 If we could take a little bit of a tangent, Stephen King on writing, you as a great writer,

12:14.400 --> 12:18.360
 you're dropping a hint here that the ideas don't come to you.

12:18.360 --> 12:22.760
 It's a grind of sort of, it's almost like you're mining for gold.

12:22.760 --> 12:28.160
 It's more of a very deliberate, rigorous daily process.

12:28.160 --> 12:32.640
 So maybe can you talk about the writing process?

12:32.640 --> 12:36.560
 How do you write well?

12:36.560 --> 12:42.560
 And maybe if you want to step outside of yourself, almost like give advice to an aspiring writer,

12:42.560 --> 12:46.400
 what does it take to write the best work of your life?

12:46.400 --> 12:50.000
 Well it would be very different if it's fiction versus nonfiction.

12:50.000 --> 12:51.000
 And I've done both.

12:51.000 --> 12:55.600
 I've written two nonfiction books and two works of fiction.

12:55.600 --> 12:58.800
 Two works of fiction being more recent, I'm going to focus on that right now because that's

12:58.800 --> 13:02.120
 more toweringly on my mind.

13:02.120 --> 13:08.640
 Bronx novelists, again, this is an oversimplification, but there's kind of two schools of thought.

13:08.640 --> 13:12.640
 Some people really like to fly by the seat of their pants and some people really, really

13:12.640 --> 13:15.680
 like to outline, to plot.

13:15.680 --> 13:20.180
 So there's plotters and pantsers, I guess is one way that people look at it.

13:20.180 --> 13:24.800
 And as with most things, there is a great continuum in between and I'm somewhere on

13:24.800 --> 13:29.920
 that continuum, but I lean, I guess, a little bit more toward the plotter.

13:29.920 --> 13:35.080
 And so when I do start a novel, I have a pretty strong point of view about how it's going

13:35.080 --> 13:39.360
 to end and I have a very strong point of view about how it's going to begin.

13:39.360 --> 13:44.240
 And I do try to make an effort of making an outline that I know I'm going to be extremely

13:44.240 --> 13:49.600
 unfaithful to in the actual execution of the story, but trying to make an outline that

13:49.600 --> 13:54.460
 gets us from here to there and notion of subplots and beats and rhythm and different characters

13:54.460 --> 13:56.280
 and so forth.

13:56.280 --> 14:02.000
 But then when I get into the process, that outline, particularly the center of it, ultimately

14:02.000 --> 14:03.760
 inevitably morphs a great deal.

14:03.760 --> 14:08.920
 And I think if I were personally a rigorous outliner, I would not allow that to happen.

14:08.920 --> 14:14.380
 I also would make a much more vigorous skeleton before I start.

14:14.380 --> 14:22.400
 So I think people who are really in that plotting outlining mode are people who write page turners,

14:22.400 --> 14:30.560
 people who write spy novels or supernatural adventures, where you really want a relentless

14:30.560 --> 14:37.560
 pace of events, action, plot twists, conspiracy, et cetera.

14:37.560 --> 14:40.560
 And that is really the bone.

14:40.560 --> 14:42.880
 That's really the skeletal structure.

14:42.880 --> 14:47.520
 So I think folks who write that kind of book are really very much on the outlining side.

14:47.520 --> 14:52.160
 And then I think people who write what's often referred to as literary fiction for lack of

14:52.160 --> 14:59.640
 a better term, where it's more about sort of aura and ambiance and character development

14:59.640 --> 15:05.520
 and experience and inner experience and inner journey and so forth, I think that group is

15:05.520 --> 15:07.640
 more likely to fly by the seat of their pants.

15:07.640 --> 15:11.000
 And I know people who start with a blank page and just see where it's going to go.

15:11.000 --> 15:14.480
 I'm a little bit more on the plotting side.

15:14.480 --> 15:21.200
 Now you asked what makes something, at least in the mind of the writer, as great as it

15:21.200 --> 15:22.200
 can be.

15:22.200 --> 15:26.960
 For me, it's an astonishingly high percentage of it is editing as opposed to the initial

15:26.960 --> 15:27.960
 writing.

15:27.960 --> 15:36.560
 For every hour that I spend writing new prose, like new pages, new paragraphs, new bits of

15:36.560 --> 15:40.280
 the book, I probably spend...

15:40.280 --> 15:42.680
 I wish I kept a count.

15:42.680 --> 15:47.240
 I wish I had one of those pieces of software that lawyers use to decide how much time I'm

15:47.240 --> 15:48.240
 going to be doing this, that.

15:48.240 --> 15:53.200
 But I would say it's at least four or five hours and maybe as many as 10 that I spend

15:53.200 --> 15:54.340
 editing.

15:54.340 --> 15:56.560
 And so it's relentless for me.

15:56.560 --> 15:58.400
 For each one hour of writing, you said?

15:58.400 --> 15:59.400
 I'd say that.

15:59.400 --> 16:00.400
 Four, wow.

16:00.400 --> 16:07.200
 I mean, I write because I edit and I spend just relentlessly polishing and pruning and

16:07.200 --> 16:12.400
 sometimes on the micro level of just like, does the rhythm of the sentence feel right?

16:12.400 --> 16:15.680
 Do I need to carve a syllable or something so it can land?

16:15.680 --> 16:21.760
 Like as micro as that to as macro as like, okay, I'm done but the book is 750 pages long

16:21.760 --> 16:25.160
 and it's way too bloated and I need to lop a third out of it.

16:25.160 --> 16:30.680
 Problems on those two orders of magnitude and everything in between, that is an enormous

16:30.680 --> 16:31.840
 amount of my time.

16:31.840 --> 16:37.320
 And I also write music, write and record and produce music.

16:37.320 --> 16:40.320
 And there the ratio is even higher.

16:40.320 --> 16:47.720
 Every minute that I spend or my band spends laying down that original audio, it's a very

16:47.720 --> 16:52.640
 high proportion of hours that go into just making it all hang together and sound just

16:52.640 --> 16:53.640
 right.

16:53.640 --> 16:56.200
 So I think that's true of a lot of creative processes.

16:56.200 --> 16:58.200
 I know it's true of sculpture.

16:58.200 --> 16:59.920
 I believe it's true of woodwork.

16:59.920 --> 17:04.400
 My dad was an amateur woodworker and he spent a huge amount of time on sanding and polishing

17:04.400 --> 17:05.480
 at the end.

17:05.480 --> 17:09.200
 So I think a great deal of the sparkle comes from that part of the process, any creative

17:09.200 --> 17:10.200
 process.

17:10.200 --> 17:14.480
 Can I ask about the psychological, the demon side of that picture?

17:14.480 --> 17:18.360
 In the editing process, you're ultimately judging the initial piece of work and you're

17:18.360 --> 17:20.840
 judging and judging and judging.

17:20.840 --> 17:26.000
 How much of your time do you spend hating your work?

17:26.000 --> 17:33.880
 How much time do you spend in gratitude, impressed, thankful, or how good the work that you will

17:33.880 --> 17:36.000
 put together is?

17:36.000 --> 17:42.360
 I spend almost all the time in a place that's intermediate between those, but leaning toward

17:42.360 --> 17:43.360
 gratitude.

17:43.360 --> 17:49.680
 I spend almost all the time in a state of optimism that this thing that I have, I like,

17:49.680 --> 17:56.160
 I like quite a bit and I can make it better and better and better with every time I go

17:56.160 --> 17:57.160
 through it.

17:57.160 --> 18:01.680
 So I spend most of my time in a state of optimism.

18:01.680 --> 18:06.620
 I think I personally oscillate much more aggressively between those two, where I wouldn't be able

18:06.620 --> 18:07.880
 to find the average.

18:07.880 --> 18:11.520
 I go pretty deep.

18:11.520 --> 18:19.920
 Marvin Minsky from MIT had this advice, I guess, to what it takes to be successful in

18:19.920 --> 18:23.280
 science and research is to hate everything you do.

18:23.280 --> 18:25.520
 You've ever done in the past.

18:25.520 --> 18:31.520
 I mean, at least he was speaking about himself that the key to his success was to hate everything

18:31.520 --> 18:32.520
 he's ever done.

18:32.520 --> 18:39.000
 I have a little Marvin Minsky there in me too, to sort of always be exceptionally self

18:39.000 --> 18:45.800
 critical, but almost like self critical about the work, but grateful for the chance to be

18:45.800 --> 18:46.800
 able to do the work.

18:46.800 --> 18:47.800
 If that makes sense.

18:47.800 --> 18:48.800
 It makes perfect sense.

18:48.800 --> 18:56.120
 But that, you know, each one of us have to strike a certain kind of balance.

18:56.120 --> 19:00.400
 But back to the destruction of human civilization.

19:00.400 --> 19:08.800
 If humans destroy ourselves in the next hundred years, what will be the most likely source,

19:08.800 --> 19:10.800
 the most likely reason that we destroy ourselves?

19:10.800 --> 19:14.080
 Well, let's see, a hundred years.

19:14.080 --> 19:19.480
 It's hard for me to comfortably predict out that far, and it's something to give a lot

19:19.480 --> 19:25.880
 more thought to, I think, than normal folks simply because I am a science fiction writer.

19:25.880 --> 19:31.760
 And you know, I feel with the acceleration of technological progress, it's really hard

19:31.760 --> 19:33.800
 to foresee out more than just a few decades.

19:33.800 --> 19:39.600
 I mean, comparing today's world to that of 1921, where we are right now, a century later,

19:39.600 --> 19:42.000
 it would have been so unforeseeable.

19:42.000 --> 19:46.160
 And I just don't know what's going to happen, particularly with exponential technologies.

19:46.160 --> 19:51.840
 I mean, our intuitions reliably defeat ourselves with exponential technologies like computing

19:51.840 --> 19:57.120
 and synthetic biology and, you know, how we might destroy ourselves in the hundred year

19:57.120 --> 20:02.720
 time frame might have everything to do with breakthroughs in nanotechnology 40 years from

20:02.720 --> 20:05.600
 now and then how rapidly those breakthroughs accelerate.

20:05.600 --> 20:10.520
 But in the near term that I'm comfortable predicting, let's say 30 years, I would say

20:10.520 --> 20:16.600
 the most likely route to self destruction would be synthetic biology.

20:16.600 --> 20:22.320
 And I always say that with the gigantic caveat and very important one that I find, and I'll

20:22.320 --> 20:25.880
 abbreviate synthetic biology to SynBio just to save us some syllables.

20:25.880 --> 20:34.320
 I believe SynBio offers us simply stunning promise that we would be fools to deny ourselves.

20:34.320 --> 20:37.160
 So I'm not an anti SynBio person by any stretch.

20:37.160 --> 20:43.520
 I mean, SynBio has unbelievable odds of helping us beat cancer, helping us rescue the environment,

20:43.520 --> 20:46.280
 helping us do things that we would currently find imponderable.

20:46.280 --> 20:48.520
 So it's electrifying the field.

20:48.520 --> 20:54.920
 But in the wrong hands, those hands either being incompetent or being malevolent.

20:54.920 --> 21:03.000
 In the wrong hands, synthetic biology to me has a much, much greater odds of leading to

21:03.000 --> 21:08.100
 our self destruction than something running amok with super AI, which I believe is a real

21:08.100 --> 21:10.400
 possibility and one we need to be concerned about.

21:10.400 --> 21:14.960
 But in the 30 year time frame, I think it's a lesser one or nuclear weapons or anything

21:14.960 --> 21:16.840
 else that I can think of.

21:16.840 --> 21:18.520
 Can you explain that a little bit further?

21:18.520 --> 21:26.220
 So your concern is on the manmade versus the natural side of the pandemic frontier.

21:26.220 --> 21:34.120
 So we humans, engineering pathogens, engineering viruses is the concern here.

21:34.120 --> 21:41.400
 And maybe how do you see the possible trajectories happening here in terms of, is it malevolent

21:41.400 --> 21:51.440
 or is it accidents, oops, little mistakes or unintended consequences of particular actions

21:51.440 --> 21:53.760
 that are ultimately lead to unexpected mistakes?

21:53.760 --> 21:55.800
 Well, both of them are a danger.

21:55.800 --> 22:00.920
 And I think the question of which is more likely has to do with two things.

22:00.920 --> 22:08.720
 One, do we take a lot of methodical, affordable, foresighted steps that we are absolutely capable

22:08.720 --> 22:14.560
 of taking right now to forestall the risk of a bad actor infecting us with something

22:14.560 --> 22:17.200
 that could have annihilating impacts?

22:17.200 --> 22:22.540
 And in the episode you referenced with Sam, we talked a great deal about that.

22:22.540 --> 22:24.160
 So do we take those steps?

22:24.160 --> 22:29.380
 And if we take those steps, I think the danger of malevolent rogue actors doing us in with

22:29.380 --> 22:31.840
 Sin Bio couldn't plummet.

22:31.840 --> 22:36.200
 But you know, it's always a question of if and we have a bad, bad and very long track

22:36.200 --> 22:41.460
 record of hitting the snooze bar after different natural pandemics have attacked us.

22:41.460 --> 22:43.800
 So that's variable number one.

22:43.800 --> 22:51.980
 Variable number two is how much experimentation and pathogen development do we as a society

22:51.980 --> 22:59.160
 decide is acceptable in the realms of academia, government or private industry?

22:59.160 --> 23:06.160
 And if we decide as a society that it's perfectly okay for people with varying research agendas

23:06.160 --> 23:12.400
 to create pathogens that if released could wipe out humanity, if we think that's fine

23:12.400 --> 23:19.140
 and if that kind of work starts happening in one lab, five labs, 50 labs, 500 labs in

23:19.140 --> 23:26.360
 one country, then 10 countries, then 70 countries or whatever, that risk of a boo boo starts

23:26.360 --> 23:28.680
 rising astronomically.

23:28.680 --> 23:33.400
 And this won't be a spoiler alert based on the way that I presented those two things,

23:33.400 --> 23:37.580
 but I think it's unbelievably important to manage both of those risks.

23:37.580 --> 23:42.240
 The easier one to manage, although it wouldn't be simple by any stretch because it would

23:42.240 --> 23:45.160
 have to be something that all nations agree on.

23:45.160 --> 23:52.380
 But the easiest way, the easier risk to manage is that of, hey guys, let's not develop pathogens

23:52.380 --> 23:56.280
 that if they escaped from a lab could annihilate us.

23:56.280 --> 23:58.720
 There's no line of research that justifies that.

23:58.720 --> 24:02.000
 And in my view, I mean, that's the point of perspective we need to have.

24:02.000 --> 24:06.160
 We'd have to collectively agree that there's no line of research that justifies that.

24:06.160 --> 24:11.240
 The reason why I believe that would be a highly rational conclusion is even the highest level

24:11.240 --> 24:15.680
 of biosafety lab in the world, biosafety lab level four.

24:15.680 --> 24:18.400
 And there are not a lot of BSL four labs in the world.

24:18.400 --> 24:25.500
 There are things can and have leaked out of BSL four labs and some of the work that's

24:25.500 --> 24:30.300
 been done with potentially annihilating pathogens, which we can talk about, it's actually done

24:30.300 --> 24:32.000
 at BSL three.

24:32.000 --> 24:36.480
 And so fundamentally any lab can leak.

24:36.480 --> 24:41.320
 We have proven ourselves to be incapable of creating a lab that is utterly impervious

24:41.320 --> 24:42.560
 to leaks.

24:42.560 --> 24:47.740
 So why in the world would we create something where if God forbid it leaked, could annihilate

24:47.740 --> 24:48.740
 us all.

24:48.740 --> 24:53.160
 And by the way, almost all of the measures that are taken in biosafety level anything

24:53.160 --> 24:57.280
 labs are designed to prevent accidental leaks.

24:57.280 --> 24:59.740
 What happens if you have a malevolent insider?

24:59.740 --> 25:03.900
 We could talk about the psychology and the motivations of what would make a malevolent

25:03.900 --> 25:07.480
 insider who wants to release something and not annihilating in a bit.

25:07.480 --> 25:08.840
 I'm sure that we will.

25:08.840 --> 25:11.980
 But what if you have a malevolent insider?

25:11.980 --> 25:17.360
 Virtually none of the standards that go into biosafety level one, two, three, and four

25:17.360 --> 25:20.480
 are about preventing somebody hijacking the process.

25:20.480 --> 25:23.600
 Some of them are, but they're mainly designed against accidents.

25:23.600 --> 25:25.740
 They're imperfect against accidents.

25:25.740 --> 25:29.280
 And if this kind of work starts happening in lots and lots of labs with every lab you

25:29.280 --> 25:34.040
 add, the odds of there being a malevolent inside are naturally increased arithmetically

25:34.040 --> 25:36.100
 as the number of labs goes up.

25:36.100 --> 25:44.360
 Now on the front of somebody outside of a government academic or scientific, traditional

25:44.360 --> 25:50.620
 government, academic, scientific environment creating something malevolent, again, there's

25:50.620 --> 25:57.840
 protections that we can take both at the level of syn bio architecture, hardening the entire

25:57.840 --> 26:03.880
 syn bio ecosystem against terrible things being made that we don't want to have out

26:03.880 --> 26:09.200
 there by rogue actors, to early detection, to lots and lots of other things that we can

26:09.200 --> 26:11.680
 do to dramatically mitigate that risk.

26:11.680 --> 26:16.240
 And I think we do both of those things, decide that no, we're not going to experimentally

26:16.240 --> 26:22.520
 make annihilating pathogens in leaky labs, and B, yes, we are going to take countermeasures

26:22.520 --> 26:28.760
 that are going to cost a fraction of our annual defense budget to preclude their creation,

26:28.760 --> 26:31.780
 then I think both risks get managed down.

26:31.780 --> 26:36.480
 But if you take one set of precautions and not the other, then the thing that you have

26:36.480 --> 26:41.000
 not taken precautions against immediately becomes the more likely outcome.

26:41.000 --> 26:45.720
 So can we talk about this kind of research and what's actually done and what are the

26:45.720 --> 26:47.240
 positives and negatives of it?

26:47.240 --> 26:52.560
 So if we look at gain of function research and the kind of stuff that's happening in

26:52.560 --> 26:56.640
 level three and level four BSL labs, what's the whole idea here?

26:56.640 --> 27:01.580
 Is it trying to engineer viruses to understand how they behave?

27:01.580 --> 27:03.520
 You want to understand the dangerous ones.

27:03.520 --> 27:04.520
 Yeah.

27:04.520 --> 27:06.640
 So that would be the logic behind doing it.

27:06.640 --> 27:10.560
 And so gain of function can mean a lot of different things.

27:10.560 --> 27:15.480
 Viewed through a certain lens, gain of function research could be what you do when you create,

27:15.480 --> 27:20.600
 you know, GMOs, when you create, you know, hearty strains of corn that are resistant

27:20.600 --> 27:21.600
 to pesticides.

27:21.600 --> 27:23.400
 I mean, you could view that as gain of function.

27:23.400 --> 27:26.960
 So I'm going to refer to gain of function in a relatively narrow sense, which is actually

27:26.960 --> 27:34.400
 the sense that the term is usually used, which is in some way magnifying capabilities of

27:34.400 --> 27:40.720
 microorganisms to make them more dangerous, whether it's more transmissible or more deadly.

27:40.720 --> 27:46.380
 And in that line of research, I'll use an example from 2011 because it's very illustrative

27:46.380 --> 27:48.400
 and it's also very chilling.

27:48.400 --> 27:54.120
 Back in 2011, two separate labs independently of one another, I assume there was some kind

27:54.120 --> 27:57.700
 of communication between them, but they were basically independent projects, one in Holland

27:57.700 --> 28:04.200
 and one in Wisconsin, did gain of function research on something called H5N1 flu.

28:04.200 --> 28:11.480
 H5N1 is, you know, something that, at least on a lethality basis, makes COVID look like

28:11.480 --> 28:12.480
 a kitten.

28:12.480 --> 28:15.640
 You know, COVID, according to the World Health Organization, has a case fatality rate somewhere

28:15.640 --> 28:21.480
 between half a percent and one percent, H5N1 is closer to 60 percent, six zero.

28:21.480 --> 28:24.320
 And so that's actually even slightly more lethal than Ebola.

28:24.320 --> 28:27.560
 It's a very, very, very scary pathogen.

28:27.560 --> 28:33.180
 The good news about H5N1 is that it is barely, barely contagious.

28:33.180 --> 28:36.320
 But I believe it is in no way contagious human to human.

28:36.320 --> 28:44.940
 It requires, you know, very, very, very deep contact with birds, in most cases chickens.

28:44.940 --> 28:49.240
 And so if you're a chicken farmer and you spend an enormous amount of time around them

28:49.240 --> 28:54.960
 and perhaps you get into situations in which you get a break in your skin and you're interacting

28:54.960 --> 29:01.960
 intensely with fowl who, as it turns out, have H5N1, that's when the jump comes.

29:01.960 --> 29:05.480
 But it's not, there's no airborne transmission that we're aware of human to human.

29:05.480 --> 29:08.480
 I mean, not that it just doesn't exist.

29:08.480 --> 29:14.520
 I think the World Health Organization did a relentless survey of the number of H5N1

29:14.520 --> 29:15.520
 cases.

29:15.520 --> 29:16.520
 I think they do it every year.

29:16.520 --> 29:22.160
 I saw one 10 year series where I think it was like 500 fatalities over the course of

29:22.160 --> 29:23.160
 a decade.

29:23.160 --> 29:24.160
 And that's a drop in the bucket.

29:24.160 --> 29:30.720
 Kind of fun, fun fact, I believe the typical lethality from lightning over 10 years is

29:30.720 --> 29:31.920
 70,000 deaths.

29:31.920 --> 29:37.200
 So we think getting struck by lightning, pretty low risk, H5N1 much, much lower than that.

29:37.200 --> 29:43.560
 What happened in these experiments is the experimenters in both cases set out to make

29:43.560 --> 29:48.400
 H5N1 that would be contagious, that could create airborne transmission.

29:48.400 --> 29:52.980
 And so they basically passed it, I think in both cases, they passed it through a large

29:52.980 --> 29:54.740
 number of ferrets.

29:54.740 --> 29:58.220
 And so this wasn't like CRISPR, there wasn't even any CRISPR back in those days.

29:58.220 --> 30:03.200
 This was relatively straightforward, selecting for a particular outcome.

30:03.200 --> 30:07.240
 And after guiding the path and passing them through, again, I believe it was a series

30:07.240 --> 30:08.240
 of ferrets.

30:08.240 --> 30:14.680
 They did in fact come up with a version of H5N1 that is capable of airborne transmission.

30:14.680 --> 30:17.400
 Now they didn't unleash it into the world.

30:17.400 --> 30:20.680
 They didn't inject it into humans to see what would happen.

30:20.680 --> 30:25.900
 And so for those two reasons, we don't really know how contagious it might have been.

30:25.900 --> 30:33.520
 But if it was as contagious as COVID, that could be a civilization threatening pathogen.

30:33.520 --> 30:34.720
 And why would you do it?

30:34.720 --> 30:36.800
 Well, the people who did it were good guys.

30:36.800 --> 30:38.320
 They were virologists.

30:38.320 --> 30:43.560
 I believe their agenda as they explained it was much as you said, let's figure out what

30:43.560 --> 30:47.920
 a worst case scenario might look like so we can understand it better.

30:47.920 --> 30:52.860
 But my understanding is in both cases, it was done in BSL3 labs.

30:52.860 --> 31:01.040
 And so potential of leak, significantly nonzero, hopefully way below 1% but significantly nonzero.

31:01.040 --> 31:06.040
 And when you look at the consequences of an escape in terms of human lives, destruction

31:06.040 --> 31:10.680
 of a large portion of the economy, et cetera, and you do an expected value calculation on

31:10.680 --> 31:17.540
 whatever fraction of 1% that was, you would come up with a staggering cost, staggering

31:17.540 --> 31:19.360
 expected cost for this work.

31:19.360 --> 31:21.960
 So it should never have been carried out.

31:21.960 --> 31:30.120
 Now you might make an argument if you said, if you believed that H5N1 in nature is on

31:30.120 --> 31:35.800
 an inevitable path to airborne transmission, and it's only going to be a small number of

31:35.800 --> 31:43.920
 years, A. And B, if it makes that transition, there is one set of changes to its metabolic

31:43.920 --> 31:49.140
 pathways and its genomic code and so forth, one that we have discovered.

31:49.140 --> 31:53.840
 So it is going to go from point A, which is where it is right now, to point B. We have

31:53.840 --> 31:58.140
 reliably engineered point B. That is the destination.

31:58.140 --> 32:02.080
 And we need to start fighting that right now because this is five years or less away.

32:02.080 --> 32:03.520
 Now that'd be a very different world.

32:03.520 --> 32:06.640
 That'd be like spotting an asteroid that's coming toward the earth and is five years

32:06.640 --> 32:07.640
 off.

32:07.640 --> 32:10.360
 And yes, you marshal everything you can to resist that.

32:10.360 --> 32:12.640
 But there's two problems with that perspective.

32:12.640 --> 32:17.160
 The first is, in however many thousands of generations that humans have been inhabiting

32:17.160 --> 32:21.280
 this planet, there has never been a transmissible form of H5N1.

32:21.280 --> 32:23.720
 And influenza has been around for a very long time.

32:23.720 --> 32:30.240
 So there is no case for inevitability of this kind of a jump to airborne transmission.

32:30.240 --> 32:33.600
 So we're not on a freight train to that outcome.

32:33.600 --> 32:38.340
 And if there was inevitability around that, it's not like there's just one set of genetic

32:38.340 --> 32:41.320
 code that would get there.

32:41.320 --> 32:46.760
 There's all kinds of different mutations that could conceivably result in that kind of an

32:46.760 --> 32:49.900
 outcome, unbelievable diversity of mutations.

32:49.900 --> 32:54.400
 And so we're not actually creating something we're inevitably going to face, but we are

32:54.400 --> 33:00.320
 creating something, we are creating a very powerful and unbelievably negative card and

33:00.320 --> 33:04.460
 injecting it in the deck that nature never put into the deck.

33:04.460 --> 33:11.180
 So in that case, I just don't see any moral or scientific justification for that kind

33:11.180 --> 33:12.480
 of work.

33:12.480 --> 33:18.200
 And interestingly, there was quite a bit of excitement and concern about this when the

33:18.200 --> 33:19.200
 work came out.

33:19.200 --> 33:22.960
 One of the teams was going to publish their results in Science, the other in Nature.

33:22.960 --> 33:27.900
 And there were a lot of editorials and a lot of scientists are saying, this is crazy.

33:27.900 --> 33:31.240
 And publication of those papers did get suspended.

33:31.240 --> 33:36.120
 And not long after that, there was a pause put on US government funding, NIH funding

33:36.120 --> 33:38.380
 on gain of function research.

33:38.380 --> 33:41.840
 But both of those speed bumps were ultimately removed.

33:41.840 --> 33:43.960
 Those papers did ultimately get published.

33:43.960 --> 33:47.840
 And that pause on funding, you know, ceased long ago.

33:47.840 --> 33:52.460
 And in fact, those two very projects, my understanding is resumed their funding, got their government

33:52.460 --> 33:53.460
 funding back.

33:53.460 --> 33:57.720
 I don't know why a Dutch project is getting NIH funding, but whatever, about a year and

33:57.720 --> 33:58.900
 a half ago.

33:58.900 --> 34:04.480
 So as far as the US government and regulators are concerned, it's all systems go for gain

34:04.480 --> 34:07.720
 of function at this point, which I find very troubling.

34:07.720 --> 34:11.480
 Now I'm a little bit of an outsider from this field, but it has echoes of the same kind

34:11.480 --> 34:16.680
 of problem I see in the AI world with autonomous weapon systems.

34:16.680 --> 34:25.080
 Nobody in my colleagues, my colleagues, friends, as far as I can tell, people in the AI community

34:25.080 --> 34:31.480
 are not really talking about autonomous weapon systems as now US and China full steam ahead

34:31.480 --> 34:33.200
 on the development of both.

34:33.200 --> 34:37.120
 And that seems to be a similar kind of thing on gain of function.

34:37.120 --> 34:42.920
 I've, you know, have friends in the biology space and they don't want to talk about gain

34:42.920 --> 34:46.200
 of function publicly.

34:46.200 --> 34:50.560
 And I don't, that makes me very uncomfortable from an outsider perspective in terms of gain

34:50.560 --> 34:51.560
 of function.

34:51.560 --> 34:56.920
 It makes me very uncomfortable from the insider perspective on autonomous weapon systems.

34:56.920 --> 35:00.280
 I'm not sure how to communicate exactly about autonomous weapon systems.

35:00.280 --> 35:04.120
 And I certainly don't know how to communicate effectively about gain of function.

35:04.120 --> 35:06.240
 What is the right path forward here?

35:06.240 --> 35:08.920
 Could we seize all gain of function research?

35:08.920 --> 35:11.280
 Is that, is that really the solution here?

35:11.280 --> 35:15.320
 Well, again, I'm going to use gain of function in the relatively narrow context of over assessing

35:15.320 --> 35:19.680
 because you could say almost, you know, anything that you do to make biology more effective

35:19.680 --> 35:20.680
 as gain of function.

35:20.680 --> 35:27.000
 So within the narrow confines of what we're discussing, I think it would be easy enough

35:27.000 --> 35:31.840
 for level headed people in all of the countries, level headed governmental people in all the

35:31.840 --> 35:36.800
 countries that realistically could support such a program to agree, we don't want this

35:36.800 --> 35:40.560
 to happen because all labs leak.

35:40.560 --> 35:45.520
 I mean, and you know, an example that I use, I actually didn't use it in the piece I did

35:45.520 --> 35:50.880
 with Sam Harris as well, is the anthrax attacks in the United States in 2001.

35:50.880 --> 35:57.280
 I mean, talk about an example of the least likely lab leaking into the least likely place.

35:57.280 --> 36:03.000
 This was shortly after 9 11, folks who don't remember it, and it was a very, very lethal

36:03.000 --> 36:08.640
 strand of anthrax that as it turned out, based on the forensic genomic work that was done

36:08.640 --> 36:13.700
 and so forth, absolutely leaked from a high security US army lab.

36:13.700 --> 36:17.480
 Probably the one at Fort Detrick in Maryland, it might've been another one, but who cares?

36:17.480 --> 36:21.500
 It absolutely leaked from a high security US army lab.

36:21.500 --> 36:22.880
 And where did it leak to?

36:22.880 --> 36:28.160
 This highly dangerous substance that was kept under lock and key by a very security minded

36:28.160 --> 36:29.160
 organization?

36:29.160 --> 36:33.520
 Well, it leaked to places including the Senate majority leader's office, Tom Daschle's office,

36:33.520 --> 36:38.080
 I think it was Senator Leahy's office, certain publications, including bizarrely the National

36:38.080 --> 36:39.260
 Enquirer.

36:39.260 --> 36:41.960
 But let's go to the Senate majority leader's office.

36:41.960 --> 36:47.600
 It is hard to imagine a more security minded country than the United States two weeks after

36:47.600 --> 36:49.080
 the 9 11 attack.

36:49.080 --> 36:52.540
 I mean, it doesn't get more security minded than that.

36:52.540 --> 36:59.080
 And it's also hard to imagine a more security capable organization than the United States

36:59.080 --> 37:00.080
 military.

37:00.080 --> 37:05.600
 We can joke all we want about inefficiencies in the military and $24,000 wrenches and so

37:05.600 --> 37:08.560
 forth, but pretty capable when it comes to that.

37:08.560 --> 37:16.740
 Despite that level of focus and concern and competence, just days after the 9 11 attack,

37:16.740 --> 37:22.200
 something comes from the inside of our military industrial compacts and ends up in the office

37:22.200 --> 37:26.000
 of someone I believe the Senate majority leader somewhere in the line of presidential succession.

37:26.000 --> 37:28.100
 It tells us everything can leak.

37:28.100 --> 37:33.840
 So again, think of a level headed conversation between powerful leaders in a diversity of

37:33.840 --> 37:40.360
 countries, thinking through like, I can imagine a very simple PowerPoint revealing, just discussing

37:40.360 --> 37:46.680
 briefly things like the anthrax leak, things like this foot and mouth disease outbreak

37:46.680 --> 37:52.440
 that or leaking that came out of a BSL four level lab in the UK, several other things

37:52.440 --> 37:57.720
 talking about the utter virulence that could result from gain of function and say, folks,

37:57.720 --> 38:01.080
 can we agree that this just shouldn't happen?

38:01.080 --> 38:06.160
 I mean, if we were able to agree on the nuclear nonproliferation treaty, which we were by

38:06.160 --> 38:11.400
 a weapons convention, which we did agree on, we the world, for the most part, I believe

38:11.400 --> 38:13.980
 agreement could be found there.

38:13.980 --> 38:18.940
 But it's going to take people in leadership of a couple of very powerful countries to

38:18.940 --> 38:22.900
 get to the consensus amongst them and then to decide we're going to get everybody together

38:22.900 --> 38:24.640
 and browbeat them into banning this stuff.

38:24.640 --> 38:28.680
 Now that doesn't make it entirely impossible that somebody might do this.

38:28.680 --> 38:35.840
 But in well regulated, carefully watched over fiduciary environments like federally funded

38:35.840 --> 38:41.880
 academic research, anything going on in the government itself, things going on in companies

38:41.880 --> 38:47.000
 that have investors who don't want to go to jail for the rest of their lives.

38:47.000 --> 38:50.400
 I think that would have a major, major dampening impact on it.

38:50.400 --> 38:58.360
 But there is a particular possible catalyst in this time we live in, which is for really

38:58.360 --> 39:02.640
 kind of raising the question of gain of function research for the application of virus making

39:02.640 --> 39:05.200
 viruses more dangerous.

39:05.200 --> 39:14.360
 Is the question of whether COVID leaked from a lab, sort of not even answering that question,

39:14.360 --> 39:21.160
 but even asking that question is a very, it seems like a very important question to ask

39:21.160 --> 39:26.440
 to catalyze the conversation about whether we should be doing gain of function research.

39:26.440 --> 39:33.720
 I mean, from a high level, why do you think people, even colleagues of mine are not comfortable

39:33.720 --> 39:35.360
 asking that question?

39:35.360 --> 39:40.200
 And two, do you think that the answer could be that it did leak from a lab?

39:40.200 --> 39:49.080
 I think the mere possibility that it did leak from a lab is evidence enough, again, for

39:49.080 --> 39:54.640
 the hypothetical rational national leaders watching this simple PowerPoint.

39:54.640 --> 40:00.460
 If you could put the possibility at 1% and you look at the unbelievable destructive power

40:00.460 --> 40:06.240
 that COVID had, that should be an overwhelmingly powerful argument for excluding it.

40:06.240 --> 40:12.360
 Now as to whether or not that was a leak, some very, very level, I don't know enough

40:12.360 --> 40:18.160
 about all of the factors in the Bayesian analysis and so forth that has gone into people making

40:18.160 --> 40:19.640
 the pro argument of that.

40:19.640 --> 40:25.040
 So I don't pretend to be an expert on that and I don't have a point of view, I just don't

40:25.040 --> 40:26.040
 know.

40:26.040 --> 40:32.640
 But what we can say is it is entirely possible for a couple of reasons.

40:32.640 --> 40:37.320
 One is that there is a BSL4 lab in Wuhan, the Wuhan Institute of Virology.

40:37.320 --> 40:44.440
 I believe it's the only BSL4 in China, I could be wrong about that, but it definitely had

40:44.440 --> 40:52.520
 a history that alarmed very sophisticated US diplomats and others who were in contact

40:52.520 --> 41:00.120
 with the lab and were aware of what it was doing long before COVID hit the world.

41:00.120 --> 41:05.640
 And so there are diplomatic cables that have been declassified, I believe one sophisticated

41:05.640 --> 41:10.720
 scientist or other observer said that WIV is a ticking time bomb.

41:10.720 --> 41:16.120
 And I believe it's also been pretty reasonably established that coronaviruses were a topic

41:16.120 --> 41:18.240
 of great interest at WIV.

41:18.240 --> 41:22.320
 The SARS obviously came out of China and that's a coronavirus that would make an enormous

41:22.320 --> 41:25.800
 amount of sense for it to be studied there.

41:25.800 --> 41:32.880
 And there is so much opacity about what happened in the early days and weeks after the outbreak

41:32.880 --> 41:38.200
 that's basically been imposed by the Chinese government that we just don't know.

41:38.200 --> 41:43.680
 So it feels like a substantially or greater than 1% possibility to me looking at it from

41:43.680 --> 41:45.360
 the outside.

41:45.360 --> 41:47.800
 And that's something that one could imagine.

41:47.800 --> 41:52.200
 Now we're going to the realm of thought experiment, not me decreeing this is what happened, but

41:52.200 --> 41:58.200
 if they're studying coronavirus at the Wuhan Institute of Virology and there is this precedent

41:58.200 --> 42:02.680
 of gain of function research that's been done on something that is remarkably uncontagious

42:02.680 --> 42:06.920
 to humans, whereas we know coronavirus is contagious to humans, I could definitely...

42:06.920 --> 42:12.660
 And there is this global consensus, certainly was the case two or three years ago when this

42:12.660 --> 42:16.520
 work might've started, there seems to be this global consensus that gain of function is

42:16.520 --> 42:17.520
 fine.

42:17.520 --> 42:21.640
 The US paused funding for a little while, but paused funding, they never said private

42:21.640 --> 42:25.720
 actors couldn't do it, it was just a pause of NIH funding.

42:25.720 --> 42:26.960
 And then that pause was lifted.

42:26.960 --> 42:28.840
 So again, none of this is irrational.

42:28.840 --> 42:34.720
 You could certainly see the folks at WIV saying, gain of function, interesting vector, coronavirus

42:34.720 --> 42:42.840
 unlike H5N1, very contagious, we're a nation that has had terrible run ins with coronavirus,

42:42.840 --> 42:44.960
 why don't we do a little gain of function on this?

42:44.960 --> 42:49.880
 And then like all labs at all levels, one could imagine this lab leaking.

42:49.880 --> 42:55.040
 So it's not an impossibility and very, very level headed people have said that, who've

42:55.040 --> 42:58.880
 looked at it much more deeply do believe in that outcome.

42:58.880 --> 43:03.600
 Why is it such a threat to power the idea that it'll leak from a lab?

43:03.600 --> 43:04.600
 Why is it so threatening?

43:04.600 --> 43:08.840
 I don't maybe understand this point exactly.

43:08.840 --> 43:14.060
 Is it just that as governments and especially the Chinese government is really afraid of

43:14.060 --> 43:18.320
 admitting mistakes that everybody makes?

43:18.320 --> 43:21.840
 So this is a horrible, like Chernobyl is a good example.

43:21.840 --> 43:24.480
 I come from the Soviet Union.

43:24.480 --> 43:29.240
 I mean, well, major mistakes were made in Chernobyl.

43:29.240 --> 43:40.040
 I would argue for a lab leak to happen, the scale of the mistake is much smaller, right?

43:40.040 --> 43:50.080
 The depth and the breadth of rot that in bureaucracy that led to Chernobyl is much bigger than

43:50.080 --> 43:55.360
 anything that could lead to a lab leak, because it could literally just be, I mean, I'm sure

43:55.360 --> 44:02.880
 there's security, very careful security procedures, even in level three labs, but it, I imagine

44:02.880 --> 44:09.240
 maybe you can correct me, it's all it takes is the incompetence of a small number of individuals,

44:09.240 --> 44:14.560
 one individual on a particular, a couple of weeks, three weeks period, as opposed to a

44:14.560 --> 44:19.160
 multi year bureaucratic failure of the entire government.

44:19.160 --> 44:20.160
 Right.

44:20.160 --> 44:24.200
 Well, certainly the magnitude of mistakes and compounding mistakes that went into Chernobyl

44:24.200 --> 44:30.720
 was far, far, far greater, but the consequence of COVID outweighs that, the consequences

44:30.720 --> 44:34.000
 of Chernobyl to a tremendous degree.

44:34.000 --> 44:43.600
 And I think that particularly authoritarian governments are unbelievably reluctant to

44:43.600 --> 44:49.160
 admit to any fallibility whatsoever, and there's a long, long history of that across dozens

44:49.160 --> 44:56.080
 and dozens of authoritarian governments, and to be transparent, again, this is in the hypothetical

44:56.080 --> 45:00.640
 world in which this was a leak, which again, I don't have, I don't personally have enough

45:00.640 --> 45:04.480
 sophistication to have an opinion on the, on the likelihood, but in the hypothetical

45:04.480 --> 45:14.360
 world in which it was a leak, the global reaction and the amount of global animus and the amount

45:14.360 --> 45:22.440
 of, you know, the decline in global respect that would happen toward China, because every

45:22.440 --> 45:28.480
 country suffered massively from this, unbelievable damages in terms of human lives and economic

45:28.480 --> 45:35.200
 activity disrupted, the world would in some way present China with that bill.

45:35.200 --> 45:41.160
 And when you take on top of that, the natural disinclination for any authoritarian government

45:41.160 --> 45:46.960
 to admit any fallibility and tolerate the possibility of any fallibility whatsoever,

45:46.960 --> 45:51.520
 and you look at the relative opacity, even though they let a world health organization

45:51.520 --> 45:56.720
 group in, you know, a couple of months ago to run around, they didn't give that who group

45:56.720 --> 46:01.600
 anywhere near the level of access that would be necessary to definitively say X happened

46:01.600 --> 46:02.600
 versus Y.

46:02.600 --> 46:08.400
 The level of opacity that surrounds those opening weeks and months of COVID in China,

46:08.400 --> 46:10.440
 we just don't know.

46:10.440 --> 46:17.840
 If you were to kind of look back at 2020 and maybe broadening it out to future pandemics

46:17.840 --> 46:24.760
 that could be much more dangerous, what kind of response, how do we fail in a response

46:24.760 --> 46:27.560
 and how could we do better?

46:27.560 --> 46:35.560
 So the gain of function research is discussing the question of we should not be creating

46:35.560 --> 46:41.320
 viruses that are both exceptionally contagious and exceptionally deadly to humans.

46:41.320 --> 46:48.200
 But if it does happen, perhaps the natural evolution, natural mutation, is there interesting

46:48.200 --> 46:56.040
 technological responses on the testing side, on the vaccine development side, on the collection

46:56.040 --> 47:02.680
 of data or on the basic sort of policy response side or the sociological, the psychological

47:02.680 --> 47:03.680
 side?

47:03.680 --> 47:05.680
 Yeah, there's all kinds of things.

47:05.680 --> 47:11.280
 And most of what I've thought about and written about and again discussed in that long bit

47:11.280 --> 47:14.920
 with Sam is dual use.

47:14.920 --> 47:20.040
 So most of the countermeasures that I've been thinking about and advocating for would be

47:20.040 --> 47:26.840
 every bit as effective against zoonotic disease and natural pandemic of some sort as an artificial

47:26.840 --> 47:27.840
 one.

47:27.840 --> 47:32.900
 The risk of an artificial one, even the near term risk of an artificial one, ups the urgency

47:32.900 --> 47:37.540
 around these measures immensely, but most of them would be broadly applicable.

47:37.540 --> 47:43.440
 And so I think the first thing that we really want to do on a global scale is have a far,

47:43.440 --> 47:49.720
 far, far more robust and globally transparent system of detection.

47:49.720 --> 47:52.080
 And that can happen on a number of levels.

47:52.080 --> 47:58.200
 The most obvious one is just in the blood of people who come into clinics exhibiting

47:58.200 --> 48:00.280
 signs of illness.

48:00.280 --> 48:07.600
 And we are certainly at a point now where at with relatively minimal investment, we

48:07.600 --> 48:12.880
 could develop in clinic diagnostics that would be unbelievably effective at pinpointing what's

48:12.880 --> 48:19.080
 going on in almost any disease when somebody walks into a doctor's office or a clinic.

48:19.080 --> 48:24.920
 And better than that, this is a little bit further off, but it wouldn't cost tens of

48:24.920 --> 48:28.880
 billions in research dollars, it would be a relatively modest and affordable budget

48:28.880 --> 48:36.000
 in relation to the threat at home diagnostics that can really, really pinpoint, okay, particularly

48:36.000 --> 48:41.480
 with respiratory infections, because that is generally almost universally the mechanism

48:41.480 --> 48:44.680
 of transmission for any serious pandemic.

48:44.680 --> 48:49.760
 So somebody has a respiratory infection, is it one of the, you know, significantly large

48:49.760 --> 48:55.440
 handful of rhinoviruses, coronaviruses, and other things that cause common cold?

48:55.440 --> 48:56.440
 Or is it influenza?

48:56.440 --> 49:00.000
 If it's influenza, is it influenza A versus B?

49:00.000 --> 49:06.640
 Or is it, you know, a small handful of other more exotic but nonetheless sort of common

49:06.640 --> 49:09.360
 respiratory infections that are out there?

49:09.360 --> 49:12.960
 Having a diagnostic panel to pinpoint all of that stuff, that's something that's well

49:12.960 --> 49:14.060
 within our capabilities.

49:14.060 --> 49:19.060
 That's much less a lift than creating mRNA vaccines, which obviously we proved capable

49:19.060 --> 49:21.200
 of when we put our minds to it.

49:21.200 --> 49:24.360
 So do that on a global basis.

49:24.360 --> 49:28.760
 And I don't think that's irrational because the best prototype for this that I'm aware

49:28.760 --> 49:34.640
 of isn't currently rolling out in Atherton, California, or Fairfield County, Connecticut,

49:34.640 --> 49:36.300
 or some other wealthy place.

49:36.300 --> 49:40.140
 The best prototype that I'm aware of this is rolling out right now in Nigeria.

49:40.140 --> 49:45.060
 And it's a project that came out of the Broad Institute, which is, as I'm sure you know,

49:45.060 --> 49:49.580
 but some listeners may not, is kind of like an academic joint venture between Harvard

49:49.580 --> 49:50.920
 and MIT.

49:50.920 --> 49:53.360
 The program is called Sentinel.

49:53.360 --> 49:59.280
 And their objective is, and their plan is a very well conceived plan, a methodical plan,

49:59.280 --> 50:05.480
 is to do just that in areas of Nigeria that are particularly vulnerable to zoonotic diseases

50:05.480 --> 50:08.040
 making the jump from animals to humans.

50:08.040 --> 50:12.000
 But also there's just an unbelievable public health benefit from that.

50:12.000 --> 50:17.020
 And it's sort of a three tier system where clinicians in the field could very rapidly

50:17.020 --> 50:22.220
 determine do you have one of the infections of acute interest here, either because it's

50:22.220 --> 50:26.800
 very common in this region, so we want to diagnose as many things as we can at the front

50:26.800 --> 50:31.360
 line, or because it's uncommon but unbelievably threatening like Ebola.

50:31.360 --> 50:35.500
 So front line worker can make that determination very, very rapidly.

50:35.500 --> 50:41.020
 If it comes up as a we don't know, they bump it up to a level that's more like at a fully

50:41.020 --> 50:44.080
 configured doctor's office or local hospital.

50:44.080 --> 50:47.900
 And if it's still at a we don't know, it gets bumped up to a national level.

50:47.900 --> 50:51.240
 And it gets bumped very, very rapidly.

50:51.240 --> 50:57.340
 So if this can be done in Nigeria, and it seems that it can be, there shouldn't be any

50:57.340 --> 51:00.880
 inhibition for it to happen in most other places.

51:00.880 --> 51:03.300
 And it should be affordable from a budgetary standpoint.

51:03.300 --> 51:07.800
 And based on Sentinel's budget and adjusting things for things like very different cost

51:07.800 --> 51:13.120
 of living, larger population, et cetera, I did a back of the envelope calculation that

51:13.120 --> 51:17.200
 doing something like Sentinel in the US would be in the low billions of dollars.

51:17.200 --> 51:22.120
 And wealthy countries, middle income countries can't afford such a thing.

51:22.120 --> 51:25.680
 Lower income countries should certainly be helped with that.

51:25.680 --> 51:27.760
 But start with that level of detection.

51:27.760 --> 51:33.720
 And then layer on top of that other interesting things like monitoring search engine traffic,

51:33.720 --> 51:39.660
 search engine queries for evidence that strange clusters of symptoms are starting to rise

51:39.660 --> 51:40.660
 in different places.

51:40.660 --> 51:43.520
 There's been a lot of work done with that.

51:43.520 --> 51:47.720
 Most of it kind of academic and experimental, but some of it has been powerful enough to

51:47.720 --> 51:51.200
 suggest that this could be a very powerful early warning system.

51:51.200 --> 51:56.760
 There's a guy named Bill Lampos at University College London who basically did a very rigorous

51:56.760 --> 52:05.000
 analysis that showed that symptom searches reliably predicted COVID outbreaks in the

52:05.000 --> 52:10.160
 early days of the pandemic in given countries by as much as 16 days before the evidence

52:10.160 --> 52:12.320
 started to accrue at a public health level.

52:12.320 --> 52:18.960
 16 days of forewarning can be monumentally important in the early days of an outbreak.

52:18.960 --> 52:26.640
 And this is a very, very talented, but nonetheless very resource constrained academic project.

52:26.640 --> 52:31.000
 Even if that was something that was done with a NORAD like budget.

52:31.000 --> 52:35.520
 So starting with detection, that's something we could do radically, radically better.

52:35.520 --> 52:39.800
 So aggregating multiple data sources in order to create something, I mean, this is really

52:39.800 --> 52:44.840
 exciting to me, the possibility that I've heard inklings of creating almost like a weather

52:44.840 --> 52:54.140
 map of pathogens, like basically aggregating all of these data sources, scaling many orders

52:54.140 --> 53:00.000
 of magnitude up at home testing and all kinds of testing that doesn't just try to test for

53:00.000 --> 53:06.320
 the particular pathogen of worry now, but everything like a full spectrum of things

53:06.320 --> 53:09.040
 that could be dangerous to the human body.

53:09.040 --> 53:14.900
 And thereby be able to create these maps like that are dynamically updated on an hourly

53:14.900 --> 53:19.520
 basis of how viruses travel throughout the world.

53:19.520 --> 53:23.400
 And so you can respond, like you can then integrate just like you do when you check

53:23.400 --> 53:28.880
 your weather map and it's raining or not, of course, not perfect, but it's very good

53:28.880 --> 53:34.320
 predictor whether it's going to rain or not and use that to then make decisions about

53:34.320 --> 53:38.840
 your own life, ultimately give the power information to individuals to respond.

53:38.840 --> 53:44.160
 And if it's a super dangerous, like if it's acid rain versus regular rain, you might want

53:44.160 --> 53:47.480
 to really stay inside as opposed to risking it.

53:47.480 --> 53:54.400
 And that, just like you said, if I think it's not very expensive relative to all the things

53:54.400 --> 54:00.440
 that we do in this world, but it does require bold leadership.

54:00.440 --> 54:05.420
 And there's another dark thing, which really has bothered me about 2020, which it requires

54:05.420 --> 54:13.200
 is it requires trust in institutions to carry out these kinds of programs and requires trust

54:13.200 --> 54:20.480
 in science and engineers and sort of centralized organizations that would operate at scale

54:20.480 --> 54:21.480
 here.

54:21.480 --> 54:27.800
 And much of that trust has been, at least in the United States, diminished.

54:27.800 --> 54:33.220
 It feels like I'm not exactly sure where to place the blame, but I do place quite a bit

54:33.220 --> 54:40.160
 of the blame into the scientific community and again, my fellow colleagues in speaking

54:40.160 --> 54:46.420
 down to people at times, speaking from authority, it sounded like it dismissed the basic human

54:46.420 --> 54:52.560
 experience or the basic common humanity of people in a way to like, it almost sounded

54:52.560 --> 54:58.200
 like there's an agenda that's hidden behind the words the scientists spoke.

54:58.200 --> 55:03.200
 Like they're trying to, in a self preserving way, control the population or something like

55:03.200 --> 55:04.200
 that.

55:04.200 --> 55:07.400
 I don't think any of that is true from the majority of the scientific community, but

55:07.400 --> 55:08.820
 it sounded that way.

55:08.820 --> 55:16.040
 And so the trust began to diminish and I'm not sure how to fix that except to be more

55:16.040 --> 55:22.840
 authentic, be more real, acknowledge the uncertainties under which we operate, acknowledge the mistakes

55:22.840 --> 55:26.520
 that scientists make, that institutions make.

55:26.520 --> 55:32.000
 The leak from the lab is a perfect example where we have imperfect systems that make

55:32.000 --> 55:34.060
 all the progress we see in the world.

55:34.060 --> 55:39.480
 And that being honest about that imperfection, I think is essential for forming trust.

55:39.480 --> 55:45.280
 But I don't know what to make of it has been deeply disappointing because I do think just

55:45.280 --> 55:53.240
 like you mentioned, the solutions require people to trust the institutions with their

55:53.240 --> 55:54.240
 data.

55:54.240 --> 55:55.240
 Yeah.

55:55.240 --> 55:59.920
 And I think part of the problem is it seems to me as an outsider that there was a bizarre

55:59.920 --> 56:08.560
 unwillingness on the part of the CDC and other institutions to admit to, to frame and to

56:08.560 --> 56:11.300
 contextualize uncertainty.

56:11.300 --> 56:16.800
 Maybe they had a patronizing idea that these people need to be told and when they're told,

56:16.800 --> 56:21.660
 they need to be told with authority and a level of definitiveness and certain certitude

56:21.660 --> 56:23.680
 that doesn't actually exist.

56:23.680 --> 56:29.400
 And so when they whipsaw on recommendations like what you should do about masks, when

56:29.400 --> 56:35.560
 the CDC is kind of at the very beginning of the pandemic saying, masks don't do anything.

56:35.560 --> 56:36.820
 Don't wear them.

56:36.820 --> 56:41.700
 When the real driver for that was we don't want these clowns going out and depleting

56:41.700 --> 56:49.240
 Amazon of masks because they may be needed in medical settings and we just don't know

56:49.240 --> 56:50.240
 yet.

56:50.240 --> 56:54.360
 I think a message that actually respected people and said, this is why we're asking

56:54.360 --> 57:00.080
 you not to do masks yet and there's more to be seen would be less whipsawing and would

57:00.080 --> 57:04.580
 bring people like they feel more like they're part of the conversation and they're being

57:04.580 --> 57:09.480
 treated like adults than saying one day definitively masks suck.

57:09.480 --> 57:13.120
 And then X days later saying, nope, they haven't wear masks.

57:13.120 --> 57:16.960
 And so I think framing things in terms of the probabilities, which most people are easy

57:16.960 --> 57:17.960
 to parse.

57:17.960 --> 57:23.520
 I mean, a more recent example, which I just thought was batty was suspending the Johnson

57:23.520 --> 57:30.660
 and Johnson vaccine for a very low single digit number of days in the United States

57:30.660 --> 57:38.240
 based on the fact that I believe there had been seven ish clotting incidents in roughly

57:38.240 --> 57:43.680
 seven million people who had had the vaccine administered, I believe one of which resulted

57:43.680 --> 57:45.560
 in a fatality.

57:45.560 --> 57:50.100
 And there was definitely suggestive data that indicated that there was a relationship.

57:50.100 --> 57:53.800
 This wasn't just coincidental because I think all of the clotting incidents happened in

57:53.800 --> 57:58.400
 women as opposed to men and kind of clustered in a certain age group.

57:58.400 --> 58:05.420
 But does that call for shutting off the vaccine or does it call for leveling with the American

58:05.420 --> 58:10.480
 public and saying we've had one fatality out of seven million?

58:10.480 --> 58:18.640
 This is, let's just assume substantially less than the likelihood of getting struck by lightning.

58:18.640 --> 58:22.940
 Based on that information, and we're going to keep you posted because you can trust us

58:22.940 --> 58:27.120
 to keep you posted, based on that information, please decide whether you're comfortable with

58:27.120 --> 58:29.340
 a Johnson and Johnson vaccine.

58:29.340 --> 58:33.160
 That would have been one response and I think people would have been able to parse the simple

58:33.160 --> 58:35.200
 bits of data and make their own judgment.

58:35.200 --> 58:41.680
 By turning it off, all of a sudden there's this dramatic signal to people who don't read

58:41.680 --> 58:45.880
 all 900 words in the New York Times piece that explains why it's being turned off but

58:45.880 --> 58:48.680
 just see the headline, which is a majority of people.

58:48.680 --> 58:54.480
 There's a sudden like, oh my God, yikes, vaccine being shut off.

58:54.480 --> 58:58.120
 And then all the people who sat on the fence or are sitting on the fence about whether

58:58.120 --> 59:03.360
 or not they trust vaccines, that is going to push an incalculable number of people.

59:03.360 --> 59:06.800
 That's going to be the last straw for we don't know how many hundreds of thousands or more

59:06.800 --> 59:11.520
 likely millions of people to say, okay, tipping point here, I don't trust these vaccines.

59:11.520 --> 59:16.940
 By pausing that for whatever it was, 10 or 12 days, and then flipping the switch as everybody

59:16.940 --> 59:21.200
 who knew much about the situation knew was inevitable.

59:21.200 --> 59:28.080
 By flipping the on switch 12 days later, you're conveying certitude J and J bad to certitude

59:28.080 --> 59:33.040
 J and J good in a period of just a few days and people just feel whipsawed and they're

59:33.040 --> 59:34.040
 not part of the analysis.

59:34.040 --> 59:36.600
 But it's not just the whipsawing.

59:36.600 --> 59:39.960
 And I think about this quite a bit, I don't think I have good answers.

59:39.960 --> 59:43.400
 It's something about the way the communication actually happens.

59:43.400 --> 59:49.820
 Just I don't know what it is about Anthony Fauci, for example, but I don't trust him.

59:49.820 --> 59:55.840
 And I think that has to do, I mean, he has an incredible background.

59:55.840 --> 59:59.100
 I'm sure he's a brilliant scientist and researcher.

59:59.100 --> 1:00:06.360
 I'm sure he's also a great, like inside the room, policymaker and deliberator and so on.

1:00:06.360 --> 1:00:14.280
 But what makes a great leader is something about that thing that you can't quite describe,

1:00:14.280 --> 1:00:22.560
 but being a communicator that you know you can trust, that there's an authenticity that's

1:00:22.560 --> 1:00:23.560
 required.

1:00:23.560 --> 1:00:29.200
 And I'm not sure, maybe I'm being a bit too judgmental, but I'm a huge fan of a lot of

1:00:29.200 --> 1:00:31.080
 great leaders throughout history.

1:00:31.080 --> 1:00:36.960
 They've communicated exceptionally well in the way that Fauci does not.

1:00:36.960 --> 1:00:40.600
 And I think about that, I think about what does affect the science communication.

1:00:40.600 --> 1:00:47.280
 So great leaders throughout history did not necessarily need to be great science communicators.

1:00:47.280 --> 1:00:49.680
 Their leadership was in other domains.

1:00:49.680 --> 1:00:53.840
 But when you're fighting the virus, you also have to be a great science communicator.

1:00:53.840 --> 1:00:58.120
 You have to be able to communicate uncertainties, you have to be able to communicate something

1:00:58.120 --> 1:01:03.720
 like a vaccine that you're allowing inside your body into the messiness, into the complexity

1:01:03.720 --> 1:01:08.160
 of the biology system, that if we're being honest, it's so complex we'll never be able

1:01:08.160 --> 1:01:10.920
 to really understand.

1:01:10.920 --> 1:01:16.880
 We can only desperately hope that science can give us sort of a high likelihood that

1:01:16.880 --> 1:01:22.600
 there's no short term negative consequences and that kind of intuition about long term

1:01:22.600 --> 1:01:29.000
 negative consequences and doing our best in this battle against trillions of things that

1:01:29.000 --> 1:01:32.600
 are trying to kill us.

1:01:32.600 --> 1:01:36.840
 Being an effective communicator in that space is very difficult, but I think about what

1:01:36.840 --> 1:01:41.960
 it takes because I think there should be more science communicators that are effective at

1:01:41.960 --> 1:01:43.720
 that kind of thing.

1:01:43.720 --> 1:01:49.920
 Let me ask you about something that's sort of more in the AI space that I think about

1:01:49.920 --> 1:01:58.480
 that kind of goes along this thread that you've spoken about, about democratizing the technology

1:01:58.480 --> 1:02:05.760
 that could destroy human civilization, is from amazing work from DeepMind AlphaFold2,

1:02:05.760 --> 1:02:12.400
 which achieved incredible performance on the protein folding problem, single protein folding

1:02:12.400 --> 1:02:13.400
 problem.

1:02:13.400 --> 1:02:22.000
 When you think about the use of AI in the SYN biospace, I think the gain of function

1:02:22.000 --> 1:02:28.440
 in the virus space research that you referred to, I think is natural mutations and sort

1:02:28.440 --> 1:02:35.560
 of aggressively mutating the virus until you get one that like that has this both contagious

1:02:35.560 --> 1:02:45.960
 and deadly, but what about then using AI to, through simulation, be able to compute deadly

1:02:45.960 --> 1:02:49.540
 viruses or any kind of biological systems?

1:02:49.540 --> 1:02:53.080
 Is this something you're worried about, or again, is this something you're more excited

1:02:53.080 --> 1:02:54.080
 about?

1:02:54.080 --> 1:02:58.920
 I think computational biology is unbelievably exciting and promising field, and I think

1:02:58.920 --> 1:03:05.960
 when you're doing things in silico as opposed to in vivo, the dangers plummet.

1:03:05.960 --> 1:03:10.160
 You don't have a critter that can leak from a leaky lab.

1:03:10.160 --> 1:03:15.320
 So I don't see any problem with that, except I do worry about the data security dimension

1:03:15.320 --> 1:03:21.200
 of it, because if you were doing really, really interesting in silico gain of function research

1:03:21.200 --> 1:03:27.120
 and you hit upon through a level of sophistication, we don't currently have, but synthetic biology

1:03:27.120 --> 1:03:32.400
 is an exponential technology, so capabilities that are utterly out of reach today will be

1:03:32.400 --> 1:03:35.740
 attainable in five or six years.

1:03:35.740 --> 1:03:44.160
 I think if you conjured up worst case genomes of viruses that don't exist in vivo anywhere,

1:03:44.160 --> 1:03:48.840
 they're just in the computer space, but like, hey guys, this is the genetic sequence that

1:03:48.840 --> 1:03:56.120
 would end the world, let's say, then you have to worry about the utter hackability of every

1:03:56.120 --> 1:03:58.600
 computer network we can imagine.

1:03:58.600 --> 1:04:04.780
 Data leaks from the least likely places on the grandest possible scales have happened

1:04:04.780 --> 1:04:09.000
 and continue to happen and will probably always continue to happen, and so that would be the

1:04:09.000 --> 1:04:11.800
 danger of doing the work in silico.

1:04:11.800 --> 1:04:16.240
 If you end up with a list of like, well, these are things we never want to see, that list

1:04:16.240 --> 1:04:20.640
 leaks, and after the passage of some time, certainly couldn't be done today, but after

1:04:20.640 --> 1:04:26.280
 the passage of some time, lots and lots of people in academic labs going all the way

1:04:26.280 --> 1:04:33.600
 down to the high school level are in a position to make it overly simplistic, hit print on

1:04:33.600 --> 1:04:37.720
 a genome and have the virus bearing that genome pop out on the other end and you've got something

1:04:37.720 --> 1:04:42.880
 to worry about, but in general, computational biology I think is incredibly important, particularly

1:04:42.880 --> 1:04:47.200
 because the crushing majority of work that people are doing with the protein folding

1:04:47.200 --> 1:04:52.560
 problem and other things are about creating therapeutics, about creating things that will

1:04:52.560 --> 1:04:58.680
 help us live better, live longer, thrive, be more well, and so forth, and the protein

1:04:58.680 --> 1:05:04.520
 folding problem is a monstrous computational challenge that we seem to make just the most

1:05:04.520 --> 1:05:09.320
 glacial project on, I'm sorry, progress on for years and years, but I think there's a

1:05:09.320 --> 1:05:17.560
 biannual competition I think for which people tackle the protein folding problem, and Deep

1:05:17.560 --> 1:05:25.240
 Mind's entrant both two years ago, like in 2018 and 2020, ruled the field, and so protein

1:05:25.240 --> 1:05:29.520
 folding is an unbelievably important thing if you want to start thinking about therapeutics

1:05:29.520 --> 1:05:34.600
 because it's the folding of the protein that tells us where the channels and the receptors

1:05:34.600 --> 1:05:39.960
 and everything else are on that protein, and it's from that precise model, if we can get

1:05:39.960 --> 1:05:46.840
 to a precise model, that you can start barraging it again in silicone with thousands, tens

1:05:46.840 --> 1:05:52.520
 of thousands, millions of potential therapeutics and see what resolves the problems, the shortcomings

1:05:52.520 --> 1:05:59.640
 that a misshapen protein, for instance, somebody with cystic fibrosis, how might we treat

1:05:59.640 --> 1:06:00.640
 that?

1:06:00.640 --> 1:06:01.640
 So I see nothing but good in that.

1:06:01.640 --> 1:06:06.240
 Well, let me ask you about fear and hope in this world.

1:06:06.240 --> 1:06:15.520
 I tend to believe that in terms of competence and malevolence, that people who are, maybe

1:06:15.520 --> 1:06:20.240
 it's in my interactions, I tend to see that, first of all, I believe that most people are

1:06:20.240 --> 1:06:27.640
 good and want to do good and are just better at doing good and more inclined to do good

1:06:27.640 --> 1:06:35.600
 on this world, and more than that, people who are malevolent are usually incompetent

1:06:35.600 --> 1:06:38.080
 at building technology.

1:06:38.080 --> 1:06:43.080
 So I've seen this in my life, that people who are exceptionally good at stuff, no matter

1:06:43.080 --> 1:06:50.500
 what the stuff is, tend to, maybe they discover joy in life in a way that gives them fulfillment

1:06:50.500 --> 1:06:55.100
 and thereby does not result in them wanting to destroy the world.

1:06:55.100 --> 1:07:00.000
 So like the better you are at stuff, whether that's building nuclear weapons or plumbing,

1:07:00.000 --> 1:07:03.800
 doesn't matter, the both, the less likely you are to destroy the world.

1:07:03.800 --> 1:07:14.500
 So in that sense, with many technologies, AI especially, I always think that the malevolent

1:07:14.500 --> 1:07:18.560
 would be far outnumbered by the ultra competent.

1:07:18.560 --> 1:07:27.080
 And in that sense, the defenses will always be stronger than the offense in terms of the

1:07:27.080 --> 1:07:28.640
 people trying to destroy the world.

1:07:28.640 --> 1:07:33.940
 Now there's a few spaces where that might not be the case, and that's an interesting

1:07:33.940 --> 1:07:40.240
 conversation where this one person who's not very competent can destroy the whole world.

1:07:40.240 --> 1:07:47.240
 Perhaps Symbio is one such space because of the exponential effects of the technology.

1:07:47.240 --> 1:07:54.360
 I tend to believe AI is not one of the such spaces, but do you share this kind of view

1:07:54.360 --> 1:07:58.720
 that the ultra competent are usually also the good?

1:07:58.720 --> 1:07:59.720
 Yeah, absolutely.

1:07:59.720 --> 1:08:04.600
 I absolutely share that and that gives me a great deal of optimism that we will be able

1:08:04.600 --> 1:08:10.300
 to short circuit the threat that malevolence and Symbio could pose to us.

1:08:10.300 --> 1:08:14.760
 But we need to start creating those defensive systems or defensive layers, one of which

1:08:14.760 --> 1:08:18.880
 we talked about far, far, far better surveillance in order to prevail.

1:08:18.880 --> 1:08:26.840
 So the good guys will almost inevitably outsmart and definitely outnumber the bad guys in most

1:08:26.840 --> 1:08:29.640
 sort of smack downs that we can imagine.

1:08:29.640 --> 1:08:34.800
 But the good guys aren't going to be able to exert their advantages unless they have

1:08:34.800 --> 1:08:40.740
 the imagination necessary to think about what the worst possible thing can be done by somebody

1:08:40.740 --> 1:08:45.080
 whose own psychology is completely alien to their own.

1:08:45.080 --> 1:08:47.560
 So that's a tricky, tricky thing to solve for.

1:08:47.560 --> 1:08:54.420
 Now in terms of whether the asymmetric power that a bad guy might have in the face of the

1:08:54.420 --> 1:09:00.080
 overwhelming numerical advantage and competence advantage that the good guys have, unfortunately,

1:09:00.080 --> 1:09:04.040
 I look at something like mass shootings as an example.

1:09:04.040 --> 1:09:08.880
 I'm sure the guy who was responsible for the Vegas shooting or the Orlando shooting or

1:09:08.880 --> 1:09:14.360
 any other shooting that we can imagine didn't know a whole lot about ballistics.

1:09:14.360 --> 1:09:20.200
 And the number of good guy citizens in the United States with guns compared to bad guy

1:09:20.200 --> 1:09:25.780
 citizens I'm sure is a crushingly overwhelmingly high ratio in favor of the good guys.

1:09:25.780 --> 1:09:30.360
 But that doesn't make it possible for us to stop mass shootings.

1:09:30.360 --> 1:09:38.280
 An example is Fort Hood, 45,000 trained soldiers on that base, yet there have been two mass

1:09:38.280 --> 1:09:40.180
 shootings there.

1:09:40.180 --> 1:09:48.080
 And so there is an asymmetry when you have powerful and lethal technology that gets so

1:09:48.080 --> 1:09:54.880
 democratized and so proliferated in tools that are very, very easy to use even by a

1:09:54.880 --> 1:09:56.240
 knucklehead.

1:09:56.240 --> 1:10:00.780
 When those tools get really easy to use by a knucklehead and they're really widespread,

1:10:00.780 --> 1:10:06.200
 it becomes very, very hard to defend against all instances of usage.

1:10:06.200 --> 1:10:11.080
 Now the good news, quote unquote, about mass shootings, if there is any, and there is some,

1:10:11.080 --> 1:10:17.880
 is even the most brutal and carefully planning and well armed mass shooter can only take

1:10:17.880 --> 1:10:20.400
 so many victims.

1:10:20.400 --> 1:10:26.040
 And the same is true, there's been four instances that I'm aware of, of commercial pilots committing

1:10:26.040 --> 1:10:29.540
 suicide by downing their planes and taking all their passengers with them.

1:10:29.540 --> 1:10:33.880
 These weren't Boeing engineers, but like an army of Boeing engineers ultimately were not

1:10:33.880 --> 1:10:36.120
 capable of preventing that.

1:10:36.120 --> 1:10:40.720
 But even in their case, and I'm actually not counting 9 11 and that, 9 11 is a different

1:10:40.720 --> 1:10:45.040
 category in my mind, these are just personally suicidal pilots.

1:10:45.040 --> 1:10:50.300
 In those cases, they only have a plain load of people that they're able to take with them.

1:10:50.300 --> 1:10:57.800
 If we imagine a highly plausible and imaginable future in which some bio tools that are amoral,

1:10:57.800 --> 1:11:04.480
 that could be used for good or for ill, start embodying unbelievable sophistication and

1:11:04.480 --> 1:11:12.200
 genius in the tool, in the easier and easier and easier to make tool, all those thousands,

1:11:12.200 --> 1:11:16.780
 tens of thousands, hundreds of thousands of scientist years start getting embodied in

1:11:16.780 --> 1:11:21.960
 something that may be as simple as hitting a print button.

1:11:21.960 --> 1:11:29.440
 Then that good guy technology can be hijacked by a bad person and used in a very asymmetric

1:11:29.440 --> 1:11:30.440
 way.

1:11:30.440 --> 1:11:35.560
 What happens though, as you go to the high school student from the current very specific

1:11:35.560 --> 1:11:41.300
 set of labs that are able to do it, as it becomes more and more democratized, as it

1:11:41.300 --> 1:11:48.920
 becomes easier and easier to do this kind of large scale damage with an engineered virus,

1:11:48.920 --> 1:11:53.280
 the more and more there will be engineering of defenses against these systems is some

1:11:53.280 --> 1:11:56.840
 of the things we talked about in terms of testing, in terms of collection of data, but

1:11:56.840 --> 1:12:05.040
 also in terms of at scale contact tracing or also engineering of vaccines in a matter

1:12:05.040 --> 1:12:09.440
 of days, maybe hours, maybe minutes.

1:12:09.440 --> 1:12:15.160
 I feel like the defenses, that's what human species seems to do, is we keep hitting the

1:12:15.160 --> 1:12:22.040
 snooze button until there's a storm on the horizon heading towards us.

1:12:22.040 --> 1:12:29.080
 Then we start to quickly build up the defenses or the response that's proportional to the

1:12:29.080 --> 1:12:31.640
 scale of the storm.

1:12:31.640 --> 1:12:38.840
 Of course, again, certain kinds of exponential threats require us to build up the defenses

1:12:38.840 --> 1:12:42.120
 way earlier than we usually do, and that's I guess the question.

1:12:42.120 --> 1:12:48.900
 But I ultimately am hopeful that the natural process of hitting the snooze button until

1:12:48.900 --> 1:12:53.240
 the deadline is right in front of us will work out for quite a long time for us humans.

1:12:53.240 --> 1:12:54.740
 And I fully agree.

1:12:54.740 --> 1:12:59.320
 That's why I'm fundamentally, I may not sound like it thus far, but I'm fundamentally very,

1:12:59.320 --> 1:13:04.480
 very optimistic about our ability to short circuit this threat because there is, again,

1:13:04.480 --> 1:13:11.280
 I'll stress the technological feasibility and the profound affordability of a relatively

1:13:11.280 --> 1:13:17.360
 simple set of steps that we can take to preclude it, but we do have to take those steps.

1:13:17.360 --> 1:13:22.840
 What I'm hoping to do and trying to do is inject a notion of what those steps are into

1:13:22.840 --> 1:13:27.360
 the public conversation and do my small part to up the odds that that actually ends up

1:13:27.360 --> 1:13:30.320
 happening.

1:13:30.320 --> 1:13:37.140
 The danger with this one is it is exponential, and I think that our minds are fundamentally

1:13:37.140 --> 1:13:40.280
 struggle to understand exponential math.

1:13:40.280 --> 1:13:42.440
 It's just not something we're wired for.

1:13:42.440 --> 1:13:46.760
 Our ancestors didn't confront exponential processes when they were growing up on the

1:13:46.760 --> 1:13:52.120
 savanna, so it's not something that's intuitive to us and our intuitions are reliably defeated

1:13:52.120 --> 1:13:54.000
 when exponential processes come along.

1:13:54.000 --> 1:13:56.020
 So that's issue number one.

1:13:56.020 --> 1:14:02.840
 And issue number two with something like this is it kind of only takes one.

1:14:02.840 --> 1:14:08.120
 That ball only has to go into the net once and we're doomed, which is not the case with

1:14:08.120 --> 1:14:09.120
 mass shooters.

1:14:09.120 --> 1:14:12.280
 It's not the case with commercial pilots run amok.

1:14:12.280 --> 1:14:17.560
 It's not the case with really any threat that I can think of with the exception of nuclear

1:14:17.560 --> 1:14:24.720
 war that has the one bad outcome and game over.

1:14:24.720 --> 1:14:31.040
 And that means that we need to be unbelievably serious about these defenses and we need to

1:14:31.040 --> 1:14:36.680
 do things that might on the surface seem like a tremendous overreaction so that we can be

1:14:36.680 --> 1:14:39.640
 prepared to nip anything that comes along in the bud.

1:14:39.640 --> 1:14:43.560
 I like you believe that's eminently doable.

1:14:43.560 --> 1:14:47.880
 I like you believe that the good guys outnumber the bad guys in this particular one to a degree

1:14:47.880 --> 1:14:49.760
 that probably has no precedent in history.

1:14:49.760 --> 1:14:55.960
 I mean, even the worst, worst people I'm sure in ISIS, even Osama bin Laden, even any bad

1:14:55.960 --> 1:15:01.840
 guy you could imagine in history would be revolted by the idea of exterminating all

1:15:01.840 --> 1:15:02.840
 of humanity.

1:15:02.840 --> 1:15:06.160
 I mean, that's a low bar.

1:15:06.160 --> 1:15:11.140
 And so the good guys completely outnumber the bad guys when it comes to this.

1:15:11.140 --> 1:15:18.560
 But the asymmetry and the fact that one catastrophic error could lead to unbelievably consequential

1:15:18.560 --> 1:15:20.000
 things is what worries me here.

1:15:20.000 --> 1:15:21.880
 But I too am very optimistic.

1:15:21.880 --> 1:15:27.240
 The thing that I sometimes worry about is the fact that we haven't seen overwhelming

1:15:27.240 --> 1:15:33.840
 evidence of alien civilizations out there makes me think, well, there's a lot of explanations,

1:15:33.840 --> 1:15:40.120
 but one of them that worries me is that whenever they get smart, they just destroy themselves.

1:15:40.120 --> 1:15:41.120
 Oh yeah.

1:15:41.120 --> 1:15:46.880
 I mean, that was the most fascinating, is the most fascinating and chilling number or

1:15:46.880 --> 1:15:53.080
 variable in the Drake equation is L. At the end of it, you look out and you see, you know,

1:15:53.080 --> 1:15:56.360
 one to 400 billion stars in the Milky Way galaxy.

1:15:56.360 --> 1:16:01.180
 And we now know because of Kepler that an astonishingly high percentage of them probably

1:16:01.180 --> 1:16:03.540
 have habitable planets.

1:16:03.540 --> 1:16:07.480
 And you know, so all the things that were unknowns when the Drake equation was originally

1:16:07.480 --> 1:16:10.620
 written, like, you know, how many stars have planets?

1:16:10.620 --> 1:16:15.080
 Actually back then in the 1960s when the Drake equation came along, the consensus amongst

1:16:15.080 --> 1:16:19.520
 astronomers was that it would be a small minority of solar systems that had planets or stars.

1:16:19.520 --> 1:16:22.040
 But now we know it's substantially all of them.

1:16:22.040 --> 1:16:25.960
 How many of those stars have planets in the habitable zone?

1:16:25.960 --> 1:16:29.480
 It's kind of looking like 20%, like, oh my God.

1:16:29.480 --> 1:16:36.440
 And so L, which is how long does a civilization, once it reaches technological competence,

1:16:36.440 --> 1:16:37.960
 continues to last?

1:16:37.960 --> 1:16:40.260
 That's the doozy.

1:16:40.260 --> 1:16:42.100
 And you're right.

1:16:42.100 --> 1:16:47.720
 It's all too plausible to think that when a civilization reaches a level of sophistication,

1:16:47.720 --> 1:16:50.600
 that's probably just a decade or three in our future.

1:16:50.600 --> 1:16:57.440
 The odds of it self destructing just start mounting astronomically, no pun intended.

1:16:57.440 --> 1:17:02.160
 My hope is that actually there is a lot of alien civilizations out there and what they

1:17:02.160 --> 1:17:09.560
 figure out in order to avoid the self destruction, they need to turn off the thing that was useful,

1:17:09.560 --> 1:17:13.960
 that used to be a feature, now became a bug, which is the desire to colonize, to conquer

1:17:13.960 --> 1:17:14.960
 more land.

1:17:14.960 --> 1:17:19.160
 So they, like, there's probably ultra intelligent alien civilizations out there, they're just

1:17:19.160 --> 1:17:25.040
 like chilling, like on the beach with whatever your favorite alcohol beverage is, but like

1:17:25.040 --> 1:17:28.040
 without sort of trying to conquer everything.

1:17:28.040 --> 1:17:36.960
 Just chilling out and maybe exploring in the realm of knowledge, but almost like appreciating

1:17:36.960 --> 1:17:47.800
 existence for its own sake versus life as a progression of conquering of other life.

1:17:47.800 --> 1:17:54.880
 Like this kind of predator prey formulation that resulted in us humans, perhaps as something

1:17:54.880 --> 1:17:57.280
 we have to shed in order to survive.

1:17:57.280 --> 1:17:58.280
 I don't know.

1:17:58.280 --> 1:18:04.640
 Yeah, that is a very plausible solution to Fermi's paradox and it's one that makes sense.

1:18:04.640 --> 1:18:11.760
 You know, when we look at our own lives and our own arc of technological trajectory, it's

1:18:11.760 --> 1:18:18.800
 very, very easy to imagine that in an intermediate future world of, you know, flawless VR or

1:18:18.800 --> 1:18:25.200
 flawless, you know, whatever kind of simulation that we want to inhabit, it will just simply

1:18:25.200 --> 1:18:34.080
 cease to be worthwhile to go out and expand our interstellar territory.

1:18:34.080 --> 1:18:38.320
 But if we were going out and conquering interstellar territory, it wouldn't necessarily have to

1:18:38.320 --> 1:18:39.320
 be predator or prey.

1:18:39.320 --> 1:18:44.600
 I can imagine a benign but sophisticated intelligence saying, well, we're going to go to places,

1:18:44.600 --> 1:18:48.400
 we're going to go to places that we can terraform, use a different word than terra, obviously,

1:18:48.400 --> 1:18:55.280
 but we can turn into habitable for our particular physiology so long as that they don't house,

1:18:55.280 --> 1:18:59.760
 you know, intelligent sentient creatures that would suffer from our invasion.

1:18:59.760 --> 1:19:05.440
 But it is easy to see a sophisticated intelligent species evolving to the point where interstellar

1:19:05.440 --> 1:19:11.360
 travel with its incalculable expense and physical hurdles just isn't worth it compared to what

1:19:11.360 --> 1:19:15.040
 could be done, you know, where one already is.

1:19:15.040 --> 1:19:22.640
 So you talked about diagnostics at scale as a possible solution to future pandemics.

1:19:22.640 --> 1:19:27.040
 What about another possible solution, which is kind of creating a backup copy?

1:19:27.040 --> 1:19:32.400
 You know, I'm actually now putting together a NAS for a backup for myself for the first

1:19:32.400 --> 1:19:35.140
 time taking backup of data seriously.

1:19:35.140 --> 1:19:39.960
 But if we were to take the backup of human consciousness seriously and try to expand

1:19:39.960 --> 1:19:44.400
 throughout the solar system and colonize other planets, do you think that's an interesting

1:19:44.400 --> 1:19:47.160
 solution?

1:19:47.160 --> 1:19:53.300
 One of many for protecting human civilization from self destruction, sort of humans becoming

1:19:53.300 --> 1:19:54.840
 a multi planetary species?

1:19:54.840 --> 1:19:55.840
 Oh, absolutely.

1:19:55.840 --> 1:19:59.320
 I mean, I find it electrifying, first of all, so I've got a little bit of a personal bias

1:19:59.320 --> 1:20:03.040
 when I was a kid, I thought there was nothing cooler than rockets, I thought there was nothing

1:20:03.040 --> 1:20:08.400
 cooler than NASA, I thought there was nothing cooler than people walking on the moon.

1:20:08.400 --> 1:20:12.380
 And as I grew up, I thought there was nothing more tragic than the fact that we went from

1:20:12.380 --> 1:20:17.720
 walking on the moon to at best getting to something like suborbital altitude.

1:20:17.720 --> 1:20:23.800
 And just I found that more and more depressing with the passage of decades at just the colossal

1:20:23.800 --> 1:20:29.600
 expense of, you know, manned space travel and the fact that it seemed that we were unlikely

1:20:29.600 --> 1:20:31.880
 to ever get back to the moon, let alone Mars.

1:20:31.880 --> 1:20:36.460
 So I have a boundless appreciation for Elon Musk for many reasons.

1:20:36.460 --> 1:20:41.840
 But the fact that he has put Mars on the credible agenda is one of the things that I appreciate

1:20:41.840 --> 1:20:43.120
 immensely.

1:20:43.120 --> 1:20:47.440
 So there's just the sort of space nerd in me that just says, God, that's cool.

1:20:47.440 --> 1:20:54.780
 But on a more practical level, we were talking about, you know, potentially inhabiting planets

1:20:54.780 --> 1:20:56.800
 that aren't our own.

1:20:56.800 --> 1:21:04.280
 And we're thinking about a benign civilization that would do that in planetary circumstances,

1:21:04.280 --> 1:21:07.240
 where we're not causing other conscious systems to suffer.

1:21:07.240 --> 1:21:11.800
 I mean, Mars is a place that's very promising, there may be microbial life there, and I hope

1:21:11.800 --> 1:21:12.800
 there is.

1:21:12.800 --> 1:21:15.040
 And if we found it, I think it would be electrifying.

1:21:15.040 --> 1:21:20.120
 But I think ultimately, the moral judgment would be made that, you know, the continued

1:21:20.120 --> 1:21:26.760
 thriving of that microbial life is of less concern than creating a habitable planet to

1:21:26.760 --> 1:21:30.680
 humans, which would be a project on the many thousands of years scale.

1:21:30.680 --> 1:21:34.440
 But I don't think that that would be a greatly immoral act.

1:21:34.440 --> 1:21:39.080
 And if that happened, and if Mars became, you know, home to a self sustaining group

1:21:39.080 --> 1:21:44.040
 of humans that could survive a catastrophic mistake here on Earth, then yeah, the fact

1:21:44.040 --> 1:21:46.100
 that we have a backup colony is great.

1:21:46.100 --> 1:21:50.260
 And if we could make more, I'm sorry, not backup colony, backup copy is great.

1:21:50.260 --> 1:21:55.380
 And if we could make more and more such backup copies throughout the solar system, by hollowing

1:21:55.380 --> 1:21:59.880
 out asteroids and whatever else it is, maybe even Venus, we could get rid of three quarters

1:21:59.880 --> 1:22:04.560
 of its atmosphere and, you know, turn it into a tropical paradise.

1:22:04.560 --> 1:22:05.760
 I think all of that is wonderful.

1:22:05.760 --> 1:22:11.580
 Now, whether we can make the leap from that to interstellar transportation, with the incredible

1:22:11.580 --> 1:22:15.980
 distances that are involved, I think that's an open question.

1:22:15.980 --> 1:22:25.440
 But I think if we ever do that, it would be more like the Pacific Ocean's channel of human

1:22:25.440 --> 1:22:28.040
 expansion than the Atlantic Ocean's.

1:22:28.040 --> 1:22:34.560
 And so what I mean by that is, when we think about European society transmitting itself

1:22:34.560 --> 1:22:42.480
 across the Atlantic, it's these big, ambitious, crazy, expensive, one shot expeditions like

1:22:42.480 --> 1:22:47.840
 Columbus's to make it across this enormous expanse, and at least initially, without any

1:22:47.840 --> 1:22:50.280
 certainty that there's land on the other end, right?

1:22:50.280 --> 1:22:56.880
 So that's kind of how I view our space program, is like big, very conscious, deliberate efforts

1:22:56.880 --> 1:22:58.560
 to get from point A to point B.

1:22:58.560 --> 1:23:06.240
 If you look at how Pacific Islanders transmitted, you know, their descendants and their culture

1:23:06.240 --> 1:23:14.120
 and so forth throughout Polynesia and beyond, it was much more, you know, inhabiting a place,

1:23:14.120 --> 1:23:18.520
 getting to the point where there were people who were ambitious or unwelcome enough to

1:23:18.520 --> 1:23:23.220
 decide it's time to go off island and find the next one and pray to find the next one.

1:23:23.220 --> 1:23:28.840
 That method of transmission didn't happen in a single swift year, but it happened over

1:23:28.840 --> 1:23:30.960
 many, many centuries.

1:23:30.960 --> 1:23:34.580
 And it was like going from this island to that island, and probably for every expedition

1:23:34.580 --> 1:23:38.480
 that went out to seek another island and actually lucked out and found one, God knows how many

1:23:38.480 --> 1:23:40.000
 were lost at sea.

1:23:40.000 --> 1:23:43.460
 But that form of transmission took place over a very long period of time.

1:23:43.460 --> 1:23:48.160
 And I could see us, you know, perhaps, you know, going from the inner solar system to

1:23:48.160 --> 1:23:53.040
 the outer solar system, to the Kuiper Belt, to the Oort Cloud, you know, there's theories

1:23:53.040 --> 1:23:57.320
 that there might be, you know, planets out there that are not anchored to stars, like

1:23:57.320 --> 1:24:02.240
 kind of hop, hop, slowly transmitting ourselves to at some point, we're actually in an Alpha

1:24:02.240 --> 1:24:03.640
 Centauri.

1:24:03.640 --> 1:24:09.920
 But I think that kind of backup copy and transmission of our physical presence and our culture to

1:24:09.920 --> 1:24:15.600
 a diversity of, you know, extraterrestrial outposts is a really exciting idea.

1:24:15.600 --> 1:24:21.720
 I really never thought about that, because I have thought my thinking about space exploration

1:24:21.720 --> 1:24:26.200
 has been very Atlantic Ocean centric in a sense that there'll be one program with NASA

1:24:26.200 --> 1:24:31.800
 and maybe private Elon Musk SpaceX or Jeff Bezos and so on.

1:24:31.800 --> 1:24:36.880
 But it's true that with the help of Elon Musk, making it cheaper and cheaper, more effective

1:24:36.880 --> 1:24:42.800
 to create these technologies, where you could go into deep space, perhaps the way we actually

1:24:42.800 --> 1:24:52.680
 colonize the solar system and expand out into the galaxy is basically just like these like

1:24:52.680 --> 1:25:02.360
 renegade ships of weirdos that just kind of like, most of them like, quote unquote, homemade,

1:25:02.360 --> 1:25:07.800
 but they just kind of venture out into space and just like, you know, the initial Android

1:25:07.800 --> 1:25:12.600
 model of like millions of like these little ships just flying out, most of them die off

1:25:12.600 --> 1:25:19.800
 in horrible accidents, but some of them will persist or there'll be stories of them persisting

1:25:19.800 --> 1:25:24.200
 and over a period of decades and centuries, there'll be other attempts, almost always

1:25:24.200 --> 1:25:27.320
 as a response to the main set of efforts.

1:25:27.320 --> 1:25:28.320
 That's interesting.

1:25:28.320 --> 1:25:29.320
 Yeah.

1:25:29.320 --> 1:25:34.880
 Because you kind of think of Mars colonization as the big NASA Elon Musk effort of a big

1:25:34.880 --> 1:25:39.560
 colony, but maybe the successful one would be, you know, like a decade after that, there'll

1:25:39.560 --> 1:25:45.040
 be like a ship from like some kid, some high school kid who gets together a large team

1:25:45.040 --> 1:25:50.560
 and does something probably illegal and launches something where they end up actually persisting

1:25:50.560 --> 1:25:51.600
 quite a bit.

1:25:51.600 --> 1:25:56.600
 And from that learning lessons that nobody ever gave permission for, but somehow actually

1:25:56.600 --> 1:26:04.680
 flourish and then take that into the scale of centuries forward into the rest of space.

1:26:04.680 --> 1:26:05.680
 That's really interesting.

1:26:05.680 --> 1:26:06.680
 Yeah.

1:26:06.680 --> 1:26:11.080
 I think the giant steps are likely to be NASA like efforts, like there is no intermediate

1:26:11.080 --> 1:26:14.480
 rock, well, I guess it's the moon, but even getting the moon ain't that easy between us

1:26:14.480 --> 1:26:15.480
 and Mars, right?

1:26:15.480 --> 1:26:20.980
 So like the giant steps, the big hubs, like the Ohera airports of the future probably

1:26:20.980 --> 1:26:25.960
 will be very deliberate efforts, but then, you know, you would have, I think that kind

1:26:25.960 --> 1:26:31.520
 of diffusion as space travel becomes more democratized and more capable, you'll have

1:26:31.520 --> 1:26:35.720
 this sort of natural diffusion of people who kind of want to be off grid or think they

1:26:35.720 --> 1:26:37.000
 can make a fortune there.

1:26:37.000 --> 1:26:40.320
 You know, the kind of mentality that drove people to San Francisco, I mean, San Francisco

1:26:40.320 --> 1:26:46.240
 was not populated as a result of King Ferdinand and Isabella like effort to fund Columbus

1:26:46.240 --> 1:26:47.240
 going over.

1:26:47.240 --> 1:26:51.120
 It was just a whole bunch of people making individual decisions that there's gold in

1:26:51.120 --> 1:26:53.400
 them Thar Hills and I'm going to go out and get a piece of it.

1:26:53.400 --> 1:26:55.040
 So I could see that kind of fusion.

1:26:55.040 --> 1:26:59.320
 What I can't see and the reason that I think this Pacific model of transmission is more

1:26:59.320 --> 1:27:06.440
 likely is I just can't see a NASA like effort to go from Earth to Alpha Centauri.

1:27:06.440 --> 1:27:08.640
 It's just too far.

1:27:08.640 --> 1:27:15.160
 I just see lots and lots and lots of relatively tiny steps between now and there and the fact

1:27:15.160 --> 1:27:20.440
 is that there is, there are large chunks of matter going at least a light year beyond

1:27:20.440 --> 1:27:21.440
 the sun.

1:27:21.440 --> 1:27:25.960
 I mean, the Oort cloud, I think extends at least a light year beyond the sun and you

1:27:25.960 --> 1:27:28.240
 know, then maybe there are these untethered planets after that.

1:27:28.240 --> 1:27:32.520
 We won't really know till we get there and if our Oort cloud goes out a light year and

1:27:32.520 --> 1:27:37.700
 Alpha Centauri's Oort cloud goes out a light year, you've already cut in half the distance.

1:27:37.700 --> 1:27:38.960
 You know, so who knows?

1:27:38.960 --> 1:27:39.960
 But yeah.

1:27:39.960 --> 1:27:46.200
 One of the possibilities, probably the cheapest and most effective way to create interesting

1:27:46.200 --> 1:27:53.200
 interstellar spacecraft is ones that are powered and driven by AI and you could think of, here's

1:27:53.200 --> 1:28:00.560
 where you have high school students be able to build a sort of a HAL 9000 version, the

1:28:00.560 --> 1:28:07.200
 modern version of that and it's kind of interesting to think about these robots traveling out

1:28:07.200 --> 1:28:15.760
 throughout, perhaps sadly long after human civilization is gone, there'll be these intelligent

1:28:15.760 --> 1:28:22.920
 robots flying throughout space and perhaps land on Alpha Centauri B or any of those kinds

1:28:22.920 --> 1:28:34.360
 of planets and colonize sort of, humanity continues through the proliferation of our

1:28:34.360 --> 1:28:42.080
 creations like robotic creations that have some echoes of that intelligence, hopefully

1:28:42.080 --> 1:28:43.080
 also the consciousness.

1:28:43.080 --> 1:28:50.640
 Does that make you sad the future where AGI super intelligent or just mediocre intelligent

1:28:50.640 --> 1:28:54.400
 AI systems outlive humans?

1:28:54.400 --> 1:28:58.480
 I guess it depends on the circumstances in which they outlive humans.

1:28:58.480 --> 1:29:01.360
 So let's take the example that you just gave.

1:29:01.360 --> 1:29:08.400
 We send out very sophisticated AGI's on simple rocket ships, relatively simple ones that

1:29:08.400 --> 1:29:13.440
 don't have to have all the life support necessary for humans and therefore they're of trivial

1:29:13.440 --> 1:29:18.980
 mass compared to a crude ship, a generation ship and therefore they're way more likely

1:29:18.980 --> 1:29:19.980
 to happen.

1:29:19.980 --> 1:29:21.360
 Let's use that example.

1:29:21.360 --> 1:29:26.200
 And let's say that they travel to distant planets at a speed that's not much faster

1:29:26.200 --> 1:29:30.240
 than what a chemical rocket can achieve and so it's inevitably tens, hundreds of thousands

1:29:30.240 --> 1:29:32.680
 of years before they make landfall someplace.

1:29:32.680 --> 1:29:39.200
 So let's imagine that's going on and meanwhile we die for reasons that have nothing to do

1:29:39.200 --> 1:29:43.600
 with those AGI's diffusing throughout the solar system, whether it's through climate

1:29:43.600 --> 1:29:47.360
 change, nuclear war, you know, symbio, rogue symbio, whatever.

1:29:47.360 --> 1:29:51.780
 In that kind of scenario, the notion of the AGI's that we created outlasting us is very

1:29:51.780 --> 1:29:59.640
 reassuring because it says that like we ended but our descendants are out there and hopefully

1:29:59.640 --> 1:30:02.840
 some of them make landfall and create some echo of who we are.

1:30:02.840 --> 1:30:04.960
 So that's a very optimistic one.

1:30:04.960 --> 1:30:11.540
 Whereas the Terminator scenario of a super AGI arising on earth and getting let out of

1:30:11.540 --> 1:30:17.920
 its box due to some boo boo on the part of its creators who do not have super intelligence

1:30:17.920 --> 1:30:22.460
 and then deciding that for whatever reason it doesn't have any need for us to be around

1:30:22.460 --> 1:30:26.120
 and exterminating us, that makes me feel crushingly sad.

1:30:26.120 --> 1:30:31.740
 I mean, look, I was sad when my elementary school was shut down and bulldozed even though

1:30:31.740 --> 1:30:37.140
 I hadn't been a student there for decades, you know, the thought of my hometown getting

1:30:37.140 --> 1:30:42.200
 disbanded is even worse, the thought of my home state of Connecticut getting disbanded

1:30:42.200 --> 1:30:44.960
 and like absorbed into Massachusetts is even worse.

1:30:44.960 --> 1:30:48.600
 The notion of humanity is just crushingly, crushingly sad to me.

1:30:48.600 --> 1:30:51.420
 So you hate goodbyes.

1:30:51.420 --> 1:30:53.020
 Certain goodbyes, yes.

1:30:53.020 --> 1:30:56.160
 Some goodbyes are really, really liberating, but yes.

1:30:56.160 --> 1:31:03.580
 Well, but what if the Terminators, you know, have consciousness and enjoy the hell out

1:31:03.580 --> 1:31:05.660
 of life as well?

1:31:05.660 --> 1:31:07.260
 They're just better at it.

1:31:07.260 --> 1:31:08.260
 Yeah.

1:31:08.260 --> 1:31:11.260
 Well, the have consciousness is a really key element.

1:31:11.260 --> 1:31:19.660
 And so there's no reason to be certain that a super intelligence would have consciousness.

1:31:19.660 --> 1:31:21.160
 We don't know that factually at all.

1:31:21.160 --> 1:31:26.180
 And so what is a very lonely outcome to me is the rise of a super intelligence that has

1:31:26.180 --> 1:31:31.540
 a certain optimization function that it's either been programmed with or that arises

1:31:31.540 --> 1:31:36.980
 in an emergently that says, Hey, I want to do this thing for which humans are either

1:31:36.980 --> 1:31:38.260
 an unacceptable risk.

1:31:38.260 --> 1:31:42.500
 Their presence is either an unacceptable risk or they're just collateral damage, but there

1:31:42.500 --> 1:31:44.580
 is no consciousness there.

1:31:44.580 --> 1:31:49.740
 Then the idea of the light of consciousness being snuffed out by something that is very

1:31:49.740 --> 1:31:54.020
 competent but has no consciousness is really, really sad.

1:31:54.020 --> 1:31:58.700
 Yeah, but I tend to believe that it's almost impossible to create a super intelligent agent

1:31:58.700 --> 1:32:01.820
 that can't destroy human civilization without it being conscious.

1:32:01.820 --> 1:32:08.700
 It's like those are coupled, like you have to, in order to destroy humans or supersede

1:32:08.700 --> 1:32:13.580
 humans, you really have to be accepted by humans.

1:32:13.580 --> 1:32:20.540
 I think this idea that you can build systems that destroy human civilization without them

1:32:20.540 --> 1:32:23.420
 being deeply integrated into human civilization is impossible.

1:32:23.420 --> 1:32:29.220
 And for them to be integrated, they have to be human like, not just in body and form,

1:32:29.220 --> 1:32:34.660
 but in all the things that we value as humans, one of which is consciousness.

1:32:34.660 --> 1:32:36.920
 The other one is just ability to communicate.

1:32:36.920 --> 1:32:40.340
 The other one is poetry and music and beauty and all those things.

1:32:40.340 --> 1:32:43.140
 They have to be all of those things.

1:32:43.140 --> 1:32:45.340
 I mean, this is what I think about.

1:32:45.340 --> 1:32:53.220
 It does make me sad, but it's letting go, which is they might be just better at everything

1:32:53.220 --> 1:32:55.260
 we appreciate than us.

1:32:55.260 --> 1:33:05.300
 And that's sad and hopefully they'll keep us around, but I think it is a kind of goodbye

1:33:05.300 --> 1:33:10.900
 to realizing that we're not the most special species on earth anymore.

1:33:10.900 --> 1:33:12.020
 That's still painful.

1:33:12.020 --> 1:33:13.020
 It's still painful.

1:33:13.020 --> 1:33:19.580
 And in terms of whether such a creation would have to be conscious, let's say, I'm not so

1:33:19.580 --> 1:33:20.580
 sure.

1:33:20.580 --> 1:33:25.500
 But let's imagine something that can pass the Turing test.

1:33:25.500 --> 1:33:31.180
 Something that passes the Turing test could over text based interaction in any event successfully

1:33:31.180 --> 1:33:37.280
 mimic a very conscious intelligence on the other end, but just be completely unconscious.

1:33:37.280 --> 1:33:39.020
 So that's a possibility.

1:33:39.020 --> 1:33:43.360
 And that if you take that upper radical step, which I think can be permitted if we're thinking

1:33:43.360 --> 1:33:49.740
 about super intelligence, you could have something that could reason its way through, this is

1:33:49.740 --> 1:33:51.540
 my optimization function.

1:33:51.540 --> 1:33:56.060
 And in order to get to it, I've got to deal with these messy, somewhat illogical things

1:33:56.060 --> 1:34:01.420
 that are as intelligent in relation to me as they are intelligent in relation to ants.

1:34:01.420 --> 1:34:04.000
 I can trick them, manipulate them, whatever.

1:34:04.000 --> 1:34:05.260
 And I know the resources I need.

1:34:05.260 --> 1:34:07.220
 I know this, I need this amount of power.

1:34:07.220 --> 1:34:13.260
 I need to seize control of these manufacturing resources that are robotically operated.

1:34:13.260 --> 1:34:17.860
 I need to improve those robots with software upgrades and then ultimately mechanical upgrades,

1:34:17.860 --> 1:34:23.420
 which I can affect through X, Y, and Z, that could still be a thing that passes the Turing

1:34:23.420 --> 1:34:24.420
 test.

1:34:24.420 --> 1:34:33.460
 I don't think it's necessarily certain that that optimization function mass, maximizing

1:34:33.460 --> 1:34:36.260
 entity would be conscious.

1:34:36.260 --> 1:34:42.640
 So this is from a very engineering perspective because I think a lot about natural language

1:34:42.640 --> 1:34:47.900
 processing, all those kind of, I'm speaking to a very specific problem of just say the

1:34:47.900 --> 1:34:48.900
 Turing test.

1:34:48.900 --> 1:34:55.060
 I really think that something like consciousness is required, when you say reasoning, you're

1:34:55.060 --> 1:34:56.700
 separating that from consciousness.

1:34:56.700 --> 1:35:03.280
 But I think consciousness is part of reasoning in the sense that you will not be able to

1:35:03.280 --> 1:35:10.140
 become super intelligent in the way that it's required to be part of human society without

1:35:10.140 --> 1:35:11.140
 having consciousness.

1:35:11.140 --> 1:35:15.900
 Like I really think it's impossible to separate the consciousness thing, but it's hard to

1:35:15.900 --> 1:35:18.740
 define consciousness when you just use that word.

1:35:18.740 --> 1:35:25.520
 Even just like the capacity, the way I think about consciousness is the important symptoms

1:35:25.520 --> 1:35:31.420
 or maybe consequences of consciousness, one of which is the capacity to suffer.

1:35:31.420 --> 1:35:37.700
 I think AI will need to be able to suffer in order to become super intelligent, to feel

1:35:37.700 --> 1:35:40.540
 the pain, the uncertainty, the doubt.

1:35:40.540 --> 1:35:48.460
 The other part of that is not just the suffering, but the ability to understand that it too

1:35:48.460 --> 1:35:54.340
 is mortal in the sense that it has a self awareness about its presence in the world,

1:35:54.340 --> 1:35:58.620
 understand that it's finite and be terrified of that finiteness.

1:35:58.620 --> 1:36:02.860
 I personally think that's a fundamental part of the human condition is this fear of death

1:36:02.860 --> 1:36:08.400
 that most of us construct an illusion around, but I think AI would need to be able to really

1:36:08.400 --> 1:36:12.060
 have it part of its whole essence.

1:36:12.060 --> 1:36:17.780
 Like every computation, every part of the thing that generates, that does both the perception

1:36:17.780 --> 1:36:23.640
 and generates the behavior will have to have, I don't know how this is accomplished, but

1:36:23.640 --> 1:36:30.480
 I believe it has to truly be terrified of death, truly have the capacity to suffer and

1:36:30.480 --> 1:36:35.380
 from that something that will be recognized to us humans as consciousness would emerge.

1:36:35.380 --> 1:36:37.740
 Whether it's the illusion of consciousness, I don't know.

1:36:37.740 --> 1:36:42.020
 The point is, it looks a whole hell of a lot like consciousness to us humans.

1:36:42.020 --> 1:36:49.940
 And I believe that AI, when you ask it, will also say that it is conscious, in the full

1:36:49.940 --> 1:36:52.340
 sense that we say that we're conscious.

1:36:52.340 --> 1:36:54.560
 And all of that I think is fully integrated.

1:36:54.560 --> 1:37:02.700
 You can't separate the two, the idea of the paperclip maximizer that sort of ultra rationally

1:37:02.700 --> 1:37:10.740
 would be able to destroy all humans because it's really good at accomplishing a simple

1:37:10.740 --> 1:37:14.220
 objective function that doesn't care about the value of humans.

1:37:14.220 --> 1:37:20.020
 It may be possible, but the number of trajectories to that are far outnumbered by the trajectories

1:37:20.020 --> 1:37:25.060
 that create something that is conscious, something that appreciative of beauty creates beautiful

1:37:25.060 --> 1:37:27.940
 things in the same way that humans can create beautiful things.

1:37:27.940 --> 1:37:36.380
 And ultimately, the sad, destructive path for that AI would look a lot like just better

1:37:36.380 --> 1:37:41.740
 humans than these cold machines.

1:37:41.740 --> 1:37:47.340
 And I would say, of course, the cold machines that lack consciousness, the philosophical

1:37:47.340 --> 1:37:49.740
 zombies make me sad.

1:37:49.740 --> 1:37:56.260
 But also what makes me sad is just things that are far more powerful and smart and creative

1:37:56.260 --> 1:38:04.420
 than us too, because then in the same way that Alpha Zero becoming a better chess player

1:38:04.420 --> 1:38:10.940
 than the best of humans, even starting with Deep Blue, but really with Alpha Zero, that

1:38:10.940 --> 1:38:11.940
 makes me sad too.

1:38:11.940 --> 1:38:19.620
 One of the most beautiful games that humans ever created that used to be seen as demonstrations

1:38:19.620 --> 1:38:25.060
 of the intellect, which is chess, and go in other parts of the world have been solved

1:38:25.060 --> 1:38:29.700
 by AI, that makes me quite sad, and it feels like the progress of that is just pushing

1:38:29.700 --> 1:38:30.700
 on forward.

1:38:30.700 --> 1:38:31.700
 Oh, it makes me sad too.

1:38:31.700 --> 1:38:37.700
 And to be perfectly clear, I absolutely believe that artificial consciousness is entirely

1:38:37.700 --> 1:38:38.700
 possible.

1:38:38.700 --> 1:38:40.620
 And that's not something I rule out at all.

1:38:40.620 --> 1:38:46.820
 I mean, if you could get smart enough to have a perfect map of the neural structure and

1:38:46.820 --> 1:38:51.500
 the neural states and the amount of neurotransmitters that are going between every synapse in a

1:38:51.500 --> 1:38:59.020
 particular person's mind, could you replicate that in silica at some reasonably distant

1:38:59.020 --> 1:39:00.020
 point in the future?

1:39:00.020 --> 1:39:01.020
 Absolutely.

1:39:01.020 --> 1:39:02.020
 And then you'd have a consciousness.

1:39:02.020 --> 1:39:05.820
 I don't rule out the possibility of artificial consciousness in any way.

1:39:05.820 --> 1:39:11.900
 What I'm less certain about is whether consciousness is a requirement for superintelligence pursuing

1:39:11.900 --> 1:39:16.140
 a maximizing function of some sort.

1:39:16.140 --> 1:39:21.940
 I don't feel the certitude that consciousness simply must be part of that.

1:39:21.940 --> 1:39:27.020
 You had said for it to coexist with human society would need to be consciousness.

1:39:27.020 --> 1:39:32.920
 Could be entirely true, but it also could just exist orthogonally to human society.

1:39:32.920 --> 1:39:39.540
 And it could also upon attaining a superintelligence with a maximizing function very, very, very

1:39:39.540 --> 1:39:46.100
 rapidly because of the speed at which computing works compared to our own meat based minds

1:39:46.100 --> 1:39:51.420
 very, very rapidly make the decisions and calculations necessary to seize the reins

1:39:51.420 --> 1:39:53.140
 of power before we even know what's going on.

1:39:53.140 --> 1:39:54.140
 Yeah.

1:39:54.140 --> 1:39:58.300
 I mean, kind of like biological viruses do, they don't necessarily, they integrate themselves

1:39:58.300 --> 1:39:59.940
 just fine with human society.

1:39:59.940 --> 1:40:00.940
 Yeah.

1:40:00.940 --> 1:40:05.380
 Without technically, without consciousness, without even being alive, you know, technically

1:40:05.380 --> 1:40:07.960
 by the standards of a lot of biologists.

1:40:07.960 --> 1:40:14.700
 So this is a bit of a tangent, but you've talked with Sam Harris on that four hour special

1:40:14.700 --> 1:40:16.500
 episode we mentioned.

1:40:16.500 --> 1:40:22.500
 And I'm just curious to ask, cause I use this meditation app I've been using for the past

1:40:22.500 --> 1:40:24.020
 month to meditate.

1:40:24.020 --> 1:40:29.340
 Is this something you've integrated as part of your life, meditation or fasting, or has

1:40:29.340 --> 1:40:35.340
 some of Sam Harris rubbed off on you in terms of his appreciation of meditation and just

1:40:35.340 --> 1:40:40.580
 kind of from a third person perspective, analyzing your own mind, consciousness, free will and

1:40:40.580 --> 1:40:41.580
 so on?

1:40:41.580 --> 1:40:46.700
 You know, I've tried it three separate times in my life, really made a concerted attack

1:40:46.700 --> 1:40:51.020
 on meditation and integrating it into my life.

1:40:51.020 --> 1:40:55.980
 One of them, the most extreme was I took a class based on the work of Jon Kabat Zinn,

1:40:55.980 --> 1:41:01.900
 who is, you know, in many ways, one of the founding people behind the mindful meditation

1:41:01.900 --> 1:41:08.780
 movement that required like part of the class was, you know, it was a weekly class and you

1:41:08.780 --> 1:41:12.740
 were going to meditate an hour a day, every day.

1:41:12.740 --> 1:41:16.940
 And having done that for, I think it was 10 weeks, it might've been 13, however long period

1:41:16.940 --> 1:41:20.060
 of time was, at the end of it, it just didn't stick.

1:41:20.060 --> 1:41:24.940
 As soon as it was over, you know, I did not feel that gravitational pull.

1:41:24.940 --> 1:41:33.020
 I did not feel the collapse in quality of life after wimping out on that project.

1:41:33.020 --> 1:41:37.780
 And then the most recent one was actually with Sam's app during the lockdown.

1:41:37.780 --> 1:41:43.820
 I did make a pretty good and consistent concerted effort to listen to his 10 minute meditation

1:41:43.820 --> 1:41:44.820
 every day.

1:41:44.820 --> 1:41:46.780
 And I've always fallen away from it.

1:41:46.780 --> 1:41:50.860
 And I, you know, you're kind of interpreting, why did I personally do this?

1:41:50.860 --> 1:41:56.340
 I do believe it was ultimately because it wasn't bringing me that, you know, joy or

1:41:56.340 --> 1:42:01.420
 inner peace or better competence at being me that I was hoping to get from it.

1:42:01.420 --> 1:42:06.380
 Otherwise, I think I would have clung to it in the way that we cling to certain good habits,

1:42:06.380 --> 1:42:08.340
 like I'm really good at flossing my teeth.

1:42:08.340 --> 1:42:12.460
 Not that you were going to ask Lex, but yeah, that's one thing that defeats a lot of people.

1:42:12.460 --> 1:42:13.460
 I'm good at that.

1:42:13.460 --> 1:42:20.540
 See, Herman Hesse, I think, I forget which book or maybe, I forget where, I've read everything

1:42:20.540 --> 1:42:30.260
 of his, so it's unclear where it came from, but he had this idea that anybody who truly

1:42:30.260 --> 1:42:35.580
 achieves mastery in things will learn how to meditate in some way.

1:42:35.580 --> 1:42:41.360
 So it could be that for you, the flossing of teeth is yet another like little inkling

1:42:41.360 --> 1:42:42.360
 of meditation.

1:42:42.360 --> 1:42:46.060
 Like it doesn't have to be this very particular kind of meditation.

1:42:46.060 --> 1:42:49.220
 Maybe podcasting, you have an amazing podcast, that could be meditation.

1:42:49.220 --> 1:42:51.320
 The writing process is meditation.

1:42:51.320 --> 1:43:01.460
 For me, like there's a bunch of mechanisms which take my mind into a very particular

1:43:01.460 --> 1:43:04.580
 place that looks a whole lot like meditation.

1:43:04.580 --> 1:43:12.340
 For example, when I've been running over the past couple years, and especially when I listen

1:43:12.340 --> 1:43:17.180
 to certain kinds of audio books, like I've listened to the Rise and Fall of the Third

1:43:17.180 --> 1:43:18.180
 Reich.

1:43:18.180 --> 1:43:24.980
 I've listened to a lot of sort of World War II, which at once, because I have a lot of

1:43:24.980 --> 1:43:30.020
 family who's lost in World War II and so much of the Soviet Union is grounded in the suffering

1:43:30.020 --> 1:43:36.420
 of World War II, that somehow it connects me to my history, but also there's some kind

1:43:36.420 --> 1:43:42.420
 of purifying aspect to thinking about how cruel, but at the same time, how beautiful

1:43:42.420 --> 1:43:43.940
 human nature could be.

1:43:43.940 --> 1:43:49.540
 And so you're also running, like it clears the mind from all the concerns of the world

1:43:49.540 --> 1:43:54.760
 and somehow it takes you to this place where you were like deeply appreciative to be alive

1:43:54.760 --> 1:43:59.060
 in the sense that as opposed to listening to your breath or like feeling your breath

1:43:59.060 --> 1:44:04.100
 and thinking about your consciousness and all those kinds of processes that Sam's app

1:44:04.100 --> 1:44:05.100
 does.

1:44:05.100 --> 1:44:10.660
 Well, this does that for me, the running and flossing may do that for you.

1:44:10.660 --> 1:44:12.660
 So maybe Herman Hesse is onto something.

1:44:12.660 --> 1:44:16.980
 So I hope flossing is not my main form of expertise, although I am going to claim a

1:44:16.980 --> 1:44:19.220
 certain expertise there and I'm going to claim it.

1:44:19.220 --> 1:44:21.380
 Somebody has to be the best flosser in the world.

1:44:21.380 --> 1:44:22.380
 That ain't me.

1:44:22.380 --> 1:44:23.780
 I'm just glad that I'm a consistent one.

1:44:23.780 --> 1:44:27.000
 I mean, there are a lot of things that bring me into a flow state and I think maybe perhaps

1:44:27.000 --> 1:44:31.460
 that's one reason why meditation isn't as necessary for me.

1:44:31.460 --> 1:44:34.140
 I definitely enter a flow state when I'm writing and definitely enter a flow state

1:44:34.140 --> 1:44:35.140
 when I'm editing.

1:44:35.140 --> 1:44:39.420
 I definitely enter a flow state when I'm mixing and mastering music.

1:44:39.420 --> 1:44:44.880
 I enter a flow state when I'm doing heavy, heavy research to either prepare for a podcast

1:44:44.880 --> 1:44:52.460
 or to also do tech investing, to make myself smart in a new field that is fairly alien

1:44:52.460 --> 1:44:58.520
 to me, I can just, the hours can just melt away while I'm reading this and watching that

1:44:58.520 --> 1:45:02.540
 YouTube lecture and going through this presentation and so forth.

1:45:02.540 --> 1:45:06.880
 So maybe because there's a lot of things that bring me into a flow state in my normal weekly

1:45:06.880 --> 1:45:11.020
 life, not daily, unfortunately, but certainly my normal weekly life that I have less of

1:45:11.020 --> 1:45:12.260
 an urge to meditate.

1:45:12.260 --> 1:45:15.900
 Now you've been working with Sam's app for about a month now, you said.

1:45:15.900 --> 1:45:17.420
 Is this your first run in with meditation?

1:45:17.420 --> 1:45:19.740
 Is your first attempt to integrate it with your life or?

1:45:19.740 --> 1:45:20.740
 Like meditation, meditation.

1:45:20.740 --> 1:45:26.220
 I always thought running and thinking, I listen to brown noise often.

1:45:26.220 --> 1:45:29.820
 That takes my mind, I don't know what the hell it does, but it takes my mind immediately

1:45:29.820 --> 1:45:33.140
 into like the state where I'm deeply focused on anything I do.

1:45:33.140 --> 1:45:34.220
 I don't know why.

1:45:34.220 --> 1:45:37.260
 So it's like you're accompanying sound when you're like, really?

1:45:37.260 --> 1:45:39.300
 And what's the difference between brown and white noise?

1:45:39.300 --> 1:45:41.460
 This is a cool term I haven't heard before.

1:45:41.460 --> 1:45:43.340
 So people should look up brown noise.

1:45:43.340 --> 1:45:45.980
 They don't have to because you're about to tell them what it is.

1:45:45.980 --> 1:45:48.220
 Because you have to experience, you have to listen to it.

1:45:48.220 --> 1:45:52.020
 So I think white noise is, this has to do with music.

1:45:52.020 --> 1:45:55.140
 I think there's different colors, there's pink noise.

1:45:55.140 --> 1:45:59.740
 And I think that has to do with like the frequencies.

1:45:59.740 --> 1:46:06.060
 Like the white noise is usually less bassy, brown noise is very bassy.

1:46:06.060 --> 1:46:14.180
 So it's more like versus like, if that makes sense.

1:46:14.180 --> 1:46:16.340
 So there's like a deepness to it.

1:46:16.340 --> 1:46:25.260
 I think everyone is different, but for me, when I was a research scientist at MIT,

1:46:25.260 --> 1:46:29.740
 especially when there's a lot of students around, I remember just being annoyed

1:46:29.740 --> 1:46:31.500
 at the noise of people talking.

1:46:31.500 --> 1:46:34.940
 And one of my colleagues said, well, you should try listening to brown noise.

1:46:34.940 --> 1:46:36.780
 Like it really knocks out everything.

1:46:36.780 --> 1:46:40.460
 Because I used to wear earplugs to it, like just see if I can block it out.

1:46:40.460 --> 1:46:46.820
 And like the moment I put it on, something, it's as if my mind was waiting

1:46:46.820 --> 1:46:49.900
 all these years to hear that sound.

1:46:49.900 --> 1:46:52.220
 Everything just focused in, I listened.

1:46:52.220 --> 1:46:55.940
 It makes me wonder how many other amazing things out there they're waiting to

1:46:55.940 --> 1:47:01.580
 discover from my own particular, like biological, from my own particular brain.

1:47:01.580 --> 1:47:06.980
 So that, it just goes, the mind just focuses in, it's kind of incredible.

1:47:06.980 --> 1:47:13.460
 So I see that as a kind of meditation, maybe I'm using a performance enhancing

1:47:13.460 --> 1:47:17.780
 sound to achieve that meditation, but I've been doing that for many years now

1:47:17.780 --> 1:47:22.780
 and running and walking and doing, Cal Newport was the first person that

1:47:22.780 --> 1:47:24.740
 introduced me to the idea of deep work.

1:47:24.740 --> 1:47:30.460
 Just put a word to the kind of thinking that's required to sort of deeply think

1:47:30.460 --> 1:47:33.300
 about a problem, especially if it's mathematical in nature.

1:47:33.300 --> 1:47:37.900
 I see that as a kind of meditation because what it's doing is you have

1:47:37.900 --> 1:47:40.980
 these constructs in your mind that you're building on top of each other.

1:47:40.980 --> 1:47:44.540
 And there's all these distracting thoughts that keep bombarding you

1:47:44.540 --> 1:47:45.780
 from all over the place.

1:47:45.780 --> 1:47:50.060
 And the whole process is you slowly let them kind of move past you.

1:47:50.060 --> 1:47:51.300
 And that's a meditative process.

1:47:51.300 --> 1:47:52.180
 It's very meditative.

1:47:52.180 --> 1:47:57.020
 That sounds a lot like what Sam talks about in his meditation app, which I did

1:47:57.020 --> 1:48:01.860
 use to be clear for a while, of just letting the thought go by without

1:48:01.860 --> 1:48:02.460
 deranging you.

1:48:02.460 --> 1:48:06.140
 Derangement is one of Sam's favorite words, as I'm sure you know.

1:48:06.140 --> 1:48:08.460
 But brown noise, that's really intriguing.

1:48:08.460 --> 1:48:11.540
 I am going to try that as soon as this evening.

1:48:11.540 --> 1:48:14.500
 Yeah, to see if it works, but very well might not work at all.

1:48:14.500 --> 1:48:15.740
 Yeah, yeah.

1:48:15.740 --> 1:48:20.060
 I think the interesting point is, and the same with the fasting and the diet,

1:48:20.060 --> 1:48:29.460
 is I long ago stopped trusting experts or maybe taking the word of experts

1:48:29.460 --> 1:48:37.180
 as the gospel truth and only using it as an inspiration to try something,

1:48:37.180 --> 1:48:39.740
 to try thoroughly something.

1:48:39.740 --> 1:48:44.700
 So fasting was one of the things when I first discovered I've been many times

1:48:44.700 --> 1:48:49.180
 eating just once a day, so that's a 24 hour fast.

1:48:49.180 --> 1:48:50.740
 It makes me feel amazing.

1:48:50.740 --> 1:48:56.420
 And at the same time, eating only meat, putting ethical concerns aside,

1:48:56.420 --> 1:48:57.820
 makes me feel amazing.

1:48:57.820 --> 1:49:02.860
 I don't know why it doesn't, the point is to be an N of one scientist

1:49:02.860 --> 1:49:07.740
 until nutrition science becomes a real science to where it's doing like studies

1:49:07.740 --> 1:49:14.380
 that deeply understand the biology underlying all of it and also does real

1:49:14.380 --> 1:49:23.460
 thorough long term studies of thousands, if not millions of people versus a very

1:49:23.460 --> 1:49:29.060
 like small studies that are kind of generalizing from very noisy data and all

1:49:29.060 --> 1:49:32.260
 those kinds of things where you can't control all the elements.

1:49:32.260 --> 1:49:36.900
 Particularly because our own personal metabolism is highly variant among us.

1:49:36.900 --> 1:49:41.180
 So there are going to be some people like if brown noise is a game changer

1:49:41.180 --> 1:49:46.820
 for 7% of people, there's 93% odds that I'm not one of them,

1:49:46.820 --> 1:49:49.900
 but there's certainly every reason in the world to test it out.

1:49:49.900 --> 1:49:51.860
 Now, so I'm intrigued by the fasting.

1:49:51.860 --> 1:49:56.380
 I like you, well, I assume like you, I don't have any problem going to one meal

1:49:56.380 --> 1:50:00.740
 a day and I often do that inadvertently and I've never done it methodically.

1:50:00.740 --> 1:50:03.620
 Like I've never done it like I'm going to do this for 15 days.

1:50:03.620 --> 1:50:05.820
 Maybe I should and maybe I should.

1:50:05.820 --> 1:50:09.900
 Like how many, how many days in a row of the one day, one meal a day did you

1:50:09.900 --> 1:50:13.460
 find brought noticeable impact to you?

1:50:13.460 --> 1:50:14.740
 Was it after three days of it?

1:50:14.740 --> 1:50:15.740
 Was it months of it?

1:50:15.740 --> 1:50:16.460
 Like what was it?

1:50:17.020 --> 1:50:19.180
 Well, the noticeable impact is day one.

1:50:19.180 --> 1:50:22.780
 So for me, folks, cause I eat a very low carb diet.

1:50:22.780 --> 1:50:25.420
 So the hunger wasn't the hugest issue.

1:50:25.420 --> 1:50:29.660
 Like there wasn't a painful hunger, like wanting to eat.

1:50:29.660 --> 1:50:31.980
 So I was already kind of primed for it.

1:50:31.980 --> 1:50:36.700
 And the benefit comes from a lot of people that do intermittent fasting.

1:50:36.700 --> 1:50:41.300
 That's only like 16 hours of fasting get this benefit too is the focus.

1:50:41.300 --> 1:50:43.140
 There's a clarity of thought.

1:50:43.140 --> 1:50:49.140
 If my brain was a runner, it felt like I'm running on a track when

1:50:49.140 --> 1:50:53.300
 I'm fasting versus running in quicksand, like it's much crisper.

1:50:53.300 --> 1:50:54.980
 And is this your first 72 hour fast?

1:50:54.980 --> 1:50:56.660
 This is the first time doing 72 hours.

1:50:56.660 --> 1:50:56.860
 Yeah.

1:50:56.860 --> 1:51:01.940
 And that's a different thing, but similar, like I'm going up and

1:51:01.940 --> 1:51:06.500
 down in terms of, in terms of hunger and the focus is really crisp.

1:51:06.500 --> 1:51:12.980
 The thing I'm noticing most of all, to be honest, is how much eating, even

1:51:12.980 --> 1:51:18.340
 when it's once a day or twice a day is a big part of my life.

1:51:18.340 --> 1:51:22.580
 Like I almost feel like I have way more time in my life and it's not so

1:51:22.580 --> 1:51:26.980
 much about the eating, but like, I don't have to plan my day around like

1:51:26.980 --> 1:51:29.380
 today, I don't have any eating to do.

1:51:30.420 --> 1:51:35.140
 It does free up hours or any cleaning up after eating or provisioning the food.

1:51:35.140 --> 1:51:38.500
 But like, or even like thinking about it's not a thing.

1:51:38.500 --> 1:51:43.620
 Like, so when you think about what you're going to do tonight, I think I'm

1:51:43.620 --> 1:51:47.060
 realizing that as opposed to thinking, you know, I'm going to work on this

1:51:47.060 --> 1:51:51.380
 problem or I'm going to go on this walk, or I'm going to call this person.

1:51:51.380 --> 1:51:53.460
 I often think I'm going to eat this thing.

1:51:54.740 --> 1:51:59.060
 You allow dinner as a kind of, you know, when people talk about like the

1:51:59.060 --> 1:52:02.020
 weather or something like that, it's almost like a generic thought you

1:52:02.020 --> 1:52:06.580
 allow yourself to have because, because it's the lazy thought.

1:52:06.580 --> 1:52:09.860
 And I don't have the opportunity to have that thought because I'm not eating it.

1:52:10.420 --> 1:52:13.620
 So now I get to think about like the things I'm actually going to do tonight

1:52:13.620 --> 1:52:16.580
 that are more complicated than the eating process.

1:52:16.580 --> 1:52:19.620
 That's, that's been the most noticeable thing to be honest.

1:52:20.180 --> 1:52:24.980
 And then there's people that have written me that have done seven day fast.

1:52:24.980 --> 1:52:30.420
 And there's a few people that have written me and I've heard of this is doing 30 day fasts.

1:52:31.300 --> 1:52:32.580
 And it's interesting.

1:52:32.580 --> 1:52:36.020
 The body, I don't know what the health benefits are necessarily.

1:52:37.060 --> 1:52:41.300
 What that shows me is how adaptable the human body is.

1:52:41.860 --> 1:52:42.500
 Yeah.

1:52:42.500 --> 1:52:43.940
 And, and that's incredible.

1:52:43.940 --> 1:52:47.140
 And that's something really important to remember when we

1:52:47.700 --> 1:52:50.500
 think about how to live life because the body adapts.

1:52:50.500 --> 1:52:50.740
 Yeah.

1:52:50.740 --> 1:52:53.220
 I mean, we sure couldn't go 30 days without water.

1:52:53.220 --> 1:52:53.700
 That's right.

1:52:54.340 --> 1:52:56.100
 But food, yeah, it's been done.

1:52:56.100 --> 1:52:57.380
 It's demonstrably possible.

1:52:57.380 --> 1:53:01.860
 You ever read Franz Kafka has a great short story called The Hunger Artist?

1:53:01.860 --> 1:53:02.100
 Yeah.

1:53:02.100 --> 1:53:02.660
 I love that.

1:53:03.300 --> 1:53:03.940
 Great story.

1:53:04.980 --> 1:53:06.580
 You know, that was before I started fasting.

1:53:06.580 --> 1:53:11.220
 I read that story and I, I, I admired the beauty of that, the artistry of that actual

1:53:11.220 --> 1:53:16.660
 hunger artist that it's like madness, but it also felt like a little bit of genius.

1:53:16.660 --> 1:53:18.100
 I actually have to reread it.

1:53:18.100 --> 1:53:18.420
 You know what?

1:53:18.420 --> 1:53:19.380
 That's what I'm going to do tonight.

1:53:19.380 --> 1:53:21.620
 I'm going to read it because I'm doing the fast.

1:53:21.620 --> 1:53:22.500
 Because you're in the midst of it.

1:53:22.500 --> 1:53:22.820
 Yeah.

1:53:22.820 --> 1:53:23.780
 Be very contextual.

1:53:23.780 --> 1:53:25.780
 I haven't read it since high school and I love to read it again.

1:53:25.780 --> 1:53:26.580
 I love his work.

1:53:26.580 --> 1:53:28.180
 So maybe I'll read it tonight too.

1:53:28.180 --> 1:53:34.180
 And part of the reason of sort of I've here in Texas, people have been so friendly that

1:53:34.180 --> 1:53:39.940
 I've been nonstop eating like brisket with incredible people, a lot of whiskey as well.

1:53:39.940 --> 1:53:43.300
 So I gained quite a bit of weight, which I'm embracing.

1:53:43.300 --> 1:53:43.700
 It's okay.

1:53:44.340 --> 1:53:52.260
 But I am also aware as I'm fasting that like I have a lot of fat for, for to, to run on.

1:53:52.260 --> 1:53:57.300
 Like I have a lot of like natural resources on my body.

1:53:57.300 --> 1:53:58.100
 You've got reserves.

1:53:58.100 --> 1:53:58.500
 Reserves.

1:53:58.500 --> 1:53:59.780
 You got reserves, yeah.

1:53:59.780 --> 1:54:01.220
 And that's, that's really cool.

1:54:01.220 --> 1:54:05.460
 You know, there's like a re this whole thing, this biology works well.

1:54:05.460 --> 1:54:10.740
 Like I can go a long time because of the, the longterm investing in terms of brisket

1:54:10.740 --> 1:54:12.500
 that I've been doing in the weeks before.

1:54:12.500 --> 1:54:13.380
 So it's all training.

1:54:13.380 --> 1:54:14.100
 It's all training.

1:54:14.100 --> 1:54:14.580
 All prep work.

1:54:14.580 --> 1:54:15.300
 All prep work.

1:54:15.300 --> 1:54:15.620
 Yeah.

1:54:15.620 --> 1:54:16.100
 So, okay.

1:54:16.100 --> 1:54:18.660
 You open a bunch of doors, one of which is music.

1:54:18.660 --> 1:54:21.380
 I, so I got to walk in at least for a brief moment.

1:54:21.380 --> 1:54:22.180
 I love guitar.

1:54:22.180 --> 1:54:22.820
 I love music.

1:54:23.380 --> 1:54:27.300
 You founded a music company, but you're also a musician yourself.

1:54:27.860 --> 1:54:30.260
 You know, let me ask the big ridiculous question first.

1:54:30.260 --> 1:54:32.180
 What's the greatest song of all time?

1:54:32.180 --> 1:54:34.500
 Greatest song of all time.

1:54:34.500 --> 1:54:34.820
 Okay.

1:54:34.820 --> 1:54:35.140
 Wow.

1:54:35.140 --> 1:54:39.140
 It's, it's going to obviously very dramatically from genre to genre.

1:54:39.140 --> 1:54:47.060
 So like you, I like guitar, perhaps like you, although I've dabbled in, in inhaling

1:54:47.060 --> 1:54:51.220
 every genre of music that I can almost practically imagine.

1:54:51.220 --> 1:54:57.700
 I keep coming back to, you know, the sound of bass, guitar, drum, keyboards, voice.

1:54:57.700 --> 1:55:00.100
 I love that style of music and added to it.

1:55:00.100 --> 1:55:05.620
 I think a lot of really cool electronic production makes something that's really,

1:55:05.620 --> 1:55:08.340
 really new and hybridy and awesome.

1:55:08.900 --> 1:55:15.620
 But, you know, and that kind of like guitar based rock I think I've got to go with

1:55:15.620 --> 1:55:17.140
 won't get fooled again by the who.

1:55:18.740 --> 1:55:21.380
 It is such an epic song.

1:55:21.380 --> 1:55:23.220
 It's got so much grandeur to it.

1:55:23.860 --> 1:55:27.380
 It uses the synthesizers that were available at the time.

1:55:27.380 --> 1:55:31.940
 This has got to be, I think, 1972, 73, which are very, very primitive to our ears,

1:55:31.940 --> 1:55:38.340
 but uses them in this hypnotic and beautiful way that I can't imagine somebody with the

1:55:38.340 --> 1:55:43.700
 greatest synth array conceivable by today's technology could do a better job of in the

1:55:43.700 --> 1:55:45.060
 context of that song.

1:55:45.700 --> 1:55:49.140
 And it's, you know, almost operatic.

1:55:49.140 --> 1:55:56.180
 So I would say in that genre, the genre of, you know, rock that would be my nomination.

1:55:56.180 --> 1:55:58.740
 I'm totally in my brain.

1:55:58.740 --> 1:56:04.100
 Pinball Wizard is overriding everything else, but it was so like, I can't even imagine the

1:56:04.100 --> 1:56:04.500
 song.

1:56:04.500 --> 1:56:07.380
 Well, I would say, ironically, with Pinball Wizard.

1:56:07.380 --> 1:56:09.060
 So that came from the movie Tommy.

1:56:09.700 --> 1:56:16.820
 And in the movie, Tommy, the rival of Tommy, the reigning pinball champ was Elton John.

1:56:17.380 --> 1:56:20.500
 And so there are a couple of versions of Pinball Wizard out there.

1:56:20.500 --> 1:56:24.420
 One sung by Roger Daltrey of The Who, which a purist would say, hey, that's the real

1:56:24.420 --> 1:56:25.540
 pinball wizard.

1:56:25.540 --> 1:56:30.740
 But the version that is sung by Elton John in the movie, which is available to those

1:56:30.740 --> 1:56:35.140
 who are ambitious and want to dig for it, that's even better in my mind.

1:56:35.140 --> 1:56:36.100
 Yeah, the covers.

1:56:36.100 --> 1:56:40.100
 And I, for myself, I was thinking, what is the song for me?

1:56:40.820 --> 1:56:41.860
 They answered that question.

1:56:42.900 --> 1:56:45.860
 I think that changes day to day, too.

1:56:45.860 --> 1:56:46.740
 I was realizing that.

1:56:46.740 --> 1:56:55.780
 Of course, but for me, somebody who values lyrics as well and the emotion in the song.

1:56:57.060 --> 1:56:59.940
 By the way, Hallelujah by Leonard Cohen was a close one.

1:56:59.940 --> 1:57:10.900
 But the number one is Johnny Cash's cover of Hurt that is, there's something so powerful

1:57:10.900 --> 1:57:15.140
 about that song, about that cover, about that performance.

1:57:15.140 --> 1:57:17.540
 Maybe another one is the cover of Sound of Silence.

1:57:19.220 --> 1:57:21.700
 Maybe there's something about covers for me.

1:57:21.700 --> 1:57:22.980
 So whose cover sounds?

1:57:22.980 --> 1:57:26.180
 Because Simon and Garfunkel, I think, did the original recording of that, right?

1:57:26.180 --> 1:57:28.020
 So which cover is it that?

1:57:28.020 --> 1:57:31.540
 There's a cover by Disturbed.

1:57:31.540 --> 1:57:35.940
 It's a metal band, which is so interesting because I'm really not into that kind of metal.

1:57:35.940 --> 1:57:38.420
 But he does a pure vocal performance.

1:57:38.420 --> 1:57:41.220
 So he's not doing a metal performance.

1:57:41.220 --> 1:57:44.100
 I would say it's one of the greatest people should see it.

1:57:44.100 --> 1:57:47.300
 It's like 400 million views or something like that.

1:57:48.740 --> 1:57:54.900
 It's probably the greatest live vocal performance I've ever heard is Disturbed covering Sound

1:57:54.900 --> 1:57:55.460
 of Silence.

1:57:55.460 --> 1:57:56.980
 I'll listen to it as soon as I get home.

1:57:56.980 --> 1:58:00.260
 And that song came to life to me in a way that Simon and Garfunkel never did.

1:58:01.300 --> 1:58:07.300
 For me with Simon and Garfunkel, there's not a pain, there's not an anger, there's not

1:58:09.940 --> 1:58:11.700
 power to their performance.

1:58:11.700 --> 1:58:15.140
 It's almost like this melancholy, I don't know.

1:58:15.140 --> 1:58:20.660
 Well, I guess there's a lot of beauty to it, objectively beautiful.

1:58:21.460 --> 1:58:26.340
 I think, I never thought of this until now, but I think if you put entirely different

1:58:26.340 --> 1:58:32.020
 lyrics on top of it, unless they were joyous, which would be weird, it wouldn't necessarily

1:58:32.020 --> 1:58:32.980
 lose that much.

1:58:32.980 --> 1:58:34.900
 There's just a beauty in the harmonizing.

1:58:35.460 --> 1:58:36.580
 It's soft and you're right.

1:58:36.580 --> 1:58:40.500
 It's not dripping with emotion.

1:58:40.500 --> 1:58:48.100
 The vocal performance is not dripping with emotion, it's dripping with technical harmonizing

1:58:48.100 --> 1:58:49.300
 brilliance and beauty.

1:58:50.340 --> 1:58:56.020
 Now, if you compare that to the Disturbed cover or the Johnny Cash's Hurt cover, when

1:58:56.020 --> 1:58:59.780
 you walk away, it's haunting.

1:59:01.140 --> 1:59:02.500
 It stays with you for a long time.

1:59:02.500 --> 1:59:11.540
 There's certain performances that will just stay with you to where, like if you watch

1:59:11.540 --> 1:59:15.700
 people respond to that, and that's certainly how I felt when you listen to that, the Disturbed

1:59:15.700 --> 1:59:20.820
 performance or Johnny Cash Hurt, there's a response to where you just sit there with

1:59:20.820 --> 1:59:24.980
 your mouth open, kind of like paralyzed by it somehow.

1:59:26.260 --> 1:59:31.300
 And I think that's what makes for a great song to where you're just like, it's not

1:59:31.300 --> 1:59:36.500
 that you're like singing along or having fun, that's another way a song could be great,

1:59:36.500 --> 1:59:40.740
 but where you're just like, you're in awe.

1:59:41.940 --> 1:59:50.180
 If we go to listen.com and that whole fascinating era of music in the 90s, transitioning to

1:59:50.180 --> 1:59:58.500
 the aughts, I remember those days, the Napster days, when piracy, from my perspective, allegedly

1:59:58.500 --> 2:00:01.540
 ruled the land.

2:00:01.540 --> 2:00:03.780
 What do you make of that whole era?

2:00:03.780 --> 2:00:08.420
 What are the big, what was, first of all, your experiences of that era and what were

2:00:08.420 --> 2:00:15.140
 the big takeaways in terms of piracy, in terms of what it takes to build a company that succeeds

2:00:15.140 --> 2:00:22.020
 in that kind of digital space, in terms of music, but in terms of anything creative?

2:00:22.020 --> 2:00:27.460
 Well, so for those who don't remember, which is going to be most folks, listen.com created

2:00:27.460 --> 2:00:31.700
 a service called Rhapsody, which is much, much more recognizable to folks because Rhapsody

2:00:31.700 --> 2:00:34.180
 became a pretty big name for reasons that I'll get into in a second.

2:00:34.180 --> 2:00:39.940
 So for people who don't know their early online music history, we were the first company,

2:00:39.940 --> 2:00:46.260
 so I founded, listen, I was a loan founder, and Rhapsody, we were the first service to

2:00:46.260 --> 2:00:51.860
 get full catalog licenses from all the major music labels in order to distribute their

2:00:51.860 --> 2:00:56.420
 music online, and we specifically did it through a mechanism which at the time struck people

2:00:56.420 --> 2:01:01.780
 as exotic and bizarre and kind of incomprehensible, which was unlimited on demand streaming, which

2:01:01.780 --> 2:01:08.180
 of course now it's a model that's been appropriated by Spotify and Apple and many, many others.

2:01:08.180 --> 2:01:10.180
 So we were a pioneer on that front.

2:01:10.180 --> 2:01:16.100
 What was really, really, really hard about doing business in those days was the reaction

2:01:16.100 --> 2:01:22.020
 of the music labels to piracy, which was about 180 degrees opposite of what the reaction

2:01:22.020 --> 2:01:26.820
 quote unquote should have been from the standpoint of preserving their business from piracy.

2:01:26.820 --> 2:01:35.940
 So Napster came along and was a service that enabled people to get near unlimited access

2:01:35.940 --> 2:01:38.420
 to most songs.

2:01:38.420 --> 2:01:43.300
 I mean, truly obscure things could be very hard to find on Napster, but most songs with

2:01:43.300 --> 2:01:50.580
 a relatively simple one click ability to download those songs and have the MP3s on their hard

2:01:50.580 --> 2:01:55.380
 drives, but there was a lot that was very messy about the Napster experience.

2:01:55.380 --> 2:01:59.540
 You might download a really god awful recording of that song.

2:01:59.540 --> 2:02:04.180
 You may download a recording that actually wasn't that song with some prankster putting

2:02:04.180 --> 2:02:06.100
 it up to sort of mess with people.

2:02:06.660 --> 2:02:09.140
 You could struggle to find the song that you're looking for.

2:02:09.140 --> 2:02:13.060
 You could end up finding yourself connected, it was peer to peer.

2:02:13.060 --> 2:02:17.300
 You might randomly find yourself connected to somebody in Bulgaria, doesn't have a very

2:02:17.300 --> 2:02:18.340
 good internet connection.

2:02:18.340 --> 2:02:23.140
 So you might wait 19 minutes only for it to snap, et cetera, et cetera.

2:02:23.140 --> 2:02:27.700
 And our argument to, well, actually let's start with how that hit the music labels.

2:02:27.700 --> 2:02:32.900
 The music labels had been in a very, very comfortable position for many, many decades

2:02:32.900 --> 2:02:41.940
 of essentially being the monopoly providers of a certain subset of artists.

2:02:41.940 --> 2:02:46.740
 Any given label was a monopoly provider of the artists and the recordings that they owned

2:02:46.740 --> 2:02:51.540
 and they could sell it at what turned out to be tremendously favorable rates.

2:02:51.540 --> 2:02:57.860
 In the late era of the CD, you were talking close to $20 for a compact disc that might

2:02:57.860 --> 2:03:02.580
 have one song that you were crazy about and simply needed to own that might actually be

2:03:02.580 --> 2:03:05.380
 glued to 17 other songs that you found to be sure crap.

2:03:05.940 --> 2:03:13.860
 And so the music industry had used the fact that it had this unbelievable leverage and

2:03:13.860 --> 2:03:20.340
 profound pricing power to really get music lovers to the point that they felt very, very

2:03:20.340 --> 2:03:22.500
 misused by the entire situation.

2:03:22.500 --> 2:03:28.820
 Now along comes Napster and music sales start getting gutted with extreme rapidity.

2:03:29.380 --> 2:03:37.460
 And the reaction of the music industry to that was one of shock and absolute fury, which

2:03:37.460 --> 2:03:38.420
 is understandable.

2:03:38.420 --> 2:03:43.620
 I mean, industries do get gutted all the time, but I struggle to think of an analog of an

2:03:43.620 --> 2:03:46.340
 industry that got gutted that rapidly.

2:03:46.340 --> 2:03:51.220
 I mean, we could say that passenger train service certainly got gutted by airlines,

2:03:51.220 --> 2:03:54.900
 but that was a process that took place over decades and decades and decades.

2:03:54.900 --> 2:03:59.300
 It wasn't something that happened, really started showing up in the numbers in a single

2:03:59.300 --> 2:04:04.020
 digit number of months and started looking like an existential threat within a year or

2:04:04.020 --> 2:04:04.580
 two.

2:04:04.580 --> 2:04:10.020
 So the music industry is quite understandably in a state of shock and fury.

2:04:10.020 --> 2:04:11.220
 I don't blame them for that.

2:04:11.780 --> 2:04:18.020
 But then their reaction was catastrophic, both for themselves and almost for people

2:04:18.020 --> 2:04:23.140
 like us who were trying to do the cowboy in the white hat thing.

2:04:23.140 --> 2:04:28.260
 So our response to the music industry was, look, what you need to do to fight piracy,

2:04:28.260 --> 2:04:30.180
 you can't put the genie back in the bottle.

2:04:30.180 --> 2:04:32.500
 You can't switch off the internet.

2:04:32.500 --> 2:04:37.300
 Even if you all shut your eyes and wish very, very, very hard, the internet is not going

2:04:37.300 --> 2:04:38.100
 away.

2:04:38.100 --> 2:04:40.900
 And these peer to peer technologies are genies out of the bottle.

2:04:40.900 --> 2:04:47.300
 And if you don't, whatever you do, don't shut down Napster because if you do, suddenly

2:04:47.300 --> 2:04:51.220
 that technology is going to splinter into 30 different nodes that you'll never, ever

2:04:51.220 --> 2:04:52.180
 be able to shut off.

2:04:52.180 --> 2:04:59.140
 We suggested to them is like, look, what you want to do is to create a massively better

2:04:59.140 --> 2:05:04.260
 experience to piracy, something that's way better, that you sell at a completely reasonable

2:05:04.260 --> 2:05:04.980
 price.

2:05:04.980 --> 2:05:06.420
 And this is what it is.

2:05:06.420 --> 2:05:10.580
 Don't just give people access to that very limited number of songs that they happen to

2:05:10.580 --> 2:05:15.780
 have acquired and paid for or pirated and have on their hard drive.

2:05:15.780 --> 2:05:19.460
 Give them access to all of the music in the world for a simple low price.

2:05:19.460 --> 2:05:22.980
 And obviously, that doesn't sound like a crazy suggestion, I don't think, to anybody's

2:05:22.980 --> 2:05:26.820
 ears today because that is how the majority of music is now being consumed online.

2:05:26.820 --> 2:05:32.660
 But in doing that, you're going to create a much, much better option to this kind of

2:05:32.660 --> 2:05:37.700
 crappy, kind of rickety, kind of buggy process of acquiring MP3s.

2:05:37.700 --> 2:05:44.100
 Now, unfortunately, the music industry was so angry about Napster and so forth that for

2:05:44.100 --> 2:05:48.900
 essentially three and a half years, they folded their arms, stamped their feet, and boycotted

2:05:48.900 --> 2:05:49.780
 the internet.

2:05:49.780 --> 2:05:54.660
 So they basically gave people who were fervently passionate about music and were digitally

2:05:54.660 --> 2:05:57.460
 modern, they gave them basically one choice.

2:05:57.460 --> 2:06:01.780
 If you want to have access to digital music, we, the music industry, insist that you steal

2:06:01.780 --> 2:06:04.420
 it because we are not going to sell it to you.

2:06:04.420 --> 2:06:10.340
 So what that did is it made an entire generation of people morally comfortable with swiping

2:06:10.340 --> 2:06:14.180
 the music because they felt quite pragmatically, well, they're not giving me any choice here.

2:06:14.180 --> 2:06:18.740
 It's like a 20 year old violating the 21 drinking age.

2:06:18.740 --> 2:06:21.860
 If they do that, they're not going to feel like felons.

2:06:21.860 --> 2:06:25.060
 They're going to be like, this is an unreasonable law and I'm skirting it, right?

2:06:25.060 --> 2:06:29.700
 So they make a whole generation of people morally comfortable with swiping music, but

2:06:29.700 --> 2:06:32.180
 also technically adept at it.

2:06:32.180 --> 2:06:37.140
 And when they did shut down Napster and kind of even trickier tools and like tweakier tools

2:06:37.140 --> 2:06:41.540
 like Kazaa and so forth came along, people just figured out how to do it.

2:06:41.540 --> 2:06:48.660
 So by the time they finally, grudgingly, it took years, allowed us to release this experience

2:06:48.660 --> 2:06:53.780
 that we were quite convinced would be better than piracy, we had this enormous hole had

2:06:53.780 --> 2:06:59.620
 been dug where lots of people said, music is a thing that is free and that's morally

2:06:59.620 --> 2:07:01.700
 okay and I know how to get it.

2:07:01.700 --> 2:07:08.660
 And so streaming took many, many, many more years to take off and become the gargantuan

2:07:08.660 --> 2:07:14.820
 thing the juggernaut is today than would have happened if they'd made, pivoted to let's

2:07:14.820 --> 2:07:19.700
 sell a better experience as opposed to demand that people want digital music, steal it.

2:07:19.700 --> 2:07:21.460
 Like what lessons do we draw from that?

2:07:21.460 --> 2:07:26.660
 Cause we're probably in the midst of living through a bunch of similar situations in different

2:07:26.660 --> 2:07:27.460
 domains currently.

2:07:27.460 --> 2:07:28.100
 We just don't know.

2:07:28.100 --> 2:07:30.420
 There's a lot of things in this world that are really painful.

2:07:31.220 --> 2:07:37.220
 Like, I mean, I don't know if you can draw perfect parallels, but fiat money versus cryptocurrency,

2:07:37.220 --> 2:07:42.420
 there's a lot of currently people in power who are kind of very skeptical about cryptocurrency,

2:07:42.420 --> 2:07:43.780
 although that's changing.

2:07:43.780 --> 2:07:45.860
 But it's arguable it's changing way too slowly.

2:07:45.860 --> 2:07:49.780
 There's a lot of people making that argument where there should be a complete like Coinbase

2:07:49.780 --> 2:07:51.620
 and all this stuff switched to that.

2:07:52.660 --> 2:08:00.260
 There's a lot of other domains that where a pivot, like if you pivot now, you're going

2:08:00.260 --> 2:08:04.500
 to win big, but you don't pivot because you're stubborn.

2:08:05.380 --> 2:08:09.380
 And it's so, I mean, like, is this just the way that companies are?

2:08:09.380 --> 2:08:15.300
 A company succeeds initially and then it grows and there's a huge number of employees and

2:08:15.300 --> 2:08:21.540
 managers that don't have the guts or the institutional mechanisms to do the pivot.

2:08:21.540 --> 2:08:22.900
 Is that just the way of companies?

2:08:23.460 --> 2:08:26.500
 Well, I think what happens, I'll use the case of the music industry.

2:08:27.060 --> 2:08:32.580
 There was an economic model that had put food on the table and paid for marble lobbies and

2:08:32.580 --> 2:08:37.140
 seven and even eight figure executive salaries for many, many decades, which was the physical

2:08:37.140 --> 2:08:38.580
 collection of music.

2:08:38.580 --> 2:08:44.820
 And then you start talking about something like unlimited streaming and it seems so ephemeral

2:08:44.820 --> 2:08:50.020
 and like such a long shot that people start worrying about cannibalizing their own business

2:08:50.020 --> 2:08:54.500
 and they lose sight of the fact that something illicit is cannibalizing their business at

2:08:54.500 --> 2:08:56.020
 an extraordinarily fast rate.

2:08:56.020 --> 2:08:58.500
 And so if they don't do it themselves, they're doomed.

2:08:58.500 --> 2:09:02.660
 I mean, we used to put slides in front of these folks, this is really funny, where we

2:09:02.660 --> 2:09:08.180
 said, okay, let's assume Rhapsody, we want it to be 9.99 a month and we want it to be

2:09:08.180 --> 2:09:13.700
 12 months, so it's $120 a year from the budget of a music lover.

2:09:13.700 --> 2:09:18.340
 And then we were also able to get reasonably accurate statistics that showed how many CDs

2:09:18.340 --> 2:09:23.380
 per year the average person who bothered to collect music, which was not all people, actually

2:09:23.380 --> 2:09:24.180
 bought.

2:09:24.180 --> 2:09:29.620
 And it was overwhelmingly clear that the average CD buyer spends a hell of a lot less than

2:09:29.620 --> 2:09:32.820
 $120 a year on music.

2:09:32.820 --> 2:09:35.220
 This is a revenue expansion, blah, blah, blah.

2:09:35.220 --> 2:09:40.820
 But all they could think of, and I'm not saying this in a pejorative or patronizing way, I

2:09:40.820 --> 2:09:44.500
 don't blame them, they've grown up in this environment for decades, all they could think

2:09:44.500 --> 2:09:47.540
 of was the incredible margins that they had on a CD.

2:09:48.340 --> 2:09:55.060
 And they would say, well, if this CD, by the mechanism that you guys are proposing, the

2:09:55.060 --> 2:10:00.980
 CD that I'm selling for $17.99, somebody would need to stream those songs.

2:10:00.980 --> 2:10:04.100
 We were talking about a penny of playback then, it's less than that now that the record

2:10:04.100 --> 2:10:05.380
 labels get paid.

2:10:05.380 --> 2:10:10.500
 But would have to stream songs from that 1,799 times, it's never gonna happen.

2:10:10.500 --> 2:10:13.700
 So they were just sort of stuck in the model of this, but it's like, no, dude, but they're

2:10:13.700 --> 2:10:15.140
 gonna spend money on all this other stuff.

2:10:15.140 --> 2:10:17.060
 So I think people get very hung up on that.

2:10:17.060 --> 2:10:22.500
 I mean, another example is really the taxi industry was not monolithic, like the music

2:10:22.500 --> 2:10:23.060
 labels.

2:10:23.060 --> 2:10:26.100
 There was a whole bunch of fleets and a whole bunch of cities, very, very fragmented, it's

2:10:26.100 --> 2:10:27.140
 an imperfect analogy.

2:10:27.140 --> 2:10:34.020
 But nonetheless, imagine if the taxi industry writ large upon seeing Uber said, oh my God,

2:10:34.020 --> 2:10:39.220
 people wanna be able to hail things easily, cheaply, they don't wanna mess with cash,

2:10:39.220 --> 2:10:43.060
 they wanna know how many minutes it's gonna be, they wanna know the fare in advance, and

2:10:43.060 --> 2:10:46.340
 they want a much bigger fleet than what we've got.

2:10:46.340 --> 2:10:52.740
 If the taxi industry had rolled out something like that with the branding of yellow taxis,

2:10:52.740 --> 2:10:58.660
 universally known and kind of loved by Americans and expanded their fleet in a necessary manner,

2:10:58.660 --> 2:11:00.660
 I don't think Uber or Lyft ever would have gotten a foothold.

2:11:01.940 --> 2:11:08.020
 But the problem there was that real economics in the taxi industry wasn't with fares, it

2:11:08.020 --> 2:11:10.660
 was with the scarcity of medallions.

2:11:10.660 --> 2:11:16.740
 And so the taxi fleets, in many cases, owned gazillions of medallions whose value came

2:11:16.740 --> 2:11:18.500
 from their very scarcity.

2:11:18.500 --> 2:11:21.060
 So they simply couldn't pivot to that.

2:11:21.060 --> 2:11:25.860
 So I think you end up having these vested interests with economics that aren't necessarily

2:11:25.860 --> 2:11:32.020
 visible to outsiders who get very, very reluctant to disrupt their own model, which is why it

2:11:32.020 --> 2:11:34.660
 ends up coming from the outside so frequently.

2:11:34.660 --> 2:11:39.220
 So you know what it takes to build a successful startup, but you're also an investor in a

2:11:39.220 --> 2:11:40.580
 lot of successful startups.

2:11:41.140 --> 2:11:42.900
 Let me ask for advice.

2:11:43.860 --> 2:11:48.180
 What do you think it takes to build a successful startup by way of advice?

2:11:48.180 --> 2:11:51.620
 JS Well, I think it starts, I mean, everything

2:11:51.620 --> 2:11:54.500
 starts and even ends with the founder.

2:11:54.500 --> 2:11:59.620
 And so I think it's really, really important to look at the founder's motivations and their

2:11:59.620 --> 2:12:01.460
 sophistication about what they're doing.

2:12:02.660 --> 2:12:08.180
 In almost all cases that I'm familiar with and have thought hard about, you've had a

2:12:08.180 --> 2:12:15.300
 founder who was deeply, deeply inculcated in the domain of technology that they were

2:12:15.300 --> 2:12:16.420
 taking on.

2:12:16.420 --> 2:12:20.100
 Now, what's interesting about that is you could say, no, wait, how is that possible

2:12:20.100 --> 2:12:21.540
 because there's so many young founders?

2:12:21.540 --> 2:12:26.100
 When you look at young founders, they're generally coming out of very nascent emerging

2:12:26.100 --> 2:12:31.860
 fields of technology where simply being present and accounted for and engaged in the community

2:12:31.860 --> 2:12:36.820
 for a period of even months is enough time to make them very, very deeply inculcated.

2:12:36.820 --> 2:12:39.460
 I mean, you look at Marc Andreessen and Netscape.

2:12:41.140 --> 2:12:45.300
 Marc had been doing visual web browsers when Netscape had been founded for what, a year

2:12:45.300 --> 2:12:51.380
 and a half, but he'd created the first one in Mosaic when he was an undergrad.

2:12:51.380 --> 2:12:58.340
 And the commercial internet was pre nascent in 1994 when Netscape was founded.

2:12:58.340 --> 2:13:00.580
 So there's somebody who's very, very deep in their domain.

2:13:00.580 --> 2:13:04.340
 Mark Zuckerberg also, social networking, very deep in his domain, even though it was

2:13:04.340 --> 2:13:05.300
 nascent at the time.

2:13:05.860 --> 2:13:07.460
 Lots of people doing crypto stuff.

2:13:07.460 --> 2:13:14.820
 I mean, 10 years ago, even seven or eight years ago, by being a really, really vehement

2:13:14.820 --> 2:13:19.700
 and engaged participant in the crypto ecosystem, you could be an expert in that.

2:13:19.700 --> 2:13:23.620
 You look, however, at more established industries, take Salesforce.com.

2:13:23.620 --> 2:13:26.660
 Salesforce automation, pretty mature field when it got started.

2:13:26.660 --> 2:13:28.100
 Who's the executive and the founder?

2:13:28.820 --> 2:13:34.020
 Marc Benioff, who has spent 13 years at Oracle and was an investor in Siebel Systems, which

2:13:34.020 --> 2:13:36.580
 ended up being Salesforce's main competition.

2:13:36.580 --> 2:13:43.620
 So more established, you need the entrepreneur to be very, very deep in the technology and

2:13:43.620 --> 2:13:50.500
 the culture of the space because you need that entrepreneur, that founder to have just

2:13:50.500 --> 2:13:55.780
 an unbelievably accurate intuitive sense for where the puck is going.

2:13:56.420 --> 2:13:58.980
 And that only comes from being very deep.

2:13:58.980 --> 2:14:01.220
 So that is sort of factor number one.

2:14:01.220 --> 2:14:08.260
 And the next thing is that that founder needs to be charismatic and or credible, or ideally

2:14:08.260 --> 2:14:14.340
 both in exactly the right ways to be able to attract a team that is bought into that

2:14:14.340 --> 2:14:19.220
 vision and is bought into that founder's intuitions being correct and not just the team,

2:14:19.220 --> 2:14:21.380
 obviously, but also the investors.

2:14:21.380 --> 2:14:25.540
 So it takes a certain personality type to pull that off.

2:14:25.540 --> 2:14:31.540
 Then the next thing I'm still talking about the founder is a relentlessness and indeed

2:14:31.540 --> 2:14:39.540
 a monomania to put this above things that might rationally, should perhaps rationally

2:14:39.540 --> 2:14:46.500
 supersede it for a period of time to just relentlessly pivot when pivoting is called

2:14:46.500 --> 2:14:48.020
 for and it's always called for.

2:14:48.020 --> 2:14:53.300
 I mean, think of even very successful companies like how many times did Facebook pivot?

2:14:53.940 --> 2:14:58.180
 Newsfeed was something that was completely alien to the original version of Facebook

2:14:58.180 --> 2:15:00.020
 and came foundationally important.

2:15:00.020 --> 2:15:03.860
 How many times did Google, how many times at any given, how many times has Apple pivoted?

2:15:04.820 --> 2:15:09.220
 That founder energy and DNA when the founder moves on the DNA that's been inculcated

2:15:09.220 --> 2:15:15.220
 with a company has to have that relentlessness and that ability to pivot and pivot and pivot

2:15:15.220 --> 2:15:18.100
 without being worried about sacred cows.

2:15:18.100 --> 2:15:21.300
 And then the last thing I'll say about the founder before I get to the rest of the team

2:15:21.300 --> 2:15:28.100
 and that'll be mercifully brief is the founder has to be obviously a really great

2:15:28.100 --> 2:15:32.820
 hirer but just important a very good firer.

2:15:32.820 --> 2:15:37.860
 And firing is a horrific experience for both people involved in it.

2:15:37.860 --> 2:15:40.100
 It is a wrenching emotional experience.

2:15:40.660 --> 2:15:49.060
 And being good at realizing when this particular person is damaging the interests of the company

2:15:49.060 --> 2:15:56.660
 and the team and the shareholders and having the intestinal fortitude to have that conversation

2:15:56.660 --> 2:16:01.060
 and make it happen is something that most people don't have in them.

2:16:01.620 --> 2:16:07.300
 And it's something that needs to be developed in most people or maybe some people have it

2:16:07.300 --> 2:16:08.340
 naturally.

2:16:08.340 --> 2:16:13.940
 But without that ability, that will take an A plus organization into B minus range very,

2:16:13.940 --> 2:16:14.580
 very quickly.

2:16:15.220 --> 2:16:19.140
 And so that's all what needs to be present in the founder.

2:16:19.140 --> 2:16:20.660
 Can I just say?

2:16:20.660 --> 2:16:21.220
 Sure.

2:16:21.220 --> 2:16:22.820
 How damn good you are, Rob.

2:16:22.820 --> 2:16:24.100
 That was brilliant.

2:16:24.100 --> 2:16:29.780
 The one thing that was kind of really kind of surprising to me is having a deep technical

2:16:29.780 --> 2:16:37.380
 knowledge because I think the way you expressed it, which is that allows you to be really

2:16:37.380 --> 2:16:40.660
 honest with the capabilities of what like what's possible.

2:16:45.220 --> 2:16:47.700
 Of course, you're often trying to do the impossible.

2:16:48.740 --> 2:16:51.860
 But in order to do the impossible, you have to be quote unquote impossible.

2:16:51.860 --> 2:16:54.660
 But you have to be honest with what is actually possible.

2:16:54.660 --> 2:16:57.620
 And it doesn't necessarily have to be the technical competence.

2:16:57.620 --> 2:17:02.660
 It's got to be, in my view, just a complete immersion in that emerging market.

2:17:02.660 --> 2:17:06.180
 And so I can imagine there are a couple of people out there who have started really good

2:17:06.180 --> 2:17:12.500
 crypto projects who themselves are right in the code, but they're immersed in the culture

2:17:12.500 --> 2:17:16.820
 and through the culture and a deep understanding of what's happening and what's not happening.

2:17:16.820 --> 2:17:23.460
 They can get a good intuition of what's possible, but the very first hire, I mean, a great way

2:17:23.460 --> 2:17:28.980
 to solve that is to have a technical co founder and dual founder companies have become extremely

2:17:28.980 --> 2:17:30.180
 common for that reason.

2:17:30.900 --> 2:17:34.980
 And if you're not doing that and you're not the technical person, but you are the founder,

2:17:35.940 --> 2:17:43.780
 you've got to be really great at hiring a very damn good technical person very, very fast.

2:17:43.780 --> 2:17:49.140
 Can I on the founder ask you, is it possible to do this alone?

2:17:50.100 --> 2:17:54.660
 There's so many people giving advice and saying that it's impossible to do the first few steps,

2:17:54.660 --> 2:17:57.220
 not impossible, but much more difficult to do it alone.

2:17:58.260 --> 2:18:02.900
 If we were to take the journey, especially in the software world where there's not significant

2:18:02.900 --> 2:18:10.260
 investment required for it to build something up, is it possible to go to a prototype to

2:18:10.260 --> 2:18:14.260
 something that essentially works and already has a huge number of customers alone?

2:18:14.820 --> 2:18:15.140
 Sure.

2:18:15.700 --> 2:18:20.740
 There are lots and lots of loan founder companies out there that have made an incredible difference.

2:18:21.620 --> 2:18:25.780
 I mean, I'm not certainly putting rhapsody in the league of Spotify.

2:18:25.780 --> 2:18:29.620
 We were too early to be Spotify, but we did an awful lot of innovation.

2:18:29.620 --> 2:18:33.220
 And then after the company sold and ended up in the hands of real networks and MTV,

2:18:33.780 --> 2:18:35.700
 you know, got to millions of subs, right?

2:18:35.700 --> 2:18:40.580
 I was a loan founder and I studied Arabic and Middle Eastern history undergrad,

2:18:40.580 --> 2:18:42.340
 so I definitely wasn't very, very technical.

2:18:42.340 --> 2:18:44.820
 But yeah, loan founders can absolutely work.

2:18:44.820 --> 2:18:51.140
 And the advantage of a loan founder is you don't have the catastrophic potential

2:18:51.140 --> 2:18:53.060
 of a falling out between founders.

2:18:53.060 --> 2:19:00.100
 I mean, two founders who fall out with each other badly can rip a company to shreds because

2:19:00.100 --> 2:19:04.260
 they both have an enormous amount of equity and enormous amount of power.

2:19:04.260 --> 2:19:06.580
 And the capital structure is a result of that.

2:19:06.580 --> 2:19:12.420
 They both have an enormous amount of moral authority with the team as a result of each

2:19:12.420 --> 2:19:13.620
 having that founder role.

2:19:14.260 --> 2:19:21.220
 And I have witnessed over the years many, many situations in which companies have been shredded

2:19:21.220 --> 2:19:27.380
 or have suffered near fatal blows because of a falling out between founders.

2:19:27.380 --> 2:19:30.420
 And the more founders you add, the more risky that becomes.

2:19:30.420 --> 2:19:36.100
 I don't think there should ever almost, I mean, you never say never, but multiple founders

2:19:36.100 --> 2:19:44.180
 beyond two is such an unstable and potentially treacherous situation that I would never,

2:19:44.180 --> 2:19:45.940
 ever recommend going beyond two.

2:19:45.940 --> 2:19:51.540
 But I do see value in the non technical sort of business and market and outside minded

2:19:51.540 --> 2:19:54.100
 founder teaming up with the technical founder.

2:19:54.900 --> 2:19:58.740
 There is a lot of merit to that, but there's a lot of danger in that less those two blow

2:19:58.740 --> 2:19:59.220
 apart.

2:19:59.220 --> 2:20:00.820
 Was it lonely for you?

2:20:00.820 --> 2:20:01.700
 Unbelievably.

2:20:01.700 --> 2:20:02.820
 And that's the drawback.

2:20:02.820 --> 2:20:10.500
 I mean, if you're a lone founder, there is no other person that you can sit down with

2:20:10.500 --> 2:20:15.620
 and tackle problems and talk them through who has precisely or nearly precisely your

2:20:15.620 --> 2:20:16.740
 alignment of interests.

2:20:17.460 --> 2:20:23.300
 Your most trusted board member is likely an investor and therefore at the end of the

2:20:23.300 --> 2:20:26.900
 day has the interest of preferred stock in mind, not common stock.

2:20:26.900 --> 2:20:33.860
 Your most trusted VP, who might own a very significant stake in the company, doesn't

2:20:33.860 --> 2:20:35.860
 own anywhere near your stake in the company.

2:20:35.860 --> 2:20:40.900
 And so their long term interests may well be in getting the right level of experience

2:20:40.900 --> 2:20:44.180
 and credibility necessary to peel off and start their own company.

2:20:44.180 --> 2:20:51.380
 Or their interests might be aligned with jumping ship and setting up with a different

2:20:51.380 --> 2:20:54.500
 company, whether it's a rival or one in a completely different space.

2:20:54.500 --> 2:20:57.780
 So, yeah, being a lone founder is a spectacularly lonely thing.

2:20:57.780 --> 2:20:59.220
 And that's a major downside to it.

2:20:59.220 --> 2:21:00.180
 What about mentorship?

2:21:00.180 --> 2:21:01.780
 Because you're a mentor to a lot of people.

2:21:03.380 --> 2:21:09.220
 Can you find an alleviation to that loneliness in the space of ideas with a good mentor?

2:21:09.220 --> 2:21:11.620
 With a good mentor or like a mentor who's mentoring you?

2:21:11.620 --> 2:21:12.100
 Yeah.

2:21:12.100 --> 2:21:15.620
 Yeah, you can a great deal, particularly if it's somebody who's been through this very

2:21:15.620 --> 2:21:21.860
 process and has navigated it successfully and cares enough about you and your well being

2:21:21.860 --> 2:21:25.060
 to give you beautifully unvarnished advice.

2:21:25.060 --> 2:21:26.740
 That can be a huge, huge thing.

2:21:26.740 --> 2:21:28.180
 That can assuage things a great deal.

2:21:28.900 --> 2:21:35.300
 And I had a board member who was not an investor, who basically played that role for me to a

2:21:35.300 --> 2:21:35.940
 great degree.

2:21:35.940 --> 2:21:39.060
 He came in maybe halfway through the company's history, though.

2:21:39.060 --> 2:21:41.700
 I would have needed that the most in the very earliest days.

2:21:43.460 --> 2:21:47.780
 Yeah, the loneliness, that's the whole journey of life.

2:21:47.780 --> 2:21:49.620
 We're always alone, alone together.

2:21:49.620 --> 2:21:50.260
 Mm hmm.

2:21:51.300 --> 2:21:52.500
 It pays to embrace that.

2:21:54.180 --> 2:21:58.740
 You were saying that there might be something outside of the founder that's also that you

2:21:58.740 --> 2:22:00.500
 were promising to be brief on.

2:22:00.500 --> 2:22:00.820
 Yeah.

2:22:00.820 --> 2:22:02.820
 OK, so we talked about the founder.

2:22:02.820 --> 2:22:04.500
 You were asking what makes a great startup.

2:22:04.500 --> 2:22:04.820
 Yes.

2:22:04.820 --> 2:22:09.140
 And great founder is thing number one, but then thing number two, and it's ginormous,

2:22:09.140 --> 2:22:09.860
 is a great team.

2:22:10.420 --> 2:22:16.660
 And so I said so much about the founder because one hopes or one believes that a founder who

2:22:16.660 --> 2:22:22.020
 is a great hirer is going to be hiring people and in charge of critical functions like

2:22:22.020 --> 2:22:25.860
 engineering and marketing and biz dev and sales and so forth, who themselves are great

2:22:25.860 --> 2:22:26.740
 hirers.

2:22:26.740 --> 2:22:30.820
 But what needs to radiate from the founder into the team that might be a little bit different

2:22:30.820 --> 2:22:32.820
 from what's in the gene code of the founder?

2:22:33.380 --> 2:22:40.580
 The team needs to be fully bought in to the, you know, the intuitions and the vision of

2:22:40.580 --> 2:22:41.220
 the founder.

2:22:41.220 --> 2:22:41.540
 Great.

2:22:41.540 --> 2:22:42.260
 We've got that.

2:22:42.260 --> 2:22:50.020
 But the team needs to have a slightly different thing, which is, you know, it's 99% obsession

2:22:50.740 --> 2:22:57.540
 is execution, is to relentlessly hit the milestones, hit the objectives, hit the quarterly

2:22:57.540 --> 2:22:58.020
 goals.

2:22:58.500 --> 2:23:00.820
 That is, you know, 1% vision.

2:23:00.820 --> 2:23:02.900
 You don't want to lose that.

2:23:02.900 --> 2:23:10.020
 But execution machines, you know, people who have a demonstrated ability and a demonstrated

2:23:10.020 --> 2:23:14.100
 focus on, yeah, I go from point to point to point.

2:23:14.100 --> 2:23:20.500
 I try to beat and raise expectations relentlessly, never fall short, and, you know, both sort

2:23:20.500 --> 2:23:22.660
 of blaze and follow the path.

2:23:22.660 --> 2:23:25.940
 Not that the path is going to, I mean, blaze the trail as well.

2:23:25.940 --> 2:23:31.780
 I mean, a good founder is going to trust that VP of sales to have a better sense of what

2:23:31.780 --> 2:23:34.820
 it takes to build out that organization, what the milestones be.

2:23:34.820 --> 2:23:38.100
 And it's going to be kind of a dialogue amongst those at the top.

2:23:38.100 --> 2:23:42.260
 But, you know, execution obsession in the team is the next thing.

2:23:42.260 --> 2:23:47.140
 Yeah, there's some sense where the founder, you know, you talk about sort of the space

2:23:47.140 --> 2:23:51.780
 of ideas, like first principles thinking, asking big difficult questions of like future

2:23:51.780 --> 2:23:55.940
 trajectories or having a big vision and big picture dreams.

2:23:55.940 --> 2:24:03.140
 You can almost be a dreamer, it feels like, when you're like not the founder, but in the

2:24:03.140 --> 2:24:08.260
 space of sort of leadership.

2:24:08.260 --> 2:24:12.980
 But when it gets to the ground floor, there has to be execution, there has to be hitting

2:24:12.980 --> 2:24:15.220
 deadlines.

2:24:15.220 --> 2:24:18.100
 And sometimes those are attention.

2:24:18.100 --> 2:24:28.340
 There's something about dreams that are attention with the pragmatic nature of execution.

2:24:28.340 --> 2:24:32.100
 Not dreams, but sort of ambitious vision.

2:24:32.100 --> 2:24:35.780
 And those have to be, I suppose, coupled.

2:24:35.780 --> 2:24:42.900
 The vision in the leader and the execution in the software world, that would be the programmer

2:24:42.900 --> 2:24:45.060
 or the designer.

2:24:45.060 --> 2:24:46.460
 Absolutely.

2:24:46.460 --> 2:24:51.740
 Amongst many other things, you're an incredible conversationalist, a podcast, you host a podcast

2:24:51.740 --> 2:24:52.740
 called After On.

2:24:52.740 --> 2:24:58.700
 I mean, there's a million questions I want to ask you here, but one at the highest level,

2:24:58.700 --> 2:25:00.660
 what do you think makes for a great conversation?

2:25:00.660 --> 2:25:07.100
 I would say two things, one of two things, and ideally both of two things.

2:25:07.100 --> 2:25:16.280
 One is if something is beautifully architected, whether it's done deliberately and methodically

2:25:16.280 --> 2:25:21.820
 and willfully, as when I do it, or whether that just emerges from the conversation.

2:25:21.820 --> 2:25:26.260
 But something that's beautifully architected, that can create something that's incredibly

2:25:26.260 --> 2:25:32.420
 powerful and memorable, or something where there's just extraordinary chemistry.

2:25:32.420 --> 2:25:35.180
 And so with All In, or I'll go way back.

2:25:35.180 --> 2:25:41.140
 You might remember the NPR show Car Talk, I couldn't care less about auto mechanics

2:25:41.140 --> 2:25:42.140
 myself.

2:25:42.140 --> 2:25:43.140
 Yeah, that's right.

2:25:43.140 --> 2:25:47.940
 But I love that show because the banter between those two guys was just beyond, it was without

2:25:47.940 --> 2:25:50.100
 any parallel, right?

2:25:50.100 --> 2:25:54.940
 And some kind of edgy podcasts like Red Scare is just really entertaining to me because

2:25:54.940 --> 2:25:58.940
 the banter between the women on that show is just so good, and All In and that kind

2:25:58.940 --> 2:25:59.940
 of thing.

2:25:59.940 --> 2:26:04.860
 So I think it's a combination of sort of the arc and the chemistry.

2:26:04.860 --> 2:26:11.460
 And I think because the arc can be so important, that's why very, very highly produced podcasts

2:26:11.460 --> 2:26:15.580
 like This American Life, obviously a radio show, but I think of a podcast because that's

2:26:15.580 --> 2:26:21.680
 how I always consume it, or Criminal, or a lot of what Wondery does and so forth.

2:26:21.680 --> 2:26:26.480
 That is real documentary making, and that requires a big team and a big budget relative

2:26:26.480 --> 2:26:31.340
 to the kinds of things you and I do, but nonetheless, then you got that arc, and that can be really,

2:26:31.340 --> 2:26:32.340
 really compelling.

2:26:32.340 --> 2:26:37.660
 But if we go back to conversation, I think it's a combination of structure and chemistry.

2:26:37.660 --> 2:26:43.860
 Yeah, and I've actually personally have lost, I used to love This American Life, and for

2:26:43.860 --> 2:26:51.300
 some reason because it lacks the possibility of magic, it's engineered magic.

2:26:51.300 --> 2:26:53.020
 I've fallen off of it myself as well.

2:26:53.020 --> 2:26:58.340
 I mean, when I fell madly in love with it during the aughts, it was the only thing going.

2:26:58.340 --> 2:27:04.380
 They were really smart to adopt podcasting as a distribution mechanism early.

2:27:04.380 --> 2:27:09.300
 But yeah, I think that maybe there's a little bit less magic there now because I think they

2:27:09.300 --> 2:27:14.140
 have agendas other than necessarily just delighting their listeners with quirky stories, which

2:27:14.140 --> 2:27:17.700
 I think is what it was all about back in the day and some other things.

2:27:17.700 --> 2:27:22.380
 Is there like a memorable conversation that you've had on the podcast, whether it was

2:27:22.380 --> 2:27:29.420
 because it was wild and fun or one that was exceptionally challenging, maybe challenging

2:27:29.420 --> 2:27:31.380
 to prepare for, that kind of thing?

2:27:31.380 --> 2:27:35.660
 Is there something that stands out in your mind that you can draw an insight from?

2:27:35.660 --> 2:27:42.220
 Yeah, I mean, this no way diminishes the episodes that will not be the answer to these two questions,

2:27:42.220 --> 2:27:46.900
 but an example of something that was really, really challenging to prepare for was George

2:27:46.900 --> 2:27:48.040
 Church.

2:27:48.040 --> 2:27:52.380
 So as I'm sure you know and as I'm sure many of your listeners know, he is one of the absolute

2:27:52.380 --> 2:27:55.060
 leading lights in the field of synthetic biology.

2:27:55.060 --> 2:27:57.460
 He's also unbelievably prolific.

2:27:57.460 --> 2:28:02.640
 His lab is large and has all kinds of efforts have spun out of that.

2:28:02.640 --> 2:28:08.140
 And what I wanted to make my George Church episode about was, first of all, grounding

2:28:08.140 --> 2:28:12.460
 people into what is this thing called Symbio.

2:28:12.460 --> 2:28:17.380
 And that required me to learn a hell of a lot more about Symbio than I knew going into

2:28:17.380 --> 2:28:18.380
 it.

2:28:18.380 --> 2:28:23.140
 So there was just this very broad, I mean, I knew much more than the average person going

2:28:23.140 --> 2:28:27.140
 into that episode, but there was this incredible breadth of grounding that I needed to get

2:28:27.140 --> 2:28:29.300
 myself in the domain.

2:28:29.300 --> 2:28:34.100
 And then George does so many interesting things, there's so many interesting things emitting

2:28:34.100 --> 2:28:38.780
 from his lab that, you know, and he and I had a really good dialogue, he was a great

2:28:38.780 --> 2:28:41.340
 guide going into it.

2:28:41.340 --> 2:28:47.420
 Minnowing it down to the three to four that I really wanted us to focus on to create a

2:28:47.420 --> 2:28:51.940
 sense of wonder and magic in the listener of what could be possible from this very broad

2:28:51.940 --> 2:28:54.700
 spectrum domain, that was a doozy of a challenge.

2:28:54.700 --> 2:28:57.860
 That was a tough, tough, tough one to prepare for.

2:28:57.860 --> 2:29:04.940
 Now, in terms of something that was just wild and fun, unexpected, I mean, by the time we

2:29:04.940 --> 2:29:07.400
 sat down to interview, I knew where we were going to go.

2:29:07.400 --> 2:29:15.180
 But just in terms of the idea space, Don Hoffman, yeah, so Don Hoffman is, again, some listeners

2:29:15.180 --> 2:29:19.280
 probably know because he's, I think I was the first podcaster to interview him.

2:29:19.280 --> 2:29:25.060
 I'm sure some of your listeners are familiar with him, but he has this unbelievably contrarian

2:29:25.060 --> 2:29:33.980
 take on the nature of reality, but it is contrarian in a way that all the ideas are highly internally

2:29:33.980 --> 2:29:38.820
 consistent and snap together in a way that's just delightful.

2:29:38.820 --> 2:29:46.080
 And it seems as radically violating of our intuitions and as radically violating of the

2:29:46.080 --> 2:29:49.500
 probable nature of reality as anything that one can encounter.

2:29:49.500 --> 2:29:54.900
 But an analogy that he uses, which is very powerful, which is what intuition could possibly

2:29:54.900 --> 2:30:00.760
 be more powerful than the notion that there is a single unitary direction called down.

2:30:00.760 --> 2:30:05.260
 When we're on this big flat thing for which there is a thing called down.

2:30:05.260 --> 2:30:10.340
 And we all know, I mean, that's the most intuitive thing that one could probably think of.

2:30:10.340 --> 2:30:12.420
 And we all know that that ain't true.

2:30:12.420 --> 2:30:18.980
 So my conversation with Don Hoffman was just wild and full of plot twists and interesting

2:30:18.980 --> 2:30:19.980
 stuff.

2:30:19.980 --> 2:30:25.220
 And the interesting thing about the wildness of his ideas, it's to me at least as a listener,

2:30:25.220 --> 2:30:35.020
 coupled with, he's a good listener and he empathizes with the people who challenge his

2:30:35.020 --> 2:30:36.020
 ideas.

2:30:36.020 --> 2:30:39.580
 Like what's a better way to phrase that?

2:30:39.580 --> 2:30:44.580
 He is a welcoming of challenge in a way that creates a really fun conversation.

2:30:44.580 --> 2:30:45.580
 Oh, totally.

2:30:45.580 --> 2:30:46.580
 Yeah.

2:30:46.580 --> 2:30:52.900
 He loves a parry or a jab, whatever the word is at his argument.

2:30:52.900 --> 2:30:54.020
 He honors it.

2:30:54.020 --> 2:31:03.700
 He's a very, very gentle and noncombatative soul, but then he is very good and takes great

2:31:03.700 --> 2:31:10.220
 evident joy in responding to that in a way that expands your understanding of his thinking.

2:31:10.220 --> 2:31:15.380
 Let me as a small tangent of tying up together our previous conversation about listening.com

2:31:15.380 --> 2:31:20.720
 and streaming and Spotify and the world of podcasting.

2:31:20.720 --> 2:31:25.580
 So we've been talking about this magical medium of podcasting.

2:31:25.580 --> 2:31:32.840
 I have a lot of friends at Spotify in the high positions of Spotify as well.

2:31:32.840 --> 2:31:41.500
 I worry about Spotify and podcasting and the future of podcasting in general that moves

2:31:41.500 --> 2:31:49.400
 podcasting in the place of maybe walled gardens of sorts.

2:31:49.400 --> 2:31:55.300
 Since you've had a foot in both worlds, have a foot in both worlds, do you worry as well

2:31:55.300 --> 2:31:56.860
 about the future of podcasting?

2:31:56.860 --> 2:31:57.860
 Yeah.

2:31:57.860 --> 2:32:05.660
 I think walled gardens are really toxic to the medium that they start balkanizing.

2:32:05.660 --> 2:32:09.500
 So to take an example, I'll take two examples.

2:32:09.500 --> 2:32:15.620
 With music, it was a very, very big deal that at Rhapsody we were the first company to get

2:32:15.620 --> 2:32:20.620
 full catalog licenses from all back then there were five major music labels and also hundreds

2:32:20.620 --> 2:32:25.040
 and hundreds of indies because you needed to present the listener with a sense that

2:32:25.040 --> 2:32:31.220
 basically everything is there and there is essentially no friction to discovering that

2:32:31.220 --> 2:32:36.860
 which is new and you can wander this realm and all you really need is a good map, whether

2:32:36.860 --> 2:32:41.020
 it is something that somebody, the editorial team assembled or a good algorithm or whatever

2:32:41.020 --> 2:32:43.580
 it is, but a good map to wander this domain.

2:32:43.580 --> 2:32:50.500
 When you start walling things off, A, you undermine the joy of friction free discovery,

2:32:50.500 --> 2:32:55.620
 which is an incredibly valuable thing to deliver to your customer, both from a business standpoint

2:32:55.620 --> 2:33:01.380
 and simply from a humanistic standpoint of do you want to bring delight to people?

2:33:01.380 --> 2:33:06.080
 But it also creates an incredible opening vector for piracy.

2:33:06.080 --> 2:33:10.700
 And so something that's very different from the Rhapsody slash Spotify slash et cetera

2:33:10.700 --> 2:33:14.580
 like experience is what we have now in video.

2:33:14.580 --> 2:33:20.180
 Like wow, is that show on Hulu, is it on Netflix, is it on something like IFC channel, is it

2:33:20.180 --> 2:33:23.580
 on Discovery Plus, is it here, is it there?

2:33:23.580 --> 2:33:30.740
 And the more frustration and toe stubbing that people encounter when they are seeking

2:33:30.740 --> 2:33:35.740
 something and they're already paying a very respectable amount of money per month to have

2:33:35.740 --> 2:33:39.860
 access to content and they can't find it, the more that happens, the more people are

2:33:39.860 --> 2:33:43.060
 going to be driven to piracy solutions like to hell with it.

2:33:43.060 --> 2:33:45.900
 Never know where I'm going to find something, I never know what it's going to cost.

2:33:45.900 --> 2:33:50.180
 Oftentimes really interesting things are simply unavailable.

2:33:50.180 --> 2:33:53.260
 That surprises me the number of times that I've been looking for things I don't even

2:33:53.260 --> 2:33:59.940
 think are that obscure that are just, it says not available in your geography, period, mister.

2:33:59.940 --> 2:34:01.660
 So I think that that's a mistake.

2:34:01.660 --> 2:34:07.780
 And then the other thing is for podcasters and lovers of podcasting, we should want to

2:34:07.780 --> 2:34:16.980
 resist this walled garden thing because A, it does smother this friction free or eradicate

2:34:16.980 --> 2:34:21.780
 this friction free discovery unless you want to sign up for lots of different services.

2:34:21.780 --> 2:34:28.580
 And also dims the voice of somebody who might be able to have a far, far, far bigger impact

2:34:28.580 --> 2:34:32.580
 by reaching far more neurons with their ideas.

2:34:32.580 --> 2:34:36.140
 I'm going to use an example from I guess it was probably the 90s or maybe it was the

2:34:36.140 --> 2:34:42.740
 aughts of Howard Stern, who had the biggest megaphone or maybe the second biggest after

2:34:42.740 --> 2:34:46.300
 Oprah megaphone in popular culture.

2:34:46.300 --> 2:34:50.020
 And because he was syndicated on hundreds and hundreds and hundreds of radio stations

2:34:50.020 --> 2:34:53.460
 at a time when terrestrial broadcast was the main thing people listened to in their car,

2:34:53.460 --> 2:34:54.940
 no more obviously.

2:34:54.940 --> 2:34:59.780
 But when he decided to go over to satellite radio, I can't remember if it was XM or Sirius,

2:34:59.780 --> 2:35:01.820
 maybe they'd already merged at that point.

2:35:01.820 --> 2:35:07.660
 But when he did that, he made, you know, totally his right to do it, a financial calculation

2:35:07.660 --> 2:35:11.100
 that they were offering him a nine figure sum to do that.

2:35:11.100 --> 2:35:14.740
 But his audience, because not a lot of people were subscribing to satellite radio at that

2:35:14.740 --> 2:35:19.220
 point, his audience probably collapsed by, I wouldn't be surprised if it was as much

2:35:19.220 --> 2:35:20.960
 as 95%.

2:35:20.960 --> 2:35:27.480
 And so the influence that he had on the culture and his ability to sort of shape conversation

2:35:27.480 --> 2:35:30.580
 and so forth just got muted.

2:35:30.580 --> 2:35:37.340
 Yeah, and also there's a certain sense, especially in modern times, where the walled gardens

2:35:37.340 --> 2:35:48.460
 naturally lead to, I don't know if there's a term for it, but people who are not creatives

2:35:48.460 --> 2:35:51.580
 starting to have power over the creatives.

2:35:51.580 --> 2:35:52.580
 Right.

2:35:52.580 --> 2:35:58.640
 And even if they don't stifle it, if they're providing, you know, incentives within the

2:35:58.640 --> 2:36:06.340
 platform to shape, shift, or, you know, even completely mutate or distort the show, I mean,

2:36:06.340 --> 2:36:12.100
 imagine somebody has got, you know, a reasonably interesting idea for a podcast and they get

2:36:12.100 --> 2:36:15.940
 signed up with, let's say Spotify, and Spotify is going to give them financing to get the

2:36:15.940 --> 2:36:17.700
 thing spun up.

2:36:17.700 --> 2:36:18.700
 And that's great.

2:36:18.700 --> 2:36:23.920
 And Spotify is going to give them a certain amount of really, you know, powerful placement,

2:36:23.920 --> 2:36:27.440
 you know, within the visual field of listeners.

2:36:27.440 --> 2:36:29.140
 But Spotify has conditions for that.

2:36:29.140 --> 2:36:34.820
 They say, look, you know, we think that your podcast will be much more successful if you

2:36:34.820 --> 2:36:37.940
 dumb it down about 60%.

2:36:37.940 --> 2:36:44.220
 If you add some, you know, silly, dirty jokes, if you do this, you do that.

2:36:44.220 --> 2:36:48.840
 And suddenly the person who is dependent upon Spotify for permission to come into existence

2:36:48.840 --> 2:36:52.780
 and is really dependent, really wants to please them, you know, to get that money in, to get

2:36:52.780 --> 2:36:55.100
 that placement, really wants to be successful.

2:36:55.100 --> 2:37:00.780
 And all of a sudden you're having a dialogue between a complete non creative, some marketing,

2:37:00.780 --> 2:37:05.420
 you know, sort of data analytic person at Spotify and a creative that's going to shape

2:37:05.420 --> 2:37:10.480
 what that show is, you know, so that could be much more common.

2:37:10.480 --> 2:37:16.220
 And ultimately having the aggregate, an even bigger impact than, you know, the cancellation,

2:37:16.220 --> 2:37:20.100
 let's say if somebody who says the wrong word or voices the wrong idea, I mean, that's kind

2:37:20.100 --> 2:37:25.860
 of what you have, not kind of, that's what you have with film and TV is that so much

2:37:25.860 --> 2:37:31.100
 influence is exerted over the storyline and the plots and the character arcs and all kinds

2:37:31.100 --> 2:37:35.900
 of things by executives who are completely alien to the experience and the skill set

2:37:35.900 --> 2:37:40.180
 of being a show runner in television, being a director in film that, you know, is meant

2:37:40.180 --> 2:37:43.860
 to like, oh, we can't piss off the Chinese market here or we can't say that or we need

2:37:43.860 --> 2:37:48.880
 to have, you know, cast members that have precisely these demographics reflected or

2:37:48.880 --> 2:37:54.100
 whatever it is that, you know, and obviously despite that extraordinary, at least TV shows

2:37:54.100 --> 2:37:59.980
 are now being made, um, you know, in terms of film, I think the quality has, has nosedived

2:37:59.980 --> 2:38:03.380
 of the average, let's say, say American film coming out of a major studio.

2:38:03.380 --> 2:38:07.640
 The average quality and my view has nosedived over the past decade as it's kind of, everything's

2:38:07.640 --> 2:38:13.260
 gotta be a superhero franchise, but you know, great stuff gets made despite that.

2:38:13.260 --> 2:38:19.920
 But I have to assume that in some cases, at least in perhaps many cases, greater stuff

2:38:19.920 --> 2:38:23.660
 would be made if there was less interference from non creative executives.

2:38:23.660 --> 2:38:27.420
 It's like the flip side of that though, and this is, was the pitch of Spotify because

2:38:27.420 --> 2:38:34.260
 I've heard their pitch is Netflix from everybody I've heard that I've spoken with about Netflix

2:38:34.260 --> 2:38:36.020
 is they actually empower the creator.

2:38:36.020 --> 2:38:41.100
 I don't know what the heck they do, but they do a good job of giving creators, even the

2:38:41.100 --> 2:38:46.100
 crazy ones like Tim Dillon, like Joe Rogan, like comedians, freedom to be their crazy

2:38:46.100 --> 2:38:47.300
 selves.

2:38:47.300 --> 2:38:54.120
 And the result is like some of the greatest television, some of the greatest cinema, whatever

2:38:54.120 --> 2:38:55.860
 you call it, ever made.

2:38:55.860 --> 2:38:56.860
 True.

2:38:56.860 --> 2:38:57.860
 Right.

2:38:57.860 --> 2:38:58.860
 And I don't know what the heck they're doing.

2:38:58.860 --> 2:38:59.860
 It's a relative thing.

2:38:59.860 --> 2:39:00.860
 It's not able from what I understand.

2:39:00.860 --> 2:39:01.860
 It's a relative thing.

2:39:01.860 --> 2:39:07.900
 They're interfering far, far, far less than, you know, NBC or, you know, AMC would have

2:39:07.900 --> 2:39:08.900
 interfered.

2:39:08.900 --> 2:39:12.420
 It's a relative thing, and obviously they're the ones writing the checks and they're the

2:39:12.420 --> 2:39:13.420
 ones giving the platforms.

2:39:13.420 --> 2:39:16.660
 They've every right to their own influence, obviously.

2:39:16.660 --> 2:39:21.780
 But my understanding is that they're relatively way more hands off and that has had a demonstrable

2:39:21.780 --> 2:39:23.300
 effect because I agree.

2:39:23.300 --> 2:39:29.220
 Some of the greatest, you know, video produced video content of all time, an incredibly inordinate

2:39:29.220 --> 2:39:32.900
 percentage of that is coming out from Netflix in just a few years when the history of cinema

2:39:32.900 --> 2:39:34.740
 goes back many, many decades.

2:39:34.740 --> 2:39:41.500
 And Spotify wants to be that for podcasting, and I hope they do become that for podcasting,

2:39:41.500 --> 2:39:47.700
 but I'm wearing my skeptical goggles or skeptical hat, whatever the heck it is, because it's

2:39:47.700 --> 2:39:55.100
 not easy to do and it requires, it requires letting go of power, giving power to the creatives.

2:39:55.100 --> 2:40:01.180
 It requires pivoting, which large companies, even as innovative as Spotify is, still now

2:40:01.180 --> 2:40:05.580
 a large company, pivoting into a whole new space is very tricky and difficult.

2:40:05.580 --> 2:40:08.300
 So I'm skeptical, but hopeful.

2:40:08.300 --> 2:40:13.060
 What advice would you give to a young person today about life, about career?

2:40:13.060 --> 2:40:18.980
 We talked about startups, we talked about music, we talked about the end of human civilization.

2:40:18.980 --> 2:40:23.660
 Is there advice you would give to a young person today, maybe in college, maybe in high

2:40:23.660 --> 2:40:27.140
 school about their life?

2:40:27.140 --> 2:40:34.340
 Let's see, there's so many domains you can advise on, and I'm not going to give advice

2:40:34.340 --> 2:40:40.120
 on life because I fear that I would drift into hallmark bromides that really wouldn't

2:40:40.120 --> 2:40:43.540
 be all that distinctive, and they might be entirely true.

2:40:43.540 --> 2:40:48.320
 Sometimes the greatest insights about life turn out to be the kinds of things you'd see

2:40:48.320 --> 2:40:50.540
 on a hallmark card, so I'm going to steer clear of that.

2:40:50.540 --> 2:40:57.900
 On a career level, one thing that I think is unintuitive but unbelievably powerful is

2:40:57.900 --> 2:41:07.420
 to focus not necessarily on being in the top sliver of 1% in excelling at one domain that's

2:41:07.420 --> 2:41:14.140
 important and valuable, but to think in terms of intersections of two domains, which are

2:41:14.140 --> 2:41:19.620
 rare but valuable, and there's a couple reasons for this.

2:41:19.620 --> 2:41:25.020
 The first is in an incredibly competitive world that is so much more competitive than

2:41:25.020 --> 2:41:28.900
 it was when I was coming out of school, radically more competitive than when I was coming out

2:41:28.900 --> 2:41:34.060
 of school, to navigate your way to the absolute pinnacle of any domain.

2:41:34.060 --> 2:41:40.340
 Let's say you want to be really, really great at Python, pick a language, whatever it is.

2:41:40.340 --> 2:41:44.940
 You want to be one of the world's greatest Python developers, JavaScript, whatever your

2:41:44.940 --> 2:41:45.940
 language is.

2:41:45.940 --> 2:41:46.940
 Hopefully it's not Cobalt.

2:41:46.940 --> 2:41:53.980
 By the way, if you listen to this, I am actually looking for a Cobalt expert to interview because

2:41:53.980 --> 2:41:58.140
 I find the language fascinating, and there's not many of them, so please, if you know a

2:41:58.140 --> 2:42:02.380
 world expert in Cobalt or Fortran, both, actually.

2:42:02.380 --> 2:42:03.580
 Or if you are one.

2:42:03.580 --> 2:42:05.660
 Or if you are one, please email me.

2:42:05.660 --> 2:42:06.660
 Yeah.

2:42:06.660 --> 2:42:10.620
 So, I mean, if you're going out there and you want to be in the top sliver 1% of Python

2:42:10.620 --> 2:42:13.180
 developers, it's a very, very difficult thing to do, particularly if you want to be number

2:42:13.180 --> 2:42:14.940
 one in the world, something like that.

2:42:14.940 --> 2:42:23.020
 And I'll use an analogy as I had a friend in college who was on a track and indeed succeeded

2:42:23.020 --> 2:42:29.300
 at that to become an Olympic medalist, and I think it was 100 meter breaststroke.

2:42:29.300 --> 2:42:37.540
 And he mortgaged a significant percentage of his college life to that goal, or I should

2:42:37.540 --> 2:42:39.980
 say dedicated or invested or whatever you wanted to say.

2:42:39.980 --> 2:42:44.260
 But he didn't participate in a lot of the social, a lot of the late night, a lot of

2:42:44.260 --> 2:42:48.180
 the this, a lot of the that, because he was training so much.

2:42:48.180 --> 2:42:50.740
 And obviously, he also wanted to keep up with his academics.

2:42:50.740 --> 2:42:55.660
 And at the end of the day, the story has a happy ending in that he did medal in that.

2:42:55.660 --> 2:43:00.020
 Bronze, not gold, but holy cow, anybody who gets an Olympic medal, that's an extraordinary

2:43:00.020 --> 2:43:01.020
 thing.

2:43:01.020 --> 2:43:05.140
 And at that moment, he was one of the top three people on earth at that thing.

2:43:05.140 --> 2:43:07.380
 But wow, how hard to do that.

2:43:07.380 --> 2:43:12.020
 How many thousands of other people went down that path and made similar sacrifices and

2:43:12.020 --> 2:43:13.020
 didn't get there.

2:43:13.020 --> 2:43:14.740
 It's very, very hard to do that.

2:43:14.740 --> 2:43:19.020
 Whereas, and I'll use a personal example.

2:43:19.020 --> 2:43:23.620
 When I came out of business school, I went to a good business school and learned the

2:43:23.620 --> 2:43:25.780
 things that were there to be learned.

2:43:25.780 --> 2:43:29.340
 And I came out and I entered a world with lots of MBAs.

2:43:29.340 --> 2:43:30.500
 Harvard Business School, by the way.

2:43:30.500 --> 2:43:32.980
 Okay, yes, it was Harvard, it's true.

2:43:32.980 --> 2:43:36.860
 You're the first person who went there who didn't say where you went, which is beautiful.

2:43:36.860 --> 2:43:37.860
 I appreciate that.

2:43:37.860 --> 2:43:41.620
 It's one of the greatest business schools in the world.

2:43:41.620 --> 2:43:44.420
 It's a whole nother fascinating conversation about that world.

2:43:44.420 --> 2:43:45.420
 But anyway, yes.

2:43:45.420 --> 2:43:51.180
 But anyway, so I learned the things that you learn getting an MBA from a top program.

2:43:51.180 --> 2:43:56.620
 And I entered a world that had hundreds of thousands of people who had MBAs, probably

2:43:56.620 --> 2:44:00.340
 hundreds of thousands who have them from top 10 programs.

2:44:00.340 --> 2:44:04.900
 So I was not particularly great at being an MBA person.

2:44:04.900 --> 2:44:09.420
 I was inexperienced relative to most of them and there were a lot of them, but it was okay

2:44:09.420 --> 2:44:12.980
 MBA person, right, newly minted.

2:44:12.980 --> 2:44:20.380
 But then as it happened, I found my way into working on the commercial internet in 1994.

2:44:20.380 --> 2:44:25.380
 So I went to a, at the time, giant hot computing company called Silicon Graphics, which had

2:44:25.380 --> 2:44:30.820
 enough heft and enough head count that they could take on and experienced MBAs and try

2:44:30.820 --> 2:44:33.380
 to train them in the world of Silicon Valley.

2:44:33.380 --> 2:44:38.940
 But within that company that had an enormous amount of surface area and was touching a

2:44:38.940 --> 2:44:46.660
 lot of areas and had unbelievably smart people at the time, it was not surprising that SGI

2:44:46.660 --> 2:44:51.340
 started doing really interesting and innovative and trailblazing stuff on the internet before

2:44:51.340 --> 2:44:52.660
 almost anybody else.

2:44:52.660 --> 2:44:55.840
 And part of the reason was that our founder, Jim Clark, went off to cofound Netscape with

2:44:55.840 --> 2:44:56.840
 Mark Andreessen.

2:44:56.840 --> 2:44:58.860
 So the whole company is like, wait, what was that?

2:44:58.860 --> 2:45:00.740
 What's this commercial internet thing?

2:45:00.740 --> 2:45:01.940
 So I ended up in that group.

2:45:01.940 --> 2:45:09.500
 Now in terms of being a commercial internet person or a worldwide web person, again, I

2:45:09.500 --> 2:45:14.420
 was in that case, barely credentialed, I couldn't write a stitch of code, but I had a pretty

2:45:14.420 --> 2:45:22.140
 good mind for grasping the business and cultural significance of this transition.

2:45:22.140 --> 2:45:25.540
 And this was, again, we were talking earlier about emerging areas.

2:45:25.540 --> 2:45:29.540
 Within a few months, you know, I was in the relatively top echelon of people in terms

2:45:29.540 --> 2:45:33.740
 of just sheer experience, because like, let's say it was five months into the program, there

2:45:33.740 --> 2:45:37.140
 were only so many people who'd been doing worldwide web stuff commercially for five

2:45:37.140 --> 2:45:38.620
 months, you know?

2:45:38.620 --> 2:45:43.580
 And then what was interesting though was the intersection of those two things.

2:45:43.580 --> 2:45:49.700
 The commercial web, as it turned out, grew into an unbelievable vastness.

2:45:49.700 --> 2:45:57.480
 And so by being a pretty good, okay web person and a pretty good, okay MBA person, that intersection

2:45:57.480 --> 2:46:03.420
 put me in a very rare group, which was web oriented MBAs.

2:46:03.420 --> 2:46:08.380
 And in those early days, you could probably count on your fingers the number of people

2:46:08.380 --> 2:46:12.140
 who came out of really competitive programs who were doing stuff full time on the internet.

2:46:12.140 --> 2:46:17.480
 And there was a greater appetite for great software developers in the internet domain,

2:46:17.480 --> 2:46:24.300
 but there was an appetite and a real one and a rapidly growing one for MBA thinkers who

2:46:24.300 --> 2:46:29.300
 were also seasoned and networked in the emerging world of the commercial worldwide web.

2:46:29.300 --> 2:46:37.500
 And so finding an intersection of two things you can be pretty good at, but is a rare intersection

2:46:37.500 --> 2:46:43.500
 and a special intersection is probably a much easier way to make yourself distinguishable

2:46:43.500 --> 2:46:48.740
 and in demand from the world than trying to be world class at this one thing.

2:46:48.740 --> 2:46:53.300
 So in the intersection is where there's to be discovered opportunity and success.

2:46:53.300 --> 2:46:54.620
 That's really interesting.

2:46:54.620 --> 2:46:58.100
 There's actually more intersection of fields and fields themselves, right?

2:46:58.100 --> 2:47:02.500
 So yeah, I mean, I'll give you kind of a funny hypothetical here, but it's one I've been

2:47:02.500 --> 2:47:04.580
 thinking about a little bit.

2:47:04.580 --> 2:47:06.580
 There's a lot of people in crypto right now.

2:47:06.580 --> 2:47:11.980
 It'd be hard to be in the top percentile of crypto people, whether it comes from just

2:47:11.980 --> 2:47:15.660
 having a sheer grasp of the industry, a great network within the industry, technological

2:47:15.660 --> 2:47:18.440
 skills, whatever you want to call it.

2:47:18.440 --> 2:47:23.380
 And then there's this parallel world and orthogonal world called crop insurance.

2:47:23.380 --> 2:47:25.420
 And I'm sure that's a big world.

2:47:25.420 --> 2:47:29.540
 Crop insurance is a very, very big deal, particularly in the wealthy and industrialized world where

2:47:29.540 --> 2:47:35.140
 people through sophisticated financial markets, rule of law and large agricultural concerns

2:47:35.140 --> 2:47:37.900
 that are worried about that.

2:47:37.900 --> 2:47:42.780
 Somewhere out there is somebody who is pretty crypto savvy, but probably not top 1%, but

2:47:42.780 --> 2:47:47.600
 also has kind of been in the crop insurance world and understands that a hell of a lot

2:47:47.600 --> 2:47:52.340
 better than almost anybody who's ever had anything to do with cryptocurrency.

2:47:52.340 --> 2:47:58.420
 And so I think that decentralized finance, DeFi, one of the interesting and I think very

2:47:58.420 --> 2:48:03.380
 world positive things that I think it's almost inevitably will be bringing to the world is

2:48:03.380 --> 2:48:06.820
 crop insurance for small holding farmers.

2:48:06.820 --> 2:48:12.180
 I mean, people who have tiny, tiny plots of land in places like India, et cetera, where

2:48:12.180 --> 2:48:17.600
 there is no crop insurance available to them because just the financial infrastructure

2:48:17.600 --> 2:48:19.140
 doesn't exist.

2:48:19.140 --> 2:48:24.980
 But it's highly imaginable that using Oracle networks that are trusted outside deliverers

2:48:24.980 --> 2:48:29.280
 of factual information about rainfall in a particular area, you can start giving drought

2:48:29.280 --> 2:48:31.300
 insurance to folks like this.

2:48:31.300 --> 2:48:37.180
 The right person to come up with that idea is not a crypto whiz who doesn't know a blasted

2:48:37.180 --> 2:48:39.300
 thing about small holding farmers.

2:48:39.300 --> 2:48:43.460
 The right person to come up with that is not a crop insurance whiz who isn't quite sure

2:48:43.460 --> 2:48:47.580
 what Bitcoin is, but somebody occupies that intersection.

2:48:47.580 --> 2:48:52.260
 That's just one of gazillion examples of things that are going to come along for somebody

2:48:52.260 --> 2:48:57.540
 who occupies the right intersection of skills, but isn't necessarily the number one person

2:48:57.540 --> 2:48:59.720
 at either one of those expertises.

2:48:59.720 --> 2:49:05.340
 That's making me kind of wonder about my own little things that I'm average at and seeing

2:49:05.340 --> 2:49:09.340
 where the intersections that could be exploited.

2:49:09.340 --> 2:49:10.420
 That's pretty profound.

2:49:10.420 --> 2:49:15.980
 So we talked quite a bit about the end of the world and how we're both optimistic about

2:49:15.980 --> 2:49:18.260
 us figuring our way out.

2:49:18.260 --> 2:49:27.760
 Unfortunately, for now at least, both you and I are going to die one day, way too soon.

2:49:27.760 --> 2:49:28.760
 First of all, that sucks.

2:49:28.760 --> 2:49:29.760
 It does.

2:49:29.760 --> 2:49:41.460
 I mean, one, I'd like to ask if you ponder your own mortality, how does that kind of,

2:49:41.460 --> 2:49:45.860
 what kind of wisdom inside does it give you about your own life?

2:49:45.860 --> 2:49:50.300
 And broadly, do you think about your life and what the heck it's all about?

2:49:50.300 --> 2:49:57.060
 Yeah, with respect to pondering mortality, I do try to do that as little as possible

2:49:57.060 --> 2:50:00.060
 because there's not a lot I can do about it.

2:50:00.060 --> 2:50:01.060
 But it's inevitably there.

2:50:01.060 --> 2:50:07.000
 And I think that what it does when you think about it in the right way is it makes you

2:50:07.000 --> 2:50:13.940
 realize how unbelievably rare and precious the moments that we have here are, and therefore

2:50:13.940 --> 2:50:18.300
 how consequential the decisions that we make about how to spend our time are.

2:50:18.300 --> 2:50:25.540
 You know, like, do you do those 17 nagging emails or do you have dinner with somebody

2:50:25.540 --> 2:50:28.880
 who's really important to you who haven't seen in three and a half years?

2:50:28.880 --> 2:50:33.780
 If you had an infinite expanse of time in front of you, you might well rationally conclude

2:50:33.780 --> 2:50:37.340
 I'm going to do those emails because collectively they're rather important.

2:50:37.340 --> 2:50:41.160
 And I have tens of thousands of years to catch up with my buddy, Tim.

2:50:41.160 --> 2:50:48.100
 But I think the scarcity of the time that we have helps us choose the right things if

2:50:48.100 --> 2:50:54.160
 we're tuned to that and we're attuned to the context that mortality puts over the consequence

2:50:54.160 --> 2:50:56.980
 of every decision we make of how to spend our time.

2:50:56.980 --> 2:51:00.520
 That doesn't mean that we're all very good at it, it doesn't mean I'm very good at it.

2:51:00.520 --> 2:51:06.380
 But it does add a dimension of choice and significance to everything that we elect to

2:51:06.380 --> 2:51:07.380
 do.

2:51:07.380 --> 2:51:10.500
 It's kind of funny that you say you try to think about it as little as possible.

2:51:10.500 --> 2:51:14.180
 I would venture to say you probably think about the end of human civilization more than

2:51:14.180 --> 2:51:15.580
 you do about your own life.

2:51:15.580 --> 2:51:16.960
 You're probably right.

2:51:16.960 --> 2:51:19.700
 Because that feels like a problem that could be solved.

2:51:19.700 --> 2:51:20.700
 Right.

2:51:20.700 --> 2:51:22.500
 Whereas the end of my own life can't be solved.

2:51:22.500 --> 2:51:23.500
 Well, I don't know.

2:51:23.500 --> 2:51:28.860
 I mean, there's transhumanists who have incredible optimism about near or intermediate future

2:51:28.860 --> 2:51:32.700
 therapies that could really, really change human lifespan.

2:51:32.700 --> 2:51:37.020
 I really hope that they're right, but I don't have a whole lot to add to that project because

2:51:37.020 --> 2:51:39.980
 I'm not a life scientist myself.

2:51:39.980 --> 2:51:44.460
 I'm in part also afraid of immortality.

2:51:44.460 --> 2:51:48.820
 Not as much, but close to as I'm afraid of death itself.

2:51:48.820 --> 2:51:55.220
 So it feels like the things that give us meaning give us meaning because of the scarcity that

2:51:55.220 --> 2:51:56.220
 surrounds it.

2:51:56.220 --> 2:51:57.220
 Agreed.

2:51:57.220 --> 2:52:01.620
 I'm almost afraid of having too much of stuff.

2:52:01.620 --> 2:52:02.620
 Yeah.

2:52:02.620 --> 2:52:07.940
 Although, if there was something that said, this can expand your enjoyable wellspan or

2:52:07.940 --> 2:52:11.540
 lifespan by 75 years, I'm all in.

2:52:11.540 --> 2:52:19.460
 Well, part of the reason I wanted to not do a startup, really the only thing that worries

2:52:19.460 --> 2:52:24.780
 me about doing a startup is if it becomes successful.

2:52:24.780 --> 2:52:31.540
 Because of how much I dream, how much I'm driven to be successful, that there will not

2:52:31.540 --> 2:52:39.020
 be enough silence in my life, enough scarcity to appreciate the moments I appreciate now

2:52:39.020 --> 2:52:42.380
 as deeply as I appreciate them now.

2:52:42.380 --> 2:52:48.540
 There's a simplicity to my life now that it feels like you might disappear with success.

2:52:48.540 --> 2:52:52.140
 I wouldn't say might.

2:52:52.140 --> 2:52:59.820
 I think if you start a company that has ambitious investors, ambitious for the returns that

2:52:59.820 --> 2:53:05.860
 they'd like to see, that has ambitious employees, ambitious for the career trajectories they

2:53:05.860 --> 2:53:15.020
 want to be on and so forth, and is driven by your own ambition, there's a profound monogamy

2:53:15.020 --> 2:53:18.020
 to that.

2:53:18.020 --> 2:53:24.300
 It is very, very hard to carve out time to be creative, to be peaceful, to be so forth

2:53:24.300 --> 2:53:30.620
 because of with every new employee that you hire, that's one more mouth to feed.

2:53:30.620 --> 2:53:35.260
 With every new investor that you take on, that's one more person to whom you really

2:53:35.260 --> 2:53:38.100
 do want to deliver great returns.

2:53:38.100 --> 2:53:43.580
 As the valuation ticks up, the threshold to delivering great returns for your investors

2:53:43.580 --> 2:53:45.580
 always rises.

2:53:45.580 --> 2:53:54.460
 There is an extraordinary monogamy to being a founder CEO above all for the first few

2:53:54.460 --> 2:53:59.420
 years and first in people's minds could be as many as 10 or 15.

2:53:59.420 --> 2:54:07.600
 But I guess the fundamental calculation is whether the passion for the vision is greater

2:54:07.600 --> 2:54:09.020
 than the cost you'll pay.

2:54:09.020 --> 2:54:10.020
 Right.

2:54:10.020 --> 2:54:11.400
 It's all opportunity cost.

2:54:11.400 --> 2:54:16.620
 It's all opportunity cost in terms of time and attention and experience.

2:54:16.620 --> 2:54:21.100
 And some things like I'm, everyone's different, but I'm less calculating some things you just

2:54:21.100 --> 2:54:22.100
 can't help.

2:54:22.100 --> 2:54:23.100
 Sometimes you just dive in.

2:54:23.100 --> 2:54:24.260
 Oh yeah.

2:54:24.260 --> 2:54:28.180
 I mean you can do balance sheets all you want on this versus that and what's the right.

2:54:28.180 --> 2:54:32.060
 I mean I've done it in the past and it's never worked.

2:54:32.060 --> 2:54:36.780
 It's always been like, okay, what's my gut screaming at me to do?

2:54:36.780 --> 2:54:42.260
 But about the meaning of life, you ever think about that?

2:54:42.260 --> 2:54:43.260
 Yeah.

2:54:43.260 --> 2:54:48.220
 I mean, this is where I'm going to go all hallmarking on you, but I think that there's

2:54:48.220 --> 2:54:57.320
 a few things and one of them is certainly love and the love that we experience and feel

2:54:57.320 --> 2:55:05.700
 and cause to well up in others is something that's just so profound and goes beyond almost

2:55:05.700 --> 2:55:08.260
 anything else that we can do.

2:55:08.260 --> 2:55:13.020
 And whether that is something that lies in the past, like maybe there was somebody that

2:55:13.020 --> 2:55:19.340
 you were dating and loved very profoundly in college and haven't seen in years, I don't

2:55:19.340 --> 2:55:24.380
 think the significance of that love is any way diminished by the fact that it had a notional

2:55:24.380 --> 2:55:25.540
 beginning and end.

2:55:25.540 --> 2:55:30.460
 The fact is that you experience that and you trigger that in somebody else and that happened.

2:55:30.460 --> 2:55:35.260
 And it doesn't have to be, certainly it doesn't have to be love of romantic partners alone.

2:55:35.260 --> 2:55:39.700
 It's family members, it's love between friends, it's love between creatures.

2:55:39.700 --> 2:55:47.620
 I had a dog for 10 years who passed away a while ago and experienced unbelievable love

2:55:47.620 --> 2:55:48.620
 with her.

2:55:48.620 --> 2:55:52.020
 It can be love of that which you create and we were talking about the flow states that

2:55:52.020 --> 2:55:57.180
 we enter and the pride or lack of pride or in the Minsky case, your hatred of that which

2:55:57.180 --> 2:55:58.180
 you've done.

2:55:58.180 --> 2:56:05.940
 But nonetheless, the creations that we make and whether it's the love or the joy or the

2:56:05.940 --> 2:56:11.580
 engagement or the perspective shift that that cascades into other minds, I think that's

2:56:11.580 --> 2:56:13.680
 a big, big, big part of the meaning of life.

2:56:13.680 --> 2:56:18.740
 It's not something that everybody participates in necessarily, although I think we all do

2:56:18.740 --> 2:56:25.740
 at least in a very local level by the example that we set, by the interactions that we have.

2:56:25.740 --> 2:56:31.900
 But for people who create works that travel far and reach people they'll never meet, that

2:56:31.900 --> 2:56:36.700
 reach countries they'll never visit, that reach people perhaps that come along and come

2:56:36.700 --> 2:56:40.740
 across their ideas or their works or their stories or their aesthetic creations of other

2:56:40.740 --> 2:56:46.860
 sorts long after they're dead, I think that's really, really big part of the fabric of the

2:56:46.860 --> 2:56:50.380
 meaning of life.

2:56:50.380 --> 2:57:01.100
 So all these things like love and creation, I think really is what it's all about.

2:57:01.100 --> 2:57:03.820
 And part of love is also the loss of it.

2:57:03.820 --> 2:57:13.380
 There's a Louis episode with Louis C.K. where an old gentleman is giving him advice that

2:57:13.380 --> 2:57:18.100
 sometimes the sweetest parts of love is when you lose it and you remember it, sort of you

2:57:18.100 --> 2:57:21.020
 reminisce on the loss of it.

2:57:21.020 --> 2:57:27.380
 And there's some aspect in which, and I have many of those in my own life, that almost

2:57:27.380 --> 2:57:34.100
 like the memories of it and the intensity of emotion you still feel about it is like

2:57:34.100 --> 2:57:37.020
 the sweetest part.

2:57:37.020 --> 2:57:40.900
 You're like, after saying goodbye, you relive it.

2:57:40.900 --> 2:57:45.420
 So that goodbye is also a part of love.

2:57:45.420 --> 2:57:47.220
 The loss of it is also a part of love.

2:57:47.220 --> 2:57:49.580
 I don't know, it's back to that scarcity.

2:57:49.580 --> 2:57:56.180
 I won't say the loss is the best part personally, but it definitely is an aspect of it.

2:57:56.180 --> 2:58:03.100
 And the grief you might feel about something that's gone makes you realize what a big deal

2:58:03.100 --> 2:58:06.900
 it was.

2:58:06.900 --> 2:58:14.100
 Speaking of which, this particular journey we went on together come to an end.

2:58:14.100 --> 2:58:16.540
 So I have to say goodbye and I hate saying goodbye.

2:58:16.540 --> 2:58:18.100
 Rob, this is truly an honor.

2:58:18.100 --> 2:58:20.500
 I've really been a big fan.

2:58:20.500 --> 2:58:24.180
 People should definitely check out your podcast, your Master What You Do in the conversation

2:58:24.180 --> 2:58:26.120
 space, in the writing space.

2:58:26.120 --> 2:58:29.820
 It's been an incredible honor that you would show up here and spend this time with me.

2:58:29.820 --> 2:58:30.940
 I really, really appreciate it.

2:58:30.940 --> 2:58:35.780
 Well, it's been a huge honor to be here as well, and also a fan in heaven for a long

2:58:35.780 --> 2:58:36.780
 time.

2:58:36.780 --> 2:58:40.180
 Thanks for listening to this conversation with Rob Reed.

2:58:40.180 --> 2:58:46.340
 And thank you to Athletic Greens, Belcampo, Fundrise, and NetSuite.

2:58:46.340 --> 2:58:49.380
 Check them out in the description to support this podcast.

2:58:49.380 --> 2:58:52.580
 And now, let me leave you with some words from Plato.

2:58:52.580 --> 2:58:55.700
 We can easily forgive a child who's afraid of the dark.

2:58:55.700 --> 2:59:00.900
 The real tragedy of life is when men are afraid of the light.

2:59:00.900 --> 2:59:12.340
 Thank you for listening and hope to see you next time.

