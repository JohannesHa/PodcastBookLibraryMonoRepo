 The following is a conversation with Kai Fu Lee. He's the chairman and CEO of Cinovation Ventures that manages a $2 billion dual currency investment fund with a focus on developing the next generation of Chinese high tech companies. He's the former president of Google China and the founder of what is now called Microsoft Research Asia, an institute that trained many of the artificial intelligence leaders in China, including CTOs or AI execs at Baidu, Tencent, Alibaba, Lenovo, and Huawei. He was named one of the 100 most influential people in the world by Time Magazine. He's the author of seven bestselling books in Chinese and most recently, the New York Times bestseller called AI Superpowers, China, Silicon Valley, and the New World Order. He has unparalleled experience in working across major tech companies and governments and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman. And now, here's my conversation with Kaifu Li. I immigrated from Russia to US when I was 13. You immigrated to US at about the same age. The Russian people, the American people, the Chinese people each have a certain soul, a spirit that permeates throughout the generations. So maybe it's a little bit of a poetic question, but could you describe your sense of what defines the Chinese soul? I think the Chinese soul of people today, right, we're talking about people who have had centuries of burden because of the poverty that the country has gone through, and suddenly shined with hope of prosperity in the past 40 years as China opened up and embraced market economy. And undoubtedly, there are two sets of pressures on the people, that of the tradition, that of facing difficult situations, and that of hope of wanting to be the first to become successful and wealthy. So that's a very strong hunger and a strong desire and strong work ethic that drives China forward. And is there roots to not just this generation, but before that's deeper than just the new economic developments? Is there something that's unique to China that you could speak to that's in the people? Yeah, well, the Chinese tradition is about excellence, dedication, and results. And the Chinese exams and study subjects in schools have traditionally started from memorizing 10,000 characters, not an easy task to start with. And further by memorizing his historic philosopher's literature poetry. So it really is probably the strongest rote learning mechanism created to make sure people had good memory and remember things extremely well. That's, I think at the same time, suppresses the breakthrough innovation and also enhances the speed execution get results. And that I think characterizes the historic basis of China. That's interesting, because there's echoes of that in Russian education as well as rote memorization. So you have to memorize a lot of poetry. I mean, there's just an emphasis on perfection in all forms that's not conducive to perhaps what you're speaking to, which is creativity. But you think that kind of education holds back the innovative spirit that you might see in the United States? Well, it holds back the breakthrough innovative spirits that we see in the United States, but it does not hold back the valuable execution oriented, result oriented value creating engines, which we see China being very successful. So is there a difference between a Chinese AI engineer today and an American AI engineer, perhaps rooted in the culture that we just talked about or the education or the very soul of the people or no? And what would your advice be to each if there's a difference? Well, there's a lot that's similar because AI is about mastering sciences, about using known technologies and trying new things, but it's also about picking from many parts of possible networks to use and different types of parameters to tune. And that part is somewhat rote. And it is also, as anyone who's built AI products can tell you a lot about cleansing the data because AI runs better with more data and data is generally unstructured, errorful and unclean. And the effort to clean the data is immense. So I think the better part of American engineering, AI engineering process is to try new things, to do things people haven't done before and to use technology to solve most if not all problems. So to make the algorithm work despite not so great data, find error tolerant ways to deal with the data. The Chinese way would be to basically enumerate to the fullest extent all the possible ways by a lot of machines, try lots of different ways to get it to work and spend a lot of resources and money and time cleaning up data. That means the AI engineer may be writing data cleansing algorithms, working with thousands of people who label or correct or do things with the data. That is the incredible hard work that might lead to better results. So the Chinese engineer would rely on and ask for more and more and more data and find ways to cleanse them and make them work in the system and probably less time thinking about new algorithms that can overcome data or other issues. So where's your intuition? Where do you think the biggest impact in the next 10 years lies? Is it in some breakthrough algorithms or is it in just this at scale rigor, a rigorous approach to data, cleaning data, organizing data onto the same algorithms? What do you think the big impact in the applied world is? Well, if you're really in the company and you have to deliver results, using known techniques and enhancing data seems like the more expedient approach that's very low risk and likely to generate better and better results. And that's why the Chinese approach has done quite well. Now, there are a lot of more challenging startups and problems such as autonomous vehicles, medical diagnosis that existing algorithms probably won't solve. And that would put the Chinese approach more challenged and give them more breakthrough innovation approach, more of an edge on those kinds of problems. So let me talk to that a little more. So my intuition personally is that data can take us extremely far. So you brought up autonomous vehicles and medical diagnosis. So your intuition is that huge amounts of data might not be able to completely help us solve that problem. Right, so breaking that down further in autonomous vehicle, I think huge amounts of data probably will solve trucks driving on highways, which will deliver a significant value and China will probably lead in that. And full L5 autonomous is likely to require new technologies we don't yet know. And that might require academia and great industrial research, both innovating and working together. And in that case, US has an advantage. So the interesting question there is, I don't know if you're familiar on the autonomous vehicle space and the developments with Tesla and Elon Musk. I am. Where they are in fact full steam ahead into this mysterious complex world of full autonomy, L5, L4, L5, and they're trying to solve that purely with data. So the same kind of thing that you're saying is just for highway, which is what a lot of people share your intuition. They're trying to solve with data. So just to linger on that moment further, do you think possible for them to achieve success with simply just a huge amount of this training on edge cases and difficult cases in urban environments, not just highway and so on? I think it would be very hard. One could characterize Tesla's approach as kind of a Chinese strength approach, right? Gather all the data you can and hope that will overcome the problems. But in autonomous driving, clearly a lot of the decisions aren't merely solved by aggregating data and having feedback loop. There are things that are more akin to human thinking. And how would those be integrated and built? There has not yet been a lot of success integrating human intelligence or call it expert systems if you will, even though that's a taboo word with the machine learning. And the integration of the two types of thinking hasn't yet been demonstrated. And the question is how much can you push a purely machine learning approach? And of course, Tesla also has an additional constraint that they don't have all the sensors. I know that they think it's foolish to use LIDARs, but that's clearly a one less very valuable and reliable source of input that they're foregoing, which may also have consequences. I think the advantage of course is capturing data that no one has ever seen before. And in some cases such as computer vision and speech recognition, I have seen Chinese companies accumulate data that's not seen anywhere in the Western world and they have delivered superior results. But then speech recognition and object recognition are relatively suitable problems for deep learning and don't have the potentially need for the human intelligence analytical planning elements. And the same on the speech recognition side, your intuition that speech recognition and the machine learning approaches to speech recognition won't take us to a conversational system that can pass the Turing test, which is sort of maybe akin to what driving is. So it needs to have something more than just simply simple language understanding, simple language generation. Roughly right. I would say that based on purely machine learning approaches, it's hard to imagine it could lead to a full conversational experience across arbitrary domains, which is akin to L5. I'm a little hesitant to use the word Turing test because the original definition was probably too easy. We probably do that, yeah. The spirit of the Turing test is what I was referring to. Of course. So you've had major leadership research positions at Apple, Microsoft, Google. So continuing on the discussion of America, Russia, Chinese, Seoul and culture and so on. What is the culture of Silicon Valley in contrast to China and maybe US broadly? And what is the unique culture of each of these three major companies in your view? I think in aggregate, Silicon Valley companies, and we could probably include Microsoft in that, even though they're not in the Valley, is really dream big and have visionary goals and believe that technology will conquer all. And also the self confidence and the self entitlement that whatever they produce, the whole world should use and must use. And those are historically important, I think. Steve Jobs famous quote that he doesn't do focus groups, he looks in the mirror and asks the person in the mirror, what do you want? And that really is an inspirational comment that says, the great company shouldn't just ask users what they want, but develop something that users will know they want when they see it, but they could never come up with themselves. I think that is probably the most exhilarating description of what the essence of Silicon Valley is, that this brilliant idea could cause you to build something that couldn't come out of the focus groups or AB tests. And iPhone would be an example of that. No one in the age of Blackberry would write down they want an iPhone or multi touch. A browser might be another example. No one would say they want that in the days of FTP, but once they see it, they want it. So I think that is what Silicon Valley is best at. But it also comes with, it came with a lot of success. These products became global platforms and there were basically no competitors anywhere. And that has also led to a belief that these are the only things that one should do, that companies should not tread on other companies territory so that a Groupon and a Yelp and then OpenTable and the Grubhub would each feel, okay, I'm not gonna do the other company's business because that would not be the pride of innovating what each of these four companies have innovated. But I think the Chinese approach is do whatever it takes to win. And it's a winner take all market. And in fact, in the internet space, the market leader will get predominantly all the value extracted out of the system. So, and the system isn't just defined as one narrow category, but gets broader and broader. So it's amazing ambition for success and domination of increasingly larger product categories leading to clear market winner status and the opportunity to extract tremendous value. And that develops a practical, result oriented, ultra ambitious winner take all gladiatorial mentality. And if what it takes is to build what the competitors built, essentially a copycat that can be done without infringing laws. If what it takes is to satisfy a foreign country's need by forking the code base and building something that looks really ugly and different, they'll do it. So it's contrasted very sharply with the Silicon Valley approach. And I think the flexibility and the speed and execution has helped the Chinese approach. And I think the Silicon Valley approach is potentially challenged if every Chinese entrepreneur is learning from the whole world, US and China, and the American entrepreneurs only look internally and write off China as a copycat. And the second part of your question about the three companies. The unique elements of the three companies perhaps. Yeah, I think Apple represents while the user please the user and the essence of design and brand and it's the one company and perhaps the only tech company that draws people with a strong, serious desire for the product and the willingness to pay a premium because of the halo effect of the brand which came from the attention to detail and great respect for user needs. Microsoft represents a platform approach that builds giant products that become very strong modes that others can't do because it's well architected at the bottom level and the work is efficiently delegated to individuals and then the whole product is built by adding small parts that sum together. So it's probably the most effective high tech assembly line that builds a very difficult product that and the whole process of doing that is kind of a differentiation and something competitors can't easily repeat. Are there elements of the Chinese approach in the way Microsoft went about assembling those little pieces and dominating, essentially dominating the market for a long time or do you see those as distinct? I think there are elements that are the same. I think the three American companies that had or have Chinese characteristics and obviously as well as American characteristics are Microsoft, Facebook and Amazon. Yes, that's right, Amazon. Because these are companies that will tenaciously go after adjacent markets, build up strong product offering and find ways to extract greater value from a sphere that's ever increasing and they understand the value of the platforms. So that's the similarity and then with Google, I think it's a genuinely value oriented company that does have a heart and soul and that wants to do great things for the world by connecting information and that has also very strong technology genes and wants to use technology and has found out of the box ways to use technology to deliver incredible value to the end user. If you can look at Google, for example, you mentioned heart and soul. There seems to be an element where Google is after making the world better. There's a more positive view. They used to have the slogan, don't be evil. And Facebook a little bit more has a negative tend to it. At least in the perception of privacy and so on. Do you have a sense of how these different companies can achieve, because you've talked about how much we can make the world better in all these kinds of ways with AI. What is it about a company that can make, give it a heart and soul, gain the trust of the public and just actually just not be evil and do good for the world? It's really hard and I think Google has struggled with that. First, the don't do evil mantra is very dangerous because every employee's definition of evil is different. And that has led to some difficult employee situations for them. So I don't necessarily think that's a good value statement, but just watching the kinds of things Google or its parent company Alphabet does in new areas like healthcare, like eradicating mosquitoes, things that are really not in the business of a internet tech company. I think that shows that there's a heart and soul and desire to do good and willingness to put in the resources to do something when they see it's good, they will pursue it. That doesn't necessarily mean it has all the trust of the users. I realize while most people would view Facebook as the primary target of their recent unhappiness about Silicon Valley companies, many would put Google in that category. And some have named Google's business practices as predatory also. So it's kind of difficult to have the two parts of a body. The brain wants to do what it's supposed to do for a shareholder, maximize profit. And then the heart and soul wants to do good things that may run against what the brain wants to do. So in this complex balancing that these companies have to do, you've mentioned that you're concerned about a future where too few companies like Google, Facebook, Amazon are controlling our data or controlling too much of our digital lives. Can you elaborate on this concern and perhaps do you have a better way forward? I think I'm hardly the most vocal complainer of this. Sure, of course. There are a lot louder complainers out there. I do observe that having a lot of data does perpetuate their strength and limits competition in many spaces. But I also believe AI is much broader than the internet space. So the entrepreneurial opportunities still exists in using AI to empower financial, retail, manufacturing, education applications. So I don't think it's quite a case of full monopolistic dominance that totally stifles innovation. But I do believe in their areas of strength it's hard to dislodge them. I don't know if I have a good solution. Probably the best solution is let the entrepreneurial VC ecosystem work well and find all the places that can create the next Google, the next Facebook. So there will always be increasing number of challengers. In some sense that has happened a little bit. You see Uber, Airbnb having emerged despite the strength of the big three. And I think China as an environment may be more interesting for the emergence because if you look at companies between let's say 50 to $300 billion, China has emerged more of such companies than the US in the last three to four years because of the larger marketplace, because of the more fearless nature of the entrepreneurs. And the Chinese giants are just as powerful as American ones. Tencent, Alibaba are very strong, but ByteDance has emerged worth 75 billion and financial while it's Alibaba affiliated, it's nevertheless independent and worth 150 billion. And so I do think if we start to extend to traditional businesses, we will see very valuable companies. So it's probably not the case that in five or 10 years we'll still see the whole world with these five companies having such dominance. So you've mentioned a couple of times this fascinating world of entrepreneurship in China of the fearless nature of the entrepreneur. So can you maybe talk a little bit about what it takes to be an entrepreneur in China? What are the strategies that are undertaken? What are the ways to achieve success? What is the dynamic of VCF funding of the way the government helps companies and so on? What are the interesting aspects here that are distinct from, that are different from the Silicon Valley world of entrepreneurship? Well, many of the listeners probably still would brand Chinese entrepreneur as copycats. And no doubt 10 years ago, that would not be an inaccurate description. Back 10 years ago, an entrepreneur probably could not get funding if he or she could not describe what product he or she is copying from the US. The first question is who has proven this business model which is a nice way of asking who are you copying? And that reason is understandable because China had a much lower internet penetration and didn't have enough indigenous experience to build innovative products. And secondly, internet was emerging. Link startup was the way to do things, building a first minimally viable product and then expanding was the right way to go. And the American successes have given a shortcut that if you built your minimally viable product based on an American product, it's guaranteed to be a decent starting point. Then you tweak it afterwards. So as long as there are no IP infringement, which as far as I know there hasn't been in the mobile and AI spaces, that's a much better shortcut. And I think Silicon Valley would view that as still not very honorable because that's not your own idea to start with, but you can't really at the same time believe every idea must be your own and believe in the link startup methodology because link startup is intended to try many, many things and then converge when that works. And it's meant to be iterated and changed. So finding a decent starting point without legal violations, there should be nothing morally dishonorable about that. Yeah, so just a quick pause on that. It's fascinating that that's, why is that not honorable, right? It's exactly as you formulated. It seems like a perfect start for business. Is to take, look at Amazon and say, okay, we'll do exactly what Amazon is doing. Let's start there in this particular market and then let's out innovate them from that starting point. Come up with new ways. I mean, is it wrong to be, except the word copycat just sounds bad, but is it wrong to be a copycat? It just seems like a smart strategy, but yes, it doesn't have a heroic nature to it that like Steve Jobs, Elon Musk, sort of in something completely, coming up with something completely new. Yeah, I like the way you describe it. It's a nonheroic, acceptable way to start the company and maybe more expedient. So that's, I think, a baggage for Silicon Valley that if it doesn't let go, then it may limit the ultimate ceiling of the company. Take Snapchat as an example. I think, you know, Evan's brilliant. He built a great product, but he's very proud that he wants to build his own features, not copy others. While Facebook was more willing to copy his features and you see what happens in the competition. So I think putting that handcuff on the company would limit its ability to reach the maximum potential. So back to the Chinese environment, copying was merely a way to learn from the American masters. Just like we, if we learned to play piano or painting, you start by copying. You don't start by innovating when you don't have the basic skill sets. So very amazingly, the Chinese entrepreneurs about six years ago started to branch off with these lean startups built on American ideas to build better products than American products. But they did start from the American idea. And today WeChat is better than WhatsApp, Weibo is better than Twitter, Zhihu is better than Quora and so on. So that I think is Chinese entrepreneurs going to step two. And then step three is once these entrepreneurs have done one or two of these companies, they now look at the Chinese market and the opportunities and come up with ideas that didn't exist elsewhere. So products like Ant Financial, under which includes Alipay, which is mobile payments, and also the financial products for loans built on that. And also in education, VIPKID, and in social video, social network, TikTok, and in social eCommerce, Pinduoduo, and then in ride sharing, Mobike, these are all Chinese innovated products that now are being copied elsewhere. So an additional interesting observation is some of these products are built on unique Chinese demographics, which may not work in the US, but may work very well in Southeast Asia, Africa, and other developing worlds that are a few years behind China. And a few of these products maybe are universal and are getting traction even in the United States, such as TikTok. So this whole ecosystem is supported by VCs as a virtuous cycle, because a large market with innovative entrepreneurs will draw a lot of money and then invest in these companies. As the market gets larger and larger, the China market is easily three, four times larger than the US, they will create greater value and greater returns for the VCs, thereby raising even more money. So at Sinovation Ventures, our first fund was 15 million, our last fund was 500 million. So it reflects the valuation of the companies and our us going multi stage and things like that. It also has government support, but not in the way most Americans would think of it. The government actually leaves the entrepreneurial space as a private enterprise, sort of self regulating, and the government would build infrastructures that would around it to make it work better. For example, the Mass Entrepreneur Mass Innovation Plan builds 8,000 incubators, so the pipeline is very strong to the VCs. For autonomous vehicles, the Chinese government is building smart highways with sensors, smart cities that separate pedestrians from cars that may allow initially an inferior autonomous vehicle company to launch a car without increasing with lower casualty because the roads or the city is smart. And the Chinese government at local levels would have these guiding funds acting as LPs, passive LPs to funds. And when the fund makes money, part of the money made is given back to the GPs and potentially other LPs to increase everybody's return at the expense of the government's return. So that's an interesting incentive that entrusts the task of choosing entrepreneurs to VCs who are better at it than the government by letting some of the profits move that way. So this is really fascinating, right? So I look at the Russian government as a case study where, let me put it this way, there's no such government driven large scale support of entrepreneurship. And probably the same is true in the United States, but the entrepreneurs themselves kind of find a way. So maybe in a form of advice or explanation, how did the Chinese government arrive to be this way so supportive on entrepreneurship to be in this particular way so forward thinking at such a large scale? And also perhaps, how can we copy it in other countries? How can we encourage other governments, like even the United States government, to support infrastructure for autonomous vehicles in that same kind of way, perhaps? Yes, so these techniques are the result of several key things, some of which may be learnable, some of which may be very hard. One is just trial and error and watching what everyone else is doing. I think it's important to be humble and not feel like you know all the answers. The guiding funds idea came from Singapore, which came from Israel. And China made a few tweaks and turned it into a, because the Chinese cities and government officials kind of compete with each other because they all want to make their city more successful so they can get the next level in their political career. And it's somewhat competitive. So the central government made it a bit of a competition. Everybody has a budget. They can put it on AI or they can put it on bio or they can put it on energy. And then whoever gets the results, the city shines, the people are better off, the mayor gets a promotion. So the tools is kind of almost like an entrepreneurial environment for local governments to see who can do a better job. And also many of them try different experiments. Some have given award to very smart researchers. Just give them money and hope they'll start a company. Some have given money to academic research labs, maybe government research labs to see if they can spin off some companies from the science lab or something like that. Some have tried to recruit overseas Chinese to come back and start companies. And they've had mixed results. The one that worked the best was the guiding funds. So it's almost like a lean startup idea where people try different things and what works sticks and everybody copies. So now every city has a guiding fund. So that's how that came about. The autonomous vehicle and the massive spending in highways and smart cities, that's a Chinese way. It's about building infrastructure to facilitate. It's a clear division of the government's responsibility from the market. The market should do everything in a private freeway, but there are things the market can't afford to do like infrastructure. So the government always appropriates large amounts of money for infrastructure building. This happens with not only autonomous vehicle and AI, but happened with the 3G and 4G. You'll find that the Chinese wireless reception is better than the US because massive spending that tries to cover the whole country, whereas in the US it may be a little spotty. It's a government driven because I think they view the coverage of cell access and 3G, 4G access to be a governmental infrastructure spending as opposed to capitalistic. So that's, of course, the state owned enterprises are also publicly traded, but they also carry a government responsibility to deliver infrastructure to all. So it's a different way of thinking that may be very hard to inject into Western countries to say starting tomorrow, bandwidth infrastructure and highways are gonna be governmental spending with some characteristics. What's your sense, and sorry to interrupt, but because it's such a fascinating point, do you think on the autonomous vehicle space it's possible to solve the problem of full autonomy without significant investment in infrastructure? Well, that's really hard to speculate. I think it's not a yes, no question, but how long does it take question? 15 years, 30 years, 45 years. Clearly with infrastructure augmentation, whether it's road, the city or whole city planning, building a new city, I'm sure that will accelerate the day of the L5. I'm not knowledgeable enough, and it's hard to predict even when we're knowledgeable because a lot of it is speculative. But in the US, I don't think people would consider building a new city the size of Chicago to make it the AI slash autonomous city. There are smaller ones being built, I'm aware of that. But is infrastructure spend really impossible for US or Western countries? I don't think so. The US highway system was built, was that during President Eisenhower or Kennedy? Eisenhower, yeah. So maybe historians can study how the President Eisenhower get the resources to build this massive infrastructure that surely gave US a tremendous amount of prosperity over the next decade, if not century. If I may comment on that then, it takes us to artificial intelligence a little bit because in order to build infrastructure, it creates a lot of jobs. So I'll be actually interested if you would say that you talk in your book about all kinds of jobs that could and could not be automated. I wonder if building infrastructure is one of the jobs that would not be easily automated. Something you could think about because I think you've mentioned somewhere in the talk or that there might be, as jobs are being automated, a role for government to create jobs that can't be automated. Yes, I think that's a possibility. Back in the last financial crisis, China put a lot of money to basically give this economy a boost and a lot of it went into infrastructure building. And I think that's a legitimate way at the government level to deal with the employment issues as well as build out the infrastructure as long as the infrastructures are truly needed and as long as there is an employment problem, which no, we don't know. So maybe taking a little step back, if you've been a leader and a researcher in AI for several decades, at least 30 years, so how has AI changed in the West and the East as you've observed, as you've been deep in it over the past 30 years? Well, AI began as the pursuit of understanding human intelligence and the term itself represents that, but it kind of drifted into the one sub area that worked extremely well, which is machine intelligence. And that's actually more using pattern recognition techniques to basically do incredibly well on a limited domain, large amount of data, but relatively simple kinds of planning tasks and not very creative. So we didn't end up building human intelligence. We built a different machine that was a lot better than us, some problems, but nowhere close to us on other problems. So today, I think a lot of people still misunderstand when we say artificial intelligence and what various products can do, people still think it's about replicating human intelligence, but the products out there really are closer to having invented the internet or the spreadsheet or the database and getting broader adoption. And speaking further to the fears, near term fears that people have about AI, so you're commenting on the sort of general intelligence that people in the popular culture from sci fi movies have a sense about AI, but there's practical fears about AI, the narrow AI that you're talking about of automating particular kinds of jobs and you talk about them in the book. So what are the kinds of jobs in your view that you see in the next five, 10 years beginning to be automated by AI systems algorithms? Yes, this is also maybe a little bit counterintuitive because it's the routine jobs that will be displaced the soonest and they may not be displaced entirely, maybe 50%, 80% of a job, but when the workload drops by that much, employment will come down. And also another part of misunderstanding is most people think of AI replacing routine jobs than they think of the assembly line, the workers. Well, that will have some effect, but it's actually the routine white collar workers that's easiest to replace because to replace a white collar worker, you just need software. To replace a blue collar worker, you need robotics, mechanical excellence, and the ability to deal with dexterity and maybe even unknown environments, very, very difficult. So if we were to categorize the most dangerous white collar jobs, they would be things like back office, people who copy and paste and deal with simple computer programs and data and maybe paper and OCR, and they don't make strategic decisions. They basically facilitate the process. These softwares and paper systems don't work. So you have people dealing with new employee orientation, searching for past lawsuits and financial documents, and doing reference check. So basic searching and management of data. That's the most endangered being lost. In addition to the white collar repetitive work, a lot of simple interaction work can also be taken care of such as telesales, telemarketing, customer service, as well as many physical jobs that are in the same location and don't require a high degree of dexterity. So fruit picking, dishwashing, assembly line inspection are jobs in that category. So altogether, back office is a big part. And the blue collar may be smaller initially, but over time, AI will get better. And when we start to get to over the next 15, 20 years, the ability to actually have the dexterity of doing assembly line, that's a huge chunk of jobs. And when autonomous vehicles start to work, initially starting with truck drivers, but eventually to all drivers, that's another huge group of workers. So I see modest numbers in the next five years, but increasing rapidly after that. On the worry of the jobs that are in danger and the gradual loss of jobs, I'm not sure if you're familiar with Andrew Yang. Yes, I am. So there's a candidate for president of the United States whose platform Andrew Yang is based around, in part around job loss due to automation. And also in addition, the need perhaps of universal basic income to support jobs that are, folks who lose their job due to automation and so on. And in general, support people under complex, unstable job market. So what are your thoughts about his concerns, him as a candidate, his ideas in general? I think his thinking is generally in the right direction, but his approach as a presidential candidate may be a little bit ahead of the time. And I think the displacements will happen, but will they happen soon enough for people to agree to vote for him? The unemployment numbers are not very high yet. And I think he and I have the same challenge. If I want to theoretically convince people this is an issue and he wants to become the president, people have to see how can this be the case when unemployment numbers are low. So that is the challenge. And I think I do agree with him on the displacement issue, on universal basic income. At a very vanilla level, I don't agree with it because I think the main issue is retraining. So people need to be incented not by just giving a monthly $2,000 check or $1,000 check and do whatever they want because they don't have the know how to know what to retrain to go into what type of a job. And guidance is needed. And retraining is needed because historically when technology revolutions, when routine jobs were displaced, new routine jobs came up. So there was always room for that. But with AI and automation, the whole point is replacing all routine jobs eventually. So there will be fewer and fewer routine jobs. And AI will create jobs, but it won't create routine jobs because if it creates routine jobs, why wouldn't AI just do it? So therefore the people who are losing the jobs are losing routine jobs. The jobs that are becoming available are non routine jobs. So the social stipend needs to be put in place is for the routine workers who lost their jobs to be retrained maybe in six months, maybe in three years, takes a while to retrain on the non routine job and then take on a job that will last for that person's lifetime. Now, having said that, if you look deeply into Andrew's document, he does cater for that. So I'm not disagreeing with what he's trying to do. But for simplification, sometimes he just says UBI, but simple UBI wouldn't work. And I think you've mentioned elsewhere that the goal isn't necessarily to give people enough money to survive or live, or even to prosper. The point is to give them a job that gives them meaning. That meaning is extremely important. That our employment, at least in the United States and perhaps it carries across the world, provides something that's, forgive me for saying, greater than money. It provides meaning. So now, what kind of jobs do you think can't be automated? Can you talk a little bit about creativity and compassion in your book? What aspects do you think it's difficult to automate for an AI system? Because an AI system is currently merely optimizing. It's not able to reason, plan, or think creatively or strategically. It's not able to deal with complex problems. It can't come up with a new problem and solve it. A human needs to find the problem and pose it as an optimization problem, then have the AI work at it. So an AI would have a very hard time discovering a new drug or discovering a new style of painting or dealing with complex tasks such as managing a company that isn't just about optimizing the bottom line, but also about employee satisfaction, corporate brand, and many, many other things. So that is one category of things. And because these things are challenging, creative, complex, doing them creates a high degree of satisfaction and therefore appealing to our desire for working, which isn't just to make the money, make the ends meet, but also that we've accomplished something that others maybe can't do or can't do as well. Another type of job that is much numerous would be compassionate jobs, jobs that require compassion, empathy, human touch, human trust. AI can't do that because AI is cold, calculating, and even if it can fake that to some extent, it will make errors and that will make it look very silly. And also, I think even if AI did okay, people would want to interact with another person, whether it's for some kind of a service or a teacher or a doctor or a concierge or a masseuse or a bartender. There are so many jobs where people just don't want to interact with a cold robot or software. I've had an entrepreneur who built an elderly care robot and they found that the elderly really only use it for customer service. And not, but not to service the product, but they click on customer service and the video of a person comes up and then the person says, how come my daughter didn't call me? Let me show you a picture of her grandkids. So people yearn for that people, people interaction. So even if robots improved, people just don't want it. And those jobs are going to be increasing because AI will create a lot of value, $16 trillion to the world in the next 10 years. Next 11 years, according to PWC. And that will give people money to enjoy services, whether it's eating a gourmet meal or tourism and traveling or having concierge services, the services revolving around every dollar of that $16 trillion will be tremendous. It will create more opportunities that are to service the people who did well through AI with things. But even at the same time, the entire society is very much short in need of many service oriented, compassionate oriented jobs. The best example is probably in healthcare services. There's going to be 2 million new jobs, not counting replacement, just brand new incremental jobs in the next six years in healthcare services. That includes nurses, orderly in the hospital, elderly care and also at home care is particularly lacking. And those jobs are not likely to be filled. So there's likely to be a shortage. And the reason they're not filled is simply because they don't pay very well and that the social status of these jobs are not very good. So they pay about half as much as a heavy equipment operator, which will be replaced a lot sooner. And they pay probably comparably to someone on the assembly line. And so if we ignoring all the other issues and just think about satisfaction from one's job, someone repetitively doing the same manual action at an assembly line, that can't create a lot of job satisfaction, but someone taking care of a sick person and getting a hug and thank you from that person and the family, I think is quite satisfying. So if only we could fix the pay for service jobs, there are plenty of jobs that require some training or a lot of training for the people coming off the routine jobs to take. We can easily imagine someone who was maybe a cashier at the grocery store as stores become automated, learns to become a nurse or an at home care. I also do want to point out the blue collar jobs are going to stay around a bit longer. Some of them quite a bit longer. AI cannot be told go clean an arbitrary home. That's incredibly hard. Arguably it's an L5 level of difficulty, right? And then AI cannot be a good plumber because plumber is almost like a mini detective that has to figure out where the leak came from. So yet AI probably can be an assembly line and auto mechanic and so on. So one has to study which blue collar jobs are going away and facilitate retraining for the people to go into the ones that won't go away or maybe even will increase. I mean, it is fascinating that it's easier to build a world champion chess player than it is to build a mediocre plumber. Yes, right. Very true. And to AI and that goes counterintuitive to a lot of people's understanding of what artificial intelligence is. So it sounds, I mean, you're painting a pretty optimistic picture about retraining about the number of jobs and actually the meaningful nature of those jobs once we automate the repetitive tasks. So overall, are you optimistic about the future where much of the repetitive tasks are automated? That there is a lot of room for humans for the compassionate, for the creative input that only humans can provide? I am optimistic if we start to take action. If we have no action in the next five years, I think it's going to be hard to deal with the devastating losses that will emerge. So if we start thinking about retraining, maybe with the low hanging fruits, explaining to vocational schools why they should train more plumbers than auto mechanics, maybe starting with some government subsidy for corporations to have more training positions. We start to explain to people why retraining is important. We start to think about what the future of education, how that needs to be tweaked for the era of AI. If we start to make incremental progress and the greater number of people understand, then there's no reason to think we can't deal with this because this technological revolution is arguably similar to what electricity, industrial revolutions, and internet brought about. Do you think there's a role for policy, for governments to step in, to help with policy to create a better world? Absolutely, and the governments don't have to believe an employment will go up, and they don't have to believe automation will be this fast to do something. Revamping vocational school would be one example. Another is if there's a big gap in healthcare service employment, and we know that a country's population is growing older, more longevity, living older, because people over 80 require five times as much care as those under 80, then it is a good time to incent training programs for elderly care to find ways to improve the pay. Maybe one way would be to offer as part of Medicare or the equivalent program for people over 80 to be entitled to a few hours of elderly care at home, and then that might be reimbursable, and that will stimulate the service industry around the policy. Do you have concerns about large entities, whether it's governments or companies, controlling the future of AI development in general? So we talked about companies. Do you have a better sense that governments can better represent the interests of the people than companies, or do you believe companies are better at representing the interests of the people? Or is there no easy answer? I don't think there's an easy answer because it's a double edged sword. The companies and governments can provide better services with more access to data and more access to AI, but that also leads to greater power, which can lead to uncontrollable problems, whether it's monopoly or corruption in the government. So I think one has to be careful to look at how much data that companies and governments have and some kind of checks and balances would be helpful. So again, I come from Russia. There's something called the Cold War. So let me ask a difficult question here looking at conflict. Steven Pinker written a great book that conflict all over the world is decreasing in general. But do you have a sense that having written the book AI Superpowers, do you see a major international conflict potentially arising between major nations, whatever they are, whether it's Russia, China, European nations, United States or others in the next 10, 20, 50 years around AI, around the digital space, cyberspace? Do you worry about that? Is that something we need to think about and try to alleviate or prevent? I believe in greater engagement. A lot of the worries about more powerful AI are based on a arms race metaphor. And when you extrapolate into military kinds of scenarios, AI can automate and autonomous weapons that needs to be controlled somehow and autonomous decision making can lead to not enough time to fix international crises. So I actually believe a Cold War mentality would be very dangerous because should two countries rely on AI to make certain decisions and they don't even talk to each other, they do their own scenario planning, then something could easily go wrong. I think engagement, interaction, some protocols to avoid inadvertent disasters is actually needed. So it's natural for each country to want to be the best, whether it's in nuclear technologies or AI or bio. But I think it's important to realize if each country has a black box AI and don't talk to each other, that probably presents greater challenges to humanity than if they interacted. I think there can still be competition, but with some degree of protocol for interaction, just like when there was a nuclear competition, there were some protocol for deterrence among US, Russia, and China. And I think that engagement is needed. So of course, we're still far from AI presenting that kind of danger. But what I worry the most about is the level of engagement seems to be coming down. The level of distrust seems to be going up, especially from the US towards other large countries such as China and of course, and Russia, yes. Is there a way to make that better? So let's beautifully put level of engagement and even just basic trust and communication as opposed to sort of making artificial enemies out of particular countries. Do you have a sense how we can make it better? Actionable items that as a society we can take on? I'm not an expert at geopolitics, but I would say that we look pretty foolish as humankind when we are faced with the opportunity to create $16 trillion for humanity, and yet we're not solving fundamental problems with parts of the world still in poverty. And for the first time, we have the resources to overcome poverty and hunger. We're not using it on that, but we're fueling competition among superpowers. And that's a very unfortunate thing. If we become utopian for a moment, imagine a benevolent world government that has this $16 trillion and maybe some AI to figure out how to use it to deal with diseases and problems and hate and things like that. World would be a lot better off. So what is wrong with the current world? I think the people with more skill than I should think about this. And then the geopolitics issue with superpower competition is one side of the issue. There's another side which I worry maybe even more, which is as the $16 trillion all gets made by US and China and a few of the other developed countries, the poorer country will get nothing because they don't have technology and the wealth disparity and inequality will increase. So a poorer country with a large population will not only benefit from the AI boom or other technology booms, but they will have their workers who previously had hoped they could do the China model and do outsource manufacturing or the India model so they could do the outsource process or call center. Well, all those jobs are gonna be gone in 10 or 15 years. So the individual citizen may be a net liability, I mean, financially speaking to a poorer country and not an asset to claw itself out of poverty. So in that kind of situation, these large countries with not much tech are going to be facing a downward spiral and it's unclear what could be done. And then when we look back and say there's $16 trillion being created and it's all being kept by US, China and other developed countries, it just doesn't feel right. So I hope people who know about geopolitics can find solutions that's beyond my expertise. So different countries that we've talked about have different value systems. If you look at the United States, to an almost extreme degree, there is an absolute desire for freedom of speech. If you look at a country where I was raised, that desire just amongst the people is not as elevated as it is to basically fundamental level to the essence of what it means to be America, right? And the same is true with China, there's different value systems. There's some censorship of internet content that China and Russia and many other countries undertake. Do you see that having effects on innovation, other aspects of some of the tech stuff, AI development we talked about, and maybe from another angle, do you see that changing in different ways over the next 10 years, 20 years, 50 years as China continues to grow as it does now in its tech innovation? There's a common belief that full freedom of speech and expression is correlated with creativity, which is correlated with entrepreneurial success. I think empirically we have seen that is not true and China has been successful. That's not to say the fundamental values are not right or not the best, but it's just that perfect correlation isn't there. It's hard to read the tea leaves on opening up or not in any country, and I've not been very good at that in my past predictions, but I do believe every country shares a lot of fundamental values for the longterm. So China is drafting its privacy policy for individual citizens, and they don't look that different from the American or European ones. So people do want to protect their privacy and have the opportunity to express and I think the fundamental values are there. The question is in the execution and timing, how soon or when will that start to open up? So as long as each government knows ultimately people want that kind of protection, there should be a plan to move towards that as to when or how and I'm not an expert. On the point of privacy to me, it's really interesting. So AI needs data to create a personalized awesome experience, right? I'm just speaking generally in terms of products. And then we have currently, depending on the age and depending on the demographics of who we're talking about, some people are more or less concerned about the amount of data they hand over. So in your view, how do we get this balance right that we provide an amazing experience to people that use products? You look at Facebook, the more Facebook knows about you, yes, it's scary to say, the better it can probably, better experience it can probably create. So in your view, how do we get that balance right? Yes, I think a lot of people have a misunderstanding that it's okay and possible to just rip all the data out from a provider and give it back to you. So you can deny them access to further data and still enjoy the services we have. If we take back all the data, all the services will give us nonsense. We'll no longer be able to use products that function well in terms of right ranking, right products, right user experience. So yet I do understand we don't want to permit misuse of the data from legal policy standpoint. I think there can be severe punishment for those who have egregious misuse of the data. That's I think a good first step. Actually China in this side on this aspect has very strong laws about people who sell or give data to other companies. And that over the past few years, since that law came into effect, pretty much eradicated the illegal distribution, sharing of data. Additionally, I think giving, I think technology is often a very good way to solve technology misuse. So can we come up with new technologies that will let us have our cake and eat it too? People are looking into homomorphic encryption, which is letting you keep the data, have it encrypted and train on encrypted data. Of course, we haven't solved that one yet, but that kind of direction may be worth pursuing. Also federated learning, which would allow one hospital to train on its hospital's patient data fully because they have a license for that. And then hospitals would then share their models, not data, but models to create a super AI. And that also maybe has some promise. So I would want to encourage us to be open minded and think of this as not just the policy binary, yes, no, but letting the technologists try to find solutions to let us have our cake and eat it too, or have most of our cake and eat most of it too. Finally, I think giving each end user a choice is important and having transparency is important. Also, I think that's universal, but the choice you give to the user should not be at a granular level that the user cannot understand. GDPR today causes all these popups of yes, no, will you give this site this right to use this part of your data? I don't think any user understands what they're saying yes or no to. And I suspect most are just saying yes because they don't understand it. So while GDPR in its current implementation has lived up to its promise of transparency and user choice, it implemented it in such a way that really didn't deliver the spirit of GDPR. It fit the letter, but not the spirit. So again, I think we need to think about is there a way to fit the spirit of GDPR by using some kind of technology? Can we have a slider that's an AI trying to figure out how much you want to slide between perfect protection security of your personal data versus a high degree of convenience with some risks of not having full privacy? Each user should have some preference and that gives you the user choice. But maybe we should turn the problem on its head and ask can there be an AI algorithm that can customize this? Because we can understand the slider, but we sure cannot understand every popup question. And I think getting that right requires getting the balance between what we talked about earlier, which is heart and soul versus profit driven decisions and strategy. I think from my perspective, the best way to make a lot of money in the long term is to keep your heart and soul intact. I think getting that slider right in the short term may feel like you'll be sacrificing profit, but in the long term, you'll be gaining user trust and providing a great experience. Do you share that kind of view in general? Yes, absolutely. I sure would hope there is a way we can do long term projects that really do the right thing. I think a lot of people who embrace GDPR, their heart's in the right place. I think they just need to figure out how to build a solution. I've heard utopians talk about solutions that get me excited, but I'm not sure how in the current funding environment they can get started. People talk about, imagine this crowdsourced data collection that we all trust. And then we have these agents that we ask the trusted agent to... That agent only, that platform, so a trusted joint platform that we all believe is trustworthy, that can give us all the closed loop personal suggestions by the new social network, new search engine, new eCommerce engine that has access to even more of our data, but not directly, but indirectly. So I think that general concept of licensing to some trusted engine and finding a way to trust that engine seems like a great idea. But if you think how long it's gonna take to implement and tweak and develop it right, as well as to collect all the trusts and the data from the people, it's beyond the current cycle of venture capital. So how do you do that is a big question. You've recently had a fight with cancer, stage four lymphoma and in a sort of deep personal level, what did it feel like in the darker moments to face your own mortality? Well, I've been the workaholic my whole life and I've basically worked nine, nine, six, nine a.m. to nine p.m. six days a week, roughly. And I didn't really pay a lot of attention to my family, friends, and people who loved me. And my life revolved around optimizing for work. While my work was not routine, my optimization really what made my life basically very mechanical process. But I got a lot of highs out of it because of accomplishments that I thought were really important and dear and the highest priority to me. But when I faced mortality and the possible death in matter of months, I suddenly realized that this really meant nothing to me, that I didn't feel like working for another minute, that if I had six months left in my life, I would spend it all with my loved ones and thanking them, giving them love back and apologizing to them that I lived my life the wrong way. So that moment of reckoning caused me to really rethink that why we exist in this world is something that we might be too much shaped by the society to think that success and accomplishments is why we live. But while that can get you periodic successes and satisfaction, it's really in the facing death you see what's truly important to you. So as a result of going through the challenges with cancer, I've resolved to live a more balanced lifestyle. I'm now in remission, knock on wood, and I'm spending more time with my family. My wife travels with me. When my kids need me, I spend more time with them. And before I used to prioritize everything around work. When I had a little bit of time, I would dole it out to my family. Now, when my family needs something, really needs something, I drop everything at work and go to them. And then in the time remaining, I allocate to work. But one's family is very understanding. It's not like they will take 50 hours a week from me. So I'm actually able to still work pretty hard, maybe 10 hours less per week. So I realized the most important thing in my life is really love and the people I love. And I give that the highest priority. It isn't the only thing I do, but when that is needed, I put that at the top priority and I feel much better and I feel much more balanced. And I think this also gives a hint as to a life of routine work, a life of pursuit of numbers. While my job was not routine, it was in pursuit of numbers, pursuit of can I make more money? Can I fund more great companies? Can I raise more money? Can I make sure our VC is ranked higher and higher every year? This competitive nature of driving for bigger numbers and better numbers became a endless pursuit that's mechanical. And bigger numbers really didn't make me happier. And faced with death, I realized bigger numbers really meant nothing. And what was important is that people who have given their heart and their love to me deserve for me to do the same. So there's deep, profound truth in that, that everyone should hear and internalize. I mean, that's really powerful for you to say that. I have to ask sort of a difficult question here. So I've competed in sports my whole life, looking historically, I'd like to challenge some aspect of that a little bit on the point of hard work. That it feels that there are certain aspects that is the greatest, the most beautiful aspects of human nature is the ability to become obsessed, of becoming extremely passionate to the point where yes, flaws are revealed and just giving yourself fully to a task. That is, in another sense, you mentioned love being important, but in another sense, this kind of obsession, this pure exhibition of passion and hard work is truly what it means to be human. What lessons should we take that's deeper? Because you've accomplished incredible things. You say it chasing numbers, but really there's some incredible work there. So how do you think about that when you look back in your 20s, your 30s, what would you do differently? Would you really take back some of the incredible hard work? I would, but it's in percentages, right? We're both computer scientists. So I think when one balances one's life, when one is younger, you might give a smaller percentage to family, but you would still give them high priority. And when you get older, you would give a larger percentage to them and still the high priority. And when you're near retirement, you give most of it to them and the highest priority. So I think the key point is not that we would work 20 hours less for the whole life and just spend it aimlessly with the family, but that's when the family has a need, when your wife is having a baby, when your daughter has a birthday or when they're depressed or when they're celebrating something or when they have a get together or when we have family time that it's important for us to put down our phone and PC and be a hundred percent with them. And that priority on the things that really matter isn't going to be so taxing that it would eliminate or even dramatically reduce our accomplishments. It might have some impact, but it might also have other impact because if you have a happier family, maybe you fight less. If you fight less, you don't spend time taking care of all the aftermath of a fight. So it's unclear that it would take more time. And if it did, I'd be willing to take that reduction. And it's not a dramatic number, but it's a number that I think would give me a greater degree of happiness and knowing that I've done the right thing and still have plenty of hours to get the success that I want to get. So given the many successful companies that you've launched and much success throughout your career, what advice would you give to young people today looking, or it doesn't have to be young, but people today looking to launch and to create the next $1 billion tech startup or even AI based startup? I would suggest that people understand technology waves move quickly. What worked two years ago may not work today. And that is very much case in point for AI. I think two years ago, or maybe three years ago, you certainly could say I have a couple of super smart PhDs and we're not sure what we're gonna do, but here's how we're gonna start and get funding for a very high valuation. Those days are over because AI is going from rocket science towards mainstream, not yet commodity, but more mainstream. So first the creation of any company to a venture capitalists has to be creation of business value and monetary value. And when you have a very scarce commodity, VCs may be willing to accept greater uncertainty. But now the number of people who have the equivalent of PhD three years ago, because that can be learned more quickly, platforms are emerging, the cost to become a AI engineer is much lower and there are many more AI engineers. So the market is different. So I would suggest someone who wants to build an AI company be thinking about the normal business questions. What customer cases are you trying to address? What kind of pain are you trying to address? How does that translate to value? How will you extract value and get paid through what channel and how much business value will get created? That today needs to be thought about much earlier upfront than it did three years ago. The scarcity question of AI talent has changed. The number of AI talent has changed. So now you need not just AI, but also understanding of business customer and the marketplace. So I also think you should have a more reasonable valuation expectation and growth expectation. There's gonna be more competition. But the good news though, is that AI technologies are now more available in open source. TensorFlow, PyTorch and such tools are much easier to use. So you should be able to experiment and get results iteratively faster than before. So take more of a business mindset to this, think less of this as a laboratory taken into a company, because we've gone beyond that stage. The only exception is if you truly have a breakthrough in some technology that really no one has, then the old way still works. But I think that's harder and harder now. So I know you believe as many do that we're far from creating an artificial general intelligence system. But say once we do, and you get to ask her one question, what would that question be? What is it that differentiates you and me? Beautifully put, Kaifu, thank you so much for your time today. Thank you.